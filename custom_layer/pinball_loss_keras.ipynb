{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\18-09-19 Document structure\\business\\Study\\Master\\Cognitive Computing\\P3\\Machine learning in practice\\git\\Private\\M5Forecast\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "E:\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Reshape, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "os.environ['DATA_DIR'] = 'data/'\n",
    "os.environ['SUB_DIR'] = 'submissions_uncertainty/'\n",
    "for dirname, _, filenames in os.walk(os.environ['DATA_DIR']):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Hardcode requested quantiles\n",
    "quantiles = [0.005, 0.025, 0.165, 0.25, 0.5, 0.75, 0.835, 0.975, 0.995]\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(18, 6))\n",
    "    ax.plot(history.history['loss'], label='Train')\n",
    "    ax.plot(history.history['val_loss'], label='Validation')\n",
    "    ax.set_ylim(0)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinball Loss function for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"custom_layer/features.csv\", index_col=0)\n",
    "target_df = pd.read_csv(\"custom_layer/targets.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "      <th>w_4</th>\n",
       "      <th>w_5</th>\n",
       "      <th>w_6</th>\n",
       "      <th>w_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wday  month  snap_CA  w_1  w_2  w_3  w_4  w_5  w_6  w_7\n",
       "date                                                               \n",
       "2011-01-29     1      1        0    1    0    0    0    0    0    0\n",
       "2011-01-30     2      1        0    0    1    0    0    0    0    0\n",
       "2011-01-31     3      1        0    0    0    1    0    0    0    0\n",
       "2011-02-01     4      2        1    0    0    0    1    0    0    0\n",
       "2011-02-02     5      2        1    0    0    0    0    1    0    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.165</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.835</th>\n",
       "      <th>0.975</th>\n",
       "      <th>0.995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>0.429084</td>\n",
       "      <td>0.500587</td>\n",
       "      <td>0.628482</td>\n",
       "      <td>0.662077</td>\n",
       "      <td>0.743227</td>\n",
       "      <td>0.824528</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>1.086067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>0.834881</td>\n",
       "      <td>1.032595</td>\n",
       "      <td>1.265410</td>\n",
       "      <td>1.343565</td>\n",
       "      <td>1.503276</td>\n",
       "      <td>1.660740</td>\n",
       "      <td>1.728179</td>\n",
       "      <td>2.014386</td>\n",
       "      <td>2.143587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>1.246369</td>\n",
       "      <td>1.329488</td>\n",
       "      <td>1.508577</td>\n",
       "      <td>1.680692</td>\n",
       "      <td>1.763780</td>\n",
       "      <td>1.976137</td>\n",
       "      <td>2.167394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>0.424697</td>\n",
       "      <td>0.501162</td>\n",
       "      <td>0.629065</td>\n",
       "      <td>0.668797</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.842714</td>\n",
       "      <td>0.878296</td>\n",
       "      <td>1.015888</td>\n",
       "      <td>1.090475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>0.438830</td>\n",
       "      <td>0.511583</td>\n",
       "      <td>0.630601</td>\n",
       "      <td>0.669403</td>\n",
       "      <td>0.754088</td>\n",
       "      <td>0.842727</td>\n",
       "      <td>0.883785</td>\n",
       "      <td>1.007879</td>\n",
       "      <td>1.084537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0.005     0.025     0.165      0.25       0.5      0.75  \\\n",
       "date                                                                     \n",
       "2011-01-29  0.429084  0.500587  0.628482  0.662077  0.743227  0.824528   \n",
       "2011-01-30  0.834881  1.032595  1.265410  1.343565  1.503276  1.660740   \n",
       "2011-01-31  0.838167  0.991256  1.246369  1.329488  1.508577  1.680692   \n",
       "2011-02-01  0.424697  0.501162  0.629065  0.668797  0.758173  0.842714   \n",
       "2011-02-02  0.438830  0.511583  0.630601  0.669403  0.754088  0.842727   \n",
       "\n",
       "               0.835     0.975     0.995  \n",
       "date                                      \n",
       "2011-01-29  0.861499  0.989619  1.086067  \n",
       "2011-01-30  1.728179  2.014386  2.143587  \n",
       "2011-01-31  1.763780  1.976137  2.167394  \n",
       "2011-02-01  0.878296  1.015888  1.090475  \n",
       "2011-02-02  0.883785  1.007879  1.084537  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp_shape, quantiles):\n",
    "    # clear previous sessions\n",
    "    K.clear_session()\n",
    "\n",
    "    inp = Input(inp_shape, name=\"input\")\n",
    "    x = inp\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dense(2)(x)  # represents mu, sigma\n",
    "    x = Dense(len(quantiles))(x)  # returns 9 points, one for each quantile\n",
    "    out = x\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 27        \n",
      "=================================================================\n",
      "Total params: 2,989\n",
      "Trainable params: 2,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantiles = [0.005, 0.025, 0.165, 0.25, 0.5, 0.75, 0.835, 0.975, 0.995]\n",
    "model = get_model(inp_shape=(train_df.columns.size,), quantiles=quantiles)\n",
    "model.compile(optimizer=\"adam\", loss=\"MAE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.values\n",
    "y = target_df.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 269 samples, validate on 68 samples\n",
      "Epoch 1/300\n",
      "269/269 [==============================] - 2s 9ms/sample - loss: 1.1917 - val_loss: 0.9042\n",
      "Epoch 2/300\n",
      "269/269 [==============================] - 0s 749us/sample - loss: 0.8217 - val_loss: 0.7791\n",
      "Epoch 3/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.7792 - val_loss: 0.6893\n",
      "Epoch 4/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.7038 - val_loss: 0.6442\n",
      "Epoch 5/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.6833 - val_loss: 0.6131\n",
      "Epoch 6/300\n",
      "269/269 [==============================] - 0s 130us/sample - loss: 0.6547 - val_loss: 0.5905\n",
      "Epoch 7/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.6272 - val_loss: 0.5632\n",
      "Epoch 8/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.5996 - val_loss: 0.5338\n",
      "Epoch 9/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.5675 - val_loss: 0.5071\n",
      "Epoch 10/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.5388 - val_loss: 0.4832\n",
      "Epoch 11/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.5117 - val_loss: 0.4658\n",
      "Epoch 12/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.4850 - val_loss: 0.4283\n",
      "Epoch 13/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.4563 - val_loss: 0.4109\n",
      "Epoch 14/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.4329 - val_loss: 0.3875\n",
      "Epoch 15/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.4086 - val_loss: 0.3633\n",
      "Epoch 16/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.3857 - val_loss: 0.3409\n",
      "Epoch 17/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.3617 - val_loss: 0.3194\n",
      "Epoch 18/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.3366 - val_loss: 0.2946\n",
      "Epoch 19/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.3118 - val_loss: 0.2766\n",
      "Epoch 20/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.2952 - val_loss: 0.2471\n",
      "Epoch 21/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.2641 - val_loss: 0.2320\n",
      "Epoch 22/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.2472 - val_loss: 0.2236\n",
      "Epoch 23/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.2265 - val_loss: 0.1986\n",
      "Epoch 24/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.2084 - val_loss: 0.1832\n",
      "Epoch 25/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.2081 - val_loss: 0.1992\n",
      "Epoch 26/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 0.2031 - val_loss: 0.1971\n",
      "Epoch 27/300\n",
      "269/269 [==============================] - 0s 128us/sample - loss: 0.1936 - val_loss: 0.1681\n",
      "Epoch 28/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.1777 - val_loss: 0.1708\n",
      "Epoch 29/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.1779 - val_loss: 0.1599\n",
      "Epoch 30/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.1646 - val_loss: 0.1626\n",
      "Epoch 31/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 0.1668 - val_loss: 0.1678\n",
      "Epoch 32/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.1733 - val_loss: 0.1993\n",
      "Epoch 33/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.1689 - val_loss: 0.1421\n",
      "Epoch 34/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.1390 - val_loss: 0.1165\n",
      "Epoch 35/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.1208 - val_loss: 0.1082\n",
      "Epoch 36/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.1102 - val_loss: 0.0944\n",
      "Epoch 37/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0983 - val_loss: 0.0839\n",
      "Epoch 38/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0910 - val_loss: 0.0949\n",
      "Epoch 39/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0867 - val_loss: 0.0735\n",
      "Epoch 40/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0785 - val_loss: 0.0575\n",
      "Epoch 41/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 42/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0588 - val_loss: 0.0449\n",
      "Epoch 43/300\n",
      "269/269 [==============================] - 0s 116us/sample - loss: 0.0518 - val_loss: 0.0449\n",
      "Epoch 44/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0490 - val_loss: 0.0339\n",
      "Epoch 45/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0394 - val_loss: 0.0295\n",
      "Epoch 46/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0306 - val_loss: 0.0288\n",
      "Epoch 47/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0392 - val_loss: 0.0424\n",
      "Epoch 48/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0566 - val_loss: 0.0445\n",
      "Epoch 49/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0374 - val_loss: 0.0373\n",
      "Epoch 50/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0316 - val_loss: 0.0342\n",
      "Epoch 51/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0301 - val_loss: 0.0284\n",
      "Epoch 52/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0330 - val_loss: 0.0351\n",
      "Epoch 53/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0325 - val_loss: 0.0385\n",
      "Epoch 54/300\n",
      "269/269 [==============================] - 0s 128us/sample - loss: 0.0324 - val_loss: 0.0268\n",
      "Epoch 55/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0323 - val_loss: 0.0271\n",
      "Epoch 56/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0255 - val_loss: 0.0220\n",
      "Epoch 57/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0292 - val_loss: 0.0198\n",
      "Epoch 58/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0220 - val_loss: 0.0204\n",
      "Epoch 59/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0269 - val_loss: 0.0213\n",
      "Epoch 60/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0296 - val_loss: 0.0199\n",
      "Epoch 61/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0284 - val_loss: 0.0438\n",
      "Epoch 62/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0421 - val_loss: 0.0672\n",
      "Epoch 63/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0396 - val_loss: 0.0319\n",
      "Epoch 64/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.0284 - val_loss: 0.0268\n",
      "Epoch 65/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0367 - val_loss: 0.0443\n",
      "Epoch 66/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0372 - val_loss: 0.0371\n",
      "Epoch 67/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0356 - val_loss: 0.0412\n",
      "Epoch 68/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0295 - val_loss: 0.0216\n",
      "Epoch 69/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0341 - val_loss: 0.0344\n",
      "Epoch 70/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 71/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0287 - val_loss: 0.0386\n",
      "Epoch 72/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0381 - val_loss: 0.0204\n",
      "Epoch 73/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0308 - val_loss: 0.0259\n",
      "Epoch 74/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0306 - val_loss: 0.0568\n",
      "Epoch 75/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0432 - val_loss: 0.0328\n",
      "Epoch 76/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0244 - val_loss: 0.0214\n",
      "Epoch 77/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0245 - val_loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0263 - val_loss: 0.0323\n",
      "Epoch 79/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0273 - val_loss: 0.0194\n",
      "Epoch 80/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0203 - val_loss: 0.0301\n",
      "Epoch 81/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0232 - val_loss: 0.0166\n",
      "Epoch 82/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0190 - val_loss: 0.0257\n",
      "Epoch 83/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0274 - val_loss: 0.0208\n",
      "Epoch 84/300\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.0262 - val_loss: 0.0208\n",
      "Epoch 85/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0415 - val_loss: 0.0457\n",
      "Epoch 86/300\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.043 - 0s 102us/sample - loss: 0.0291 - val_loss: 0.0365\n",
      "Epoch 87/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.0309 - val_loss: 0.0405\n",
      "Epoch 88/300\n",
      "269/269 [==============================] - 0s 128us/sample - loss: 0.0407 - val_loss: 0.0185\n",
      "Epoch 89/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 0.0200 - val_loss: 0.0163\n",
      "Epoch 90/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 91/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0243 - val_loss: 0.0372\n",
      "Epoch 92/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0384 - val_loss: 0.0287\n",
      "Epoch 93/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0400 - val_loss: 0.0239\n",
      "Epoch 94/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0205 - val_loss: 0.0319\n",
      "Epoch 95/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0280 - val_loss: 0.0363\n",
      "Epoch 96/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0398 - val_loss: 0.0196\n",
      "Epoch 97/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0233 - val_loss: 0.0157\n",
      "Epoch 98/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 99/300\n",
      "269/269 [==============================] - 0s 132us/sample - loss: 0.0235 - val_loss: 0.0197\n",
      "Epoch 100/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 101/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0178 - val_loss: 0.0268\n",
      "Epoch 102/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0219 - val_loss: 0.0198\n",
      "Epoch 103/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0224 - val_loss: 0.0354\n",
      "Epoch 104/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0281 - val_loss: 0.0221\n",
      "Epoch 105/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0362 - val_loss: 0.0328\n",
      "Epoch 106/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0255 - val_loss: 0.0424\n",
      "Epoch 107/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0317 - val_loss: 0.0245\n",
      "Epoch 108/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0183 - val_loss: 0.0141\n",
      "Epoch 109/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 110/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0191 - val_loss: 0.0156\n",
      "Epoch 111/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0187 - val_loss: 0.0300\n",
      "Epoch 112/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 113/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 0.0172 - val_loss: 0.0243\n",
      "Epoch 114/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0235 - val_loss: 0.0201\n",
      "Epoch 115/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0219 - val_loss: 0.0197\n",
      "Epoch 116/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0208 - val_loss: 0.0168\n",
      "Epoch 117/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 118/300\n",
      "269/269 [==============================] - 0s 149us/sample - loss: 0.0141 - val_loss: 0.0189\n",
      "Epoch 119/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0177 - val_loss: 0.0156\n",
      "Epoch 120/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 121/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 122/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 123/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0150 - val_loss: 0.0142\n",
      "Epoch 124/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 125/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0172 - val_loss: 0.0208\n",
      "Epoch 126/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 127/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0215 - val_loss: 0.0259\n",
      "Epoch 128/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0235 - val_loss: 0.0192\n",
      "Epoch 129/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0208 - val_loss: 0.0222\n",
      "Epoch 130/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0231 - val_loss: 0.0178\n",
      "Epoch 131/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0206 - val_loss: 0.0257\n",
      "Epoch 132/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0237 - val_loss: 0.0194\n",
      "Epoch 133/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0168 - val_loss: 0.0157\n",
      "Epoch 134/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0185 - val_loss: 0.0236\n",
      "Epoch 135/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0153 - val_loss: 0.0131\n",
      "Epoch 136/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 137/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 138/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 139/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0157 - val_loss: 0.0255\n",
      "Epoch 140/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0218 - val_loss: 0.0149\n",
      "Epoch 141/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0152 - val_loss: 0.0178\n",
      "Epoch 142/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0178 - val_loss: 0.0253\n",
      "Epoch 143/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0213 - val_loss: 0.0114\n",
      "Epoch 144/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0215 - val_loss: 0.0180\n",
      "Epoch 145/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0247 - val_loss: 0.0218\n",
      "Epoch 146/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0222 - val_loss: 0.0131\n",
      "Epoch 147/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 148/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 149/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0219 - val_loss: 0.0233\n",
      "Epoch 150/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 151/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 152/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0135 - val_loss: 0.0172\n",
      "Epoch 153/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 155/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0145 - val_loss: 0.0216\n",
      "Epoch 156/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0167 - val_loss: 0.0154\n",
      "Epoch 157/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 158/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 159/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 160/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0124 - val_loss: 0.0274\n",
      "Epoch 161/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0253 - val_loss: 0.0303\n",
      "Epoch 162/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0203 - val_loss: 0.0225\n",
      "Epoch 163/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0191 - val_loss: 0.0255\n",
      "Epoch 164/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0246 - val_loss: 0.0213\n",
      "Epoch 165/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0159 - val_loss: 0.0177\n",
      "Epoch 166/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 167/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 168/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 169/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 170/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0209 - val_loss: 0.0135\n",
      "Epoch 171/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0193 - val_loss: 0.0148\n",
      "Epoch 172/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0245 - val_loss: 0.0197\n",
      "Epoch 173/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 174/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0187 - val_loss: 0.0137\n",
      "Epoch 175/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0168 - val_loss: 0.0157\n",
      "Epoch 176/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 177/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0146 - val_loss: 0.0174\n",
      "Epoch 178/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0192 - val_loss: 0.0193\n",
      "Epoch 179/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0214 - val_loss: 0.0304\n",
      "Epoch 180/300\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 0.0236 - val_loss: 0.0254\n",
      "Epoch 181/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.0276 - val_loss: 0.0112\n",
      "Epoch 182/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0216 - val_loss: 0.0166\n",
      "Epoch 183/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 184/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0182 - val_loss: 0.0161\n",
      "Epoch 185/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0196 - val_loss: 0.0188\n",
      "Epoch 186/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0209 - val_loss: 0.0171\n",
      "Epoch 187/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0223 - val_loss: 0.0204\n",
      "Epoch 188/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0174 - val_loss: 0.0196\n",
      "Epoch 189/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0185 - val_loss: 0.0151\n",
      "Epoch 190/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0230 - val_loss: 0.0154\n",
      "Epoch 191/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0175 - val_loss: 0.0109\n",
      "Epoch 192/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0181 - val_loss: 0.0125\n",
      "Epoch 193/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0183 - val_loss: 0.0122\n",
      "Epoch 194/300\n",
      "269/269 [==============================] - 0s 132us/sample - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 195/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 196/300\n",
      "269/269 [==============================] - 0s 130us/sample - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 197/300\n",
      "269/269 [==============================] - 0s 132us/sample - loss: 0.0150 - val_loss: 0.0241\n",
      "Epoch 198/300\n",
      "269/269 [==============================] - 0s 130us/sample - loss: 0.0216 - val_loss: 0.0119\n",
      "Epoch 199/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 200/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 201/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0158 - val_loss: 0.0221\n",
      "Epoch 202/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0204 - val_loss: 0.0254\n",
      "Epoch 203/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0234 - val_loss: 0.0189\n",
      "Epoch 204/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 205/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 206/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0137 - val_loss: 0.0186\n",
      "Epoch 207/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 208/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 209/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0161 - val_loss: 0.0218\n",
      "Epoch 210/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 211/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0164 - val_loss: 0.0141\n",
      "Epoch 212/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0202 - val_loss: 0.0239\n",
      "Epoch 213/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 214/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 215/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 216/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 217/300\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 218/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 219/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0181 - val_loss: 0.0158\n",
      "Epoch 220/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0167 - val_loss: 0.0252\n",
      "Epoch 221/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0180 - val_loss: 0.0151\n",
      "Epoch 222/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0176 - val_loss: 0.0135\n",
      "Epoch 223/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 224/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 225/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0188 - val_loss: 0.0260\n",
      "Epoch 226/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0225 - val_loss: 0.0208\n",
      "Epoch 227/300\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 228/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 229/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 231/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 232/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 233/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 234/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0126 - val_loss: 0.0199\n",
      "Epoch 235/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0220 - val_loss: 0.0207\n",
      "Epoch 236/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 237/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0172 - val_loss: 0.0183\n",
      "Epoch 238/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 239/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0228 - val_loss: 0.0326\n",
      "Epoch 240/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0268 - val_loss: 0.0382\n",
      "Epoch 241/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0378 - val_loss: 0.0225\n",
      "Epoch 242/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0222 - val_loss: 0.0150\n",
      "Epoch 243/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0215 - val_loss: 0.0369\n",
      "Epoch 244/300\n",
      "269/269 [==============================] - 0s 125us/sample - loss: 0.0311 - val_loss: 0.0155\n",
      "Epoch 245/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0213 - val_loss: 0.0270\n",
      "Epoch 246/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 247/300\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 248/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 249/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 0.0184 - val_loss: 0.0194\n",
      "Epoch 250/300\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 251/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 252/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0163 - val_loss: 0.0220\n",
      "Epoch 253/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0197 - val_loss: 0.0174\n",
      "Epoch 254/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 255/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 256/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 257/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0130 - val_loss: 0.0162\n",
      "Epoch 258/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 259/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0141 - val_loss: 0.0234\n",
      "Epoch 260/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 261/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0202 - val_loss: 0.0168\n",
      "Epoch 262/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 263/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0169 - val_loss: 0.0153\n",
      "Epoch 264/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0155 - val_loss: 0.0146\n",
      "Epoch 265/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0149 - val_loss: 0.0132\n",
      "Epoch 266/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0165 - val_loss: 0.0136\n",
      "Epoch 267/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 268/300\n",
      "269/269 [==============================] - 0s 126us/sample - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 269/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 270/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 271/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 272/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 273/300\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.014 - 0s 106us/sample - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 274/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 275/300\n",
      "269/269 [==============================] - 0s 117us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 276/300\n",
      "269/269 [==============================] - 0s 123us/sample - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 277/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 278/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 279/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 280/300\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 281/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0168 - val_loss: 0.0127\n",
      "Epoch 282/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 283/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0157 - val_loss: 0.0228\n",
      "Epoch 284/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0224 - val_loss: 0.0124\n",
      "Epoch 285/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 286/300\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.0162 - val_loss: 0.0143\n",
      "Epoch 287/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0170 - val_loss: 0.0139\n",
      "Epoch 288/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 289/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0163 - val_loss: 0.0136\n",
      "Epoch 290/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0158 - val_loss: 0.0215\n",
      "Epoch 291/300\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 292/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0139 - val_loss: 0.0239\n",
      "Epoch 293/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0194 - val_loss: 0.0171\n",
      "Epoch 294/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0219 - val_loss: 0.0161\n",
      "Epoch 295/300\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.0147 - val_loss: 0.0179\n",
      "Epoch 296/300\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 297/300\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 298/300\n",
      "269/269 [==============================] - 0s 115us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 299/300\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.0152 - val_loss: 0.0177\n",
      "Epoch 300/300\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.0148 - val_loss: 0.0168\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300,\n",
    "                    \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4114417 , 0.48735207, 0.61332107, 0.6514602 , 0.7352706 ,\n",
       "        0.82840574, 0.8609055 , 0.9938454 , 1.0638919 ],\n",
       "       [0.8470335 , 1.0021744 , 1.2437438 , 1.3201789 , 1.4834784 ,\n",
       "        1.6747763 , 1.7289132 , 2.0042746 , 2.1307094 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite to multi-output for each quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes the following order of statistical distribution parameters for\n",
    "# the neurons in the layer before this custom layer:\n",
    "# x[0] = mu\n",
    "# x[1] = sigma\n",
    "# x[2] = skewness\n",
    "# x[3] = kurtosis\n",
    "def DistributionLayer(quantile_index,x):\n",
    "    mu = x[0]\n",
    "    sigma = x[1] \n",
    "    skewness = None\n",
    "    kurtosis = None\n",
    "    \n",
    "    # absorb extra statistical distribution parameters if present\n",
    "    if (len(x.get_shape().as_list())>2):\n",
    "        skewness= x[2]\n",
    "    if (len(x.get_shape().as_list())>3):\n",
    "        kurtosis = x[3]\n",
    "        \n",
    "    if (skewness==None):\n",
    "        if (kurtosis==None):\n",
    "            # Source of Z-scores: https://www.wolframalpha.com/input/?i=percentiles+of+a+normal+distribution\n",
    "             return {\n",
    "                0.005: mu-2.57583*sigma, # https://www.wolframalpha.com/input/?i=0.5+percentiles+of+a+normal+distribution\n",
    "                0.025: mu-1.95996*sigma, # https://www.wolframalpha.com/input/?i=2.5+percentiles+of+a+normal+distribution\n",
    "                0.165: mu-0.974114*sigma, # https://www.wolframalpha.com/input/?i=16.5+percentiles+of+a+normal+distribution\n",
    "                0.25: mu-0.674*sigma, # https://www.wolframalpha.com/input/?i=25+percentiles+of+a+normal+distribution\n",
    "                0.5: mu, # https://www.wolframalpha.com/input/?i=50+percentiles+of+a+normal+distribution\n",
    "                0.75: mu+0.674*sigma, # https://www.wolframalpha.com/input/?i=75+percentiles+of+a+normal+distribution\n",
    "                0.835: mu+0.9741114*sigma, #https://www.wolframalpha.com/input/?i=83.5+percentiles+of+a+normal+distribution\n",
    "                0.975: mu+1.95996*sigma, #https://www.wolframalpha.com/input/?i=97.5+percentiles+of+a+normal+distribution\n",
    "                0.995: mu+2.57583*sigma, #https://www.wolframalpha.com/input/?i=99.5+percentiles+of+a+normal+distribution\n",
    "            }[quantile]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp_shape, quantiles):\n",
    "    # clear previous sessions\n",
    "    K.clear_session()\n",
    "\n",
    "    inp = Input(inp_shape, name=\"input\")\n",
    "    x = inp\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dense(2)(x)  # represents mu, sigma\n",
    "    \n",
    "    #out_q0 = Dense(1, name=\"q0\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q0 = Dense(1, name=\"q0\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q1 = Dense(1, name=\"q1\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q2 = Dense(1, name=\"q2\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q3 = Dense(1, name=\"q3\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q4 = Dense(1, name=\"q4\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q5 = Dense(1, name=\"q5\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q6 = Dense(1, name=\"q6\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q7 = Dense(1, name=\"q7\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q8 = Dense(1, name=\"q8\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    \n",
    "#     out_q0 = DistributionLayer(quantiles[0],x)\n",
    "#     out_q1 = DistributionLayer(quantiles[1],x)\n",
    "#     out_q2 = DistributionLayer(quantiles[2],x)\n",
    "#     out_q3 = DistributionLayer(quantiles[3],x)\n",
    "#     out_q4 = DistributionLayer(quantiles[4],x)\n",
    "#     out_q5 = DistributionLayer(quantiles[5],x)\n",
    "#     out_q6 = DistributionLayer(quantiles[6],x)\n",
    "#     out_q7 = DistributionLayer(quantiles[7],x)\n",
    "#     out_q8 = DistributionLayer(quantiles[8],x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=[out_q0, out_q1, out_q2, out_q3, out_q4, out_q5, out_q6, out_q7, out_q8])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           176         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           544         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           2112        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            130         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q0 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q1 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q2 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q3 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q4 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q5 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q6 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q7 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q8 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,989\n",
      "Trainable params: 2,989\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(inp_shape=(train_df.columns.size,), quantiles=quantiles)\n",
    "model.compile(optimizer=\"adam\", loss=\"MAE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q0': array([0.77976871, 0.4255634 , 0.41740025, 0.42903284, 0.82754025,\n",
       "        0.4064456 , 0.40616237, 0.45264247, 0.41096554, 0.41689168,\n",
       "        0.38520678, 0.41300217, 0.40747019, 0.86864485, 0.43559714,\n",
       "        0.42313449, 0.41549744, 0.43160425, 0.4241328 , 0.39397524,\n",
       "        0.45516087, 0.92357664, 0.41138681, 0.4042906 , 0.84447597,\n",
       "        0.42392267, 0.7718635 , 0.44973176, 0.43213789, 0.84063285,\n",
       "        0.82372458, 0.78483486, 0.41210167, 0.43546165, 0.92956534,\n",
       "        0.44674431, 0.40117869, 0.44582427, 0.83591121, 0.87259832,\n",
       "        0.90353443, 0.42208748, 0.38899553, 0.45153601, 0.39837333,\n",
       "        0.41525051, 0.42364229, 0.86586664, 0.40607733, 0.41816087,\n",
       "        0.38255025, 0.89064516, 0.42218558, 0.42119283, 0.40201799,\n",
       "        0.90192745, 0.40566299, 0.42338319, 0.41504695, 0.43416054,\n",
       "        0.40994688, 0.41956467, 0.86222354, 0.40953107, 0.87499344,\n",
       "        0.43268808, 0.40363463, 0.43650302, 0.41236164, 0.91755915,\n",
       "        0.84431159, 0.79940419, 0.41597326, 0.41392266, 0.42782747,\n",
       "        0.39393664, 0.89695079, 0.86224126, 0.43617093, 0.85140217,\n",
       "        0.42278976, 0.39106672, 0.41890434, 0.39874521, 0.41975423,\n",
       "        0.89906273, 0.45000559, 0.40947942, 0.44329988, 0.42845406,\n",
       "        0.432556  , 0.39379119, 0.40501631, 0.41589453, 0.78193413,\n",
       "        0.42418178, 0.40707033, 0.41339733, 0.43810726, 0.41006597,\n",
       "        0.43851828, 0.85018333, 0.42148472, 0.43332995, 0.83816669,\n",
       "        0.4207673 , 0.90264225, 0.44033269, 0.80576037, 0.84932577,\n",
       "        0.43348768, 0.83992371, 0.39006657, 0.88018906, 0.43101839,\n",
       "        0.44261483, 0.83254959, 0.40761605, 0.42398747, 0.39113956,\n",
       "        0.79373536, 0.4129318 , 0.90506873, 0.84718589, 0.85837079,\n",
       "        0.83941267, 0.88721045, 0.4195636 , 0.42338891, 0.44482469,\n",
       "        0.44546948, 0.43602464, 0.44134388, 0.89297545, 0.83983143,\n",
       "        0.4293607 , 0.43347221, 0.41334255, 0.84876859, 0.43941201,\n",
       "        0.44940611, 0.41955864, 0.85634571, 0.42355538, 0.43945227,\n",
       "        0.41727819, 0.42498001, 0.42266657, 0.42266616, 0.41148532,\n",
       "        0.88900356, 0.83327412, 0.85083557, 0.36450726, 0.42908377,\n",
       "        0.8729209 , 0.84048098, 0.40453602, 0.81843599, 0.85376998,\n",
       "        0.41641431, 0.41676266, 0.87021769, 0.41394461, 0.42832182,\n",
       "        0.41310186, 0.41093871, 0.85118556, 0.45711055, 0.41131593,\n",
       "        0.42535109, 0.42494805, 0.42291034, 0.44941366, 0.39662125,\n",
       "        0.41934535, 0.43803166, 0.42816385, 0.44481512, 0.40592902,\n",
       "        0.44510568, 0.87551584, 0.43882955, 0.40980793, 0.39726162,\n",
       "        0.83865186, 0.82391532, 0.43606232, 0.903867  , 0.42598936,\n",
       "        0.39335341, 0.87932989, 0.88167455, 0.92069727, 0.88504133,\n",
       "        0.41160328, 0.82383574, 0.41669152, 0.8902058 , 0.86226759,\n",
       "        0.42570417, 0.42333129, 0.41146715, 0.40853873, 0.87497931,\n",
       "        0.41888769, 0.4174933 , 0.40137973, 0.41868108, 0.41480139,\n",
       "        0.41762532, 0.43417065, 0.83195903, 0.42012424, 0.88049122,\n",
       "        0.43808452, 0.43475285, 0.37609209, 0.83488053, 0.39741986,\n",
       "        0.45581282, 0.87479406, 0.41141341, 0.41079624, 0.43100557,\n",
       "        0.37878448, 0.40052723, 0.41471736, 0.41684838, 0.43305646,\n",
       "        0.37894753, 0.4310462 , 0.88510673, 0.91283571, 0.90124721,\n",
       "        0.39263573, 0.41654587, 0.8974081 , 0.42264731, 0.42741047,\n",
       "        0.42512897, 0.42810603, 0.81919692, 0.84746617, 0.42715475,\n",
       "        0.39471582, 0.41054117, 0.41730352, 0.41887935, 0.41252063,\n",
       "        0.39940721, 0.90601885, 0.44086474, 0.42635516, 0.41635982,\n",
       "        0.89206673, 0.4321597 , 0.38922181, 0.81370253, 0.41180009,\n",
       "        0.42916062, 0.8504008 , 0.43751243, 0.45314441, 0.43264675,\n",
       "        0.81895532, 0.83909076, 0.3941779 , 0.41131961]),\n",
       " 'q1': array([0.98694101, 0.49009461, 0.49216885, 0.49557415, 1.01162224,\n",
       "        0.50957932, 0.49744197, 0.51033935, 0.48771643, 0.49897617,\n",
       "        0.48736895, 0.48874831, 0.49512264, 1.01446794, 0.49360654,\n",
       "        0.5011236 , 0.49018645, 0.48991859, 0.50036596, 0.49762297,\n",
       "        0.49253734, 1.05807856, 0.50273478, 0.48129021, 0.99869867,\n",
       "        0.49927749, 1.00492484, 0.50894352, 0.50124206, 1.00702438,\n",
       "        1.0056577 , 0.98704648, 0.47556742, 0.50901135, 1.03540212,\n",
       "        0.49528869, 0.49726181, 0.50423386, 1.01871513, 1.00822702,\n",
       "        1.00746122, 0.48079287, 0.48451008, 0.51382279, 0.50449866,\n",
       "        0.49952134, 0.4781263 , 1.02966442, 0.47676185, 0.50073502,\n",
       "        0.48975022, 1.02514877, 0.47741895, 0.50557659, 0.47679472,\n",
       "        1.02220408, 0.48937788, 0.51426022, 0.49339485, 0.50352995,\n",
       "        0.47363033, 0.48989425, 1.00843135, 0.50756214, 1.02545345,\n",
       "        0.51216801, 0.48720753, 0.50620415, 0.49156689, 1.02284072,\n",
       "        1.00312264, 0.98599412, 0.49582001, 0.48670795, 0.49725651,\n",
       "        0.51115274, 1.0135584 , 1.00080876, 0.51531796, 1.03367328,\n",
       "        0.49577904, 0.47843734, 0.48073988, 0.48792381, 0.47876208,\n",
       "        1.05745382, 0.52552364, 0.49381206, 0.50296196, 0.5092961 ,\n",
       "        0.49874424, 0.49395363, 0.50255466, 0.50275193, 0.96459871,\n",
       "        0.48562709, 0.47127788, 0.49053995, 0.49197004, 0.48347861,\n",
       "        0.51034104, 0.9515071 , 0.49285103, 0.50164632, 0.9912556 ,\n",
       "        0.51201887, 1.02047253, 0.50266385, 1.00514551, 1.02315231,\n",
       "        0.50567869, 0.98625531, 0.48620697, 0.98859376, 0.49709315,\n",
       "        0.49514335, 0.9951382 , 0.49400333, 0.50803919, 0.45791431,\n",
       "        0.99710541, 0.50437562, 1.00353863, 1.01851988, 1.01320094,\n",
       "        1.03688206, 1.01064562, 0.4876326 , 0.49487272, 0.49730388,\n",
       "        0.49577792, 0.50022169, 0.50017166, 1.02817656, 1.01071715,\n",
       "        0.4923242 , 0.50834872, 0.50602337, 1.01779662, 0.51028976,\n",
       "        0.50552597, 0.4913838 , 0.99181463, 0.48212265, 0.5041746 ,\n",
       "        0.50426376, 0.49784764, 0.50485703, 0.50799094, 0.48854629,\n",
       "        1.00389055, 1.02390523, 0.99702205, 0.49905009, 0.50058671,\n",
       "        0.988371  , 0.98308459, 0.49724383, 0.9584036 , 1.04166762,\n",
       "        0.49458875, 0.4937687 , 1.01964101, 0.49731282, 0.50025734,\n",
       "        0.49637799, 0.48975453, 1.01972863, 0.49900831, 0.51659863,\n",
       "        0.49381212, 0.51276073, 0.49783404, 0.49254733, 0.48678729,\n",
       "        0.48216814, 0.49518275, 0.50301859, 0.50641068, 0.48711808,\n",
       "        0.50619097, 1.00885207, 0.51158332, 0.493986  , 0.49348383,\n",
       "        0.99602502, 0.99890815, 0.5113605 , 1.02705827, 0.49046472,\n",
       "        0.48983167, 1.04348895, 1.0209626 , 1.04413318, 1.01637382,\n",
       "        0.49396519, 1.00992583, 0.48080134, 1.03971773, 1.0195359 ,\n",
       "        0.50181136, 0.50765927, 0.48838422, 0.48219274, 1.03215824,\n",
       "        0.50128541, 0.50672073, 0.48209268, 0.49500284, 0.50020777,\n",
       "        0.50038114, 0.50654676, 1.00557768, 0.49480572, 0.98793313,\n",
       "        0.50006588, 0.49145004, 0.4907908 , 1.03259482, 0.50191482,\n",
       "        0.50186779, 1.00173852, 0.49176462, 0.49286449, 0.49103959,\n",
       "        0.454028  , 0.48626906, 0.50566403, 0.49470059, 0.49883381,\n",
       "        0.48859335, 0.49235676, 0.99662842, 1.00860885, 1.01120466,\n",
       "        0.50197417, 0.47646561, 1.00163566, 0.49193431, 0.4881685 ,\n",
       "        0.48211356, 0.51494388, 1.00079741, 1.03201598, 0.50704743,\n",
       "        0.48413271, 0.4891214 , 0.50328069, 0.50908513, 0.49309843,\n",
       "        0.50374785, 1.01776805, 0.50391482, 0.4974368 , 0.48559929,\n",
       "        1.01745078, 0.49532064, 0.49530214, 1.00560392, 0.48604815,\n",
       "        0.5079594 , 1.03177231, 0.4954174 , 0.50915667, 0.49112741,\n",
       "        0.98531047, 1.030373  , 0.49810812, 0.49329876]),\n",
       " 'q2': array([1.23415944, 0.62403202, 0.62149103, 0.62300947, 1.26217082,\n",
       "        0.62762769, 0.62297613, 0.62618969, 0.61528915, 0.60759722,\n",
       "        0.62185884, 0.61635795, 0.61774114, 1.24545958, 0.62086249,\n",
       "        0.63097009, 0.62455689, 0.62501272, 0.62425812, 0.61958445,\n",
       "        0.62107551, 1.25297968, 0.63520761, 0.61876652, 1.24592338,\n",
       "        0.62841592, 1.26300544, 0.6191478 , 0.62087474, 1.24998631,\n",
       "        1.24402391, 1.25977008, 0.63122105, 0.62802461, 1.27008318,\n",
       "        0.63156619, 0.62309866, 0.61808352, 1.26380532, 1.25014126,\n",
       "        1.25052403, 0.61524934, 0.62261617, 0.62218547, 0.62446789,\n",
       "        0.62792731, 0.61535662, 1.26161977, 0.63268795, 0.62502217,\n",
       "        0.61358015, 1.25408356, 0.61417772, 0.6187807 , 0.62082149,\n",
       "        1.25556961, 0.62059392, 0.63016314, 0.61566804, 0.62620342,\n",
       "        0.62485769, 0.61284626, 1.25019815, 0.62844213, 1.24936877,\n",
       "        0.62590049, 0.61753697, 0.62757603, 0.62059209, 1.25260924,\n",
       "        1.25127986, 1.25972421, 0.61954638, 0.6219585 , 0.6251437 ,\n",
       "        0.61962757, 1.25075908, 1.26367542, 0.63655936, 1.26564917,\n",
       "        0.61661823, 0.61760989, 0.61921294, 0.62597898, 0.63110533,\n",
       "        1.28091955, 0.62643384, 0.61875223, 0.62327298, 0.63437493,\n",
       "        0.61764525, 0.62440675, 0.62818242, 0.61168596, 1.25598814,\n",
       "        0.62785221, 0.63263717, 0.6362003 , 0.62902647, 0.62689884,\n",
       "        0.63049301, 1.23807505, 0.62119081, 0.62525419, 1.24636912,\n",
       "        0.61818913, 1.25492035, 0.62320071, 1.24944229, 1.25072259,\n",
       "        0.63032966, 1.23606224, 0.6225696 , 1.24354047, 0.62096936,\n",
       "        0.61900264, 1.25995944, 0.62769148, 0.62463672, 0.61376801,\n",
       "        1.24298732, 0.62407361, 1.24711397, 1.26567477, 1.25588174,\n",
       "        1.25179153, 1.2545534 , 0.62665707, 0.63109202, 0.6241268 ,\n",
       "        0.61305931, 0.63568395, 0.61551026, 1.25921581, 1.24369283,\n",
       "        0.63489319, 0.63133156, 0.62466468, 1.2522283 , 0.62784165,\n",
       "        0.62538753, 0.6224903 , 1.24460801, 0.61645724, 0.6207517 ,\n",
       "        0.61960804, 0.61947945, 0.62512051, 0.62509865, 0.62387299,\n",
       "        1.24593917, 1.25183447, 1.25118721, 0.62087067, 0.62848196,\n",
       "        1.25838881, 1.24631658, 0.62873451, 1.23836776, 1.28015594,\n",
       "        0.62710721, 0.62954164, 1.2469327 , 0.62730045, 0.62263382,\n",
       "        0.62645677, 0.62458252, 1.25597435, 0.62666851, 0.62180764,\n",
       "        0.6237753 , 0.63216437, 0.63072   , 0.62137434, 0.61358608,\n",
       "        0.62738811, 0.62285963, 0.6182879 , 0.62145093, 0.61782083,\n",
       "        0.63708837, 1.24535217, 0.63060131, 0.61901192, 0.63018767,\n",
       "        1.25103069, 1.24506989, 0.63763215, 1.24530069, 0.62061272,\n",
       "        0.62626489, 1.26568293, 1.25222736, 1.27266938, 1.27394426,\n",
       "        0.62286346, 1.24133757, 0.62443488, 1.26655064, 1.24946391,\n",
       "        0.62046132, 0.63028102, 0.60989389, 0.62220374, 1.27361788,\n",
       "        0.62416329, 0.62252152, 0.61191324, 0.62704227, 0.62203599,\n",
       "        0.61010957, 0.62473649, 1.26372783, 0.62091589, 1.25416445,\n",
       "        0.62243683, 0.62823039, 0.62325411, 1.26540977, 0.63103205,\n",
       "        0.61854779, 1.25410241, 0.61453691, 0.61191762, 0.61421155,\n",
       "        0.62780954, 0.62538423, 0.63184065, 0.62216598, 0.63340651,\n",
       "        0.62276536, 0.63135018, 1.25964817, 1.25504678, 1.25336523,\n",
       "        0.6208399 , 0.62564658, 1.27201883, 0.62142732, 0.61582923,\n",
       "        0.62132782, 0.62427135, 1.24520786, 1.27288314, 0.63639293,\n",
       "        0.6201414 , 0.61925565, 0.63652999, 0.62532106, 0.61005924,\n",
       "        0.62440197, 1.26007469, 0.62045531, 0.62473529, 0.62820411,\n",
       "        1.25797305, 0.61559212, 0.62824833, 1.25897925, 0.6230901 ,\n",
       "        0.62864541, 1.25387655, 0.62733589, 0.62673391, 0.61007945,\n",
       "        1.23435803, 1.2576428 , 0.62595282, 0.63103304]),\n",
       " 'q3': array([1.31723581, 0.66033059, 0.6592753 , 0.66133424, 1.3320228 ,\n",
       "        0.66096545, 0.66778587, 0.66731533, 0.65420575, 0.65171159,\n",
       "        0.66240246, 0.65164507, 0.65922365, 1.32561766, 0.6677954 ,\n",
       "        0.66781545, 0.66213692, 0.66217674, 0.66500155, 0.66005076,\n",
       "        0.662469  , 1.32945328, 0.67289112, 0.65365688, 1.3248756 ,\n",
       "        0.66823926, 1.33438623, 0.66103369, 0.66224226, 1.32742574,\n",
       "        1.31016559, 1.33532641, 0.66370602, 0.66152799, 1.33202984,\n",
       "        0.66714988, 0.66181973, 0.65787594, 1.33929344, 1.32268346,\n",
       "        1.32921383, 0.66191331, 0.66761227, 0.66658659, 0.66963971,\n",
       "        0.66364068, 0.65155188, 1.33274491, 0.66466645, 0.66832897,\n",
       "        0.65979445, 1.33403622, 0.64902849, 0.65692324, 0.66415054,\n",
       "        1.32694221, 0.65699836, 0.66900737, 0.65501408, 0.6667991 ,\n",
       "        0.66460612, 0.65276886, 1.33644125, 0.66673362, 1.31697297,\n",
       "        0.6638489 , 0.65916382, 0.66533093, 0.66289015, 1.32582536,\n",
       "        1.3309913 , 1.32398213, 0.65848908, 0.65736769, 0.66822425,\n",
       "        0.65469048, 1.33712331, 1.34322155, 0.66833558, 1.34623098,\n",
       "        0.65422535, 0.65770452, 0.65885716, 0.66361448, 0.6726797 ,\n",
       "        1.34852505, 0.67024972, 0.66091273, 0.66475046, 0.66330258,\n",
       "        0.65851398, 0.66524878, 0.66746875, 0.65518494, 1.3307843 ,\n",
       "        0.66485312, 0.66801475, 0.67620529, 0.66060127, 0.66544112,\n",
       "        0.66273628, 1.32585813, 0.6576778 , 0.66715572, 1.32948766,\n",
       "        0.65810468, 1.3366208 , 0.66305498, 1.32771181, 1.32233661,\n",
       "        0.67460366, 1.31917846, 0.6563776 , 1.33086716, 0.66804441,\n",
       "        0.65868687, 1.33316089, 0.66264201, 0.66013637, 0.6545152 ,\n",
       "        1.30599382, 0.66380807, 1.33689595, 1.33920802, 1.33262933,\n",
       "        1.3330205 , 1.34104905, 0.66017325, 0.66974601, 0.65960514,\n",
       "        0.65511992, 0.66711553, 0.66115331, 1.34198528, 1.31341776,\n",
       "        0.66610277, 0.67507959, 0.66490458, 1.31449508, 0.66491295,\n",
       "        0.65974554, 0.66519467, 1.31906406, 0.65585645, 0.6584035 ,\n",
       "        0.66022654, 0.65510033, 0.66430143, 0.6632202 , 0.66658849,\n",
       "        1.31791209, 1.33595034, 1.34569084, 0.65889827, 0.66207737,\n",
       "        1.3341927 , 1.32643953, 0.66569416, 1.31515611, 1.34801759,\n",
       "        0.66101623, 0.66520537, 1.31971292, 0.66417882, 0.65952361,\n",
       "        0.66037153, 0.66578517, 1.34019329, 0.66350399, 0.66137706,\n",
       "        0.66806438, 0.6658318 , 0.67077618, 0.6613522 , 0.6546362 ,\n",
       "        0.67384116, 0.65473279, 0.65900636, 0.65504968, 0.66114336,\n",
       "        0.66902905, 1.32166958, 0.66940348, 0.65616147, 0.67037101,\n",
       "        1.32138349, 1.3215389 , 0.67487097, 1.32076563, 0.65212862,\n",
       "        0.66742075, 1.33618606, 1.32276201, 1.35912042, 1.35240622,\n",
       "        0.66038175, 1.31726581, 0.6686082 , 1.3206293 , 1.33427645,\n",
       "        0.65293161, 0.6672563 , 0.6546146 , 0.65407474, 1.34048064,\n",
       "        0.67135263, 0.66006081, 0.66097128, 0.66393153, 0.65635722,\n",
       "        0.65295342, 0.66215016, 1.33118645, 0.65886816, 1.31912821,\n",
       "        0.65940915, 0.66337067, 0.66303018, 1.34356549, 0.67124209,\n",
       "        0.65403181, 1.34054726, 0.65593613, 0.6507664 , 0.65117838,\n",
       "        0.67030755, 0.66736413, 0.67614335, 0.65581685, 0.66430211,\n",
       "        0.66369168, 0.66810155, 1.33207219, 1.32588064, 1.33476591,\n",
       "        0.66382865, 0.6610979 , 1.34380321, 0.66258363, 0.6487662 ,\n",
       "        0.66337552, 0.66072435, 1.31717271, 1.34536928, 0.66856589,\n",
       "        0.66457383, 0.66321706, 0.67634305, 0.6615422 , 0.64971732,\n",
       "        0.66153683, 1.34106452, 0.66314342, 0.66124236, 0.66651766,\n",
       "        1.34624637, 0.6603903 , 0.66258055, 1.34134286, 0.66270542,\n",
       "        0.66795638, 1.31890679, 0.66617373, 0.66740451, 0.64821642,\n",
       "        1.30644805, 1.3262954 , 0.66118063, 0.67123138]),\n",
       " 'q4': array([1.5100656 , 0.74822681, 0.74982045, 0.75453434, 1.48676496,\n",
       "        0.74195801, 0.74741724, 0.75372374, 0.73928988, 0.74428014,\n",
       "        0.74841454, 0.7402475 , 0.75118736, 1.51373431, 0.75832049,\n",
       "        0.75932027, 0.74863458, 0.74617607, 0.7476841 , 0.74723838,\n",
       "        0.74832949, 1.49270971, 0.75674059, 0.74724952, 1.48864857,\n",
       "        0.74385411, 1.5126433 , 0.75057122, 0.74357343, 1.49620184,\n",
       "        1.49606645, 1.49800857, 0.75009822, 0.74819103, 1.50686467,\n",
       "        0.76178339, 0.7480796 , 0.73696697, 1.49544974, 1.49892692,\n",
       "        1.49940888, 0.74818176, 0.75018603, 0.75238629, 0.75024151,\n",
       "        0.74326155, 0.73681029, 1.50080102, 0.75455704, 0.74996131,\n",
       "        0.74648846, 1.50887967, 0.7460205 , 0.74765216, 0.7569674 ,\n",
       "        1.48781365, 0.74770215, 0.75297981, 0.74505495, 0.75490098,\n",
       "        0.74925689, 0.74441207, 1.51619391, 0.75105289, 1.49471673,\n",
       "        0.7533792 , 0.74630323, 0.75198586, 0.7493437 , 1.49026591,\n",
       "        1.51197556, 1.49152473, 0.74839996, 0.74647735, 0.7568787 ,\n",
       "        0.75023516, 1.51007932, 1.4965232 , 0.75587967, 1.51019802,\n",
       "        0.73570152, 0.74849736, 0.74856966, 0.73730822, 0.75691439,\n",
       "        1.50906947, 0.74903076, 0.75224535, 0.75254082, 0.74963723,\n",
       "        0.74670426, 0.75051351, 0.75115476, 0.74403247, 1.49298817,\n",
       "        0.74607242, 0.75038284, 0.75572511, 0.74872104, 0.75540265,\n",
       "        0.75343217, 1.49260006, 0.74874655, 0.75217636, 1.50857724,\n",
       "        0.74479666, 1.51092051, 0.74942527, 1.4988225 , 1.50428838,\n",
       "        0.76124171, 1.50560036, 0.74469012, 1.49965766, 0.74756264,\n",
       "        0.74311585, 1.50517282, 0.74774004, 0.74923508, 0.74408483,\n",
       "        1.47423323, 0.74874573, 1.50559785, 1.49419114, 1.51098044,\n",
       "        1.50134111, 1.50331097, 0.75413766, 0.76075745, 0.74762835,\n",
       "        0.74711808, 0.75437177, 0.75171942, 1.50968405, 1.48936262,\n",
       "        0.75215321, 0.76664192, 0.74177192, 1.48187877, 0.75107274,\n",
       "        0.74778019, 0.74837335, 1.50432296, 0.74563251, 0.74562415,\n",
       "        0.74002898, 0.74752009, 0.7493414 , 0.7485994 , 0.75502846,\n",
       "        1.49271667, 1.50673622, 1.51788811, 0.74385506, 0.74322669,\n",
       "        1.50363757, 1.49836031, 0.75259109, 1.49110143, 1.50246998,\n",
       "        0.74908291, 0.74870296, 1.49136378, 0.75196171, 0.75640562,\n",
       "        0.75171093, 0.74799322, 1.49889604, 0.74832334, 0.74511182,\n",
       "        0.75463159, 0.75173232, 0.75582459, 0.74311302, 0.7496083 ,\n",
       "        0.76199825, 0.74690747, 0.74902564, 0.73911585, 0.75627819,\n",
       "        0.75291877, 1.50538424, 0.75408822, 0.7510456 , 0.74941204,\n",
       "        1.48848485, 1.49148319, 0.76275596, 1.47873013, 0.75139125,\n",
       "        0.74568479, 1.50660153, 1.49483216, 1.51510901, 1.51044308,\n",
       "        0.74153067, 1.47742769, 0.75512174, 1.49839525, 1.51368102,\n",
       "        0.74921602, 0.75062455, 0.74936644, 0.747576  , 1.50401196,\n",
       "        0.76040851, 0.74518887, 0.74769309, 0.74842496, 0.7510373 ,\n",
       "        0.75083463, 0.75335919, 1.48708747, 0.74897388, 1.49382568,\n",
       "        0.74548741, 0.74822118, 0.74118576, 1.50327553, 0.75722457,\n",
       "        0.74586819, 1.51626112, 0.7461525 , 0.74149261, 0.7422184 ,\n",
       "        0.74813799, 0.75064743, 0.74831977, 0.74938803, 0.75255957,\n",
       "        0.75662137, 0.76090278, 1.49971652, 1.50748914, 1.48000432,\n",
       "        0.74478527, 0.76033179, 1.50659412, 0.74943245, 0.7410154 ,\n",
       "        0.75659307, 0.74394757, 1.49128421, 1.51573975, 0.74914677,\n",
       "        0.75643219, 0.7465252 , 0.75736845, 0.74899783, 0.73108062,\n",
       "        0.74868915, 1.49972606, 0.74659186, 0.75286189, 0.75147106,\n",
       "        1.50323227, 0.74059542, 0.74878979, 1.50291545, 0.74695471,\n",
       "        0.74733893, 1.49416699, 0.75304884, 0.75517107, 0.74023395,\n",
       "        1.4892553 , 1.49989782, 0.75330607, 0.75011839]),\n",
       " 'q5': array([1.67374622, 0.84016758, 0.84377537, 0.84576592, 1.65148878,\n",
       "        0.83085102, 0.83258688, 0.83810715, 0.83428072, 0.83026302,\n",
       "        0.84116677, 0.83240735, 0.83514995, 1.68687976, 0.84331779,\n",
       "        0.83916233, 0.83815162, 0.82966707, 0.8359668 , 0.83993458,\n",
       "        0.84155963, 1.67383697, 0.84273922, 0.83808839, 1.67856803,\n",
       "        0.83554821, 1.68606898, 0.83570981, 0.83211353, 1.66278769,\n",
       "        1.66414264, 1.66801022, 0.84494573, 0.83894649, 1.66732913,\n",
       "        0.84215705, 0.83536403, 0.83355667, 1.66494027, 1.65810229,\n",
       "        1.68371541, 0.83776667, 0.83457828, 0.83782458, 0.84414499,\n",
       "        0.83475972, 0.82915522, 1.67647544, 0.83958574, 0.84059994,\n",
       "        0.83626011, 1.68541776, 0.84027952, 0.83723327, 0.84303092,\n",
       "        1.66660701, 0.83869018, 0.83932062, 0.82420387, 0.83892582,\n",
       "        0.82908067, 0.83180874, 1.67326323, 0.82707661, 1.6718176 ,\n",
       "        0.83465635, 0.83419748, 0.845422  , 0.84185962, 1.67027819,\n",
       "        1.67074884, 1.66004558, 0.83759065, 0.83138418, 0.83997861,\n",
       "        0.84001279, 1.68315213, 1.65842053, 0.8409922 , 1.67429627,\n",
       "        0.8312459 , 0.84042881, 0.83332312, 0.82870832, 0.84266563,\n",
       "        1.69137551, 0.85123817, 0.83740963, 0.83204024, 0.82660811,\n",
       "        0.83344016, 0.84483664, 0.83510273, 0.82912734, 1.66916166,\n",
       "        0.83499132, 0.83327394, 0.84671232, 0.82934602, 0.84010137,\n",
       "        0.83818508, 1.65302078, 0.8374185 , 0.84323036, 1.68069173,\n",
       "        0.8360008 , 1.67653258, 0.83389361, 1.65905407, 1.6676716 ,\n",
       "        0.84285312, 1.66716817, 0.82878886, 1.66260041, 0.84127541,\n",
       "        0.82956244, 1.68200664, 0.83943353, 0.82913265, 0.83468833,\n",
       "        1.63521292, 0.83913974, 1.67074601, 1.66700145, 1.6711549 ,\n",
       "        1.67154105, 1.67200287, 0.8433452 , 0.84874213, 0.83266817,\n",
       "        0.83285057, 0.83787423, 0.84039823, 1.67897274, 1.65874168,\n",
       "        0.84012594, 0.84689386, 0.83817443, 1.66587953, 0.83355136,\n",
       "        0.83440044, 0.83297253, 1.66101161, 0.82740477, 0.8381581 ,\n",
       "        0.83065399, 0.82971237, 0.84531651, 0.83523624, 0.83877731,\n",
       "        1.66205052, 1.67436915, 1.67596083, 0.83050899, 0.82452839,\n",
       "        1.67232324, 1.66768601, 0.84127404, 1.65717636, 1.67587677,\n",
       "        0.83453713, 0.83805277, 1.64246721, 0.83458854, 0.84563534,\n",
       "        0.84364949, 0.8266728 , 1.67107827, 0.83460236, 0.83040486,\n",
       "        0.84810799, 0.8376577 , 0.84464552, 0.83263149, 0.83477493,\n",
       "        0.85160644, 0.83166874, 0.84011747, 0.82815917, 0.84080626,\n",
       "        0.8396329 , 1.67709702, 0.84272726, 0.83485546, 0.83085369,\n",
       "        1.65952495, 1.67130351, 0.84549281, 1.63869719, 0.84532734,\n",
       "        0.84008748, 1.66917613, 1.6737096 , 1.67477079, 1.68758859,\n",
       "        0.83269288, 1.65345508, 0.84084529, 1.66959166, 1.67930212,\n",
       "        0.8365798 , 0.83668538, 0.83633476, 0.83429344, 1.65746148,\n",
       "        0.84134752, 0.83633899, 0.8283425 , 0.83903473, 0.84169868,\n",
       "        0.83640679, 0.84298699, 1.66495946, 0.83922594, 1.65045166,\n",
       "        0.83106007, 0.83726643, 0.83399012, 1.66074016, 0.83445624,\n",
       "        0.83591717, 1.66180131, 0.83586845, 0.8304199 , 0.8332543 ,\n",
       "        0.84021033, 0.83521673, 0.83700425, 0.83969305, 0.83293521,\n",
       "        0.84182247, 0.83598728, 1.66389834, 1.66536661, 1.65993064,\n",
       "        0.83782695, 0.85042064, 1.66969934, 0.83486962, 0.83235181,\n",
       "        0.85324856, 0.82959682, 1.65473583, 1.68408985, 0.82728989,\n",
       "        0.84095402, 0.83102794, 0.83964186, 0.83906084, 0.82575629,\n",
       "        0.83305459, 1.67743285, 0.84136574, 0.83739237, 0.84053846,\n",
       "        1.67126051, 0.82637456, 0.83912328, 1.67078518, 0.82639824,\n",
       "        0.83283376, 1.64965077, 0.84007524, 0.83684134, 0.82973529,\n",
       "        1.67283916, 1.66277595, 0.84290698, 0.83246499]),\n",
       " 'q6': array([1.74195185, 0.88105827, 0.88393236, 0.88144774, 1.72881422,\n",
       "        0.86958931, 0.87737013, 0.870177  , 0.87716683, 0.86648274,\n",
       "        0.87378011, 0.87740338, 0.87238128, 1.77059489, 0.88325817,\n",
       "        0.88135373, 0.87979495, 0.87489069, 0.87667536, 0.87364856,\n",
       "        0.87717292, 1.75138063, 0.87329689, 0.87293133, 1.75641213,\n",
       "        0.87624299, 1.75453076, 0.87162619, 0.87120566, 1.73896149,\n",
       "        1.74867578, 1.73046465, 0.8823514 , 0.88385679, 1.74852877,\n",
       "        0.87932942, 0.87561409, 0.86991776, 1.7422114 , 1.7323857 ,\n",
       "        1.76625405, 0.87609063, 0.87450039, 0.87549699, 0.88268638,\n",
       "        0.87070362, 0.87056279, 1.75262846, 0.87387565, 0.8758311 ,\n",
       "        0.87575085, 1.74383564, 0.87529135, 0.87792338, 0.88458725,\n",
       "        1.73977302, 0.88608564, 0.88149378, 0.86273461, 0.87469878,\n",
       "        0.86697847, 0.86850916, 1.74672578, 0.86706362, 1.74122136,\n",
       "        0.87310568, 0.87709287, 0.8860738 , 0.88246532, 1.74825171,\n",
       "        1.74443526, 1.73941911, 0.87858733, 0.87265869, 0.884272  ,\n",
       "        0.87299567, 1.76070122, 1.73471598, 0.88139814, 1.76830212,\n",
       "        0.86370436, 0.87679355, 0.86868839, 0.85991599, 0.88296048,\n",
       "        1.75789671, 0.88745414, 0.87517068, 0.87221801, 0.87139807,\n",
       "        0.87416334, 0.89259652, 0.86780013, 0.86965747, 1.74024412,\n",
       "        0.87673533, 0.87467894, 0.88066115, 0.87040804, 0.873279  ,\n",
       "        0.88021086, 1.73112744, 0.87133195, 0.87959003, 1.76377954,\n",
       "        0.87732488, 1.74691904, 0.87635708, 1.7453755 , 1.73834449,\n",
       "        0.88511977, 1.73854134, 0.86458425, 1.74433023, 0.88428226,\n",
       "        0.87252446, 1.75597381, 0.88239143, 0.87389175, 0.87875318,\n",
       "        1.73650723, 0.87422482, 1.74130868, 1.7345566 , 1.74717189,\n",
       "        1.74694905, 1.7565437 , 0.88051642, 0.88989865, 0.87105356,\n",
       "        0.87243723, 0.8739277 , 0.86669883, 1.74121565, 1.73233355,\n",
       "        0.88047019, 0.88365046, 0.88361439, 1.75095915, 0.87591348,\n",
       "        0.87175319, 0.86876639, 1.73799466, 0.86834474, 0.87681762,\n",
       "        0.87604765, 0.87320623, 0.88804147, 0.86757118, 0.87129337,\n",
       "        1.73633199, 1.74450832, 1.76497507, 0.88245147, 0.8614993 ,\n",
       "        1.736073  , 1.75066113, 0.88150412, 1.7313193 , 1.76217367,\n",
       "        0.87284392, 0.87994989, 1.73512721, 0.87462341, 0.88075811,\n",
       "        0.883489  , 0.86412674, 1.73720331, 0.86711142, 0.86002466,\n",
       "        0.88521444, 0.87538368, 0.88204357, 0.87229161, 0.87643746,\n",
       "        0.89244296, 0.87278923, 0.88014383, 0.86624509, 0.88197603,\n",
       "        0.87744073, 1.7466918 , 0.88378493, 0.88146789, 0.86500443,\n",
       "        1.73381806, 1.75569769, 0.88224558, 1.72377405, 0.87783526,\n",
       "        0.87726799, 1.74667657, 1.7367824 , 1.74830866, 1.74945167,\n",
       "        0.87528341, 1.72815448, 0.88328333, 1.74885424, 1.7468889 ,\n",
       "        0.87787745, 0.88058709, 0.87861279, 0.87095332, 1.74547462,\n",
       "        0.87364571, 0.87141496, 0.87110652, 0.88287184, 0.87867683,\n",
       "        0.874668  , 0.87776895, 1.73824319, 0.88298947, 1.72427147,\n",
       "        0.87402945, 0.87931899, 0.87255763, 1.72817853, 0.87575707,\n",
       "        0.87478053, 1.72736494, 0.87124377, 0.87271375, 0.87186566,\n",
       "        0.87607336, 0.87648262, 0.87796611, 0.87728218, 0.87624096,\n",
       "        0.88444005, 0.86838682, 1.73022123, 1.74146895, 1.73570596,\n",
       "        0.8807363 , 0.89093439, 1.7451223 , 0.87028341, 0.87088157,\n",
       "        0.88810889, 0.86836669, 1.72742244, 1.75308032, 0.87144793,\n",
       "        0.87977031, 0.87632772, 0.87352375, 0.87707365, 0.86950892,\n",
       "        0.88156983, 1.76149332, 0.87634989, 0.8789147 , 0.87284646,\n",
       "        1.73647405, 0.8733107 , 0.87477594, 1.73445427, 0.86678364,\n",
       "        0.87807068, 1.7210894 , 0.88180324, 0.86804214, 0.86498486,\n",
       "        1.74007212, 1.74106075, 0.88017806, 0.86469267]),\n",
       " 'q7': array([1.99980573, 1.01760656, 0.99053578, 0.99063677, 1.97885326,\n",
       "        1.00036719, 0.99631661, 0.9881006 , 0.99976005, 0.99902039,\n",
       "        1.00020853, 1.00764962, 0.99494261, 2.02823373, 0.98969791,\n",
       "        1.01234816, 0.99759951, 1.00903969, 1.01042375, 1.02117746,\n",
       "        1.00737723, 1.99068011, 0.97794512, 1.00224587, 2.00341201,\n",
       "        1.00160016, 1.99595481, 0.98498625, 0.98749433, 1.95822202,\n",
       "        1.95582568, 1.98084066, 1.01484992, 1.04367993, 1.98530635,\n",
       "        0.99938745, 1.00251671, 0.98134009, 1.97255996, 1.98526355,\n",
       "        2.01553436, 1.01672904, 1.00505446, 0.99876932, 0.99423887,\n",
       "        0.99582509, 1.00235845, 1.98470284, 1.00032018, 1.01571048,\n",
       "        0.99166418, 1.99012148, 1.01011105, 1.00589492, 1.00938668,\n",
       "        1.98759298, 1.00285863, 1.00817647, 0.98536608, 0.98850621,\n",
       "        0.99488704, 1.00669485, 1.98319699, 0.9977021 , 2.01359506,\n",
       "        1.00737551, 0.98897697, 0.99855032, 0.99038376, 1.96275629,\n",
       "        2.00901592, 1.95943738, 1.01209558, 1.00684425, 0.9925567 ,\n",
       "        1.00179211, 2.02184581, 1.97245536, 1.02008887, 2.02428412,\n",
       "        0.99205341, 0.98943681, 0.99180687, 0.99132538, 1.01878925,\n",
       "        2.00026576, 1.00713015, 1.00776277, 1.00191591, 1.00665869,\n",
       "        0.98574312, 1.00568525, 1.0136539 , 1.00226848, 1.95937298,\n",
       "        0.9992244 , 1.00800398, 1.01819503, 0.99770593, 1.01424949,\n",
       "        1.00207821, 1.99804417, 0.99210187, 1.00018871, 1.97613727,\n",
       "        0.99886212, 1.96794637, 1.01497239, 1.96532769, 1.96144898,\n",
       "        1.01407895, 1.99984596, 0.99083132, 2.00555769, 1.00870465,\n",
       "        1.00318143, 1.99170158, 1.00587332, 0.98734066, 1.00622121,\n",
       "        1.99426088, 1.00436466, 1.98588995, 1.94015586, 1.97283879,\n",
       "        1.99634705, 2.02636528, 1.01230443, 1.03311478, 1.00439846,\n",
       "        0.99255841, 0.99753594, 1.01011367, 2.00387077, 2.01019966,\n",
       "        0.98963825, 1.0020149 , 0.99790967, 1.96300849, 0.99818323,\n",
       "        0.99777196, 1.01319306, 1.9657046 , 0.99913134, 0.99401599,\n",
       "        1.01618564, 1.01966632, 1.00718065, 1.00024225, 1.00656151,\n",
       "        1.94179118, 1.97622269, 2.05694329, 1.01496445, 0.98961883,\n",
       "        1.97136704, 2.00111467, 1.02232651, 1.9878484 , 2.00021758,\n",
       "        0.98609303, 1.01142634, 2.00699137, 0.98911583, 0.99478366,\n",
       "        1.00987451, 0.99086484, 1.98964829, 1.01019716, 1.00190405,\n",
       "        1.02006446, 0.99540859, 1.02320276, 0.99633265, 1.01110598,\n",
       "        1.0191145 , 1.01733917, 0.99202398, 0.99435899, 1.02325424,\n",
       "        1.01662977, 1.98244338, 1.00787904, 1.00248475, 0.97972498,\n",
       "        1.96386133, 1.98377741, 0.99686956, 1.96267363, 1.00048684,\n",
       "        0.99039057, 2.04802845, 1.99057895, 2.02497607, 2.00365735,\n",
       "        0.9950518 , 2.01151557, 1.01498635, 2.00716659, 2.01081131,\n",
       "        1.00529962, 1.009514  , 1.00980838, 0.99760429, 2.02379052,\n",
       "        0.98735475, 0.98675214, 0.98907356, 1.00344388, 1.00586365,\n",
       "        0.99041192, 1.01954518, 1.99434188, 0.99389246, 2.00003118,\n",
       "        1.00865857, 1.00206268, 1.00260117, 2.01438601, 1.00939584,\n",
       "        1.00217101, 1.98078664, 0.99725272, 0.99192542, 0.9987111 ,\n",
       "        1.00870627, 1.012167  , 1.00158482, 1.00445355, 0.99890722,\n",
       "        1.01620254, 0.99014044, 2.02633474, 2.01020908, 1.98321154,\n",
       "        1.02574556, 1.01337612, 1.97206497, 0.99690538, 0.99409559,\n",
       "        1.0250761 , 0.99217708, 1.97185091, 1.99918504, 1.00196785,\n",
       "        1.01236041, 1.00727739, 1.02206626, 1.00973149, 1.01200497,\n",
       "        1.01198597, 2.02039766, 0.98619504, 1.00423432, 1.00704223,\n",
       "        1.96651259, 0.99978361, 1.00559699, 1.9935524 , 0.98312721,\n",
       "        1.00242942, 1.94024548, 1.01911256, 0.97996944, 1.00123463,\n",
       "        2.00354662, 1.9720583 , 0.99523263, 1.00401376]),\n",
       " 'q8': array([2.22013777, 1.08509588, 1.06001875, 1.04958425, 2.10919476,\n",
       "        1.06647006, 1.08536509, 1.04237012, 1.05456584, 1.1046199 ,\n",
       "        1.07523211, 1.07383787, 1.07007969, 2.17073842, 1.07768251,\n",
       "        1.10543154, 1.06262427, 1.07801412, 1.07470267, 1.07658743,\n",
       "        1.09501919, 2.15454445, 1.04801219, 1.06780623, 2.21256323,\n",
       "        1.09990158, 2.1083167 , 1.04010703, 1.06877979, 2.15024784,\n",
       "        2.08415371, 2.13644475, 1.08347247, 1.16309747, 2.14992404,\n",
       "        1.11904061, 1.07312518, 1.0633484 , 2.05794993, 2.13603831,\n",
       "        2.15035549, 1.07507664, 1.07342144, 1.07536214, 1.04634921,\n",
       "        1.04795609, 1.07015535, 2.07647416, 1.12594741, 1.09101412,\n",
       "        1.04925619, 2.17895969, 1.06610128, 1.06528978, 1.07477708,\n",
       "        2.16999656, 1.07253261, 1.13360942, 1.06101216, 1.04465696,\n",
       "        1.07003646, 1.09974758, 2.05965129, 1.07873883, 2.21957439,\n",
       "        1.13477446, 1.06209612, 1.08257485, 1.03429683, 2.1312346 ,\n",
       "        2.16804508, 2.09130952, 1.07535202, 1.08423033, 1.04632201,\n",
       "        1.10146131, 2.07748237, 2.08667213, 1.11316515, 2.1019435 ,\n",
       "        1.0556157 , 1.05445063, 1.06060432, 1.05640261, 1.10639073,\n",
       "        2.14468085, 1.07729569, 1.09067246, 1.11187747, 1.06617799,\n",
       "        1.04974193, 1.05758079, 1.07562555, 1.08892457, 2.15526177,\n",
       "        1.10805444, 1.07755487, 1.08237594, 1.08141843, 1.0606405 ,\n",
       "        1.10524903, 2.09810708, 1.05730481, 1.08254506, 2.16739353,\n",
       "        1.0759497 , 2.09843032, 1.07234503, 2.10145226, 2.09477432,\n",
       "        1.09549732, 2.12767884, 1.08049272, 2.16355013, 1.06869506,\n",
       "        1.07046426, 2.15124199, 1.08406736, 1.08282744, 1.06903779,\n",
       "        2.11129925, 1.06035961, 2.10613675, 2.06813423, 2.15383599,\n",
       "        2.15181924, 2.16117407, 1.1101216 , 1.11196208, 1.07639126,\n",
       "        1.08136889, 1.07647809, 1.10052029, 2.1606462 , 2.15141392,\n",
       "        1.04320058, 1.09846669, 1.07404156, 2.06506051, 1.07365976,\n",
       "        1.06578632, 1.08645382, 2.12225002, 1.08890938, 1.0818338 ,\n",
       "        1.08342925, 1.08531825, 1.0825517 , 1.064838  , 1.0866444 ,\n",
       "        2.1509083 , 2.07087945, 2.24578071, 1.08049834, 1.08606653,\n",
       "        2.13921618, 2.13029631, 1.08636236, 2.11605951, 2.14700442,\n",
       "        1.08287845, 1.07361228, 2.15380115, 1.05453775, 1.0681494 ,\n",
       "        1.06330795, 1.04708872, 2.17129213, 1.0895648 , 1.08577397,\n",
       "        1.09787535, 1.0745957 , 1.11044974, 1.06023056, 1.10467807,\n",
       "        1.09818018, 1.07999014, 1.06313236, 1.05774682, 1.09393765,\n",
       "        1.07518992, 2.11337304, 1.08453693, 1.08532703, 1.04307017,\n",
       "        2.10072166, 2.16505371, 1.04878313, 2.14201867, 1.05639909,\n",
       "        1.05368461, 2.17514641, 2.11282479, 2.12074514, 2.15249924,\n",
       "        1.05873959, 2.15853976, 1.10572942, 2.16042065, 2.15037019,\n",
       "        1.0810845 , 1.07153549, 1.10753028, 1.06345844, 2.17555564,\n",
       "        1.06129531, 1.06257148, 1.10083134, 1.06899118, 1.10739951,\n",
       "        1.07678303, 1.10331112, 2.10300452, 1.07675014, 2.14518399,\n",
       "        1.0939737 , 1.05409456, 1.06317029, 2.14358696, 1.05051671,\n",
       "        1.09919978, 2.08193704, 1.09803279, 1.08899608, 1.0649629 ,\n",
       "        1.09186546, 1.09024406, 1.1228653 , 1.07348174, 1.08093119,\n",
       "        1.07575071, 1.09140113, 2.13859601, 2.12310023, 2.0717006 ,\n",
       "        1.10984644, 1.11205763, 2.09049262, 1.06204147, 1.07200161,\n",
       "        1.10076801, 1.12774468, 2.09141926, 2.11319916, 1.06642113,\n",
       "        1.08257229, 1.079482  , 1.11075938, 1.08785691, 1.08811072,\n",
       "        1.09867689, 2.13963383, 1.07509933, 1.08762683, 1.07883011,\n",
       "        2.0874249 , 1.08439228, 1.05816573, 2.12866131, 1.0524235 ,\n",
       "        1.13614032, 2.04301432, 1.0813418 , 1.05227582, 1.05784615,\n",
       "        2.12049193, 2.1058704 , 1.06354564, 1.09404334])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mo = {'q'+str(i): y_train[:, i] for i in range(len(quantiles))}\n",
    "y_val_mo = {'q'+str(i): y_val[:, i] for i in range(len(quantiles))}\n",
    "y_train_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 269 samples, validate on 68 samples\n",
      "Epoch 1/300\n",
      "269/269 [==============================] - 8s 30ms/sample - loss: 9.3887 - q0_loss: 0.3492 - q1_loss: 1.2614 - q2_loss: 0.8594 - q3_loss: 0.7702 - q4_loss: 1.7556 - q5_loss: 0.9433 - q6_loss: 1.3629 - q7_loss: 1.0075 - q8_loss: 0.9800 - val_loss: 7.7223 - val_q0_loss: 0.2429 - val_q1_loss: 0.6034 - val_q2_loss: 0.7927 - val_q3_loss: 0.3369 - val_q4_loss: 2.3526 - val_q5_loss: 0.4498 - val_q6_loss: 1.4083 - val_q7_loss: 0.4748 - val_q8_loss: 0.7471\n",
      "Epoch 2/300\n",
      "269/269 [==============================] - 0s 909us/sample - loss: 7.7623 - q0_loss: 0.3139 - q1_loss: 0.4869 - q2_loss: 0.8207 - q3_loss: 0.5435 - q4_loss: 1.8904 - q5_loss: 0.6724 - q6_loss: 1.5193 - q7_loss: 0.8002 - q8_loss: 0.7495 - val_loss: 6.9800 - val_q0_loss: 0.2315 - val_q1_loss: 0.4347 - val_q2_loss: 0.7173 - val_q3_loss: 0.4473 - val_q4_loss: 1.6614 - val_q5_loss: 0.5546 - val_q6_loss: 1.3188 - val_q7_loss: 0.6444 - val_q8_loss: 0.4899\n",
      "Epoch 3/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 7.2602 - q0_loss: 0.2390 - q1_loss: 0.5376 - q2_loss: 0.8138 - q3_loss: 0.4462 - q4_loss: 1.9933 - q5_loss: 0.5434 - q6_loss: 1.5041 - q7_loss: 0.6651 - q8_loss: 0.5416 - val_loss: 6.2865 - val_q0_loss: 0.1603 - val_q1_loss: 0.3074 - val_q2_loss: 0.6832 - val_q3_loss: 0.3365 - val_q4_loss: 1.7084 - val_q5_loss: 0.3908 - val_q6_loss: 1.4082 - val_q7_loss: 0.5261 - val_q8_loss: 0.3583\n",
      "Epoch 4/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 6.9207 - q0_loss: 0.2344 - q1_loss: 0.4064 - q2_loss: 0.7867 - q3_loss: 0.4244 - q4_loss: 1.9116 - q5_loss: 0.5188 - q6_loss: 1.4975 - q7_loss: 0.6434 - q8_loss: 0.5381 - val_loss: 6.0568 - val_q0_loss: 0.1471 - val_q1_loss: 0.2450 - val_q2_loss: 0.6668 - val_q3_loss: 0.3131 - val_q4_loss: 1.6701 - val_q5_loss: 0.3680 - val_q6_loss: 1.3748 - val_q7_loss: 0.5125 - val_q8_loss: 0.3516\n",
      "Epoch 5/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 6.7156 - q0_loss: 0.2139 - q1_loss: 0.3927 - q2_loss: 0.7750 - q3_loss: 0.3895 - q4_loss: 1.9592 - q5_loss: 0.4757 - q6_loss: 1.4877 - q7_loss: 0.5940 - q8_loss: 0.4949 - val_loss: 5.9355 - val_q0_loss: 0.1434 - val_q1_loss: 0.2177 - val_q2_loss: 0.6427 - val_q3_loss: 0.3043 - val_q4_loss: 1.6647 - val_q5_loss: 0.3561 - val_q6_loss: 1.3868 - val_q7_loss: 0.4940 - val_q8_loss: 0.3582\n",
      "Epoch 6/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 6.3849 - q0_loss: 0.1781 - q1_loss: 0.3121 - q2_loss: 0.7429 - q3_loss: 0.3176 - q4_loss: 1.9822 - q5_loss: 0.3837 - q6_loss: 1.4834 - q7_loss: 0.5123 - q8_loss: 0.4365 - val_loss: 5.6766 - val_q0_loss: 0.1279 - val_q1_loss: 0.1998 - val_q2_loss: 0.6358 - val_q3_loss: 0.2339 - val_q4_loss: 1.7677 - val_q5_loss: 0.2792 - val_q6_loss: 1.3530 - val_q7_loss: 0.3927 - val_q8_loss: 0.3073\n",
      "Epoch 7/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 6.1619 - q0_loss: 0.1636 - q1_loss: 0.2909 - q2_loss: 0.7228 - q3_loss: 0.2853 - q4_loss: 1.9685 - q5_loss: 0.3431 - q6_loss: 1.4634 - q7_loss: 0.4718 - q8_loss: 0.4059 - val_loss: 5.5251 - val_q0_loss: 0.1221 - val_q1_loss: 0.2110 - val_q2_loss: 0.6275 - val_q3_loss: 0.1944 - val_q4_loss: 1.8816 - val_q5_loss: 0.2420 - val_q6_loss: 1.3163 - val_q7_loss: 0.3031 - val_q8_loss: 0.2772\n",
      "Epoch 8/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 5.8861 - q0_loss: 0.1495 - q1_loss: 0.2769 - q2_loss: 0.7061 - q3_loss: 0.2465 - q4_loss: 1.9814 - q5_loss: 0.2996 - q6_loss: 1.4491 - q7_loss: 0.4087 - q8_loss: 0.3636 - val_loss: 5.2510 - val_q0_loss: 0.0985 - val_q1_loss: 0.1483 - val_q2_loss: 0.5951 - val_q3_loss: 0.1901 - val_q4_loss: 1.7266 - val_q5_loss: 0.2225 - val_q6_loss: 1.3174 - val_q7_loss: 0.3420 - val_q8_loss: 0.2396\n",
      "Epoch 9/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 5.6703 - q0_loss: 0.1336 - q1_loss: 0.2395 - q2_loss: 0.6830 - q3_loss: 0.2333 - q4_loss: 1.9228 - q5_loss: 0.2797 - q6_loss: 1.4295 - q7_loss: 0.4090 - q8_loss: 0.3287 - val_loss: 5.0182 - val_q0_loss: 0.0891 - val_q1_loss: 0.1493 - val_q2_loss: 0.5818 - val_q3_loss: 0.1393 - val_q4_loss: 1.7810 - val_q5_loss: 0.1694 - val_q6_loss: 1.2818 - val_q7_loss: 0.2596 - val_q8_loss: 0.1978\n",
      "Epoch 10/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 5.4315 - q0_loss: 0.1198 - q1_loss: 0.2260 - q2_loss: 0.6645 - q3_loss: 0.1899 - q4_loss: 1.9624 - q5_loss: 0.2298 - q6_loss: 1.4221 - q7_loss: 0.3395 - q8_loss: 0.2913 - val_loss: 4.9033 - val_q0_loss: 0.0751 - val_q1_loss: 0.1559 - val_q2_loss: 0.5390 - val_q3_loss: 0.1322 - val_q4_loss: 1.7348 - val_q5_loss: 0.1538 - val_q6_loss: 1.3432 - val_q7_loss: 0.2627 - val_q8_loss: 0.1886\n",
      "Epoch 11/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 5.1811 - q0_loss: 0.0972 - q1_loss: 0.2177 - q2_loss: 0.6386 - q3_loss: 0.1491 - q4_loss: 1.9554 - q5_loss: 0.1788 - q6_loss: 1.3863 - q7_loss: 0.2864 - q8_loss: 0.2397 - val_loss: 4.6998 - val_q0_loss: 0.0579 - val_q1_loss: 0.1415 - val_q2_loss: 0.5477 - val_q3_loss: 0.1257 - val_q4_loss: 1.6584 - val_q5_loss: 0.1529 - val_q6_loss: 1.2116 - val_q7_loss: 0.2813 - val_q8_loss: 0.1788\n",
      "Epoch 12/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 4.9186 - q0_loss: 0.0823 - q1_loss: 0.1802 - q2_loss: 0.6226 - q3_loss: 0.1189 - q4_loss: 1.9755 - q5_loss: 0.1413 - q6_loss: 1.3896 - q7_loss: 0.2454 - q8_loss: 0.2061 - val_loss: 4.3614 - val_q0_loss: 0.0540 - val_q1_loss: 0.1261 - val_q2_loss: 0.5239 - val_q3_loss: 0.0606 - val_q4_loss: 1.7770 - val_q5_loss: 0.0719 - val_q6_loss: 1.2035 - val_q7_loss: 0.1333 - val_q8_loss: 0.1061\n",
      "Epoch 13/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 4.6790 - q0_loss: 0.0602 - q1_loss: 0.1694 - q2_loss: 0.5874 - q3_loss: 0.0838 - q4_loss: 1.9517 - q5_loss: 0.0983 - q6_loss: 1.3348 - q7_loss: 0.1811 - q8_loss: 0.1403 - val_loss: 4.2207 - val_q0_loss: 0.0378 - val_q1_loss: 0.0797 - val_q2_loss: 0.4995 - val_q3_loss: 0.0713 - val_q4_loss: 1.6642 - val_q5_loss: 0.0893 - val_q6_loss: 1.1975 - val_q7_loss: 0.1974 - val_q8_loss: 0.1002\n",
      "Epoch 14/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 4.4098 - q0_loss: 0.0406 - q1_loss: 0.1342 - q2_loss: 0.5642 - q3_loss: 0.0464 - q4_loss: 1.9618 - q5_loss: 0.0561 - q6_loss: 1.3423 - q7_loss: 0.1366 - q8_loss: 0.1002 - val_loss: 3.9091 - val_q0_loss: 0.0324 - val_q1_loss: 0.0686 - val_q2_loss: 0.4736 - val_q3_loss: 0.0271 - val_q4_loss: 1.7580 - val_q5_loss: 0.0324 - val_q6_loss: 1.1808 - val_q7_loss: 0.0631 - val_q8_loss: 0.0415\n",
      "Epoch 15/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 4.2683 - q0_loss: 0.0351 - q1_loss: 0.1098 - q2_loss: 0.5389 - q3_loss: 0.0547 - q4_loss: 1.9448 - q5_loss: 0.0736 - q6_loss: 1.3251 - q7_loss: 0.1150 - q8_loss: 0.0713 - val_loss: 4.3666 - val_q0_loss: 0.0895 - val_q1_loss: 0.0917 - val_q2_loss: 0.4754 - val_q3_loss: 0.1566 - val_q4_loss: 1.4836 - val_q5_loss: 0.2074 - val_q6_loss: 1.1206 - val_q7_loss: 0.2888 - val_q8_loss: 0.2281\n",
      "Epoch 16/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 4.5414 - q0_loss: 0.0717 - q1_loss: 0.1158 - q2_loss: 0.5191 - q3_loss: 0.1364 - q4_loss: 1.8645 - q5_loss: 0.1742 - q6_loss: 1.3002 - q7_loss: 0.2008 - q8_loss: 0.1410 - val_loss: 3.7062 - val_q0_loss: 0.0173 - val_q1_loss: 0.0433 - val_q2_loss: 0.4311 - val_q3_loss: 0.0290 - val_q4_loss: 1.6735 - val_q5_loss: 0.0441 - val_q6_loss: 1.1402 - val_q7_loss: 0.0630 - val_q8_loss: 0.0329\n",
      "Epoch 17/300\n",
      "269/269 [==============================] - 0s 223us/sample - loss: 4.3410 - q0_loss: 0.0610 - q1_loss: 0.0820 - q2_loss: 0.5049 - q3_loss: 0.1210 - q4_loss: 1.8781 - q5_loss: 0.1535 - q6_loss: 1.3211 - q7_loss: 0.1860 - q8_loss: 0.0986 - val_loss: 3.9709 - val_q0_loss: 0.0397 - val_q1_loss: 0.1079 - val_q2_loss: 0.4025 - val_q3_loss: 0.1240 - val_q4_loss: 1.5037 - val_q5_loss: 0.1630 - val_q6_loss: 1.1796 - val_q7_loss: 0.2044 - val_q8_loss: 0.0504\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 199us/sample - loss: 4.1618 - q0_loss: 0.0481 - q1_loss: 0.0965 - q2_loss: 0.4700 - q3_loss: 0.0790 - q4_loss: 1.8472 - q5_loss: 0.1004 - q6_loss: 1.2631 - q7_loss: 0.1208 - q8_loss: 0.1130 - val_loss: 3.9532 - val_q0_loss: 0.0610 - val_q1_loss: 0.1489 - val_q2_loss: 0.4294 - val_q3_loss: 0.0874 - val_q4_loss: 1.4993 - val_q5_loss: 0.1253 - val_q6_loss: 1.0112 - val_q7_loss: 0.1751 - val_q8_loss: 0.2201\n",
      "Epoch 19/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 4.1765 - q0_loss: 0.0430 - q1_loss: 0.1634 - q2_loss: 0.4565 - q3_loss: 0.0970 - q4_loss: 1.8247 - q5_loss: 0.1200 - q6_loss: 1.2271 - q7_loss: 0.1345 - q8_loss: 0.0944 - val_loss: 3.7307 - val_q0_loss: 0.0338 - val_q1_loss: 0.2525 - val_q2_loss: 0.4198 - val_q3_loss: 0.0183 - val_q4_loss: 1.5903 - val_q5_loss: 0.0192 - val_q6_loss: 0.9263 - val_q7_loss: 0.0485 - val_q8_loss: 0.2036\n",
      "Epoch 20/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 3.9703 - q0_loss: 0.0301 - q1_loss: 0.1847 - q2_loss: 0.4392 - q3_loss: 0.0463 - q4_loss: 1.8188 - q5_loss: 0.0554 - q6_loss: 1.1835 - q7_loss: 0.0719 - q8_loss: 0.1320 - val_loss: 3.9367 - val_q0_loss: 0.0696 - val_q1_loss: 0.2304 - val_q2_loss: 0.4093 - val_q3_loss: 0.0778 - val_q4_loss: 1.4651 - val_q5_loss: 0.1109 - val_q6_loss: 0.9184 - val_q7_loss: 0.1521 - val_q8_loss: 0.2835\n",
      "Epoch 21/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 3.8498 - q0_loss: 0.0355 - q1_loss: 0.1307 - q2_loss: 0.4293 - q3_loss: 0.0490 - q4_loss: 1.8205 - q5_loss: 0.0639 - q6_loss: 1.1753 - q7_loss: 0.0779 - q8_loss: 0.1164 - val_loss: 3.3845 - val_q0_loss: 0.0188 - val_q1_loss: 0.0671 - val_q2_loss: 0.3288 - val_q3_loss: 0.0436 - val_q4_loss: 1.5019 - val_q5_loss: 0.0643 - val_q6_loss: 1.0506 - val_q7_loss: 0.0756 - val_q8_loss: 0.0324\n",
      "Epoch 22/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 3.6108 - q0_loss: 0.0259 - q1_loss: 0.0559 - q2_loss: 0.3849 - q3_loss: 0.0375 - q4_loss: 1.7730 - q5_loss: 0.0471 - q6_loss: 1.1666 - q7_loss: 0.0554 - q8_loss: 0.0593 - val_loss: 3.4041 - val_q0_loss: 0.0321 - val_q1_loss: 0.0373 - val_q2_loss: 0.3314 - val_q3_loss: 0.0574 - val_q4_loss: 1.4528 - val_q5_loss: 0.0860 - val_q6_loss: 0.9792 - val_q7_loss: 0.0987 - val_q8_loss: 0.1161\n",
      "Epoch 23/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 3.6097 - q0_loss: 0.0370 - q1_loss: 0.0343 - q2_loss: 0.3678 - q3_loss: 0.0602 - q4_loss: 1.7358 - q5_loss: 0.0764 - q6_loss: 1.1365 - q7_loss: 0.0870 - q8_loss: 0.0786 - val_loss: 3.3714 - val_q0_loss: 0.0366 - val_q1_loss: 0.0285 - val_q2_loss: 0.3076 - val_q3_loss: 0.0779 - val_q4_loss: 1.4078 - val_q5_loss: 0.1116 - val_q6_loss: 0.9827 - val_q7_loss: 0.1187 - val_q8_loss: 0.1057\n",
      "Epoch 24/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 3.4318 - q0_loss: 0.0274 - q1_loss: 0.0243 - q2_loss: 0.3382 - q3_loss: 0.0382 - q4_loss: 1.6998 - q5_loss: 0.0447 - q6_loss: 1.0962 - q7_loss: 0.0547 - q8_loss: 0.0561 - val_loss: 3.1741 - val_q0_loss: 0.0222 - val_q1_loss: 0.0207 - val_q2_loss: 0.2834 - val_q3_loss: 0.0468 - val_q4_loss: 1.4221 - val_q5_loss: 0.0711 - val_q6_loss: 0.9571 - val_q7_loss: 0.0731 - val_q8_loss: 0.0785\n",
      "Epoch 25/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 3.3470 - q0_loss: 0.0233 - q1_loss: 0.0475 - q2_loss: 0.3243 - q3_loss: 0.0310 - q4_loss: 1.6848 - q5_loss: 0.0397 - q6_loss: 1.0926 - q7_loss: 0.0440 - q8_loss: 0.0601 - val_loss: 3.3072 - val_q0_loss: 0.0438 - val_q1_loss: 0.0500 - val_q2_loss: 0.2496 - val_q3_loss: 0.0862 - val_q4_loss: 1.5521 - val_q5_loss: 0.0981 - val_q6_loss: 0.8871 - val_q7_loss: 0.1079 - val_q8_loss: 0.0388\n",
      "Epoch 26/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 3.4334 - q0_loss: 0.0385 - q1_loss: 0.0553 - q2_loss: 0.3118 - q3_loss: 0.0604 - q4_loss: 1.6395 - q5_loss: 0.0760 - q6_loss: 1.0470 - q7_loss: 0.0864 - q8_loss: 0.0955 - val_loss: 3.4421 - val_q0_loss: 0.0678 - val_q1_loss: 0.0533 - val_q2_loss: 0.2050 - val_q3_loss: 0.1029 - val_q4_loss: 1.5518 - val_q5_loss: 0.1219 - val_q6_loss: 0.9107 - val_q7_loss: 0.1413 - val_q8_loss: 0.1250\n",
      "Epoch 27/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 3.4569 - q0_loss: 0.0469 - q1_loss: 0.0631 - q2_loss: 0.2868 - q3_loss: 0.0702 - q4_loss: 1.6470 - q5_loss: 0.0892 - q6_loss: 1.0615 - q7_loss: 0.0996 - q8_loss: 0.1096 - val_loss: 3.0138 - val_q0_loss: 0.0220 - val_q1_loss: 0.0576 - val_q2_loss: 0.2285 - val_q3_loss: 0.0455 - val_q4_loss: 1.4279 - val_q5_loss: 0.0541 - val_q6_loss: 0.8460 - val_q7_loss: 0.0593 - val_q8_loss: 0.0657\n",
      "Epoch 28/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 3.1685 - q0_loss: 0.0250 - q1_loss: 0.0587 - q2_loss: 0.2574 - q3_loss: 0.0363 - q4_loss: 1.5916 - q5_loss: 0.0455 - q6_loss: 0.9925 - q7_loss: 0.0503 - q8_loss: 0.0569 - val_loss: 3.0130 - val_q0_loss: 0.0173 - val_q1_loss: 0.1405 - val_q2_loss: 0.1811 - val_q3_loss: 0.0454 - val_q4_loss: 1.3388 - val_q5_loss: 0.0639 - val_q6_loss: 0.9365 - val_q7_loss: 0.0570 - val_q8_loss: 0.0580\n",
      "Epoch 29/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 3.2588 - q0_loss: 0.0370 - q1_loss: 0.0942 - q2_loss: 0.2468 - q3_loss: 0.0623 - q4_loss: 1.5731 - q5_loss: 0.0780 - q6_loss: 1.0012 - q7_loss: 0.0884 - q8_loss: 0.0930 - val_loss: 3.1239 - val_q0_loss: 0.0527 - val_q1_loss: 0.0283 - val_q2_loss: 0.2080 - val_q3_loss: 0.1085 - val_q4_loss: 1.2406 - val_q5_loss: 0.1465 - val_q6_loss: 0.8667 - val_q7_loss: 0.1568 - val_q8_loss: 0.1388\n",
      "Epoch 30/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 3.2910 - q0_loss: 0.0401 - q1_loss: 0.0941 - q2_loss: 0.2208 - q3_loss: 0.0957 - q4_loss: 1.5574 - q5_loss: 0.1178 - q6_loss: 0.9710 - q7_loss: 0.1236 - q8_loss: 0.0632 - val_loss: 2.8745 - val_q0_loss: 0.0251 - val_q1_loss: 0.1746 - val_q2_loss: 0.2048 - val_q3_loss: 0.0162 - val_q4_loss: 1.3460 - val_q5_loss: 0.0146 - val_q6_loss: 0.7219 - val_q7_loss: 0.0221 - val_q8_loss: 0.1648\n",
      "Epoch 31/300\n",
      "269/269 [==============================] - 0s 181us/sample - loss: 3.1460 - q0_loss: 0.0420 - q1_loss: 0.0904 - q2_loss: 0.2196 - q3_loss: 0.0660 - q4_loss: 1.5369 - q5_loss: 0.0836 - q6_loss: 0.9347 - q7_loss: 0.0966 - q8_loss: 0.1105 - val_loss: 3.3968 - val_q0_loss: 0.0924 - val_q1_loss: 0.0713 - val_q2_loss: 0.1125 - val_q3_loss: 0.1770 - val_q4_loss: 1.5103 - val_q5_loss: 0.2136 - val_q6_loss: 0.7174 - val_q7_loss: 0.2346 - val_q8_loss: 0.1102\n",
      "Epoch 32/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 3.5177 - q0_loss: 0.0804 - q1_loss: 0.0718 - q2_loss: 0.1928 - q3_loss: 0.1648 - q4_loss: 1.5177 - q5_loss: 0.2078 - q6_loss: 0.9247 - q7_loss: 0.2240 - q8_loss: 0.1392 - val_loss: 2.5484 - val_q0_loss: 0.0280 - val_q1_loss: 0.0230 - val_q2_loss: 0.1174 - val_q3_loss: 0.0279 - val_q4_loss: 1.3273 - val_q5_loss: 0.0266 - val_q6_loss: 0.7715 - val_q7_loss: 0.0343 - val_q8_loss: 0.0267\n",
      "Epoch 33/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 3.3116 - q0_loss: 0.0703 - q1_loss: 0.0350 - q2_loss: 0.1745 - q3_loss: 0.1313 - q4_loss: 1.4734 - q5_loss: 0.1670 - q6_loss: 0.9184 - q7_loss: 0.1849 - q8_loss: 0.1475 - val_loss: 3.1048 - val_q0_loss: 0.0758 - val_q1_loss: 0.0265 - val_q2_loss: 0.1620 - val_q3_loss: 0.1446 - val_q4_loss: 1.1255 - val_q5_loss: 0.1925 - val_q6_loss: 0.7747 - val_q7_loss: 0.2109 - val_q8_loss: 0.2109\n",
      "Epoch 34/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 3.1790 - q0_loss: 0.0666 - q1_loss: 0.0281 - q2_loss: 0.1547 - q3_loss: 0.1228 - q4_loss: 1.4452 - q5_loss: 0.1558 - q6_loss: 0.8795 - q7_loss: 0.1714 - q8_loss: 0.1310 - val_loss: 2.5198 - val_q0_loss: 0.0345 - val_q1_loss: 0.0226 - val_q2_loss: 0.0822 - val_q3_loss: 0.0533 - val_q4_loss: 1.3109 - val_q5_loss: 0.0561 - val_q6_loss: 0.7062 - val_q7_loss: 0.0662 - val_q8_loss: 0.0237\n",
      "Epoch 35/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 2.8302 - q0_loss: 0.0404 - q1_loss: 0.0261 - q2_loss: 0.1307 - q3_loss: 0.0662 - q4_loss: 1.4887 - q5_loss: 0.0814 - q6_loss: 0.8670 - q7_loss: 0.0939 - q8_loss: 0.0759 - val_loss: 2.7032 - val_q0_loss: 0.0425 - val_q1_loss: 0.0374 - val_q2_loss: 0.1038 - val_q3_loss: 0.0864 - val_q4_loss: 1.1528 - val_q5_loss: 0.1160 - val_q6_loss: 0.7346 - val_q7_loss: 0.1242 - val_q8_loss: 0.1213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 2.7759 - q0_loss: 0.0391 - q1_loss: 0.0359 - q2_loss: 0.1073 - q3_loss: 0.0690 - q4_loss: 1.4465 - q5_loss: 0.0856 - q6_loss: 0.8225 - q7_loss: 0.0917 - q8_loss: 0.0697 - val_loss: 2.4291 - val_q0_loss: 0.0230 - val_q1_loss: 0.0423 - val_q2_loss: 0.0836 - val_q3_loss: 0.0336 - val_q4_loss: 1.1854 - val_q5_loss: 0.0505 - val_q6_loss: 0.6765 - val_q7_loss: 0.0561 - val_q8_loss: 0.1050\n",
      "Epoch 37/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 2.5534 - q0_loss: 0.0249 - q1_loss: 0.0305 - q2_loss: 0.0993 - q3_loss: 0.0291 - q4_loss: 1.4099 - q5_loss: 0.0355 - q6_loss: 0.8088 - q7_loss: 0.0418 - q8_loss: 0.0661 - val_loss: 2.3759 - val_q0_loss: 0.0332 - val_q1_loss: 0.0346 - val_q2_loss: 0.0531 - val_q3_loss: 0.0506 - val_q4_loss: 1.2477 - val_q5_loss: 0.0542 - val_q6_loss: 0.6496 - val_q7_loss: 0.0652 - val_q8_loss: 0.0333\n",
      "Epoch 38/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 2.4928 - q0_loss: 0.0266 - q1_loss: 0.0255 - q2_loss: 0.0856 - q3_loss: 0.0337 - q4_loss: 1.3818 - q5_loss: 0.0415 - q6_loss: 0.7766 - q7_loss: 0.0480 - q8_loss: 0.0598 - val_loss: 2.4453 - val_q0_loss: 0.0354 - val_q1_loss: 0.0222 - val_q2_loss: 0.0614 - val_q3_loss: 0.0714 - val_q4_loss: 1.1063 - val_q5_loss: 0.0993 - val_q6_loss: 0.6715 - val_q7_loss: 0.1025 - val_q8_loss: 0.1077\n",
      "Epoch 39/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 2.4786 - q0_loss: 0.0279 - q1_loss: 0.0294 - q2_loss: 0.0927 - q3_loss: 0.0421 - q4_loss: 1.3891 - q5_loss: 0.0502 - q6_loss: 0.7854 - q7_loss: 0.0587 - q8_loss: 0.0562 - val_loss: 2.2446 - val_q0_loss: 0.0257 - val_q1_loss: 0.0427 - val_q2_loss: 0.0493 - val_q3_loss: 0.0446 - val_q4_loss: 1.2011 - val_q5_loss: 0.0458 - val_q6_loss: 0.5867 - val_q7_loss: 0.0544 - val_q8_loss: 0.0366\n",
      "Epoch 40/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 2.5087 - q0_loss: 0.0322 - q1_loss: 0.0482 - q2_loss: 0.0830 - q3_loss: 0.0617 - q4_loss: 1.3311 - q5_loss: 0.0771 - q6_loss: 0.7405 - q7_loss: 0.0803 - q8_loss: 0.0598 - val_loss: 2.1872 - val_q0_loss: 0.0155 - val_q1_loss: 0.0605 - val_q2_loss: 0.0501 - val_q3_loss: 0.0309 - val_q4_loss: 1.1088 - val_q5_loss: 0.0462 - val_q6_loss: 0.6384 - val_q7_loss: 0.0409 - val_q8_loss: 0.0392\n",
      "Epoch 41/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 2.6813 - q0_loss: 0.0494 - q1_loss: 0.0631 - q2_loss: 0.0914 - q3_loss: 0.0905 - q4_loss: 1.3135 - q5_loss: 0.1123 - q6_loss: 0.7024 - q7_loss: 0.1241 - q8_loss: 0.0956 - val_loss: 2.1240 - val_q0_loss: 0.0166 - val_q1_loss: 0.0665 - val_q2_loss: 0.0438 - val_q3_loss: 0.0246 - val_q4_loss: 1.1337 - val_q5_loss: 0.0281 - val_q6_loss: 0.5424 - val_q7_loss: 0.0305 - val_q8_loss: 0.0716\n",
      "Epoch 42/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 2.5895 - q0_loss: 0.0484 - q1_loss: 0.0503 - q2_loss: 0.0900 - q3_loss: 0.0888 - q4_loss: 1.2850 - q5_loss: 0.1134 - q6_loss: 0.6869 - q7_loss: 0.1235 - q8_loss: 0.1035 - val_loss: 2.2606 - val_q0_loss: 0.0233 - val_q1_loss: 0.0616 - val_q2_loss: 0.0440 - val_q3_loss: 0.0720 - val_q4_loss: 1.0299 - val_q5_loss: 0.0996 - val_q6_loss: 0.6142 - val_q7_loss: 0.0983 - val_q8_loss: 0.0661\n",
      "Epoch 43/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 2.4164 - q0_loss: 0.0360 - q1_loss: 0.0389 - q2_loss: 0.0848 - q3_loss: 0.0585 - q4_loss: 1.2887 - q5_loss: 0.0715 - q6_loss: 0.6608 - q7_loss: 0.0807 - q8_loss: 0.0775 - val_loss: 2.2157 - val_q0_loss: 0.0348 - val_q1_loss: 0.0235 - val_q2_loss: 0.0549 - val_q3_loss: 0.0627 - val_q4_loss: 1.0218 - val_q5_loss: 0.0891 - val_q6_loss: 0.5522 - val_q7_loss: 0.0936 - val_q8_loss: 0.1141\n",
      "Epoch 44/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2.3797 - q0_loss: 0.0357 - q1_loss: 0.0467 - q2_loss: 0.0823 - q3_loss: 0.0619 - q4_loss: 1.2610 - q5_loss: 0.0791 - q6_loss: 0.6512 - q7_loss: 0.0855 - q8_loss: 0.0731 - val_loss: 2.1040 - val_q0_loss: 0.0407 - val_q1_loss: 0.0289 - val_q2_loss: 0.0744 - val_q3_loss: 0.0549 - val_q4_loss: 1.1084 - val_q5_loss: 0.0590 - val_q6_loss: 0.5003 - val_q7_loss: 0.0739 - val_q8_loss: 0.0481\n",
      "Epoch 45/300\n",
      "269/269 [==============================] - 0s 183us/sample - loss: 2.3352 - q0_loss: 0.0354 - q1_loss: 0.0648 - q2_loss: 0.0854 - q3_loss: 0.0513 - q4_loss: 1.2375 - q5_loss: 0.0643 - q6_loss: 0.5955 - q7_loss: 0.0754 - q8_loss: 0.0941 - val_loss: 1.9951 - val_q0_loss: 0.0312 - val_q1_loss: 0.0136 - val_q2_loss: 0.0630 - val_q3_loss: 0.0435 - val_q4_loss: 1.0767 - val_q5_loss: 0.0485 - val_q6_loss: 0.4740 - val_q7_loss: 0.0581 - val_q8_loss: 0.0435\n",
      "Epoch 46/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 2.1798 - q0_loss: 0.0252 - q1_loss: 0.0414 - q2_loss: 0.0803 - q3_loss: 0.0417 - q4_loss: 1.2342 - q5_loss: 0.0514 - q6_loss: 0.6057 - q7_loss: 0.0561 - q8_loss: 0.0525 - val_loss: 1.8645 - val_q0_loss: 0.0203 - val_q1_loss: 0.0354 - val_q2_loss: 0.0529 - val_q3_loss: 0.0228 - val_q4_loss: 1.0403 - val_q5_loss: 0.0231 - val_q6_loss: 0.4494 - val_q7_loss: 0.0272 - val_q8_loss: 0.0416\n",
      "Epoch 47/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2.0983 - q0_loss: 0.0251 - q1_loss: 0.0268 - q2_loss: 0.0798 - q3_loss: 0.0378 - q4_loss: 1.2159 - q5_loss: 0.0465 - q6_loss: 0.5758 - q7_loss: 0.0517 - q8_loss: 0.0529 - val_loss: 1.9549 - val_q0_loss: 0.0252 - val_q1_loss: 0.0175 - val_q2_loss: 0.0435 - val_q3_loss: 0.0517 - val_q4_loss: 0.9569 - val_q5_loss: 0.0729 - val_q6_loss: 0.4746 - val_q7_loss: 0.0759 - val_q8_loss: 0.0847\n",
      "Epoch 48/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 2.0959 - q0_loss: 0.0295 - q1_loss: 0.0216 - q2_loss: 0.0821 - q3_loss: 0.0475 - q4_loss: 1.1971 - q5_loss: 0.0593 - q6_loss: 0.5616 - q7_loss: 0.0666 - q8_loss: 0.0564 - val_loss: 2.0391 - val_q0_loss: 0.0362 - val_q1_loss: 0.0315 - val_q2_loss: 0.0487 - val_q3_loss: 0.0802 - val_q4_loss: 0.9132 - val_q5_loss: 0.1084 - val_q6_loss: 0.4757 - val_q7_loss: 0.1139 - val_q8_loss: 0.0988\n",
      "Epoch 49/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 2.2704 - q0_loss: 0.0478 - q1_loss: 0.0372 - q2_loss: 0.0860 - q3_loss: 0.0933 - q4_loss: 1.1448 - q5_loss: 0.1184 - q6_loss: 0.5623 - q7_loss: 0.1289 - q8_loss: 0.0904 - val_loss: 1.9929 - val_q0_loss: 0.0470 - val_q1_loss: 0.0284 - val_q2_loss: 0.0715 - val_q3_loss: 0.0755 - val_q4_loss: 1.0166 - val_q5_loss: 0.0872 - val_q6_loss: 0.3774 - val_q7_loss: 0.1005 - val_q8_loss: 0.0531\n",
      "Epoch 50/300\n",
      "269/269 [==============================] - 0s 176us/sample - loss: 2.2835 - q0_loss: 0.0463 - q1_loss: 0.0731 - q2_loss: 0.0899 - q3_loss: 0.0932 - q4_loss: 1.1742 - q5_loss: 0.1158 - q6_loss: 0.4853 - q7_loss: 0.1271 - q8_loss: 0.0906 - val_loss: 1.8274 - val_q0_loss: 0.0202 - val_q1_loss: 0.0828 - val_q2_loss: 0.0429 - val_q3_loss: 0.0440 - val_q4_loss: 0.9746 - val_q5_loss: 0.0516 - val_q6_loss: 0.3338 - val_q7_loss: 0.0567 - val_q8_loss: 0.0724\n",
      "Epoch 51/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 2.1810 - q0_loss: 0.0480 - q1_loss: 0.0590 - q2_loss: 0.0903 - q3_loss: 0.0810 - q4_loss: 1.1105 - q5_loss: 0.1018 - q6_loss: 0.4735 - q7_loss: 0.1133 - q8_loss: 0.1133 - val_loss: 2.0519 - val_q0_loss: 0.0435 - val_q1_loss: 0.0455 - val_q2_loss: 0.0484 - val_q3_loss: 0.1043 - val_q4_loss: 0.8389 - val_q5_loss: 0.1386 - val_q6_loss: 0.4372 - val_q7_loss: 0.1455 - val_q8_loss: 0.1091\n",
      "Epoch 52/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 2.1389 - q0_loss: 0.0441 - q1_loss: 0.0734 - q2_loss: 0.0890 - q3_loss: 0.0736 - q4_loss: 1.1310 - q5_loss: 0.0936 - q6_loss: 0.4793 - q7_loss: 0.1036 - q8_loss: 0.1070 - val_loss: 2.4892 - val_q0_loss: 0.1040 - val_q1_loss: 0.0671 - val_q2_loss: 0.1155 - val_q3_loss: 0.1633 - val_q4_loss: 1.0387 - val_q5_loss: 0.1997 - val_q6_loss: 0.2811 - val_q7_loss: 0.2325 - val_q8_loss: 0.1990\n",
      "Epoch 53/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 2.3615 - q0_loss: 0.0684 - q1_loss: 0.0689 - q2_loss: 0.0999 - q3_loss: 0.1210 - q4_loss: 1.0944 - q5_loss: 0.1532 - q6_loss: 0.4279 - q7_loss: 0.1715 - q8_loss: 0.1611 - val_loss: 2.1317 - val_q0_loss: 0.0654 - val_q1_loss: 0.0988 - val_q2_loss: 0.0767 - val_q3_loss: 0.1397 - val_q4_loss: 1.0085 - val_q5_loss: 0.1657 - val_q6_loss: 0.2033 - val_q7_loss: 0.1814 - val_q8_loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2.0937 - q0_loss: 0.0471 - q1_loss: 0.0912 - q2_loss: 0.0956 - q3_loss: 0.0717 - q4_loss: 1.0652 - q5_loss: 0.0900 - q6_loss: 0.4023 - q7_loss: 0.1047 - q8_loss: 0.1244 - val_loss: 1.8314 - val_q0_loss: 0.0403 - val_q1_loss: 0.1003 - val_q2_loss: 0.0579 - val_q3_loss: 0.0546 - val_q4_loss: 0.8388 - val_q5_loss: 0.0771 - val_q6_loss: 0.2880 - val_q7_loss: 0.0897 - val_q8_loss: 0.1640\n",
      "Epoch 55/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 1.8549 - q0_loss: 0.0268 - q1_loss: 0.0787 - q2_loss: 0.0772 - q3_loss: 0.0469 - q4_loss: 1.0485 - q5_loss: 0.0574 - q6_loss: 0.3711 - q7_loss: 0.0610 - q8_loss: 0.0700 - val_loss: 1.6594 - val_q0_loss: 0.0303 - val_q1_loss: 0.0251 - val_q2_loss: 0.0524 - val_q3_loss: 0.0500 - val_q4_loss: 0.8177 - val_q5_loss: 0.0699 - val_q6_loss: 0.3042 - val_q7_loss: 0.0741 - val_q8_loss: 0.0893\n",
      "Epoch 56/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 1.7631 - q0_loss: 0.0264 - q1_loss: 0.0708 - q2_loss: 0.0765 - q3_loss: 0.0333 - q4_loss: 1.0130 - q5_loss: 0.0412 - q6_loss: 0.3712 - q7_loss: 0.0451 - q8_loss: 0.0725 - val_loss: 1.6144 - val_q0_loss: 0.0212 - val_q1_loss: 0.0978 - val_q2_loss: 0.0658 - val_q3_loss: 0.0393 - val_q4_loss: 0.8170 - val_q5_loss: 0.0494 - val_q6_loss: 0.3032 - val_q7_loss: 0.0445 - val_q8_loss: 0.0411\n",
      "Epoch 57/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1.6566 - q0_loss: 0.0227 - q1_loss: 0.0594 - q2_loss: 0.0750 - q3_loss: 0.0239 - q4_loss: 1.0206 - q5_loss: 0.0296 - q6_loss: 0.3519 - q7_loss: 0.0327 - q8_loss: 0.0607 - val_loss: 1.5421 - val_q0_loss: 0.0336 - val_q1_loss: 0.0473 - val_q2_loss: 0.0657 - val_q3_loss: 0.0568 - val_q4_loss: 0.8638 - val_q5_loss: 0.0620 - val_q6_loss: 0.1873 - val_q7_loss: 0.0725 - val_q8_loss: 0.0344\n",
      "Epoch 58/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 1.6221 - q0_loss: 0.0274 - q1_loss: 0.0360 - q2_loss: 0.0758 - q3_loss: 0.0338 - q4_loss: 1.0060 - q5_loss: 0.0422 - q6_loss: 0.3214 - q7_loss: 0.0487 - q8_loss: 0.0581 - val_loss: 1.4090 - val_q0_loss: 0.0309 - val_q1_loss: 0.0221 - val_q2_loss: 0.0677 - val_q3_loss: 0.0361 - val_q4_loss: 0.8265 - val_q5_loss: 0.0373 - val_q6_loss: 0.1980 - val_q7_loss: 0.0503 - val_q8_loss: 0.0329\n",
      "Epoch 59/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 1.6108 - q0_loss: 0.0309 - q1_loss: 0.0261 - q2_loss: 0.0771 - q3_loss: 0.0417 - q4_loss: 0.9772 - q5_loss: 0.0519 - q6_loss: 0.3068 - q7_loss: 0.0603 - q8_loss: 0.0612 - val_loss: 1.5468 - val_q0_loss: 0.0427 - val_q1_loss: 0.0194 - val_q2_loss: 0.0675 - val_q3_loss: 0.0702 - val_q4_loss: 0.8345 - val_q5_loss: 0.0806 - val_q6_loss: 0.1450 - val_q7_loss: 0.0961 - val_q8_loss: 0.0686\n",
      "Epoch 60/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 1.5979 - q0_loss: 0.0323 - q1_loss: 0.0207 - q2_loss: 0.0774 - q3_loss: 0.0491 - q4_loss: 0.9476 - q5_loss: 0.0604 - q6_loss: 0.2765 - q7_loss: 0.0675 - q8_loss: 0.0594 - val_loss: 1.4020 - val_q0_loss: 0.0343 - val_q1_loss: 0.0294 - val_q2_loss: 0.0668 - val_q3_loss: 0.0457 - val_q4_loss: 0.7960 - val_q5_loss: 0.0496 - val_q6_loss: 0.1484 - val_q7_loss: 0.0657 - val_q8_loss: 0.0492\n",
      "Epoch 61/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 1.4808 - q0_loss: 0.0243 - q1_loss: 0.0217 - q2_loss: 0.0734 - q3_loss: 0.0339 - q4_loss: 0.9389 - q5_loss: 0.0411 - q6_loss: 0.2518 - q7_loss: 0.0462 - q8_loss: 0.0538 - val_loss: 1.2234 - val_q0_loss: 0.0203 - val_q1_loss: 0.0132 - val_q2_loss: 0.0504 - val_q3_loss: 0.0202 - val_q4_loss: 0.7584 - val_q5_loss: 0.0219 - val_q6_loss: 0.1400 - val_q7_loss: 0.0301 - val_q8_loss: 0.0346\n",
      "Epoch 62/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 1.4212 - q0_loss: 0.0235 - q1_loss: 0.0290 - q2_loss: 0.0701 - q3_loss: 0.0313 - q4_loss: 0.9208 - q5_loss: 0.0390 - q6_loss: 0.2294 - q7_loss: 0.0438 - q8_loss: 0.0454 - val_loss: 1.3750 - val_q0_loss: 0.0204 - val_q1_loss: 0.0669 - val_q2_loss: 0.0419 - val_q3_loss: 0.0528 - val_q4_loss: 0.6869 - val_q5_loss: 0.0726 - val_q6_loss: 0.1919 - val_q7_loss: 0.0684 - val_q8_loss: 0.0392\n",
      "Epoch 63/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1.5384 - q0_loss: 0.0287 - q1_loss: 0.0752 - q2_loss: 0.0735 - q3_loss: 0.0501 - q4_loss: 0.8887 - q5_loss: 0.0630 - q6_loss: 0.2392 - q7_loss: 0.0678 - q8_loss: 0.0563 - val_loss: 1.3440 - val_q0_loss: 0.0410 - val_q1_loss: 0.0270 - val_q2_loss: 0.0697 - val_q3_loss: 0.0604 - val_q4_loss: 0.7498 - val_q5_loss: 0.0698 - val_q6_loss: 0.1060 - val_q7_loss: 0.0848 - val_q8_loss: 0.0581\n",
      "Epoch 64/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1.5043 - q0_loss: 0.0352 - q1_loss: 0.0525 - q2_loss: 0.0800 - q3_loss: 0.0467 - q4_loss: 0.8602 - q5_loss: 0.0593 - q6_loss: 0.2007 - q7_loss: 0.0692 - q8_loss: 0.0804 - val_loss: 1.2831 - val_q0_loss: 0.0335 - val_q1_loss: 0.0170 - val_q2_loss: 0.0586 - val_q3_loss: 0.0550 - val_q4_loss: 0.7281 - val_q5_loss: 0.0643 - val_q6_loss: 0.1094 - val_q7_loss: 0.0756 - val_q8_loss: 0.0400\n",
      "Epoch 65/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 1.3363 - q0_loss: 0.0230 - q1_loss: 0.0429 - q2_loss: 0.0682 - q3_loss: 0.0327 - q4_loss: 0.8419 - q5_loss: 0.0401 - q6_loss: 0.2011 - q7_loss: 0.0434 - q8_loss: 0.0359 - val_loss: 1.2708 - val_q0_loss: 0.0207 - val_q1_loss: 0.0692 - val_q2_loss: 0.0417 - val_q3_loss: 0.0459 - val_q4_loss: 0.7082 - val_q5_loss: 0.0515 - val_q6_loss: 0.1217 - val_q7_loss: 0.0546 - val_q8_loss: 0.0372\n",
      "Epoch 66/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 1.3650 - q0_loss: 0.0265 - q1_loss: 0.0438 - q2_loss: 0.0703 - q3_loss: 0.0381 - q4_loss: 0.8241 - q5_loss: 0.0491 - q6_loss: 0.1837 - q7_loss: 0.0541 - q8_loss: 0.0577 - val_loss: 1.1304 - val_q0_loss: 0.0163 - val_q1_loss: 0.0448 - val_q2_loss: 0.0385 - val_q3_loss: 0.0349 - val_q4_loss: 0.6270 - val_q5_loss: 0.0501 - val_q6_loss: 0.1200 - val_q7_loss: 0.0491 - val_q8_loss: 0.0356\n",
      "Epoch 67/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 1.2584 - q0_loss: 0.0237 - q1_loss: 0.0378 - q2_loss: 0.0704 - q3_loss: 0.0258 - q4_loss: 0.8085 - q5_loss: 0.0331 - q6_loss: 0.1865 - q7_loss: 0.0380 - q8_loss: 0.0444 - val_loss: 1.1344 - val_q0_loss: 0.0215 - val_q1_loss: 0.0791 - val_q2_loss: 0.0523 - val_q3_loss: 0.0236 - val_q4_loss: 0.6181 - val_q5_loss: 0.0339 - val_q6_loss: 0.1114 - val_q7_loss: 0.0354 - val_q8_loss: 0.0520\n",
      "Epoch 68/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1.2290 - q0_loss: 0.0231 - q1_loss: 0.0371 - q2_loss: 0.0663 - q3_loss: 0.0238 - q4_loss: 0.7742 - q5_loss: 0.0297 - q6_loss: 0.1762 - q7_loss: 0.0338 - q8_loss: 0.0467 - val_loss: 1.1666 - val_q0_loss: 0.0158 - val_q1_loss: 0.0755 - val_q2_loss: 0.0401 - val_q3_loss: 0.0514 - val_q4_loss: 0.5753 - val_q5_loss: 0.0679 - val_q6_loss: 0.1317 - val_q7_loss: 0.0665 - val_q8_loss: 0.0306\n",
      "Epoch 69/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1.2710 - q0_loss: 0.0261 - q1_loss: 0.0486 - q2_loss: 0.0694 - q3_loss: 0.0362 - q4_loss: 0.7558 - q5_loss: 0.0462 - q6_loss: 0.1857 - q7_loss: 0.0520 - q8_loss: 0.0543 - val_loss: 1.2118 - val_q0_loss: 0.0308 - val_q1_loss: 0.0524 - val_q2_loss: 0.0542 - val_q3_loss: 0.0495 - val_q4_loss: 0.5705 - val_q5_loss: 0.0691 - val_q6_loss: 0.0914 - val_q7_loss: 0.0779 - val_q8_loss: 0.1128\n",
      "Epoch 70/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 1.2249 - q0_loss: 0.0252 - q1_loss: 0.0446 - q2_loss: 0.0661 - q3_loss: 0.0319 - q4_loss: 0.7398 - q5_loss: 0.0411 - q6_loss: 0.1790 - q7_loss: 0.0431 - q8_loss: 0.0474 - val_loss: 1.0805 - val_q0_loss: 0.0305 - val_q1_loss: 0.0238 - val_q2_loss: 0.0550 - val_q3_loss: 0.0362 - val_q4_loss: 0.5949 - val_q5_loss: 0.0414 - val_q6_loss: 0.1142 - val_q7_loss: 0.0504 - val_q8_loss: 0.0366\n",
      "Epoch 71/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 1.1380 - q0_loss: 0.0215 - q1_loss: 0.0288 - q2_loss: 0.0640 - q3_loss: 0.0240 - q4_loss: 0.7273 - q5_loss: 0.0311 - q6_loss: 0.1741 - q7_loss: 0.0343 - q8_loss: 0.0386 - val_loss: 0.9429 - val_q0_loss: 0.0169 - val_q1_loss: 0.0423 - val_q2_loss: 0.0433 - val_q3_loss: 0.0191 - val_q4_loss: 0.5418 - val_q5_loss: 0.0289 - val_q6_loss: 0.0945 - val_q7_loss: 0.0264 - val_q8_loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 1.1810 - q0_loss: 0.0278 - q1_loss: 0.0201 - q2_loss: 0.0661 - q3_loss: 0.0366 - q4_loss: 0.6836 - q5_loss: 0.0463 - q6_loss: 0.1730 - q7_loss: 0.0518 - q8_loss: 0.0501 - val_loss: 1.1947 - val_q0_loss: 0.0448 - val_q1_loss: 0.0507 - val_q2_loss: 0.0656 - val_q3_loss: 0.0521 - val_q4_loss: 0.5584 - val_q5_loss: 0.0613 - val_q6_loss: 0.1192 - val_q7_loss: 0.0758 - val_q8_loss: 0.0825\n",
      "Epoch 73/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 1.2567 - q0_loss: 0.0340 - q1_loss: 0.0324 - q2_loss: 0.0738 - q3_loss: 0.0492 - q4_loss: 0.6852 - q5_loss: 0.0631 - q6_loss: 0.1870 - q7_loss: 0.0726 - q8_loss: 0.0711 - val_loss: 0.9674 - val_q0_loss: 0.0170 - val_q1_loss: 0.0453 - val_q2_loss: 0.0333 - val_q3_loss: 0.0194 - val_q4_loss: 0.5210 - val_q5_loss: 0.0273 - val_q6_loss: 0.1112 - val_q7_loss: 0.0286 - val_q8_loss: 0.0492\n",
      "Epoch 74/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 1.1482 - q0_loss: 0.0224 - q1_loss: 0.0555 - q2_loss: 0.0607 - q3_loss: 0.0361 - q4_loss: 0.6613 - q5_loss: 0.0460 - q6_loss: 0.1927 - q7_loss: 0.0498 - q8_loss: 0.0439 - val_loss: 0.8894 - val_q0_loss: 0.0220 - val_q1_loss: 0.0531 - val_q2_loss: 0.0500 - val_q3_loss: 0.0121 - val_q4_loss: 0.4886 - val_q5_loss: 0.0197 - val_q6_loss: 0.0918 - val_q7_loss: 0.0188 - val_q8_loss: 0.0385\n",
      "Epoch 75/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 1.1010 - q0_loss: 0.0243 - q1_loss: 0.0512 - q2_loss: 0.0627 - q3_loss: 0.0265 - q4_loss: 0.6382 - q5_loss: 0.0355 - q6_loss: 0.1693 - q7_loss: 0.0385 - q8_loss: 0.0520 - val_loss: 0.8611 - val_q0_loss: 0.0195 - val_q1_loss: 0.0204 - val_q2_loss: 0.0420 - val_q3_loss: 0.0162 - val_q4_loss: 0.4803 - val_q5_loss: 0.0188 - val_q6_loss: 0.1092 - val_q7_loss: 0.0208 - val_q8_loss: 0.0219\n",
      "Epoch 76/300\n",
      "269/269 [==============================] - 0s 167us/sample - loss: 1.0368 - q0_loss: 0.0215 - q1_loss: 0.0522 - q2_loss: 0.0654 - q3_loss: 0.0186 - q4_loss: 0.6010 - q5_loss: 0.0250 - q6_loss: 0.1626 - q7_loss: 0.0269 - q8_loss: 0.0428 - val_loss: 1.0101 - val_q0_loss: 0.0251 - val_q1_loss: 0.0493 - val_q2_loss: 0.0472 - val_q3_loss: 0.0460 - val_q4_loss: 0.4839 - val_q5_loss: 0.0511 - val_q6_loss: 0.1342 - val_q7_loss: 0.0572 - val_q8_loss: 0.0179\n",
      "Epoch 77/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 1.1196 - q0_loss: 0.0278 - q1_loss: 0.0578 - q2_loss: 0.0637 - q3_loss: 0.0358 - q4_loss: 0.5824 - q5_loss: 0.0457 - q6_loss: 0.1680 - q7_loss: 0.0529 - q8_loss: 0.0631 - val_loss: 0.9105 - val_q0_loss: 0.0264 - val_q1_loss: 0.0332 - val_q2_loss: 0.0536 - val_q3_loss: 0.0332 - val_q4_loss: 0.4497 - val_q5_loss: 0.0360 - val_q6_loss: 0.1143 - val_q7_loss: 0.0457 - val_q8_loss: 0.0339\n",
      "Epoch 78/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 1.0170 - q0_loss: 0.0219 - q1_loss: 0.0459 - q2_loss: 0.0599 - q3_loss: 0.0284 - q4_loss: 0.5652 - q5_loss: 0.0368 - q6_loss: 0.1697 - q7_loss: 0.0390 - q8_loss: 0.0352 - val_loss: 1.0206 - val_q0_loss: 0.0338 - val_q1_loss: 0.0253 - val_q2_loss: 0.0446 - val_q3_loss: 0.0573 - val_q4_loss: 0.3911 - val_q5_loss: 0.0804 - val_q6_loss: 0.1003 - val_q7_loss: 0.0861 - val_q8_loss: 0.0935\n",
      "Epoch 79/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 1.0376 - q0_loss: 0.0292 - q1_loss: 0.0292 - q2_loss: 0.0605 - q3_loss: 0.0413 - q4_loss: 0.5438 - q5_loss: 0.0531 - q6_loss: 0.1689 - q7_loss: 0.0596 - q8_loss: 0.0556 - val_loss: 0.8866 - val_q0_loss: 0.0202 - val_q1_loss: 0.0407 - val_q2_loss: 0.0315 - val_q3_loss: 0.0470 - val_q4_loss: 0.3696 - val_q5_loss: 0.0659 - val_q6_loss: 0.1050 - val_q7_loss: 0.0656 - val_q8_loss: 0.0417\n",
      "Epoch 80/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.9996 - q0_loss: 0.0269 - q1_loss: 0.0352 - q2_loss: 0.0574 - q3_loss: 0.0392 - q4_loss: 0.5368 - q5_loss: 0.0504 - q6_loss: 0.1755 - q7_loss: 0.0548 - q8_loss: 0.0412 - val_loss: 0.8282 - val_q0_loss: 0.0294 - val_q1_loss: 0.0644 - val_q2_loss: 0.0573 - val_q3_loss: 0.0178 - val_q4_loss: 0.3757 - val_q5_loss: 0.0200 - val_q6_loss: 0.0950 - val_q7_loss: 0.0302 - val_q8_loss: 0.0568\n",
      "Epoch 81/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.9778 - q0_loss: 0.0286 - q1_loss: 0.0333 - q2_loss: 0.0583 - q3_loss: 0.0371 - q4_loss: 0.5045 - q5_loss: 0.0483 - q6_loss: 0.1654 - q7_loss: 0.0533 - q8_loss: 0.0520 - val_loss: 0.7891 - val_q0_loss: 0.0198 - val_q1_loss: 0.0199 - val_q2_loss: 0.0361 - val_q3_loss: 0.0255 - val_q4_loss: 0.3655 - val_q5_loss: 0.0335 - val_q6_loss: 0.1114 - val_q7_loss: 0.0376 - val_q8_loss: 0.0355\n",
      "Epoch 82/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.9076 - q0_loss: 0.0234 - q1_loss: 0.0287 - q2_loss: 0.0550 - q3_loss: 0.0285 - q4_loss: 0.4843 - q5_loss: 0.0374 - q6_loss: 0.1633 - q7_loss: 0.0413 - q8_loss: 0.0403 - val_loss: 0.7496 - val_q0_loss: 0.0167 - val_q1_loss: 0.0240 - val_q2_loss: 0.0294 - val_q3_loss: 0.0199 - val_q4_loss: 0.3341 - val_q5_loss: 0.0327 - val_q6_loss: 0.0991 - val_q7_loss: 0.0350 - val_q8_loss: 0.0522\n",
      "Epoch 83/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.8627 - q0_loss: 0.0209 - q1_loss: 0.0212 - q2_loss: 0.0533 - q3_loss: 0.0233 - q4_loss: 0.4561 - q5_loss: 0.0326 - q6_loss: 0.1611 - q7_loss: 0.0356 - q8_loss: 0.0390 - val_loss: 0.7506 - val_q0_loss: 0.0253 - val_q1_loss: 0.0182 - val_q2_loss: 0.0481 - val_q3_loss: 0.0276 - val_q4_loss: 0.3267 - val_q5_loss: 0.0311 - val_q6_loss: 0.1153 - val_q7_loss: 0.0386 - val_q8_loss: 0.0335\n",
      "Epoch 84/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.8121 - q0_loss: 0.0212 - q1_loss: 0.0172 - q2_loss: 0.0542 - q3_loss: 0.0217 - q4_loss: 0.4476 - q5_loss: 0.0278 - q6_loss: 0.1663 - q7_loss: 0.0311 - q8_loss: 0.0323 - val_loss: 0.6817 - val_q0_loss: 0.0203 - val_q1_loss: 0.0164 - val_q2_loss: 0.0391 - val_q3_loss: 0.0206 - val_q4_loss: 0.3017 - val_q5_loss: 0.0248 - val_q6_loss: 0.1029 - val_q7_loss: 0.0304 - val_q8_loss: 0.0292\n",
      "Epoch 85/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.7926 - q0_loss: 0.0207 - q1_loss: 0.0258 - q2_loss: 0.0520 - q3_loss: 0.0192 - q4_loss: 0.4169 - q5_loss: 0.0278 - q6_loss: 0.1561 - q7_loss: 0.0300 - q8_loss: 0.0355 - val_loss: 0.7803 - val_q0_loss: 0.0302 - val_q1_loss: 0.0123 - val_q2_loss: 0.0478 - val_q3_loss: 0.0447 - val_q4_loss: 0.2958 - val_q5_loss: 0.0507 - val_q6_loss: 0.1243 - val_q7_loss: 0.0598 - val_q8_loss: 0.0378\n",
      "Epoch 86/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.9418 - q0_loss: 0.0333 - q1_loss: 0.0302 - q2_loss: 0.0530 - q3_loss: 0.0550 - q4_loss: 0.3898 - q5_loss: 0.0698 - q6_loss: 0.1751 - q7_loss: 0.0765 - q8_loss: 0.0535 - val_loss: 0.6224 - val_q0_loss: 0.0200 - val_q1_loss: 0.0542 - val_q2_loss: 0.0426 - val_q3_loss: 0.0102 - val_q4_loss: 0.2475 - val_q5_loss: 0.0164 - val_q6_loss: 0.0910 - val_q7_loss: 0.0152 - val_q8_loss: 0.0372\n",
      "Epoch 87/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.8880 - q0_loss: 0.0288 - q1_loss: 0.0372 - q2_loss: 0.0575 - q3_loss: 0.0446 - q4_loss: 0.3805 - q5_loss: 0.0558 - q6_loss: 0.1733 - q7_loss: 0.0617 - q8_loss: 0.0509 - val_loss: 0.8812 - val_q0_loss: 0.0340 - val_q1_loss: 0.0364 - val_q2_loss: 0.0406 - val_q3_loss: 0.0759 - val_q4_loss: 0.2064 - val_q5_loss: 0.1003 - val_q6_loss: 0.1204 - val_q7_loss: 0.1065 - val_q8_loss: 0.0651\n",
      "Epoch 88/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.8993 - q0_loss: 0.0304 - q1_loss: 0.0252 - q2_loss: 0.0609 - q3_loss: 0.0516 - q4_loss: 0.3592 - q5_loss: 0.0648 - q6_loss: 0.1778 - q7_loss: 0.0722 - q8_loss: 0.0560 - val_loss: 0.7077 - val_q0_loss: 0.0244 - val_q1_loss: 0.0169 - val_q2_loss: 0.0329 - val_q3_loss: 0.0487 - val_q4_loss: 0.2017 - val_q5_loss: 0.0676 - val_q6_loss: 0.0926 - val_q7_loss: 0.0726 - val_q8_loss: 0.0604\n",
      "Epoch 89/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 0.8134 - q0_loss: 0.0300 - q1_loss: 0.0183 - q2_loss: 0.0492 - q3_loss: 0.0424 - q4_loss: 0.3337 - q5_loss: 0.0557 - q6_loss: 0.1603 - q7_loss: 0.0620 - q8_loss: 0.0565 - val_loss: 0.5513 - val_q0_loss: 0.0168 - val_q1_loss: 0.0127 - val_q2_loss: 0.0286 - val_q3_loss: 0.0174 - val_q4_loss: 0.1954 - val_q5_loss: 0.0296 - val_q6_loss: 0.0876 - val_q7_loss: 0.0297 - val_q8_loss: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 0.6908 - q0_loss: 0.0218 - q1_loss: 0.0184 - q2_loss: 0.0487 - q3_loss: 0.0221 - q4_loss: 0.3253 - q5_loss: 0.0306 - q6_loss: 0.1596 - q7_loss: 0.0354 - q8_loss: 0.0423 - val_loss: 0.6262 - val_q0_loss: 0.0220 - val_q1_loss: 0.0158 - val_q2_loss: 0.0280 - val_q3_loss: 0.0348 - val_q4_loss: 0.1723 - val_q5_loss: 0.0494 - val_q6_loss: 0.0892 - val_q7_loss: 0.0534 - val_q8_loss: 0.0550\n",
      "Epoch 91/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.6843 - q0_loss: 0.0219 - q1_loss: 0.0228 - q2_loss: 0.0501 - q3_loss: 0.0244 - q4_loss: 0.2868 - q5_loss: 0.0303 - q6_loss: 0.1568 - q7_loss: 0.0364 - q8_loss: 0.0357 - val_loss: 0.5006 - val_q0_loss: 0.0206 - val_q1_loss: 0.0147 - val_q2_loss: 0.0414 - val_q3_loss: 0.0155 - val_q4_loss: 0.1650 - val_q5_loss: 0.0150 - val_q6_loss: 0.1068 - val_q7_loss: 0.0203 - val_q8_loss: 0.0186\n",
      "Epoch 92/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.7227 - q0_loss: 0.0280 - q1_loss: 0.0223 - q2_loss: 0.0489 - q3_loss: 0.0396 - q4_loss: 0.2860 - q5_loss: 0.0497 - q6_loss: 0.1693 - q7_loss: 0.0559 - q8_loss: 0.0401 - val_loss: 0.4609 - val_q0_loss: 0.0189 - val_q1_loss: 0.0258 - val_q2_loss: 0.0384 - val_q3_loss: 0.0081 - val_q4_loss: 0.1406 - val_q5_loss: 0.0135 - val_q6_loss: 0.0894 - val_q7_loss: 0.0152 - val_q8_loss: 0.0272\n",
      "Epoch 93/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.8256 - q0_loss: 0.0305 - q1_loss: 0.0439 - q2_loss: 0.0475 - q3_loss: 0.0542 - q4_loss: 0.2768 - q5_loss: 0.0691 - q6_loss: 0.1844 - q7_loss: 0.0731 - q8_loss: 0.0430 - val_loss: 0.9282 - val_q0_loss: 0.0469 - val_q1_loss: 0.0499 - val_q2_loss: 0.0557 - val_q3_loss: 0.0941 - val_q4_loss: 0.1675 - val_q5_loss: 0.1142 - val_q6_loss: 0.1649 - val_q7_loss: 0.1259 - val_q8_loss: 0.0559\n",
      "Epoch 94/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.9917 - q0_loss: 0.0386 - q1_loss: 0.0774 - q2_loss: 0.0532 - q3_loss: 0.0798 - q4_loss: 0.2828 - q5_loss: 0.0993 - q6_loss: 0.1820 - q7_loss: 0.1080 - q8_loss: 0.0682 - val_loss: 0.8223 - val_q0_loss: 0.0404 - val_q1_loss: 0.0438 - val_q2_loss: 0.0412 - val_q3_loss: 0.0700 - val_q4_loss: 0.1510 - val_q5_loss: 0.0913 - val_q6_loss: 0.0987 - val_q7_loss: 0.1020 - val_q8_loss: 0.1044\n",
      "Epoch 95/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.9785 - q0_loss: 0.0466 - q1_loss: 0.0421 - q2_loss: 0.0528 - q3_loss: 0.0830 - q4_loss: 0.2697 - q5_loss: 0.1044 - q6_loss: 0.1902 - q7_loss: 0.1143 - q8_loss: 0.0762 - val_loss: 0.5041 - val_q0_loss: 0.0185 - val_q1_loss: 0.0433 - val_q2_loss: 0.0427 - val_q3_loss: 0.0113 - val_q4_loss: 0.1455 - val_q5_loss: 0.0154 - val_q6_loss: 0.0966 - val_q7_loss: 0.0165 - val_q8_loss: 0.0344\n",
      "Epoch 96/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.9130 - q0_loss: 0.0364 - q1_loss: 0.0489 - q2_loss: 0.0527 - q3_loss: 0.0738 - q4_loss: 0.2573 - q5_loss: 0.0914 - q6_loss: 0.1906 - q7_loss: 0.0993 - q8_loss: 0.0550 - val_loss: 0.6324 - val_q0_loss: 0.0202 - val_q1_loss: 0.0659 - val_q2_loss: 0.0354 - val_q3_loss: 0.0349 - val_q4_loss: 0.1390 - val_q5_loss: 0.0412 - val_q6_loss: 0.1461 - val_q7_loss: 0.0441 - val_q8_loss: 0.0363\n",
      "Epoch 97/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 0.8086 - q0_loss: 0.0339 - q1_loss: 0.0439 - q2_loss: 0.0454 - q3_loss: 0.0484 - q4_loss: 0.2723 - q5_loss: 0.0616 - q6_loss: 0.1695 - q7_loss: 0.0694 - q8_loss: 0.0702 - val_loss: 0.6989 - val_q0_loss: 0.0353 - val_q1_loss: 0.0342 - val_q2_loss: 0.0594 - val_q3_loss: 0.0478 - val_q4_loss: 0.1447 - val_q5_loss: 0.0605 - val_q6_loss: 0.1203 - val_q7_loss: 0.0727 - val_q8_loss: 0.0650\n",
      "Epoch 98/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.7204 - q0_loss: 0.0294 - q1_loss: 0.0252 - q2_loss: 0.0426 - q3_loss: 0.0411 - q4_loss: 0.2522 - q5_loss: 0.0523 - q6_loss: 0.1556 - q7_loss: 0.0583 - q8_loss: 0.0519 - val_loss: 0.5488 - val_q0_loss: 0.0240 - val_q1_loss: 0.0358 - val_q2_loss: 0.0514 - val_q3_loss: 0.0194 - val_q4_loss: 0.1475 - val_q5_loss: 0.0239 - val_q6_loss: 0.1090 - val_q7_loss: 0.0322 - val_q8_loss: 0.0423\n",
      "Epoch 99/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.6176 - q0_loss: 0.0242 - q1_loss: 0.0221 - q2_loss: 0.0412 - q3_loss: 0.0219 - q4_loss: 0.2773 - q5_loss: 0.0299 - q6_loss: 0.1559 - q7_loss: 0.0330 - q8_loss: 0.0386 - val_loss: 0.5053 - val_q0_loss: 0.0219 - val_q1_loss: 0.0204 - val_q2_loss: 0.0443 - val_q3_loss: 0.0190 - val_q4_loss: 0.1414 - val_q5_loss: 0.0223 - val_q6_loss: 0.1158 - val_q7_loss: 0.0268 - val_q8_loss: 0.0209\n",
      "Epoch 100/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.6875 - q0_loss: 0.0269 - q1_loss: 0.0200 - q2_loss: 0.0437 - q3_loss: 0.0368 - q4_loss: 0.2494 - q5_loss: 0.0461 - q6_loss: 0.1543 - q7_loss: 0.0529 - q8_loss: 0.0499 - val_loss: 0.5351 - val_q0_loss: 0.0248 - val_q1_loss: 0.0182 - val_q2_loss: 0.0423 - val_q3_loss: 0.0273 - val_q4_loss: 0.1345 - val_q5_loss: 0.0320 - val_q6_loss: 0.1290 - val_q7_loss: 0.0360 - val_q8_loss: 0.0206\n",
      "Epoch 101/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.6614 - q0_loss: 0.0272 - q1_loss: 0.0159 - q2_loss: 0.0366 - q3_loss: 0.0374 - q4_loss: 0.2698 - q5_loss: 0.0476 - q6_loss: 0.1588 - q7_loss: 0.0522 - q8_loss: 0.0433 - val_loss: 0.6557 - val_q0_loss: 0.0312 - val_q1_loss: 0.0311 - val_q2_loss: 0.0445 - val_q3_loss: 0.0507 - val_q4_loss: 0.1379 - val_q5_loss: 0.0601 - val_q6_loss: 0.1392 - val_q7_loss: 0.0661 - val_q8_loss: 0.0278\n",
      "Epoch 102/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 0.6462 - q0_loss: 0.0225 - q1_loss: 0.0239 - q2_loss: 0.0370 - q3_loss: 0.0331 - q4_loss: 0.2660 - q5_loss: 0.0424 - q6_loss: 0.1548 - q7_loss: 0.0475 - q8_loss: 0.0364 - val_loss: 0.5296 - val_q0_loss: 0.0207 - val_q1_loss: 0.0135 - val_q2_loss: 0.0365 - val_q3_loss: 0.0265 - val_q4_loss: 0.1392 - val_q5_loss: 0.0327 - val_q6_loss: 0.1083 - val_q7_loss: 0.0385 - val_q8_loss: 0.0274\n",
      "Epoch 103/300\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 0.6614 - q0_loss: 0.0241 - q1_loss: 0.0186 - q2_loss: 0.0420 - q3_loss: 0.0354 - q4_loss: 0.2545 - q5_loss: 0.0446 - q6_loss: 0.1603 - q7_loss: 0.0519 - q8_loss: 0.0366 - val_loss: 0.7506 - val_q0_loss: 0.0426 - val_q1_loss: 0.0154 - val_q2_loss: 0.0579 - val_q3_loss: 0.0659 - val_q4_loss: 0.1364 - val_q5_loss: 0.0790 - val_q6_loss: 0.1402 - val_q7_loss: 0.0913 - val_q8_loss: 0.0691\n",
      "Epoch 104/300\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 0.7036 - q0_loss: 0.0290 - q1_loss: 0.0158 - q2_loss: 0.0390 - q3_loss: 0.0420 - q4_loss: 0.2584 - q5_loss: 0.0530 - q6_loss: 0.1597 - q7_loss: 0.0600 - q8_loss: 0.0469 - val_loss: 0.5116 - val_q0_loss: 0.0196 - val_q1_loss: 0.0200 - val_q2_loss: 0.0300 - val_q3_loss: 0.0255 - val_q4_loss: 0.1346 - val_q5_loss: 0.0284 - val_q6_loss: 0.1171 - val_q7_loss: 0.0332 - val_q8_loss: 0.0227\n",
      "Epoch 105/300\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 0.5819 - q0_loss: 0.0204 - q1_loss: 0.0162 - q2_loss: 0.0297 - q3_loss: 0.0219 - q4_loss: 0.2472 - q5_loss: 0.0292 - q6_loss: 0.1417 - q7_loss: 0.0322 - q8_loss: 0.0305 - val_loss: 0.4567 - val_q0_loss: 0.0198 - val_q1_loss: 0.0218 - val_q2_loss: 0.0327 - val_q3_loss: 0.0126 - val_q4_loss: 0.1408 - val_q5_loss: 0.0162 - val_q6_loss: 0.0971 - val_q7_loss: 0.0178 - val_q8_loss: 0.0201\n",
      "Epoch 106/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.5586 - q0_loss: 0.0202 - q1_loss: 0.0206 - q2_loss: 0.0332 - q3_loss: 0.0139 - q4_loss: 0.2477 - q5_loss: 0.0178 - q6_loss: 0.1483 - q7_loss: 0.0209 - q8_loss: 0.0283 - val_loss: 0.5125 - val_q0_loss: 0.0242 - val_q1_loss: 0.0208 - val_q2_loss: 0.0354 - val_q3_loss: 0.0264 - val_q4_loss: 0.1345 - val_q5_loss: 0.0289 - val_q6_loss: 0.1174 - val_q7_loss: 0.0337 - val_q8_loss: 0.0247\n",
      "Epoch 107/300\n",
      "269/269 [==============================] - 0s 217us/sample - loss: 0.6389 - q0_loss: 0.0259 - q1_loss: 0.0324 - q2_loss: 0.0399 - q3_loss: 0.0256 - q4_loss: 0.2493 - q5_loss: 0.0331 - q6_loss: 0.1554 - q7_loss: 0.0392 - q8_loss: 0.0492 - val_loss: 0.5683 - val_q0_loss: 0.0191 - val_q1_loss: 0.0401 - val_q2_loss: 0.0193 - val_q3_loss: 0.0395 - val_q4_loss: 0.1478 - val_q5_loss: 0.0531 - val_q6_loss: 0.0929 - val_q7_loss: 0.0559 - val_q8_loss: 0.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.6591 - q0_loss: 0.0242 - q1_loss: 0.0290 - q2_loss: 0.0338 - q3_loss: 0.0341 - q4_loss: 0.2624 - q5_loss: 0.0435 - q6_loss: 0.1505 - q7_loss: 0.0493 - q8_loss: 0.0446 - val_loss: 0.5336 - val_q0_loss: 0.0200 - val_q1_loss: 0.0401 - val_q2_loss: 0.0233 - val_q3_loss: 0.0309 - val_q4_loss: 0.1454 - val_q5_loss: 0.0417 - val_q6_loss: 0.0889 - val_q7_loss: 0.0440 - val_q8_loss: 0.0193\n",
      "Epoch 109/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.6318 - q0_loss: 0.0219 - q1_loss: 0.0294 - q2_loss: 0.0310 - q3_loss: 0.0316 - q4_loss: 0.2607 - q5_loss: 0.0402 - q6_loss: 0.1557 - q7_loss: 0.0425 - q8_loss: 0.0292 - val_loss: 0.4591 - val_q0_loss: 0.0220 - val_q1_loss: 0.0248 - val_q2_loss: 0.0304 - val_q3_loss: 0.0159 - val_q4_loss: 0.1377 - val_q5_loss: 0.0198 - val_q6_loss: 0.0901 - val_q7_loss: 0.0223 - val_q8_loss: 0.0235\n",
      "Epoch 110/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.5470 - q0_loss: 0.0185 - q1_loss: 0.0156 - q2_loss: 0.0289 - q3_loss: 0.0166 - q4_loss: 0.2530 - q5_loss: 0.0218 - q6_loss: 0.1466 - q7_loss: 0.0240 - q8_loss: 0.0274 - val_loss: 0.6451 - val_q0_loss: 0.0243 - val_q1_loss: 0.0214 - val_q2_loss: 0.0249 - val_q3_loss: 0.0574 - val_q4_loss: 0.1468 - val_q5_loss: 0.0737 - val_q6_loss: 0.0875 - val_q7_loss: 0.0801 - val_q8_loss: 0.0527\n",
      "Epoch 111/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.6672 - q0_loss: 0.0260 - q1_loss: 0.0169 - q2_loss: 0.0330 - q3_loss: 0.0377 - q4_loss: 0.2543 - q5_loss: 0.0472 - q6_loss: 0.1533 - q7_loss: 0.0520 - q8_loss: 0.0439 - val_loss: 0.4842 - val_q0_loss: 0.0190 - val_q1_loss: 0.0193 - val_q2_loss: 0.0211 - val_q3_loss: 0.0255 - val_q4_loss: 0.1396 - val_q5_loss: 0.0352 - val_q6_loss: 0.0779 - val_q7_loss: 0.0364 - val_q8_loss: 0.0268\n",
      "Epoch 112/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.5491 - q0_loss: 0.0204 - q1_loss: 0.0166 - q2_loss: 0.0255 - q3_loss: 0.0168 - q4_loss: 0.2526 - q5_loss: 0.0228 - q6_loss: 0.1417 - q7_loss: 0.0265 - q8_loss: 0.0310 - val_loss: 0.4356 - val_q0_loss: 0.0168 - val_q1_loss: 0.0245 - val_q2_loss: 0.0203 - val_q3_loss: 0.0161 - val_q4_loss: 0.1393 - val_q5_loss: 0.0252 - val_q6_loss: 0.0759 - val_q7_loss: 0.0248 - val_q8_loss: 0.0159\n",
      "Epoch 113/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.6207 - q0_loss: 0.0246 - q1_loss: 0.0185 - q2_loss: 0.0303 - q3_loss: 0.0317 - q4_loss: 0.2482 - q5_loss: 0.0411 - q6_loss: 0.1454 - q7_loss: 0.0457 - q8_loss: 0.0367 - val_loss: 0.4985 - val_q0_loss: 0.0245 - val_q1_loss: 0.0184 - val_q2_loss: 0.0343 - val_q3_loss: 0.0273 - val_q4_loss: 0.1325 - val_q5_loss: 0.0306 - val_q6_loss: 0.1053 - val_q7_loss: 0.0377 - val_q8_loss: 0.0296\n",
      "Epoch 114/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.6134 - q0_loss: 0.0225 - q1_loss: 0.0286 - q2_loss: 0.0243 - q3_loss: 0.0309 - q4_loss: 0.2506 - q5_loss: 0.0387 - q6_loss: 0.1450 - q7_loss: 0.0429 - q8_loss: 0.0328 - val_loss: 0.6476 - val_q0_loss: 0.0365 - val_q1_loss: 0.0189 - val_q2_loss: 0.0485 - val_q3_loss: 0.0541 - val_q4_loss: 0.1299 - val_q5_loss: 0.0631 - val_q6_loss: 0.1255 - val_q7_loss: 0.0749 - val_q8_loss: 0.0600\n",
      "Epoch 115/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.7066 - q0_loss: 0.0290 - q1_loss: 0.0460 - q2_loss: 0.0369 - q3_loss: 0.0382 - q4_loss: 0.2579 - q5_loss: 0.0475 - q6_loss: 0.1459 - q7_loss: 0.0568 - q8_loss: 0.0608 - val_loss: 0.4393 - val_q0_loss: 0.0183 - val_q1_loss: 0.0131 - val_q2_loss: 0.0228 - val_q3_loss: 0.0162 - val_q4_loss: 0.1331 - val_q5_loss: 0.0204 - val_q6_loss: 0.0922 - val_q7_loss: 0.0250 - val_q8_loss: 0.0222\n",
      "Epoch 116/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.6328 - q0_loss: 0.0203 - q1_loss: 0.0572 - q2_loss: 0.0255 - q3_loss: 0.0255 - q4_loss: 0.2468 - q5_loss: 0.0328 - q6_loss: 0.1443 - q7_loss: 0.0350 - q8_loss: 0.0439 - val_loss: 0.6184 - val_q0_loss: 0.0315 - val_q1_loss: 0.0614 - val_q2_loss: 0.0502 - val_q3_loss: 0.0335 - val_q4_loss: 0.1412 - val_q5_loss: 0.0407 - val_q6_loss: 0.0874 - val_q7_loss: 0.0487 - val_q8_loss: 0.0687\n",
      "Epoch 117/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.6628 - q0_loss: 0.0238 - q1_loss: 0.0643 - q2_loss: 0.0303 - q3_loss: 0.0267 - q4_loss: 0.2467 - q5_loss: 0.0338 - q6_loss: 0.1347 - q7_loss: 0.0393 - q8_loss: 0.0571 - val_loss: 0.6408 - val_q0_loss: 0.0156 - val_q1_loss: 0.0972 - val_q2_loss: 0.0175 - val_q3_loss: 0.0293 - val_q4_loss: 0.1393 - val_q5_loss: 0.0357 - val_q6_loss: 0.1184 - val_q7_loss: 0.0376 - val_q8_loss: 0.0703\n",
      "Epoch 118/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.6196 - q0_loss: 0.0221 - q1_loss: 0.0615 - q2_loss: 0.0285 - q3_loss: 0.0173 - q4_loss: 0.2460 - q5_loss: 0.0230 - q6_loss: 0.1351 - q7_loss: 0.0266 - q8_loss: 0.0493 - val_loss: 0.6007 - val_q0_loss: 0.0175 - val_q1_loss: 0.0549 - val_q2_loss: 0.0133 - val_q3_loss: 0.0509 - val_q4_loss: 0.1505 - val_q5_loss: 0.0666 - val_q6_loss: 0.0913 - val_q7_loss: 0.0700 - val_q8_loss: 0.0235\n",
      "Epoch 119/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 0.6550 - q0_loss: 0.0235 - q1_loss: 0.0376 - q2_loss: 0.0254 - q3_loss: 0.0386 - q4_loss: 0.2576 - q5_loss: 0.0483 - q6_loss: 0.1551 - q7_loss: 0.0523 - q8_loss: 0.0305 - val_loss: 0.6329 - val_q0_loss: 0.0221 - val_q1_loss: 0.0442 - val_q2_loss: 0.0225 - val_q3_loss: 0.0423 - val_q4_loss: 0.1397 - val_q5_loss: 0.0576 - val_q6_loss: 0.0894 - val_q7_loss: 0.0648 - val_q8_loss: 0.0658\n",
      "Epoch 120/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.6269 - q0_loss: 0.0226 - q1_loss: 0.0468 - q2_loss: 0.0240 - q3_loss: 0.0279 - q4_loss: 0.2537 - q5_loss: 0.0361 - q6_loss: 0.1411 - q7_loss: 0.0407 - q8_loss: 0.0491 - val_loss: 0.5804 - val_q0_loss: 0.0193 - val_q1_loss: 0.0488 - val_q2_loss: 0.0206 - val_q3_loss: 0.0407 - val_q4_loss: 0.1476 - val_q5_loss: 0.0546 - val_q6_loss: 0.0792 - val_q7_loss: 0.0578 - val_q8_loss: 0.0436\n",
      "Epoch 121/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.6247 - q0_loss: 0.0235 - q1_loss: 0.0395 - q2_loss: 0.0226 - q3_loss: 0.0320 - q4_loss: 0.2452 - q5_loss: 0.0400 - q6_loss: 0.1400 - q7_loss: 0.0443 - q8_loss: 0.0425 - val_loss: 0.4700 - val_q0_loss: 0.0149 - val_q1_loss: 0.0224 - val_q2_loss: 0.0126 - val_q3_loss: 0.0294 - val_q4_loss: 0.1402 - val_q5_loss: 0.0401 - val_q6_loss: 0.0720 - val_q7_loss: 0.0421 - val_q8_loss: 0.0291\n",
      "Epoch 122/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.5853 - q0_loss: 0.0233 - q1_loss: 0.0269 - q2_loss: 0.0246 - q3_loss: 0.0228 - q4_loss: 0.2397 - q5_loss: 0.0295 - q6_loss: 0.1310 - q7_loss: 0.0373 - q8_loss: 0.0449 - val_loss: 0.5356 - val_q0_loss: 0.0256 - val_q1_loss: 0.0260 - val_q2_loss: 0.0264 - val_q3_loss: 0.0342 - val_q4_loss: 0.1270 - val_q5_loss: 0.0401 - val_q6_loss: 0.1208 - val_q7_loss: 0.0462 - val_q8_loss: 0.0303\n",
      "Epoch 123/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.5898 - q0_loss: 0.0219 - q1_loss: 0.0207 - q2_loss: 0.0196 - q3_loss: 0.0327 - q4_loss: 0.2394 - q5_loss: 0.0410 - q6_loss: 0.1318 - q7_loss: 0.0463 - q8_loss: 0.0326 - val_loss: 0.6024 - val_q0_loss: 0.0320 - val_q1_loss: 0.0142 - val_q2_loss: 0.0337 - val_q3_loss: 0.0464 - val_q4_loss: 0.1320 - val_q5_loss: 0.0572 - val_q6_loss: 0.1137 - val_q7_loss: 0.0658 - val_q8_loss: 0.0428\n",
      "Epoch 124/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.6328 - q0_loss: 0.0272 - q1_loss: 0.0154 - q2_loss: 0.0232 - q3_loss: 0.0401 - q4_loss: 0.2466 - q5_loss: 0.0509 - q6_loss: 0.1351 - q7_loss: 0.0573 - q8_loss: 0.0404 - val_loss: 0.5179 - val_q0_loss: 0.0255 - val_q1_loss: 0.0172 - val_q2_loss: 0.0279 - val_q3_loss: 0.0320 - val_q4_loss: 0.1283 - val_q5_loss: 0.0373 - val_q6_loss: 0.1147 - val_q7_loss: 0.0438 - val_q8_loss: 0.0238\n",
      "Epoch 125/300\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 0.5653 - q0_loss: 0.0223 - q1_loss: 0.0235 - q2_loss: 0.0217 - q3_loss: 0.0238 - q4_loss: 0.2434 - q5_loss: 0.0294 - q6_loss: 0.1368 - q7_loss: 0.0346 - q8_loss: 0.0353 - val_loss: 0.4290 - val_q0_loss: 0.0146 - val_q1_loss: 0.0157 - val_q2_loss: 0.0107 - val_q3_loss: 0.0160 - val_q4_loss: 0.1281 - val_q5_loss: 0.0250 - val_q6_loss: 0.0832 - val_q7_loss: 0.0283 - val_q8_loss: 0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.5350 - q0_loss: 0.0220 - q1_loss: 0.0238 - q2_loss: 0.0169 - q3_loss: 0.0185 - q4_loss: 0.2319 - q5_loss: 0.0242 - q6_loss: 0.1248 - q7_loss: 0.0277 - q8_loss: 0.0339 - val_loss: 0.4039 - val_q0_loss: 0.0170 - val_q1_loss: 0.0265 - val_q2_loss: 0.0135 - val_q3_loss: 0.0124 - val_q4_loss: 0.1325 - val_q5_loss: 0.0209 - val_q6_loss: 0.0747 - val_q7_loss: 0.0207 - val_q8_loss: 0.0194\n",
      "Epoch 127/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.5149 - q0_loss: 0.0193 - q1_loss: 0.0243 - q2_loss: 0.0167 - q3_loss: 0.0150 - q4_loss: 0.2420 - q5_loss: 0.0201 - q6_loss: 0.1300 - q7_loss: 0.0239 - q8_loss: 0.0289 - val_loss: 0.5404 - val_q0_loss: 0.0271 - val_q1_loss: 0.0529 - val_q2_loss: 0.0340 - val_q3_loss: 0.0254 - val_q4_loss: 0.1328 - val_q5_loss: 0.0306 - val_q6_loss: 0.0821 - val_q7_loss: 0.0399 - val_q8_loss: 0.0583\n",
      "Epoch 128/300\n",
      "269/269 [==============================] - 0s 179us/sample - loss: 0.6331 - q0_loss: 0.0254 - q1_loss: 0.0368 - q2_loss: 0.0287 - q3_loss: 0.0296 - q4_loss: 0.2473 - q5_loss: 0.0388 - q6_loss: 0.1332 - q7_loss: 0.0450 - q8_loss: 0.0525 - val_loss: 0.5889 - val_q0_loss: 0.0239 - val_q1_loss: 0.0556 - val_q2_loss: 0.0167 - val_q3_loss: 0.0442 - val_q4_loss: 0.1356 - val_q5_loss: 0.0512 - val_q6_loss: 0.1224 - val_q7_loss: 0.0556 - val_q8_loss: 0.0203\n",
      "Epoch 129/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.6221 - q0_loss: 0.0207 - q1_loss: 0.0399 - q2_loss: 0.0168 - q3_loss: 0.0374 - q4_loss: 0.2359 - q5_loss: 0.0471 - q6_loss: 0.1321 - q7_loss: 0.0509 - q8_loss: 0.0302 - val_loss: 0.5516 - val_q0_loss: 0.0305 - val_q1_loss: 0.0305 - val_q2_loss: 0.0357 - val_q3_loss: 0.0331 - val_q4_loss: 0.1264 - val_q5_loss: 0.0389 - val_q6_loss: 0.0995 - val_q7_loss: 0.0468 - val_q8_loss: 0.0542\n",
      "Epoch 130/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.5857 - q0_loss: 0.0231 - q1_loss: 0.0467 - q2_loss: 0.0219 - q3_loss: 0.0216 - q4_loss: 0.2281 - q5_loss: 0.0281 - q6_loss: 0.1217 - q7_loss: 0.0317 - q8_loss: 0.0475 - val_loss: 0.3903 - val_q0_loss: 0.0163 - val_q1_loss: 0.0118 - val_q2_loss: 0.0100 - val_q3_loss: 0.0127 - val_q4_loss: 0.1284 - val_q5_loss: 0.0188 - val_q6_loss: 0.0788 - val_q7_loss: 0.0218 - val_q8_loss: 0.0228\n",
      "Epoch 131/300\n",
      "269/269 [==============================] - 0s 176us/sample - loss: 0.5947 - q0_loss: 0.0210 - q1_loss: 0.0588 - q2_loss: 0.0220 - q3_loss: 0.0221 - q4_loss: 0.2486 - q5_loss: 0.0283 - q6_loss: 0.1305 - q7_loss: 0.0316 - q8_loss: 0.0465 - val_loss: 0.4889 - val_q0_loss: 0.0244 - val_q1_loss: 0.0409 - val_q2_loss: 0.0296 - val_q3_loss: 0.0231 - val_q4_loss: 0.1333 - val_q5_loss: 0.0285 - val_q6_loss: 0.0832 - val_q7_loss: 0.0344 - val_q8_loss: 0.0439\n",
      "Epoch 132/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 0.6002 - q0_loss: 0.0230 - q1_loss: 0.0498 - q2_loss: 0.0203 - q3_loss: 0.0270 - q4_loss: 0.2334 - q5_loss: 0.0332 - q6_loss: 0.1242 - q7_loss: 0.0374 - q8_loss: 0.0460 - val_loss: 0.4060 - val_q0_loss: 0.0179 - val_q1_loss: 0.0168 - val_q2_loss: 0.0081 - val_q3_loss: 0.0147 - val_q4_loss: 0.1279 - val_q5_loss: 0.0205 - val_q6_loss: 0.0820 - val_q7_loss: 0.0244 - val_q8_loss: 0.0216\n",
      "Epoch 133/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.5290 - q0_loss: 0.0200 - q1_loss: 0.0393 - q2_loss: 0.0161 - q3_loss: 0.0155 - q4_loss: 0.2417 - q5_loss: 0.0214 - q6_loss: 0.1183 - q7_loss: 0.0256 - q8_loss: 0.0349 - val_loss: 0.4715 - val_q0_loss: 0.0171 - val_q1_loss: 0.0601 - val_q2_loss: 0.0101 - val_q3_loss: 0.0159 - val_q4_loss: 0.1241 - val_q5_loss: 0.0152 - val_q6_loss: 0.1090 - val_q7_loss: 0.0165 - val_q8_loss: 0.0371\n",
      "Epoch 134/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.5041 - q0_loss: 0.0198 - q1_loss: 0.0347 - q2_loss: 0.0140 - q3_loss: 0.0121 - q4_loss: 0.2414 - q5_loss: 0.0154 - q6_loss: 0.1282 - q7_loss: 0.0194 - q8_loss: 0.0301 - val_loss: 0.4313 - val_q0_loss: 0.0220 - val_q1_loss: 0.0410 - val_q2_loss: 0.0223 - val_q3_loss: 0.0110 - val_q4_loss: 0.1316 - val_q5_loss: 0.0117 - val_q6_loss: 0.0821 - val_q7_loss: 0.0161 - val_q8_loss: 0.0375\n",
      "Epoch 135/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.5125 - q0_loss: 0.0203 - q1_loss: 0.0290 - q2_loss: 0.0139 - q3_loss: 0.0178 - q4_loss: 0.2224 - q5_loss: 0.0217 - q6_loss: 0.1160 - q7_loss: 0.0266 - q8_loss: 0.0321 - val_loss: 0.4412 - val_q0_loss: 0.0208 - val_q1_loss: 0.0620 - val_q2_loss: 0.0220 - val_q3_loss: 0.0090 - val_q4_loss: 0.1370 - val_q5_loss: 0.0140 - val_q6_loss: 0.0669 - val_q7_loss: 0.0115 - val_q8_loss: 0.0432\n",
      "Epoch 136/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.5215 - q0_loss: 0.0214 - q1_loss: 0.0382 - q2_loss: 0.0178 - q3_loss: 0.0145 - q4_loss: 0.2367 - q5_loss: 0.0179 - q6_loss: 0.1229 - q7_loss: 0.0203 - q8_loss: 0.0348 - val_loss: 0.3914 - val_q0_loss: 0.0184 - val_q1_loss: 0.0142 - val_q2_loss: 0.0113 - val_q3_loss: 0.0138 - val_q4_loss: 0.1237 - val_q5_loss: 0.0162 - val_q6_loss: 0.0858 - val_q7_loss: 0.0207 - val_q8_loss: 0.0219\n",
      "Epoch 137/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.4918 - q0_loss: 0.0199 - q1_loss: 0.0281 - q2_loss: 0.0125 - q3_loss: 0.0147 - q4_loss: 0.2327 - q5_loss: 0.0187 - q6_loss: 0.1150 - q7_loss: 0.0228 - q8_loss: 0.0284 - val_loss: 0.4103 - val_q0_loss: 0.0203 - val_q1_loss: 0.0154 - val_q2_loss: 0.0126 - val_q3_loss: 0.0201 - val_q4_loss: 0.1216 - val_q5_loss: 0.0228 - val_q6_loss: 0.0918 - val_q7_loss: 0.0257 - val_q8_loss: 0.0198\n",
      "Epoch 138/300\n",
      "269/269 [==============================] - 0s 230us/sample - loss: 0.5407 - q0_loss: 0.0214 - q1_loss: 0.0281 - q2_loss: 0.0145 - q3_loss: 0.0246 - q4_loss: 0.2354 - q5_loss: 0.0312 - q6_loss: 0.1210 - q7_loss: 0.0352 - q8_loss: 0.0299 - val_loss: 0.5261 - val_q0_loss: 0.0200 - val_q1_loss: 0.0346 - val_q2_loss: 0.0308 - val_q3_loss: 0.0316 - val_q4_loss: 0.1221 - val_q5_loss: 0.0419 - val_q6_loss: 0.0600 - val_q7_loss: 0.0518 - val_q8_loss: 0.0607\n",
      "Epoch 139/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.6162 - q0_loss: 0.0257 - q1_loss: 0.0385 - q2_loss: 0.0297 - q3_loss: 0.0303 - q4_loss: 0.2266 - q5_loss: 0.0381 - q6_loss: 0.1124 - q7_loss: 0.0476 - q8_loss: 0.0559 - val_loss: 0.4721 - val_q0_loss: 0.0187 - val_q1_loss: 0.0214 - val_q2_loss: 0.0137 - val_q3_loss: 0.0340 - val_q4_loss: 0.1301 - val_q5_loss: 0.0451 - val_q6_loss: 0.0593 - val_q7_loss: 0.0508 - val_q8_loss: 0.0279\n",
      "Epoch 140/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.5589 - q0_loss: 0.0213 - q1_loss: 0.0351 - q2_loss: 0.0161 - q3_loss: 0.0253 - q4_loss: 0.2230 - q5_loss: 0.0325 - q6_loss: 0.1148 - q7_loss: 0.0380 - q8_loss: 0.0361 - val_loss: 0.4842 - val_q0_loss: 0.0276 - val_q1_loss: 0.0354 - val_q2_loss: 0.0291 - val_q3_loss: 0.0231 - val_q4_loss: 0.1264 - val_q5_loss: 0.0282 - val_q6_loss: 0.0825 - val_q7_loss: 0.0346 - val_q8_loss: 0.0482\n",
      "Epoch 141/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.5790 - q0_loss: 0.0247 - q1_loss: 0.0226 - q2_loss: 0.0260 - q3_loss: 0.0306 - q4_loss: 0.2250 - q5_loss: 0.0380 - q6_loss: 0.1165 - q7_loss: 0.0447 - q8_loss: 0.0442 - val_loss: 0.4697 - val_q0_loss: 0.0245 - val_q1_loss: 0.0213 - val_q2_loss: 0.0201 - val_q3_loss: 0.0285 - val_q4_loss: 0.1251 - val_q5_loss: 0.0353 - val_q6_loss: 0.0854 - val_q7_loss: 0.0405 - val_q8_loss: 0.0295\n",
      "Epoch 142/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.5702 - q0_loss: 0.0258 - q1_loss: 0.0195 - q2_loss: 0.0212 - q3_loss: 0.0334 - q4_loss: 0.2184 - q5_loss: 0.0419 - q6_loss: 0.1145 - q7_loss: 0.0476 - q8_loss: 0.0356 - val_loss: 0.4419 - val_q0_loss: 0.0159 - val_q1_loss: 0.0400 - val_q2_loss: 0.0106 - val_q3_loss: 0.0160 - val_q4_loss: 0.1259 - val_q5_loss: 0.0223 - val_q6_loss: 0.0738 - val_q7_loss: 0.0257 - val_q8_loss: 0.0323\n",
      "Epoch 143/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.5176 - q0_loss: 0.0211 - q1_loss: 0.0367 - q2_loss: 0.0158 - q3_loss: 0.0195 - q4_loss: 0.2182 - q5_loss: 0.0241 - q6_loss: 0.1030 - q7_loss: 0.0291 - q8_loss: 0.0368 - val_loss: 0.4207 - val_q0_loss: 0.0167 - val_q1_loss: 0.0145 - val_q2_loss: 0.0138 - val_q3_loss: 0.0239 - val_q4_loss: 0.1245 - val_q5_loss: 0.0323 - val_q6_loss: 0.0597 - val_q7_loss: 0.0365 - val_q8_loss: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.5155 - q0_loss: 0.0221 - q1_loss: 0.0223 - q2_loss: 0.0169 - q3_loss: 0.0211 - q4_loss: 0.2222 - q5_loss: 0.0269 - q6_loss: 0.1119 - q7_loss: 0.0322 - q8_loss: 0.0334 - val_loss: 0.6045 - val_q0_loss: 0.0363 - val_q1_loss: 0.0326 - val_q2_loss: 0.0403 - val_q3_loss: 0.0446 - val_q4_loss: 0.1200 - val_q5_loss: 0.0529 - val_q6_loss: 0.1025 - val_q7_loss: 0.0633 - val_q8_loss: 0.0692\n",
      "Epoch 145/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.6073 - q0_loss: 0.0290 - q1_loss: 0.0279 - q2_loss: 0.0300 - q3_loss: 0.0335 - q4_loss: 0.2253 - q5_loss: 0.0417 - q6_loss: 0.1145 - q7_loss: 0.0514 - q8_loss: 0.0555 - val_loss: 0.4084 - val_q0_loss: 0.0191 - val_q1_loss: 0.0299 - val_q2_loss: 0.0118 - val_q3_loss: 0.0150 - val_q4_loss: 0.1207 - val_q5_loss: 0.0166 - val_q6_loss: 0.0855 - val_q7_loss: 0.0201 - val_q8_loss: 0.0240\n",
      "Epoch 146/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.5148 - q0_loss: 0.0218 - q1_loss: 0.0241 - q2_loss: 0.0153 - q3_loss: 0.0247 - q4_loss: 0.2298 - q5_loss: 0.0306 - q6_loss: 0.1073 - q7_loss: 0.0368 - q8_loss: 0.0316 - val_loss: 0.4159 - val_q0_loss: 0.0169 - val_q1_loss: 0.0417 - val_q2_loss: 0.0118 - val_q3_loss: 0.0089 - val_q4_loss: 0.1226 - val_q5_loss: 0.0130 - val_q6_loss: 0.0804 - val_q7_loss: 0.0168 - val_q8_loss: 0.0336\n",
      "Epoch 147/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.5384 - q0_loss: 0.0239 - q1_loss: 0.0343 - q2_loss: 0.0196 - q3_loss: 0.0237 - q4_loss: 0.2324 - q5_loss: 0.0299 - q6_loss: 0.1129 - q7_loss: 0.0361 - q8_loss: 0.0387 - val_loss: 0.4936 - val_q0_loss: 0.0180 - val_q1_loss: 0.0243 - val_q2_loss: 0.0183 - val_q3_loss: 0.0396 - val_q4_loss: 0.1268 - val_q5_loss: 0.0515 - val_q6_loss: 0.0678 - val_q7_loss: 0.0586 - val_q8_loss: 0.0305\n",
      "Epoch 148/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.6661 - q0_loss: 0.0288 - q1_loss: 0.0472 - q2_loss: 0.0227 - q3_loss: 0.0485 - q4_loss: 0.2361 - q5_loss: 0.0605 - q6_loss: 0.1275 - q7_loss: 0.0659 - q8_loss: 0.0388 - val_loss: 0.5948 - val_q0_loss: 0.0218 - val_q1_loss: 0.0953 - val_q2_loss: 0.0368 - val_q3_loss: 0.0207 - val_q4_loss: 0.1248 - val_q5_loss: 0.0264 - val_q6_loss: 0.0943 - val_q7_loss: 0.0318 - val_q8_loss: 0.0808\n",
      "Epoch 149/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.5729 - q0_loss: 0.0238 - q1_loss: 0.0615 - q2_loss: 0.0217 - q3_loss: 0.0217 - q4_loss: 0.2158 - q5_loss: 0.0272 - q6_loss: 0.1047 - q7_loss: 0.0315 - q8_loss: 0.0477 - val_loss: 0.5270 - val_q0_loss: 0.0203 - val_q1_loss: 0.0542 - val_q2_loss: 0.0150 - val_q3_loss: 0.0418 - val_q4_loss: 0.1375 - val_q5_loss: 0.0538 - val_q6_loss: 0.0679 - val_q7_loss: 0.0580 - val_q8_loss: 0.0212\n",
      "Epoch 150/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.5822 - q0_loss: 0.0247 - q1_loss: 0.0470 - q2_loss: 0.0241 - q3_loss: 0.0298 - q4_loss: 0.2147 - q5_loss: 0.0368 - q6_loss: 0.1033 - q7_loss: 0.0412 - q8_loss: 0.0479 - val_loss: 0.5219 - val_q0_loss: 0.0222 - val_q1_loss: 0.0269 - val_q2_loss: 0.0305 - val_q3_loss: 0.0359 - val_q4_loss: 0.1243 - val_q5_loss: 0.0469 - val_q6_loss: 0.0530 - val_q7_loss: 0.0566 - val_q8_loss: 0.0533\n",
      "Epoch 151/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.5060 - q0_loss: 0.0216 - q1_loss: 0.0338 - q2_loss: 0.0153 - q3_loss: 0.0216 - q4_loss: 0.2269 - q5_loss: 0.0263 - q6_loss: 0.1011 - q7_loss: 0.0295 - q8_loss: 0.0340 - val_loss: 0.3667 - val_q0_loss: 0.0180 - val_q1_loss: 0.0261 - val_q2_loss: 0.0078 - val_q3_loss: 0.0127 - val_q4_loss: 0.1246 - val_q5_loss: 0.0164 - val_q6_loss: 0.0703 - val_q7_loss: 0.0170 - val_q8_loss: 0.0195\n",
      "Epoch 152/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.4469 - q0_loss: 0.0187 - q1_loss: 0.0239 - q2_loss: 0.0087 - q3_loss: 0.0128 - q4_loss: 0.2107 - q5_loss: 0.0165 - q6_loss: 0.0983 - q7_loss: 0.0198 - q8_loss: 0.0237 - val_loss: 0.4316 - val_q0_loss: 0.0231 - val_q1_loss: 0.0268 - val_q2_loss: 0.0193 - val_q3_loss: 0.0190 - val_q4_loss: 0.1192 - val_q5_loss: 0.0214 - val_q6_loss: 0.0861 - val_q7_loss: 0.0280 - val_q8_loss: 0.0404\n",
      "Epoch 153/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.4717 - q0_loss: 0.0203 - q1_loss: 0.0186 - q2_loss: 0.0142 - q3_loss: 0.0184 - q4_loss: 0.2185 - q5_loss: 0.0222 - q6_loss: 0.1016 - q7_loss: 0.0271 - q8_loss: 0.0290 - val_loss: 0.3923 - val_q0_loss: 0.0156 - val_q1_loss: 0.0198 - val_q2_loss: 0.0141 - val_q3_loss: 0.0184 - val_q4_loss: 0.1171 - val_q5_loss: 0.0264 - val_q6_loss: 0.0581 - val_q7_loss: 0.0311 - val_q8_loss: 0.0314\n",
      "Epoch 154/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.4543 - q0_loss: 0.0194 - q1_loss: 0.0245 - q2_loss: 0.0119 - q3_loss: 0.0133 - q4_loss: 0.2248 - q5_loss: 0.0170 - q6_loss: 0.0987 - q7_loss: 0.0226 - q8_loss: 0.0301 - val_loss: 0.3708 - val_q0_loss: 0.0161 - val_q1_loss: 0.0348 - val_q2_loss: 0.0085 - val_q3_loss: 0.0114 - val_q4_loss: 0.1193 - val_q5_loss: 0.0163 - val_q6_loss: 0.0609 - val_q7_loss: 0.0174 - val_q8_loss: 0.0261\n",
      "Epoch 155/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.4517 - q0_loss: 0.0200 - q1_loss: 0.0243 - q2_loss: 0.0112 - q3_loss: 0.0150 - q4_loss: 0.2147 - q5_loss: 0.0186 - q6_loss: 0.0951 - q7_loss: 0.0228 - q8_loss: 0.0265 - val_loss: 0.3767 - val_q0_loss: 0.0184 - val_q1_loss: 0.0165 - val_q2_loss: 0.0109 - val_q3_loss: 0.0141 - val_q4_loss: 0.1143 - val_q5_loss: 0.0181 - val_q6_loss: 0.0731 - val_q7_loss: 0.0205 - val_q8_loss: 0.0214\n",
      "Epoch 156/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 0.5431 - q0_loss: 0.0253 - q1_loss: 0.0205 - q2_loss: 0.0245 - q3_loss: 0.0318 - q4_loss: 0.2158 - q5_loss: 0.0398 - q6_loss: 0.1041 - q7_loss: 0.0460 - q8_loss: 0.0450 - val_loss: 0.3586 - val_q0_loss: 0.0167 - val_q1_loss: 0.0120 - val_q2_loss: 0.0100 - val_q3_loss: 0.0142 - val_q4_loss: 0.1153 - val_q5_loss: 0.0211 - val_q6_loss: 0.0536 - val_q7_loss: 0.0247 - val_q8_loss: 0.0228\n",
      "Epoch 157/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.6484 - q0_loss: 0.0308 - q1_loss: 0.0215 - q2_loss: 0.0328 - q3_loss: 0.0481 - q4_loss: 0.2234 - q5_loss: 0.0595 - q6_loss: 0.1145 - q7_loss: 0.0700 - q8_loss: 0.0537 - val_loss: 0.4962 - val_q0_loss: 0.0219 - val_q1_loss: 0.0401 - val_q2_loss: 0.0312 - val_q3_loss: 0.0277 - val_q4_loss: 0.1144 - val_q5_loss: 0.0383 - val_q6_loss: 0.0498 - val_q7_loss: 0.0463 - val_q8_loss: 0.0591\n",
      "Epoch 158/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.5344 - q0_loss: 0.0240 - q1_loss: 0.0282 - q2_loss: 0.0236 - q3_loss: 0.0262 - q4_loss: 0.2257 - q5_loss: 0.0325 - q6_loss: 0.0971 - q7_loss: 0.0398 - q8_loss: 0.0457 - val_loss: 0.3882 - val_q0_loss: 0.0161 - val_q1_loss: 0.0163 - val_q2_loss: 0.0141 - val_q3_loss: 0.0181 - val_q4_loss: 0.1154 - val_q5_loss: 0.0263 - val_q6_loss: 0.0508 - val_q7_loss: 0.0312 - val_q8_loss: 0.0309\n",
      "Epoch 159/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 0.5074 - q0_loss: 0.0233 - q1_loss: 0.0203 - q2_loss: 0.0215 - q3_loss: 0.0264 - q4_loss: 0.2106 - q5_loss: 0.0324 - q6_loss: 0.0891 - q7_loss: 0.0397 - q8_loss: 0.0416 - val_loss: 0.3606 - val_q0_loss: 0.0188 - val_q1_loss: 0.0118 - val_q2_loss: 0.0110 - val_q3_loss: 0.0153 - val_q4_loss: 0.1148 - val_q5_loss: 0.0198 - val_q6_loss: 0.0636 - val_q7_loss: 0.0259 - val_q8_loss: 0.0259\n",
      "Epoch 160/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.4364 - q0_loss: 0.0198 - q1_loss: 0.0204 - q2_loss: 0.0121 - q3_loss: 0.0150 - q4_loss: 0.2172 - q5_loss: 0.0187 - q6_loss: 0.0908 - q7_loss: 0.0231 - q8_loss: 0.0280 - val_loss: 0.3464 - val_q0_loss: 0.0182 - val_q1_loss: 0.0201 - val_q2_loss: 0.0109 - val_q3_loss: 0.0093 - val_q4_loss: 0.1147 - val_q5_loss: 0.0124 - val_q6_loss: 0.0623 - val_q7_loss: 0.0171 - val_q8_loss: 0.0275\n",
      "Epoch 161/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 0.4310 - q0_loss: 0.0186 - q1_loss: 0.0212 - q2_loss: 0.0087 - q3_loss: 0.0147 - q4_loss: 0.2090 - q5_loss: 0.0178 - q6_loss: 0.0886 - q7_loss: 0.0220 - q8_loss: 0.0237 - val_loss: 0.3618 - val_q0_loss: 0.0223 - val_q1_loss: 0.0257 - val_q2_loss: 0.0150 - val_q3_loss: 0.0118 - val_q4_loss: 0.1158 - val_q5_loss: 0.0140 - val_q6_loss: 0.0650 - val_q7_loss: 0.0182 - val_q8_loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.4242 - q0_loss: 0.0198 - q1_loss: 0.0173 - q2_loss: 0.0115 - q3_loss: 0.0126 - q4_loss: 0.2042 - q5_loss: 0.0155 - q6_loss: 0.0851 - q7_loss: 0.0208 - q8_loss: 0.0274 - val_loss: 0.3363 - val_q0_loss: 0.0189 - val_q1_loss: 0.0164 - val_q2_loss: 0.0080 - val_q3_loss: 0.0119 - val_q4_loss: 0.1139 - val_q5_loss: 0.0143 - val_q6_loss: 0.0606 - val_q7_loss: 0.0190 - val_q8_loss: 0.0190\n",
      "Epoch 163/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.4040 - q0_loss: 0.0187 - q1_loss: 0.0144 - q2_loss: 0.0087 - q3_loss: 0.0110 - q4_loss: 0.2099 - q5_loss: 0.0132 - q6_loss: 0.0848 - q7_loss: 0.0172 - q8_loss: 0.0230 - val_loss: 0.3462 - val_q0_loss: 0.0197 - val_q1_loss: 0.0311 - val_q2_loss: 0.0120 - val_q3_loss: 0.0081 - val_q4_loss: 0.1140 - val_q5_loss: 0.0092 - val_q6_loss: 0.0572 - val_q7_loss: 0.0120 - val_q8_loss: 0.0312\n",
      "Epoch 164/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.4381 - q0_loss: 0.0197 - q1_loss: 0.0268 - q2_loss: 0.0110 - q3_loss: 0.0139 - q4_loss: 0.2071 - q5_loss: 0.0163 - q6_loss: 0.0886 - q7_loss: 0.0208 - q8_loss: 0.0275 - val_loss: 0.4303 - val_q0_loss: 0.0162 - val_q1_loss: 0.0245 - val_q2_loss: 0.0162 - val_q3_loss: 0.0307 - val_q4_loss: 0.1141 - val_q5_loss: 0.0403 - val_q6_loss: 0.0585 - val_q7_loss: 0.0456 - val_q8_loss: 0.0257\n",
      "Epoch 165/300\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 0.4393 - q0_loss: 0.0197 - q1_loss: 0.0213 - q2_loss: 0.0126 - q3_loss: 0.0160 - q4_loss: 0.2028 - q5_loss: 0.0208 - q6_loss: 0.0792 - q7_loss: 0.0261 - q8_loss: 0.0308 - val_loss: 0.3927 - val_q0_loss: 0.0227 - val_q1_loss: 0.0415 - val_q2_loss: 0.0216 - val_q3_loss: 0.0122 - val_q4_loss: 0.1161 - val_q5_loss: 0.0148 - val_q6_loss: 0.0536 - val_q7_loss: 0.0209 - val_q8_loss: 0.0450\n",
      "Epoch 166/300\n",
      "269/269 [==============================] - 0s 176us/sample - loss: 0.4982 - q0_loss: 0.0226 - q1_loss: 0.0245 - q2_loss: 0.0186 - q3_loss: 0.0262 - q4_loss: 0.1987 - q5_loss: 0.0316 - q6_loss: 0.0885 - q7_loss: 0.0366 - q8_loss: 0.0357 - val_loss: 0.5527 - val_q0_loss: 0.0250 - val_q1_loss: 0.0175 - val_q2_loss: 0.0294 - val_q3_loss: 0.0502 - val_q4_loss: 0.1144 - val_q5_loss: 0.0627 - val_q6_loss: 0.0793 - val_q7_loss: 0.0726 - val_q8_loss: 0.0410\n",
      "Epoch 167/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.5784 - q0_loss: 0.0288 - q1_loss: 0.0180 - q2_loss: 0.0283 - q3_loss: 0.0437 - q4_loss: 0.2095 - q5_loss: 0.0532 - q6_loss: 0.1041 - q7_loss: 0.0588 - q8_loss: 0.0440 - val_loss: 0.4223 - val_q0_loss: 0.0207 - val_q1_loss: 0.0218 - val_q2_loss: 0.0202 - val_q3_loss: 0.0248 - val_q4_loss: 0.1086 - val_q5_loss: 0.0323 - val_q6_loss: 0.0545 - val_q7_loss: 0.0392 - val_q8_loss: 0.0372\n",
      "Epoch 168/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.4917 - q0_loss: 0.0232 - q1_loss: 0.0277 - q2_loss: 0.0175 - q3_loss: 0.0264 - q4_loss: 0.2173 - q5_loss: 0.0330 - q6_loss: 0.0816 - q7_loss: 0.0382 - q8_loss: 0.0358 - val_loss: 0.4262 - val_q0_loss: 0.0208 - val_q1_loss: 0.0136 - val_q2_loss: 0.0206 - val_q3_loss: 0.0282 - val_q4_loss: 0.1109 - val_q5_loss: 0.0366 - val_q6_loss: 0.0554 - val_q7_loss: 0.0430 - val_q8_loss: 0.0321\n",
      "Epoch 169/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.4888 - q0_loss: 0.0241 - q1_loss: 0.0181 - q2_loss: 0.0204 - q3_loss: 0.0285 - q4_loss: 0.2025 - q5_loss: 0.0341 - q6_loss: 0.0838 - q7_loss: 0.0394 - q8_loss: 0.0354 - val_loss: 0.4514 - val_q0_loss: 0.0213 - val_q1_loss: 0.0214 - val_q2_loss: 0.0195 - val_q3_loss: 0.0333 - val_q4_loss: 0.1140 - val_q5_loss: 0.0422 - val_q6_loss: 0.0618 - val_q7_loss: 0.0467 - val_q8_loss: 0.0268\n",
      "Epoch 170/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.4708 - q0_loss: 0.0236 - q1_loss: 0.0196 - q2_loss: 0.0171 - q3_loss: 0.0240 - q4_loss: 0.2042 - q5_loss: 0.0303 - q6_loss: 0.0769 - q7_loss: 0.0369 - q8_loss: 0.0348 - val_loss: 0.3926 - val_q0_loss: 0.0240 - val_q1_loss: 0.0185 - val_q2_loss: 0.0173 - val_q3_loss: 0.0195 - val_q4_loss: 0.1099 - val_q5_loss: 0.0229 - val_q6_loss: 0.0726 - val_q7_loss: 0.0288 - val_q8_loss: 0.0312\n",
      "Epoch 171/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.4338 - q0_loss: 0.0203 - q1_loss: 0.0242 - q2_loss: 0.0140 - q3_loss: 0.0169 - q4_loss: 0.2004 - q5_loss: 0.0212 - q6_loss: 0.0768 - q7_loss: 0.0264 - q8_loss: 0.0312 - val_loss: 0.3395 - val_q0_loss: 0.0174 - val_q1_loss: 0.0133 - val_q2_loss: 0.0097 - val_q3_loss: 0.0156 - val_q4_loss: 0.1088 - val_q5_loss: 0.0204 - val_q6_loss: 0.0544 - val_q7_loss: 0.0223 - val_q8_loss: 0.0166\n",
      "Epoch 172/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.4627 - q0_loss: 0.0209 - q1_loss: 0.0326 - q2_loss: 0.0143 - q3_loss: 0.0228 - q4_loss: 0.2012 - q5_loss: 0.0273 - q6_loss: 0.0790 - q7_loss: 0.0292 - q8_loss: 0.0297 - val_loss: 0.5872 - val_q0_loss: 0.0377 - val_q1_loss: 0.0554 - val_q2_loss: 0.0461 - val_q3_loss: 0.0399 - val_q4_loss: 0.1175 - val_q5_loss: 0.0474 - val_q6_loss: 0.0813 - val_q7_loss: 0.0603 - val_q8_loss: 0.0820\n",
      "Epoch 173/300\n",
      "269/269 [==============================] - 0s 217us/sample - loss: 0.5065 - q0_loss: 0.0243 - q1_loss: 0.0338 - q2_loss: 0.0232 - q3_loss: 0.0266 - q4_loss: 0.2043 - q5_loss: 0.0333 - q6_loss: 0.0726 - q7_loss: 0.0401 - q8_loss: 0.0438 - val_loss: 0.4565 - val_q0_loss: 0.0238 - val_q1_loss: 0.0268 - val_q2_loss: 0.0154 - val_q3_loss: 0.0366 - val_q4_loss: 0.1065 - val_q5_loss: 0.0426 - val_q6_loss: 0.0913 - val_q7_loss: 0.0470 - val_q8_loss: 0.0222\n",
      "Epoch 174/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.4232 - q0_loss: 0.0210 - q1_loss: 0.0259 - q2_loss: 0.0117 - q3_loss: 0.0173 - q4_loss: 0.1994 - q5_loss: 0.0225 - q6_loss: 0.0697 - q7_loss: 0.0266 - q8_loss: 0.0268 - val_loss: 0.3663 - val_q0_loss: 0.0199 - val_q1_loss: 0.0235 - val_q2_loss: 0.0084 - val_q3_loss: 0.0187 - val_q4_loss: 0.1078 - val_q5_loss: 0.0213 - val_q6_loss: 0.0781 - val_q7_loss: 0.0249 - val_q8_loss: 0.0171\n",
      "Epoch 175/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.4582 - q0_loss: 0.0217 - q1_loss: 0.0256 - q2_loss: 0.0166 - q3_loss: 0.0258 - q4_loss: 0.2000 - q5_loss: 0.0302 - q6_loss: 0.0758 - q7_loss: 0.0346 - q8_loss: 0.0334 - val_loss: 0.5276 - val_q0_loss: 0.0322 - val_q1_loss: 0.0235 - val_q2_loss: 0.0314 - val_q3_loss: 0.0448 - val_q4_loss: 0.1098 - val_q5_loss: 0.0550 - val_q6_loss: 0.0887 - val_q7_loss: 0.0635 - val_q8_loss: 0.0494\n",
      "Epoch 176/300\n",
      "269/269 [==============================] - 0s 249us/sample - loss: 0.4962 - q0_loss: 0.0221 - q1_loss: 0.0264 - q2_loss: 0.0196 - q3_loss: 0.0305 - q4_loss: 0.1937 - q5_loss: 0.0384 - q6_loss: 0.0707 - q7_loss: 0.0442 - q8_loss: 0.0370 - val_loss: 0.4663 - val_q0_loss: 0.0273 - val_q1_loss: 0.0311 - val_q2_loss: 0.0273 - val_q3_loss: 0.0320 - val_q4_loss: 0.1111 - val_q5_loss: 0.0393 - val_q6_loss: 0.0778 - val_q7_loss: 0.0466 - val_q8_loss: 0.0467\n",
      "Epoch 177/300\n",
      "269/269 [==============================] - 0s 266us/sample - loss: 0.4583 - q0_loss: 0.0205 - q1_loss: 0.0395 - q2_loss: 0.0158 - q3_loss: 0.0181 - q4_loss: 0.2044 - q5_loss: 0.0221 - q6_loss: 0.0714 - q7_loss: 0.0286 - q8_loss: 0.0381 - val_loss: 0.3236 - val_q0_loss: 0.0167 - val_q1_loss: 0.0305 - val_q2_loss: 0.0091 - val_q3_loss: 0.0101 - val_q4_loss: 0.1119 - val_q5_loss: 0.0148 - val_q6_loss: 0.0436 - val_q7_loss: 0.0183 - val_q8_loss: 0.0256\n",
      "Epoch 178/300\n",
      "269/269 [==============================] - 0s 225us/sample - loss: 0.4629 - q0_loss: 0.0222 - q1_loss: 0.0246 - q2_loss: 0.0181 - q3_loss: 0.0252 - q4_loss: 0.2111 - q5_loss: 0.0309 - q6_loss: 0.0703 - q7_loss: 0.0387 - q8_loss: 0.0359 - val_loss: 0.4415 - val_q0_loss: 0.0253 - val_q1_loss: 0.0137 - val_q2_loss: 0.0214 - val_q3_loss: 0.0374 - val_q4_loss: 0.1043 - val_q5_loss: 0.0430 - val_q6_loss: 0.0855 - val_q7_loss: 0.0490 - val_q8_loss: 0.0321\n",
      "Epoch 179/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.4735 - q0_loss: 0.0242 - q1_loss: 0.0152 - q2_loss: 0.0199 - q3_loss: 0.0283 - q4_loss: 0.1981 - q5_loss: 0.0347 - q6_loss: 0.0758 - q7_loss: 0.0414 - q8_loss: 0.0361 - val_loss: 0.4503 - val_q0_loss: 0.0277 - val_q1_loss: 0.0179 - val_q2_loss: 0.0253 - val_q3_loss: 0.0333 - val_q4_loss: 0.1064 - val_q5_loss: 0.0378 - val_q6_loss: 0.0748 - val_q7_loss: 0.0466 - val_q8_loss: 0.0453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "269/269 [==============================] - 0s 183us/sample - loss: 0.4712 - q0_loss: 0.0237 - q1_loss: 0.0146 - q2_loss: 0.0217 - q3_loss: 0.0280 - q4_loss: 0.1946 - q5_loss: 0.0347 - q6_loss: 0.0672 - q7_loss: 0.0413 - q8_loss: 0.0384 - val_loss: 0.4047 - val_q0_loss: 0.0250 - val_q1_loss: 0.0148 - val_q2_loss: 0.0211 - val_q3_loss: 0.0290 - val_q4_loss: 0.1044 - val_q5_loss: 0.0326 - val_q6_loss: 0.0739 - val_q7_loss: 0.0398 - val_q8_loss: 0.0366\n",
      "Epoch 181/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.4265 - q0_loss: 0.0214 - q1_loss: 0.0239 - q2_loss: 0.0173 - q3_loss: 0.0178 - q4_loss: 0.1945 - q5_loss: 0.0220 - q6_loss: 0.0623 - q7_loss: 0.0291 - q8_loss: 0.0357 - val_loss: 0.4153 - val_q0_loss: 0.0174 - val_q1_loss: 0.0298 - val_q2_loss: 0.0152 - val_q3_loss: 0.0361 - val_q4_loss: 0.1092 - val_q5_loss: 0.0472 - val_q6_loss: 0.0403 - val_q7_loss: 0.0513 - val_q8_loss: 0.0208\n",
      "Epoch 182/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 0.4489 - q0_loss: 0.0224 - q1_loss: 0.0168 - q2_loss: 0.0172 - q3_loss: 0.0280 - q4_loss: 0.1905 - q5_loss: 0.0354 - q6_loss: 0.0625 - q7_loss: 0.0416 - q8_loss: 0.0324 - val_loss: 0.4631 - val_q0_loss: 0.0210 - val_q1_loss: 0.0274 - val_q2_loss: 0.0202 - val_q3_loss: 0.0432 - val_q4_loss: 0.1069 - val_q5_loss: 0.0546 - val_q6_loss: 0.0486 - val_q7_loss: 0.0609 - val_q8_loss: 0.0259\n",
      "Epoch 183/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.4374 - q0_loss: 0.0220 - q1_loss: 0.0251 - q2_loss: 0.0187 - q3_loss: 0.0202 - q4_loss: 0.1928 - q5_loss: 0.0264 - q6_loss: 0.0620 - q7_loss: 0.0321 - q8_loss: 0.0372 - val_loss: 0.4244 - val_q0_loss: 0.0281 - val_q1_loss: 0.0161 - val_q2_loss: 0.0256 - val_q3_loss: 0.0318 - val_q4_loss: 0.1033 - val_q5_loss: 0.0388 - val_q6_loss: 0.0790 - val_q7_loss: 0.0447 - val_q8_loss: 0.0416\n",
      "Epoch 184/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.4414 - q0_loss: 0.0222 - q1_loss: 0.0173 - q2_loss: 0.0189 - q3_loss: 0.0241 - q4_loss: 0.1847 - q5_loss: 0.0308 - q6_loss: 0.0602 - q7_loss: 0.0386 - q8_loss: 0.0369 - val_loss: 0.3143 - val_q0_loss: 0.0176 - val_q1_loss: 0.0198 - val_q2_loss: 0.0106 - val_q3_loss: 0.0080 - val_q4_loss: 0.1028 - val_q5_loss: 0.0104 - val_q6_loss: 0.0504 - val_q7_loss: 0.0143 - val_q8_loss: 0.0231\n",
      "Epoch 185/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.3746 - q0_loss: 0.0209 - q1_loss: 0.0186 - q2_loss: 0.0117 - q3_loss: 0.0128 - q4_loss: 0.1966 - q5_loss: 0.0164 - q6_loss: 0.0547 - q7_loss: 0.0208 - q8_loss: 0.0292 - val_loss: 0.3550 - val_q0_loss: 0.0225 - val_q1_loss: 0.0185 - val_q2_loss: 0.0169 - val_q3_loss: 0.0190 - val_q4_loss: 0.1033 - val_q5_loss: 0.0214 - val_q6_loss: 0.0595 - val_q7_loss: 0.0272 - val_q8_loss: 0.0321\n",
      "Epoch 186/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.4860 - q0_loss: 0.0267 - q1_loss: 0.0155 - q2_loss: 0.0249 - q3_loss: 0.0351 - q4_loss: 0.1949 - q5_loss: 0.0435 - q6_loss: 0.0680 - q7_loss: 0.0492 - q8_loss: 0.0411 - val_loss: 0.3069 - val_q0_loss: 0.0199 - val_q1_loss: 0.0243 - val_q2_loss: 0.0099 - val_q3_loss: 0.0110 - val_q4_loss: 0.1038 - val_q5_loss: 0.0136 - val_q6_loss: 0.0447 - val_q7_loss: 0.0157 - val_q8_loss: 0.0234\n",
      "Epoch 187/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.4780 - q0_loss: 0.0249 - q1_loss: 0.0345 - q2_loss: 0.0212 - q3_loss: 0.0328 - q4_loss: 0.1934 - q5_loss: 0.0396 - q6_loss: 0.0627 - q7_loss: 0.0448 - q8_loss: 0.0375 - val_loss: 0.3457 - val_q0_loss: 0.0163 - val_q1_loss: 0.0171 - val_q2_loss: 0.0161 - val_q3_loss: 0.0206 - val_q4_loss: 0.0993 - val_q5_loss: 0.0273 - val_q6_loss: 0.0379 - val_q7_loss: 0.0320 - val_q8_loss: 0.0288\n",
      "Epoch 188/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.5108 - q0_loss: 0.0280 - q1_loss: 0.0322 - q2_loss: 0.0283 - q3_loss: 0.0323 - q4_loss: 0.1849 - q5_loss: 0.0404 - q6_loss: 0.0554 - q7_loss: 0.0500 - q8_loss: 0.0521 - val_loss: 0.3897 - val_q0_loss: 0.0192 - val_q1_loss: 0.0137 - val_q2_loss: 0.0228 - val_q3_loss: 0.0303 - val_q4_loss: 0.1014 - val_q5_loss: 0.0395 - val_q6_loss: 0.0328 - val_q7_loss: 0.0461 - val_q8_loss: 0.0345\n",
      "Epoch 189/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.4108 - q0_loss: 0.0219 - q1_loss: 0.0233 - q2_loss: 0.0136 - q3_loss: 0.0226 - q4_loss: 0.1882 - q5_loss: 0.0274 - q6_loss: 0.0520 - q7_loss: 0.0317 - q8_loss: 0.0291 - val_loss: 0.2731 - val_q0_loss: 0.0176 - val_q1_loss: 0.0121 - val_q2_loss: 0.0068 - val_q3_loss: 0.0075 - val_q4_loss: 0.1021 - val_q5_loss: 0.0088 - val_q6_loss: 0.0504 - val_q7_loss: 0.0126 - val_q8_loss: 0.0166\n",
      "Epoch 190/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.3613 - q0_loss: 0.0189 - q1_loss: 0.0222 - q2_loss: 0.0084 - q3_loss: 0.0124 - q4_loss: 0.1854 - q5_loss: 0.0154 - q6_loss: 0.0526 - q7_loss: 0.0208 - q8_loss: 0.0243 - val_loss: 0.2772 - val_q0_loss: 0.0164 - val_q1_loss: 0.0135 - val_q2_loss: 0.0056 - val_q3_loss: 0.0097 - val_q4_loss: 0.1006 - val_q5_loss: 0.0138 - val_q6_loss: 0.0402 - val_q7_loss: 0.0171 - val_q8_loss: 0.0183\n",
      "Epoch 191/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3832 - q0_loss: 0.0210 - q1_loss: 0.0266 - q2_loss: 0.0146 - q3_loss: 0.0160 - q4_loss: 0.1805 - q5_loss: 0.0189 - q6_loss: 0.0498 - q7_loss: 0.0248 - q8_loss: 0.0310 - val_loss: 0.4312 - val_q0_loss: 0.0282 - val_q1_loss: 0.0711 - val_q2_loss: 0.0322 - val_q3_loss: 0.0131 - val_q4_loss: 0.1139 - val_q5_loss: 0.0157 - val_q6_loss: 0.0456 - val_q7_loss: 0.0258 - val_q8_loss: 0.0706\n",
      "Epoch 192/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.4309 - q0_loss: 0.0201 - q1_loss: 0.0427 - q2_loss: 0.0130 - q3_loss: 0.0226 - q4_loss: 0.1839 - q5_loss: 0.0276 - q6_loss: 0.0521 - q7_loss: 0.0322 - q8_loss: 0.0310 - val_loss: 0.3920 - val_q0_loss: 0.0187 - val_q1_loss: 0.0358 - val_q2_loss: 0.0269 - val_q3_loss: 0.0203 - val_q4_loss: 0.0971 - val_q5_loss: 0.0263 - val_q6_loss: 0.0318 - val_q7_loss: 0.0358 - val_q8_loss: 0.0477\n",
      "Epoch 193/300\n",
      "269/269 [==============================] - 0s 175us/sample - loss: 0.4009 - q0_loss: 0.0209 - q1_loss: 0.0340 - q2_loss: 0.0163 - q3_loss: 0.0172 - q4_loss: 0.1812 - q5_loss: 0.0220 - q6_loss: 0.0409 - q7_loss: 0.0273 - q8_loss: 0.0377 - val_loss: 0.2988 - val_q0_loss: 0.0175 - val_q1_loss: 0.0226 - val_q2_loss: 0.0075 - val_q3_loss: 0.0116 - val_q4_loss: 0.0970 - val_q5_loss: 0.0137 - val_q6_loss: 0.0529 - val_q7_loss: 0.0168 - val_q8_loss: 0.0212\n",
      "Epoch 194/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.3604 - q0_loss: 0.0199 - q1_loss: 0.0323 - q2_loss: 0.0103 - q3_loss: 0.0116 - q4_loss: 0.1793 - q5_loss: 0.0149 - q6_loss: 0.0427 - q7_loss: 0.0187 - q8_loss: 0.0307 - val_loss: 0.2762 - val_q0_loss: 0.0161 - val_q1_loss: 0.0103 - val_q2_loss: 0.0083 - val_q3_loss: 0.0120 - val_q4_loss: 0.0987 - val_q5_loss: 0.0163 - val_q6_loss: 0.0318 - val_q7_loss: 0.0195 - val_q8_loss: 0.0174\n",
      "Epoch 195/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.3754 - q0_loss: 0.0200 - q1_loss: 0.0288 - q2_loss: 0.0140 - q3_loss: 0.0149 - q4_loss: 0.1811 - q5_loss: 0.0179 - q6_loss: 0.0470 - q7_loss: 0.0234 - q8_loss: 0.0319 - val_loss: 0.3726 - val_q0_loss: 0.0168 - val_q1_loss: 0.0319 - val_q2_loss: 0.0122 - val_q3_loss: 0.0326 - val_q4_loss: 0.1041 - val_q5_loss: 0.0414 - val_q6_loss: 0.0332 - val_q7_loss: 0.0457 - val_q8_loss: 0.0166\n",
      "Epoch 196/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.3890 - q0_loss: 0.0207 - q1_loss: 0.0226 - q2_loss: 0.0125 - q3_loss: 0.0217 - q4_loss: 0.1800 - q5_loss: 0.0272 - q6_loss: 0.0428 - q7_loss: 0.0310 - q8_loss: 0.0277 - val_loss: 0.3035 - val_q0_loss: 0.0201 - val_q1_loss: 0.0380 - val_q2_loss: 0.0151 - val_q3_loss: 0.0074 - val_q4_loss: 0.1030 - val_q5_loss: 0.0092 - val_q6_loss: 0.0333 - val_q7_loss: 0.0148 - val_q8_loss: 0.0327\n",
      "Epoch 197/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3932 - q0_loss: 0.0209 - q1_loss: 0.0244 - q2_loss: 0.0143 - q3_loss: 0.0238 - q4_loss: 0.1747 - q5_loss: 0.0283 - q6_loss: 0.0493 - q7_loss: 0.0326 - q8_loss: 0.0277 - val_loss: 0.3438 - val_q0_loss: 0.0200 - val_q1_loss: 0.0125 - val_q2_loss: 0.0186 - val_q3_loss: 0.0205 - val_q4_loss: 0.0940 - val_q5_loss: 0.0269 - val_q6_loss: 0.0311 - val_q7_loss: 0.0324 - val_q8_loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.3810 - q0_loss: 0.0205 - q1_loss: 0.0264 - q2_loss: 0.0165 - q3_loss: 0.0177 - q4_loss: 0.1687 - q5_loss: 0.0224 - q6_loss: 0.0370 - q7_loss: 0.0292 - q8_loss: 0.0369 - val_loss: 0.3185 - val_q0_loss: 0.0174 - val_q1_loss: 0.0337 - val_q2_loss: 0.0155 - val_q3_loss: 0.0073 - val_q4_loss: 0.0958 - val_q5_loss: 0.0093 - val_q6_loss: 0.0386 - val_q7_loss: 0.0140 - val_q8_loss: 0.0324\n",
      "Epoch 199/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.4680 - q0_loss: 0.0245 - q1_loss: 0.0264 - q2_loss: 0.0192 - q3_loss: 0.0371 - q4_loss: 0.1729 - q5_loss: 0.0454 - q6_loss: 0.0649 - q7_loss: 0.0507 - q8_loss: 0.0326 - val_loss: 0.4599 - val_q0_loss: 0.0187 - val_q1_loss: 0.0381 - val_q2_loss: 0.0193 - val_q3_loss: 0.0471 - val_q4_loss: 0.0998 - val_q5_loss: 0.0586 - val_q6_loss: 0.0519 - val_q7_loss: 0.0656 - val_q8_loss: 0.0221\n",
      "Epoch 200/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.4344 - q0_loss: 0.0232 - q1_loss: 0.0303 - q2_loss: 0.0196 - q3_loss: 0.0247 - q4_loss: 0.1850 - q5_loss: 0.0315 - q6_loss: 0.0497 - q7_loss: 0.0364 - q8_loss: 0.0386 - val_loss: 0.2850 - val_q0_loss: 0.0181 - val_q1_loss: 0.0207 - val_q2_loss: 0.0062 - val_q3_loss: 0.0137 - val_q4_loss: 0.0923 - val_q5_loss: 0.0165 - val_q6_loss: 0.0412 - val_q7_loss: 0.0212 - val_q8_loss: 0.0176\n",
      "Epoch 201/300\n",
      "269/269 [==============================] - 0s 187us/sample - loss: 0.3630 - q0_loss: 0.0203 - q1_loss: 0.0165 - q2_loss: 0.0135 - q3_loss: 0.0203 - q4_loss: 0.1750 - q5_loss: 0.0252 - q6_loss: 0.0347 - q7_loss: 0.0309 - q8_loss: 0.0290 - val_loss: 0.3520 - val_q0_loss: 0.0167 - val_q1_loss: 0.0153 - val_q2_loss: 0.0221 - val_q3_loss: 0.0265 - val_q4_loss: 0.0913 - val_q5_loss: 0.0336 - val_q6_loss: 0.0232 - val_q7_loss: 0.0419 - val_q8_loss: 0.0382\n",
      "Epoch 202/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.4231 - q0_loss: 0.0243 - q1_loss: 0.0171 - q2_loss: 0.0210 - q3_loss: 0.0273 - q4_loss: 0.1809 - q5_loss: 0.0340 - q6_loss: 0.0466 - q7_loss: 0.0403 - q8_loss: 0.0390 - val_loss: 0.3945 - val_q0_loss: 0.0176 - val_q1_loss: 0.0139 - val_q2_loss: 0.0250 - val_q3_loss: 0.0379 - val_q4_loss: 0.0929 - val_q5_loss: 0.0470 - val_q6_loss: 0.0386 - val_q7_loss: 0.0536 - val_q8_loss: 0.0394\n",
      "Epoch 203/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.4106 - q0_loss: 0.0229 - q1_loss: 0.0164 - q2_loss: 0.0210 - q3_loss: 0.0256 - q4_loss: 0.1792 - q5_loss: 0.0313 - q6_loss: 0.0425 - q7_loss: 0.0390 - q8_loss: 0.0403 - val_loss: 0.3721 - val_q0_loss: 0.0166 - val_q1_loss: 0.0126 - val_q2_loss: 0.0211 - val_q3_loss: 0.0349 - val_q4_loss: 0.0912 - val_q5_loss: 0.0445 - val_q6_loss: 0.0332 - val_q7_loss: 0.0518 - val_q8_loss: 0.0391\n",
      "Epoch 204/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.3976 - q0_loss: 0.0238 - q1_loss: 0.0155 - q2_loss: 0.0201 - q3_loss: 0.0257 - q4_loss: 0.1716 - q5_loss: 0.0326 - q6_loss: 0.0389 - q7_loss: 0.0394 - q8_loss: 0.0375 - val_loss: 0.3014 - val_q0_loss: 0.0158 - val_q1_loss: 0.0208 - val_q2_loss: 0.0124 - val_q3_loss: 0.0205 - val_q4_loss: 0.0925 - val_q5_loss: 0.0264 - val_q6_loss: 0.0170 - val_q7_loss: 0.0312 - val_q8_loss: 0.0268\n",
      "Epoch 205/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.3650 - q0_loss: 0.0209 - q1_loss: 0.0183 - q2_loss: 0.0169 - q3_loss: 0.0195 - q4_loss: 0.1721 - q5_loss: 0.0240 - q6_loss: 0.0354 - q7_loss: 0.0288 - q8_loss: 0.0318 - val_loss: 0.4120 - val_q0_loss: 0.0279 - val_q1_loss: 0.0172 - val_q2_loss: 0.0243 - val_q3_loss: 0.0309 - val_q4_loss: 0.0936 - val_q5_loss: 0.0382 - val_q6_loss: 0.0611 - val_q7_loss: 0.0464 - val_q8_loss: 0.0455\n",
      "Epoch 206/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.4034 - q0_loss: 0.0239 - q1_loss: 0.0237 - q2_loss: 0.0179 - q3_loss: 0.0254 - q4_loss: 0.1761 - q5_loss: 0.0311 - q6_loss: 0.0382 - q7_loss: 0.0381 - q8_loss: 0.0354 - val_loss: 0.2706 - val_q0_loss: 0.0192 - val_q1_loss: 0.0170 - val_q2_loss: 0.0081 - val_q3_loss: 0.0126 - val_q4_loss: 0.0901 - val_q5_loss: 0.0148 - val_q6_loss: 0.0389 - val_q7_loss: 0.0170 - val_q8_loss: 0.0182\n",
      "Epoch 207/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.3565 - q0_loss: 0.0201 - q1_loss: 0.0267 - q2_loss: 0.0115 - q3_loss: 0.0183 - q4_loss: 0.1720 - q5_loss: 0.0222 - q6_loss: 0.0357 - q7_loss: 0.0254 - q8_loss: 0.0275 - val_loss: 0.2771 - val_q0_loss: 0.0163 - val_q1_loss: 0.0267 - val_q2_loss: 0.0127 - val_q3_loss: 0.0077 - val_q4_loss: 0.0893 - val_q5_loss: 0.0107 - val_q6_loss: 0.0292 - val_q7_loss: 0.0165 - val_q8_loss: 0.0278\n",
      "Epoch 208/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.3331 - q0_loss: 0.0192 - q1_loss: 0.0318 - q2_loss: 0.0117 - q3_loss: 0.0108 - q4_loss: 0.1707 - q5_loss: 0.0124 - q6_loss: 0.0306 - q7_loss: 0.0172 - q8_loss: 0.0297 - val_loss: 0.3470 - val_q0_loss: 0.0196 - val_q1_loss: 0.0317 - val_q2_loss: 0.0076 - val_q3_loss: 0.0258 - val_q4_loss: 0.0905 - val_q5_loss: 0.0313 - val_q6_loss: 0.0582 - val_q7_loss: 0.0315 - val_q8_loss: 0.0163\n",
      "Epoch 209/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.3578 - q0_loss: 0.0206 - q1_loss: 0.0306 - q2_loss: 0.0120 - q3_loss: 0.0174 - q4_loss: 0.1669 - q5_loss: 0.0212 - q6_loss: 0.0350 - q7_loss: 0.0251 - q8_loss: 0.0310 - val_loss: 0.3531 - val_q0_loss: 0.0191 - val_q1_loss: 0.0233 - val_q2_loss: 0.0207 - val_q3_loss: 0.0260 - val_q4_loss: 0.0908 - val_q5_loss: 0.0324 - val_q6_loss: 0.0226 - val_q7_loss: 0.0392 - val_q8_loss: 0.0350\n",
      "Epoch 210/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.3338 - q0_loss: 0.0201 - q1_loss: 0.0182 - q2_loss: 0.0130 - q3_loss: 0.0152 - q4_loss: 0.1545 - q5_loss: 0.0176 - q6_loss: 0.0302 - q7_loss: 0.0242 - q8_loss: 0.0303 - val_loss: 0.3255 - val_q0_loss: 0.0239 - val_q1_loss: 0.0123 - val_q2_loss: 0.0153 - val_q3_loss: 0.0232 - val_q4_loss: 0.0912 - val_q5_loss: 0.0279 - val_q6_loss: 0.0482 - val_q7_loss: 0.0324 - val_q8_loss: 0.0269\n",
      "Epoch 211/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3161 - q0_loss: 0.0196 - q1_loss: 0.0212 - q2_loss: 0.0111 - q3_loss: 0.0129 - q4_loss: 0.1620 - q5_loss: 0.0160 - q6_loss: 0.0227 - q7_loss: 0.0210 - q8_loss: 0.0295 - val_loss: 0.2395 - val_q0_loss: 0.0185 - val_q1_loss: 0.0140 - val_q2_loss: 0.0085 - val_q3_loss: 0.0087 - val_q4_loss: 0.0887 - val_q5_loss: 0.0102 - val_q6_loss: 0.0218 - val_q7_loss: 0.0138 - val_q8_loss: 0.0181\n",
      "Epoch 212/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.2973 - q0_loss: 0.0192 - q1_loss: 0.0167 - q2_loss: 0.0091 - q3_loss: 0.0105 - q4_loss: 0.1630 - q5_loss: 0.0125 - q6_loss: 0.0252 - q7_loss: 0.0174 - q8_loss: 0.0251 - val_loss: 0.2645 - val_q0_loss: 0.0152 - val_q1_loss: 0.0125 - val_q2_loss: 0.0117 - val_q3_loss: 0.0165 - val_q4_loss: 0.0850 - val_q5_loss: 0.0210 - val_q6_loss: 0.0178 - val_q7_loss: 0.0263 - val_q8_loss: 0.0240\n",
      "Epoch 213/300\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 0.3058 - q0_loss: 0.0198 - q1_loss: 0.0137 - q2_loss: 0.0117 - q3_loss: 0.0131 - q4_loss: 0.1632 - q5_loss: 0.0159 - q6_loss: 0.0224 - q7_loss: 0.0225 - q8_loss: 0.0287 - val_loss: 0.2648 - val_q0_loss: 0.0177 - val_q1_loss: 0.0142 - val_q2_loss: 0.0086 - val_q3_loss: 0.0156 - val_q4_loss: 0.0850 - val_q5_loss: 0.0199 - val_q6_loss: 0.0197 - val_q7_loss: 0.0228 - val_q8_loss: 0.0172\n",
      "Epoch 214/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.3978 - q0_loss: 0.0219 - q1_loss: 0.0301 - q2_loss: 0.0126 - q3_loss: 0.0284 - q4_loss: 0.1664 - q5_loss: 0.0357 - q6_loss: 0.0466 - q7_loss: 0.0389 - q8_loss: 0.0256 - val_loss: 0.3859 - val_q0_loss: 0.0207 - val_q1_loss: 0.0780 - val_q2_loss: 0.0186 - val_q3_loss: 0.0186 - val_q4_loss: 0.1006 - val_q5_loss: 0.0238 - val_q6_loss: 0.0311 - val_q7_loss: 0.0223 - val_q8_loss: 0.0498\n",
      "Epoch 215/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.4166 - q0_loss: 0.0231 - q1_loss: 0.0423 - q2_loss: 0.0229 - q3_loss: 0.0227 - q4_loss: 0.1630 - q5_loss: 0.0292 - q6_loss: 0.0340 - q7_loss: 0.0358 - q8_loss: 0.0484 - val_loss: 0.3078 - val_q0_loss: 0.0159 - val_q1_loss: 0.0450 - val_q2_loss: 0.0103 - val_q3_loss: 0.0131 - val_q4_loss: 0.0839 - val_q5_loss: 0.0143 - val_q6_loss: 0.0426 - val_q7_loss: 0.0171 - val_q8_loss: 0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.3427 - q0_loss: 0.0210 - q1_loss: 0.0277 - q2_loss: 0.0120 - q3_loss: 0.0173 - q4_loss: 0.1600 - q5_loss: 0.0211 - q6_loss: 0.0302 - q7_loss: 0.0255 - q8_loss: 0.0290 - val_loss: 0.2462 - val_q0_loss: 0.0166 - val_q1_loss: 0.0183 - val_q2_loss: 0.0075 - val_q3_loss: 0.0105 - val_q4_loss: 0.0835 - val_q5_loss: 0.0137 - val_q6_loss: 0.0208 - val_q7_loss: 0.0161 - val_q8_loss: 0.0204\n",
      "Epoch 217/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.2979 - q0_loss: 0.0186 - q1_loss: 0.0190 - q2_loss: 0.0092 - q3_loss: 0.0124 - q4_loss: 0.1513 - q5_loss: 0.0146 - q6_loss: 0.0257 - q7_loss: 0.0197 - q8_loss: 0.0247 - val_loss: 0.2227 - val_q0_loss: 0.0177 - val_q1_loss: 0.0135 - val_q2_loss: 0.0073 - val_q3_loss: 0.0073 - val_q4_loss: 0.0837 - val_q5_loss: 0.0079 - val_q6_loss: 0.0217 - val_q7_loss: 0.0117 - val_q8_loss: 0.0165\n",
      "Epoch 218/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.3695 - q0_loss: 0.0211 - q1_loss: 0.0360 - q2_loss: 0.0127 - q3_loss: 0.0225 - q4_loss: 0.1506 - q5_loss: 0.0271 - q6_loss: 0.0381 - q7_loss: 0.0318 - q8_loss: 0.0300 - val_loss: 0.5305 - val_q0_loss: 0.0335 - val_q1_loss: 0.0516 - val_q2_loss: 0.0331 - val_q3_loss: 0.0484 - val_q4_loss: 0.0888 - val_q5_loss: 0.0600 - val_q6_loss: 0.0789 - val_q7_loss: 0.0685 - val_q8_loss: 0.0557\n",
      "Epoch 219/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.4114 - q0_loss: 0.0215 - q1_loss: 0.0475 - q2_loss: 0.0211 - q3_loss: 0.0224 - q4_loss: 0.1540 - q5_loss: 0.0286 - q6_loss: 0.0353 - q7_loss: 0.0333 - q8_loss: 0.0450 - val_loss: 0.3734 - val_q0_loss: 0.0205 - val_q1_loss: 0.0604 - val_q2_loss: 0.0307 - val_q3_loss: 0.0106 - val_q4_loss: 0.0913 - val_q5_loss: 0.0130 - val_q6_loss: 0.0188 - val_q7_loss: 0.0221 - val_q8_loss: 0.0573\n",
      "Epoch 220/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.3989 - q0_loss: 0.0219 - q1_loss: 0.0679 - q2_loss: 0.0231 - q3_loss: 0.0117 - q4_loss: 0.1553 - q5_loss: 0.0135 - q6_loss: 0.0289 - q7_loss: 0.0193 - q8_loss: 0.0537 - val_loss: 0.2576 - val_q0_loss: 0.0193 - val_q1_loss: 0.0385 - val_q2_loss: 0.0131 - val_q3_loss: 0.0070 - val_q4_loss: 0.0922 - val_q5_loss: 0.0088 - val_q6_loss: 0.0116 - val_q7_loss: 0.0129 - val_q8_loss: 0.0352\n",
      "Epoch 221/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3795 - q0_loss: 0.0198 - q1_loss: 0.0533 - q2_loss: 0.0169 - q3_loss: 0.0186 - q4_loss: 0.1533 - q5_loss: 0.0219 - q6_loss: 0.0311 - q7_loss: 0.0266 - q8_loss: 0.0431 - val_loss: 0.2573 - val_q0_loss: 0.0199 - val_q1_loss: 0.0297 - val_q2_loss: 0.0125 - val_q3_loss: 0.0083 - val_q4_loss: 0.0914 - val_q5_loss: 0.0096 - val_q6_loss: 0.0199 - val_q7_loss: 0.0131 - val_q8_loss: 0.0324\n",
      "Epoch 222/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.3387 - q0_loss: 0.0203 - q1_loss: 0.0332 - q2_loss: 0.0154 - q3_loss: 0.0156 - q4_loss: 0.1415 - q5_loss: 0.0186 - q6_loss: 0.0255 - q7_loss: 0.0233 - q8_loss: 0.0357 - val_loss: 0.2138 - val_q0_loss: 0.0170 - val_q1_loss: 0.0135 - val_q2_loss: 0.0052 - val_q3_loss: 0.0080 - val_q4_loss: 0.0865 - val_q5_loss: 0.0106 - val_q6_loss: 0.0138 - val_q7_loss: 0.0136 - val_q8_loss: 0.0163\n",
      "Epoch 223/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.3131 - q0_loss: 0.0197 - q1_loss: 0.0280 - q2_loss: 0.0111 - q3_loss: 0.0146 - q4_loss: 0.1486 - q5_loss: 0.0176 - q6_loss: 0.0264 - q7_loss: 0.0223 - q8_loss: 0.0304 - val_loss: 0.2713 - val_q0_loss: 0.0167 - val_q1_loss: 0.0372 - val_q2_loss: 0.0125 - val_q3_loss: 0.0093 - val_q4_loss: 0.0796 - val_q5_loss: 0.0110 - val_q6_loss: 0.0211 - val_q7_loss: 0.0154 - val_q8_loss: 0.0281\n",
      "Epoch 224/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.3698 - q0_loss: 0.0224 - q1_loss: 0.0269 - q2_loss: 0.0181 - q3_loss: 0.0247 - q4_loss: 0.1438 - q5_loss: 0.0300 - q6_loss: 0.0345 - q7_loss: 0.0356 - q8_loss: 0.0332 - val_loss: 0.4169 - val_q0_loss: 0.0200 - val_q1_loss: 0.0331 - val_q2_loss: 0.0176 - val_q3_loss: 0.0420 - val_q4_loss: 0.0831 - val_q5_loss: 0.0526 - val_q6_loss: 0.0570 - val_q7_loss: 0.0581 - val_q8_loss: 0.0206\n",
      "Epoch 225/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.4002 - q0_loss: 0.0232 - q1_loss: 0.0336 - q2_loss: 0.0177 - q3_loss: 0.0273 - q4_loss: 0.1458 - q5_loss: 0.0341 - q6_loss: 0.0426 - q7_loss: 0.0385 - q8_loss: 0.0347 - val_loss: 0.4087 - val_q0_loss: 0.0227 - val_q1_loss: 0.0476 - val_q2_loss: 0.0304 - val_q3_loss: 0.0265 - val_q4_loss: 0.0829 - val_q5_loss: 0.0331 - val_q6_loss: 0.0291 - val_q7_loss: 0.0403 - val_q8_loss: 0.0558\n",
      "Epoch 226/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.3706 - q0_loss: 0.0207 - q1_loss: 0.0323 - q2_loss: 0.0145 - q3_loss: 0.0236 - q4_loss: 0.1433 - q5_loss: 0.0299 - q6_loss: 0.0372 - q7_loss: 0.0356 - q8_loss: 0.0313 - val_loss: 0.3346 - val_q0_loss: 0.0251 - val_q1_loss: 0.0314 - val_q2_loss: 0.0235 - val_q3_loss: 0.0205 - val_q4_loss: 0.0886 - val_q5_loss: 0.0255 - val_q6_loss: 0.0334 - val_q7_loss: 0.0304 - val_q8_loss: 0.0480\n",
      "Epoch 227/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3201 - q0_loss: 0.0207 - q1_loss: 0.0261 - q2_loss: 0.0131 - q3_loss: 0.0154 - q4_loss: 0.1446 - q5_loss: 0.0187 - q6_loss: 0.0235 - q7_loss: 0.0243 - q8_loss: 0.0342 - val_loss: 0.3381 - val_q0_loss: 0.0178 - val_q1_loss: 0.0281 - val_q2_loss: 0.0124 - val_q3_loss: 0.0308 - val_q4_loss: 0.0809 - val_q5_loss: 0.0383 - val_q6_loss: 0.0390 - val_q7_loss: 0.0427 - val_q8_loss: 0.0173\n",
      "Epoch 228/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.3833 - q0_loss: 0.0229 - q1_loss: 0.0243 - q2_loss: 0.0181 - q3_loss: 0.0264 - q4_loss: 0.1484 - q5_loss: 0.0319 - q6_loss: 0.0397 - q7_loss: 0.0374 - q8_loss: 0.0348 - val_loss: 0.3305 - val_q0_loss: 0.0184 - val_q1_loss: 0.0225 - val_q2_loss: 0.0236 - val_q3_loss: 0.0237 - val_q4_loss: 0.0758 - val_q5_loss: 0.0295 - val_q6_loss: 0.0224 - val_q7_loss: 0.0364 - val_q8_loss: 0.0397\n",
      "Epoch 229/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.3064 - q0_loss: 0.0199 - q1_loss: 0.0289 - q2_loss: 0.0110 - q3_loss: 0.0154 - q4_loss: 0.1361 - q5_loss: 0.0183 - q6_loss: 0.0236 - q7_loss: 0.0225 - q8_loss: 0.0286 - val_loss: 0.2907 - val_q0_loss: 0.0175 - val_q1_loss: 0.0457 - val_q2_loss: 0.0202 - val_q3_loss: 0.0067 - val_q4_loss: 0.0803 - val_q5_loss: 0.0088 - val_q6_loss: 0.0143 - val_q7_loss: 0.0145 - val_q8_loss: 0.0428\n",
      "Epoch 230/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.3304 - q0_loss: 0.0202 - q1_loss: 0.0362 - q2_loss: 0.0136 - q3_loss: 0.0178 - q4_loss: 0.1402 - q5_loss: 0.0213 - q6_loss: 0.0294 - q7_loss: 0.0255 - q8_loss: 0.0327 - val_loss: 0.5025 - val_q0_loss: 0.0387 - val_q1_loss: 0.0468 - val_q2_loss: 0.0424 - val_q3_loss: 0.0407 - val_q4_loss: 0.0962 - val_q5_loss: 0.0505 - val_q6_loss: 0.0561 - val_q7_loss: 0.0614 - val_q8_loss: 0.0771\n",
      "Epoch 231/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.4308 - q0_loss: 0.0266 - q1_loss: 0.0320 - q2_loss: 0.0263 - q3_loss: 0.0304 - q4_loss: 0.1371 - q5_loss: 0.0374 - q6_loss: 0.0401 - q7_loss: 0.0439 - q8_loss: 0.0505 - val_loss: 0.4440 - val_q0_loss: 0.0291 - val_q1_loss: 0.0348 - val_q2_loss: 0.0200 - val_q3_loss: 0.0475 - val_q4_loss: 0.0780 - val_q5_loss: 0.0583 - val_q6_loss: 0.0817 - val_q7_loss: 0.0638 - val_q8_loss: 0.0247\n",
      "Epoch 232/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.4330 - q0_loss: 0.0258 - q1_loss: 0.0237 - q2_loss: 0.0209 - q3_loss: 0.0396 - q4_loss: 0.1394 - q5_loss: 0.0488 - q6_loss: 0.0615 - q7_loss: 0.0541 - q8_loss: 0.0324 - val_loss: 0.3449 - val_q0_loss: 0.0186 - val_q1_loss: 0.0370 - val_q2_loss: 0.0099 - val_q3_loss: 0.0304 - val_q4_loss: 0.0760 - val_q5_loss: 0.0382 - val_q6_loss: 0.0454 - val_q7_loss: 0.0409 - val_q8_loss: 0.0168\n",
      "Epoch 233/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3920 - q0_loss: 0.0230 - q1_loss: 0.0264 - q2_loss: 0.0215 - q3_loss: 0.0297 - q4_loss: 0.1263 - q5_loss: 0.0368 - q6_loss: 0.0418 - q7_loss: 0.0436 - q8_loss: 0.0393 - val_loss: 0.3768 - val_q0_loss: 0.0223 - val_q1_loss: 0.0120 - val_q2_loss: 0.0230 - val_q3_loss: 0.0351 - val_q4_loss: 0.0711 - val_q5_loss: 0.0443 - val_q6_loss: 0.0467 - val_q7_loss: 0.0505 - val_q8_loss: 0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.3444 - q0_loss: 0.0230 - q1_loss: 0.0207 - q2_loss: 0.0167 - q3_loss: 0.0244 - q4_loss: 0.1281 - q5_loss: 0.0294 - q6_loss: 0.0351 - q7_loss: 0.0355 - q8_loss: 0.0319 - val_loss: 0.4912 - val_q0_loss: 0.0249 - val_q1_loss: 0.0253 - val_q2_loss: 0.0285 - val_q3_loss: 0.0518 - val_q4_loss: 0.0734 - val_q5_loss: 0.0655 - val_q6_loss: 0.0736 - val_q7_loss: 0.0722 - val_q8_loss: 0.0378\n",
      "Epoch 235/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.5230 - q0_loss: 0.0304 - q1_loss: 0.0289 - q2_loss: 0.0288 - q3_loss: 0.0499 - q4_loss: 0.1307 - q5_loss: 0.0618 - q6_loss: 0.0759 - q7_loss: 0.0698 - q8_loss: 0.0448 - val_loss: 0.6186 - val_q0_loss: 0.0387 - val_q1_loss: 0.0366 - val_q2_loss: 0.0331 - val_q3_loss: 0.0719 - val_q4_loss: 0.0746 - val_q5_loss: 0.0868 - val_q6_loss: 0.1132 - val_q7_loss: 0.0949 - val_q8_loss: 0.0445\n",
      "Epoch 236/300\n",
      "269/269 [==============================] - 0s 194us/sample - loss: 0.5145 - q0_loss: 0.0305 - q1_loss: 0.0500 - q2_loss: 0.0308 - q3_loss: 0.0410 - q4_loss: 0.1344 - q5_loss: 0.0510 - q6_loss: 0.0593 - q7_loss: 0.0582 - q8_loss: 0.0577 - val_loss: 0.3727 - val_q0_loss: 0.0216 - val_q1_loss: 0.0281 - val_q2_loss: 0.0283 - val_q3_loss: 0.0279 - val_q4_loss: 0.0715 - val_q5_loss: 0.0366 - val_q6_loss: 0.0325 - val_q7_loss: 0.0463 - val_q8_loss: 0.0486\n",
      "Epoch 237/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.3665 - q0_loss: 0.0239 - q1_loss: 0.0251 - q2_loss: 0.0198 - q3_loss: 0.0248 - q4_loss: 0.1282 - q5_loss: 0.0299 - q6_loss: 0.0348 - q7_loss: 0.0380 - q8_loss: 0.0402 - val_loss: 0.3086 - val_q0_loss: 0.0205 - val_q1_loss: 0.0153 - val_q2_loss: 0.0151 - val_q3_loss: 0.0251 - val_q4_loss: 0.0726 - val_q5_loss: 0.0302 - val_q6_loss: 0.0378 - val_q7_loss: 0.0363 - val_q8_loss: 0.0294\n",
      "Epoch 238/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.3412 - q0_loss: 0.0217 - q1_loss: 0.0173 - q2_loss: 0.0153 - q3_loss: 0.0241 - q4_loss: 0.1279 - q5_loss: 0.0302 - q6_loss: 0.0363 - q7_loss: 0.0350 - q8_loss: 0.0295 - val_loss: 0.1965 - val_q0_loss: 0.0168 - val_q1_loss: 0.0150 - val_q2_loss: 0.0087 - val_q3_loss: 0.0067 - val_q4_loss: 0.0697 - val_q5_loss: 0.0082 - val_q6_loss: 0.0092 - val_q7_loss: 0.0127 - val_q8_loss: 0.0193\n",
      "Epoch 239/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.2459 - q0_loss: 0.0187 - q1_loss: 0.0160 - q2_loss: 0.0090 - q3_loss: 0.0104 - q4_loss: 0.1276 - q5_loss: 0.0118 - q6_loss: 0.0137 - q7_loss: 0.0159 - q8_loss: 0.0246 - val_loss: 0.2112 - val_q0_loss: 0.0174 - val_q1_loss: 0.0172 - val_q2_loss: 0.0071 - val_q3_loss: 0.0096 - val_q4_loss: 0.0672 - val_q5_loss: 0.0112 - val_q6_loss: 0.0155 - val_q7_loss: 0.0135 - val_q8_loss: 0.0176\n",
      "Epoch 240/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.2659 - q0_loss: 0.0193 - q1_loss: 0.0192 - q2_loss: 0.0101 - q3_loss: 0.0145 - q4_loss: 0.1226 - q5_loss: 0.0170 - q6_loss: 0.0225 - q7_loss: 0.0212 - q8_loss: 0.0257 - val_loss: 0.2932 - val_q0_loss: 0.0192 - val_q1_loss: 0.0347 - val_q2_loss: 0.0100 - val_q3_loss: 0.0201 - val_q4_loss: 0.0662 - val_q5_loss: 0.0255 - val_q6_loss: 0.0400 - val_q7_loss: 0.0288 - val_q8_loss: 0.0246\n",
      "Epoch 241/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.2971 - q0_loss: 0.0201 - q1_loss: 0.0192 - q2_loss: 0.0124 - q3_loss: 0.0185 - q4_loss: 0.1254 - q5_loss: 0.0223 - q6_loss: 0.0269 - q7_loss: 0.0262 - q8_loss: 0.0272 - val_loss: 0.5252 - val_q0_loss: 0.0268 - val_q1_loss: 0.0168 - val_q2_loss: 0.0414 - val_q3_loss: 0.0565 - val_q4_loss: 0.0717 - val_q5_loss: 0.0693 - val_q6_loss: 0.0727 - val_q7_loss: 0.0786 - val_q8_loss: 0.0599\n",
      "Epoch 242/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.5286 - q0_loss: 0.0291 - q1_loss: 0.0305 - q2_loss: 0.0304 - q3_loss: 0.0506 - q4_loss: 0.1264 - q5_loss: 0.0630 - q6_loss: 0.0765 - q7_loss: 0.0708 - q8_loss: 0.0496 - val_loss: 0.4283 - val_q0_loss: 0.0279 - val_q1_loss: 0.0355 - val_q2_loss: 0.0295 - val_q3_loss: 0.0348 - val_q4_loss: 0.0778 - val_q5_loss: 0.0429 - val_q6_loss: 0.0466 - val_q7_loss: 0.0540 - val_q8_loss: 0.0575\n",
      "Epoch 243/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.3768 - q0_loss: 0.0231 - q1_loss: 0.0297 - q2_loss: 0.0233 - q3_loss: 0.0255 - q4_loss: 0.1256 - q5_loss: 0.0310 - q6_loss: 0.0336 - q7_loss: 0.0379 - q8_loss: 0.0426 - val_loss: 0.3191 - val_q0_loss: 0.0212 - val_q1_loss: 0.0142 - val_q2_loss: 0.0191 - val_q3_loss: 0.0250 - val_q4_loss: 0.0680 - val_q5_loss: 0.0305 - val_q6_loss: 0.0357 - val_q7_loss: 0.0390 - val_q8_loss: 0.0372\n",
      "Epoch 244/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 0.3396 - q0_loss: 0.0199 - q1_loss: 0.0401 - q2_loss: 0.0142 - q3_loss: 0.0221 - q4_loss: 0.1215 - q5_loss: 0.0266 - q6_loss: 0.0358 - q7_loss: 0.0301 - q8_loss: 0.0343 - val_loss: 0.3928 - val_q0_loss: 0.0224 - val_q1_loss: 0.0481 - val_q2_loss: 0.0226 - val_q3_loss: 0.0293 - val_q4_loss: 0.0810 - val_q5_loss: 0.0368 - val_q6_loss: 0.0445 - val_q7_loss: 0.0441 - val_q8_loss: 0.0453\n",
      "Epoch 245/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.3947 - q0_loss: 0.0251 - q1_loss: 0.0345 - q2_loss: 0.0236 - q3_loss: 0.0288 - q4_loss: 0.1257 - q5_loss: 0.0354 - q6_loss: 0.0427 - q7_loss: 0.0412 - q8_loss: 0.0450 - val_loss: 0.4184 - val_q0_loss: 0.0213 - val_q1_loss: 0.0193 - val_q2_loss: 0.0291 - val_q3_loss: 0.0411 - val_q4_loss: 0.0614 - val_q5_loss: 0.0524 - val_q6_loss: 0.0550 - val_q7_loss: 0.0617 - val_q8_loss: 0.0524\n",
      "Epoch 246/300\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 0.3942 - q0_loss: 0.0246 - q1_loss: 0.0282 - q2_loss: 0.0242 - q3_loss: 0.0294 - q4_loss: 0.1216 - q5_loss: 0.0359 - q6_loss: 0.0410 - q7_loss: 0.0463 - q8_loss: 0.0445 - val_loss: 0.1934 - val_q0_loss: 0.0185 - val_q1_loss: 0.0136 - val_q2_loss: 0.0084 - val_q3_loss: 0.0076 - val_q4_loss: 0.0715 - val_q5_loss: 0.0088 - val_q6_loss: 0.0123 - val_q7_loss: 0.0139 - val_q8_loss: 0.0181\n",
      "Epoch 247/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.3061 - q0_loss: 0.0217 - q1_loss: 0.0269 - q2_loss: 0.0145 - q3_loss: 0.0185 - q4_loss: 0.1159 - q5_loss: 0.0211 - q6_loss: 0.0259 - q7_loss: 0.0261 - q8_loss: 0.0318 - val_loss: 0.2515 - val_q0_loss: 0.0175 - val_q1_loss: 0.0252 - val_q2_loss: 0.0089 - val_q3_loss: 0.0164 - val_q4_loss: 0.0734 - val_q5_loss: 0.0207 - val_q6_loss: 0.0249 - val_q7_loss: 0.0249 - val_q8_loss: 0.0222\n",
      "Epoch 248/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 0.2887 - q0_loss: 0.0197 - q1_loss: 0.0205 - q2_loss: 0.0109 - q3_loss: 0.0192 - q4_loss: 0.1144 - q5_loss: 0.0238 - q6_loss: 0.0293 - q7_loss: 0.0274 - q8_loss: 0.0260 - val_loss: 0.2380 - val_q0_loss: 0.0166 - val_q1_loss: 0.0217 - val_q2_loss: 0.0077 - val_q3_loss: 0.0159 - val_q4_loss: 0.0677 - val_q5_loss: 0.0204 - val_q6_loss: 0.0215 - val_q7_loss: 0.0252 - val_q8_loss: 0.0191\n",
      "Epoch 249/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.2435 - q0_loss: 0.0186 - q1_loss: 0.0213 - q2_loss: 0.0092 - q3_loss: 0.0105 - q4_loss: 0.1110 - q5_loss: 0.0125 - q6_loss: 0.0161 - q7_loss: 0.0176 - q8_loss: 0.0261 - val_loss: 0.2125 - val_q0_loss: 0.0196 - val_q1_loss: 0.0192 - val_q2_loss: 0.0080 - val_q3_loss: 0.0111 - val_q4_loss: 0.0673 - val_q5_loss: 0.0132 - val_q6_loss: 0.0175 - val_q7_loss: 0.0155 - val_q8_loss: 0.0198\n",
      "Epoch 250/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 0.2519 - q0_loss: 0.0188 - q1_loss: 0.0267 - q2_loss: 0.0090 - q3_loss: 0.0128 - q4_loss: 0.1092 - q5_loss: 0.0149 - q6_loss: 0.0202 - q7_loss: 0.0200 - q8_loss: 0.0256 - val_loss: 0.3528 - val_q0_loss: 0.0181 - val_q1_loss: 0.0622 - val_q2_loss: 0.0079 - val_q3_loss: 0.0276 - val_q4_loss: 0.0629 - val_q5_loss: 0.0335 - val_q6_loss: 0.0527 - val_q7_loss: 0.0348 - val_q8_loss: 0.0257\n",
      "Epoch 251/300\n",
      "269/269 [==============================] - 0s 194us/sample - loss: 0.3150 - q0_loss: 0.0205 - q1_loss: 0.0383 - q2_loss: 0.0146 - q3_loss: 0.0179 - q4_loss: 0.1062 - q5_loss: 0.0220 - q6_loss: 0.0273 - q7_loss: 0.0251 - q8_loss: 0.0359 - val_loss: 0.2191 - val_q0_loss: 0.0184 - val_q1_loss: 0.0148 - val_q2_loss: 0.0093 - val_q3_loss: 0.0128 - val_q4_loss: 0.0645 - val_q5_loss: 0.0158 - val_q6_loss: 0.0189 - val_q7_loss: 0.0209 - val_q8_loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.2674 - q0_loss: 0.0195 - q1_loss: 0.0308 - q2_loss: 0.0131 - q3_loss: 0.0124 - q4_loss: 0.1051 - q5_loss: 0.0140 - q6_loss: 0.0185 - q7_loss: 0.0183 - q8_loss: 0.0328 - val_loss: 0.2402 - val_q0_loss: 0.0203 - val_q1_loss: 0.0353 - val_q2_loss: 0.0150 - val_q3_loss: 0.0098 - val_q4_loss: 0.0707 - val_q5_loss: 0.0114 - val_q6_loss: 0.0126 - val_q7_loss: 0.0152 - val_q8_loss: 0.0359\n",
      "Epoch 253/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.3516 - q0_loss: 0.0209 - q1_loss: 0.0529 - q2_loss: 0.0127 - q3_loss: 0.0236 - q4_loss: 0.1087 - q5_loss: 0.0289 - q6_loss: 0.0397 - q7_loss: 0.0326 - q8_loss: 0.0360 - val_loss: 0.2341 - val_q0_loss: 0.0203 - val_q1_loss: 0.0163 - val_q2_loss: 0.0097 - val_q3_loss: 0.0166 - val_q4_loss: 0.0653 - val_q5_loss: 0.0193 - val_q6_loss: 0.0245 - val_q7_loss: 0.0220 - val_q8_loss: 0.0236\n",
      "Epoch 254/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.3225 - q0_loss: 0.0202 - q1_loss: 0.0412 - q2_loss: 0.0137 - q3_loss: 0.0212 - q4_loss: 0.1035 - q5_loss: 0.0260 - q6_loss: 0.0345 - q7_loss: 0.0285 - q8_loss: 0.0330 - val_loss: 0.2882 - val_q0_loss: 0.0176 - val_q1_loss: 0.0446 - val_q2_loss: 0.0145 - val_q3_loss: 0.0169 - val_q4_loss: 0.0563 - val_q5_loss: 0.0207 - val_q6_loss: 0.0340 - val_q7_loss: 0.0200 - val_q8_loss: 0.0301\n",
      "Epoch 255/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3117 - q0_loss: 0.0217 - q1_loss: 0.0293 - q2_loss: 0.0153 - q3_loss: 0.0208 - q4_loss: 0.1048 - q5_loss: 0.0257 - q6_loss: 0.0319 - q7_loss: 0.0308 - q8_loss: 0.0324 - val_loss: 0.3730 - val_q0_loss: 0.0195 - val_q1_loss: 0.0296 - val_q2_loss: 0.0169 - val_q3_loss: 0.0397 - val_q4_loss: 0.0575 - val_q5_loss: 0.0490 - val_q6_loss: 0.0587 - val_q7_loss: 0.0539 - val_q8_loss: 0.0232\n",
      "Epoch 256/300\n",
      "269/269 [==============================] - 0s 223us/sample - loss: 0.2807 - q0_loss: 0.0200 - q1_loss: 0.0252 - q2_loss: 0.0129 - q3_loss: 0.0176 - q4_loss: 0.0997 - q5_loss: 0.0217 - q6_loss: 0.0261 - q7_loss: 0.0266 - q8_loss: 0.0293 - val_loss: 0.1858 - val_q0_loss: 0.0192 - val_q1_loss: 0.0116 - val_q2_loss: 0.0089 - val_q3_loss: 0.0091 - val_q4_loss: 0.0629 - val_q5_loss: 0.0109 - val_q6_loss: 0.0126 - val_q7_loss: 0.0147 - val_q8_loss: 0.0222\n",
      "Epoch 257/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.3043 - q0_loss: 0.0216 - q1_loss: 0.0227 - q2_loss: 0.0136 - q3_loss: 0.0213 - q4_loss: 0.0965 - q5_loss: 0.0258 - q6_loss: 0.0326 - q7_loss: 0.0306 - q8_loss: 0.0289 - val_loss: 0.3490 - val_q0_loss: 0.0179 - val_q1_loss: 0.0181 - val_q2_loss: 0.0273 - val_q3_loss: 0.0333 - val_q4_loss: 0.0548 - val_q5_loss: 0.0422 - val_q6_loss: 0.0426 - val_q7_loss: 0.0488 - val_q8_loss: 0.0430\n",
      "Epoch 258/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3069 - q0_loss: 0.0223 - q1_loss: 0.0161 - q2_loss: 0.0178 - q3_loss: 0.0230 - q4_loss: 0.0946 - q5_loss: 0.0286 - q6_loss: 0.0320 - q7_loss: 0.0353 - q8_loss: 0.0334 - val_loss: 0.2809 - val_q0_loss: 0.0175 - val_q1_loss: 0.0101 - val_q2_loss: 0.0192 - val_q3_loss: 0.0248 - val_q4_loss: 0.0531 - val_q5_loss: 0.0322 - val_q6_loss: 0.0320 - val_q7_loss: 0.0381 - val_q8_loss: 0.0303\n",
      "Epoch 259/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3589 - q0_loss: 0.0251 - q1_loss: 0.0144 - q2_loss: 0.0212 - q3_loss: 0.0311 - q4_loss: 0.1031 - q5_loss: 0.0376 - q6_loss: 0.0440 - q7_loss: 0.0443 - q8_loss: 0.0377 - val_loss: 0.2501 - val_q0_loss: 0.0184 - val_q1_loss: 0.0125 - val_q2_loss: 0.0129 - val_q3_loss: 0.0191 - val_q4_loss: 0.0549 - val_q5_loss: 0.0231 - val_q6_loss: 0.0261 - val_q7_loss: 0.0265 - val_q8_loss: 0.0202\n",
      "Epoch 260/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.2701 - q0_loss: 0.0204 - q1_loss: 0.0128 - q2_loss: 0.0120 - q3_loss: 0.0196 - q4_loss: 0.1005 - q5_loss: 0.0238 - q6_loss: 0.0286 - q7_loss: 0.0276 - q8_loss: 0.0263 - val_loss: 0.2294 - val_q0_loss: 0.0170 - val_q1_loss: 0.0178 - val_q2_loss: 0.0087 - val_q3_loss: 0.0184 - val_q4_loss: 0.0535 - val_q5_loss: 0.0227 - val_q6_loss: 0.0264 - val_q7_loss: 0.0263 - val_q8_loss: 0.0168\n",
      "Epoch 261/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 0.2876 - q0_loss: 0.0206 - q1_loss: 0.0145 - q2_loss: 0.0144 - q3_loss: 0.0220 - q4_loss: 0.0932 - q5_loss: 0.0272 - q6_loss: 0.0318 - q7_loss: 0.0312 - q8_loss: 0.0274 - val_loss: 0.2309 - val_q0_loss: 0.0220 - val_q1_loss: 0.0124 - val_q2_loss: 0.0145 - val_q3_loss: 0.0184 - val_q4_loss: 0.0594 - val_q5_loss: 0.0227 - val_q6_loss: 0.0277 - val_q7_loss: 0.0250 - val_q8_loss: 0.0277\n",
      "Epoch 262/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.3382 - q0_loss: 0.0232 - q1_loss: 0.0222 - q2_loss: 0.0171 - q3_loss: 0.0308 - q4_loss: 0.0967 - q5_loss: 0.0382 - q6_loss: 0.0480 - q7_loss: 0.0432 - q8_loss: 0.0322 - val_loss: 0.3393 - val_q0_loss: 0.0195 - val_q1_loss: 0.0672 - val_q2_loss: 0.0143 - val_q3_loss: 0.0240 - val_q4_loss: 0.0630 - val_q5_loss: 0.0301 - val_q6_loss: 0.0456 - val_q7_loss: 0.0301 - val_q8_loss: 0.0369\n",
      "Epoch 263/300\n",
      "269/269 [==============================] - 0s 249us/sample - loss: 0.4103 - q0_loss: 0.0242 - q1_loss: 0.0436 - q2_loss: 0.0267 - q3_loss: 0.0314 - q4_loss: 0.0945 - q5_loss: 0.0385 - q6_loss: 0.0454 - q7_loss: 0.0437 - q8_loss: 0.0484 - val_loss: 0.4018 - val_q0_loss: 0.0212 - val_q1_loss: 0.0306 - val_q2_loss: 0.0305 - val_q3_loss: 0.0368 - val_q4_loss: 0.0581 - val_q5_loss: 0.0468 - val_q6_loss: 0.0479 - val_q7_loss: 0.0544 - val_q8_loss: 0.0507\n",
      "Epoch 264/300\n",
      "269/269 [==============================] - 0s 245us/sample - loss: 0.3295 - q0_loss: 0.0214 - q1_loss: 0.0360 - q2_loss: 0.0178 - q3_loss: 0.0225 - q4_loss: 0.0898 - q5_loss: 0.0282 - q6_loss: 0.0337 - q7_loss: 0.0338 - q8_loss: 0.0394 - val_loss: 0.2172 - val_q0_loss: 0.0198 - val_q1_loss: 0.0360 - val_q2_loss: 0.0143 - val_q3_loss: 0.0071 - val_q4_loss: 0.0637 - val_q5_loss: 0.0089 - val_q6_loss: 0.0104 - val_q7_loss: 0.0126 - val_q8_loss: 0.0363\n",
      "Epoch 265/300\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 0.2421 - q0_loss: 0.0201 - q1_loss: 0.0337 - q2_loss: 0.0128 - q3_loss: 0.0096 - q4_loss: 0.0933 - q5_loss: 0.0109 - q6_loss: 0.0152 - q7_loss: 0.0158 - q8_loss: 0.0322 - val_loss: 0.2285 - val_q0_loss: 0.0173 - val_q1_loss: 0.0397 - val_q2_loss: 0.0080 - val_q3_loss: 0.0149 - val_q4_loss: 0.0487 - val_q5_loss: 0.0173 - val_q6_loss: 0.0288 - val_q7_loss: 0.0196 - val_q8_loss: 0.0230\n",
      "Epoch 266/300\n",
      "269/269 [==============================] - 0s 244us/sample - loss: 0.2343 - q0_loss: 0.0187 - q1_loss: 0.0263 - q2_loss: 0.0106 - q3_loss: 0.0128 - q4_loss: 0.0832 - q5_loss: 0.0150 - q6_loss: 0.0194 - q7_loss: 0.0200 - q8_loss: 0.0265 - val_loss: 0.2033 - val_q0_loss: 0.0166 - val_q1_loss: 0.0126 - val_q2_loss: 0.0113 - val_q3_loss: 0.0130 - val_q4_loss: 0.0522 - val_q5_loss: 0.0165 - val_q6_loss: 0.0184 - val_q7_loss: 0.0209 - val_q8_loss: 0.0232\n",
      "Epoch 267/300\n",
      "269/269 [==============================] - 0s 342us/sample - loss: 0.2919 - q0_loss: 0.0215 - q1_loss: 0.0148 - q2_loss: 0.0158 - q3_loss: 0.0228 - q4_loss: 0.0874 - q5_loss: 0.0276 - q6_loss: 0.0328 - q7_loss: 0.0341 - q8_loss: 0.0309 - val_loss: 0.2843 - val_q0_loss: 0.0162 - val_q1_loss: 0.0138 - val_q2_loss: 0.0214 - val_q3_loss: 0.0278 - val_q4_loss: 0.0463 - val_q5_loss: 0.0339 - val_q6_loss: 0.0371 - val_q7_loss: 0.0417 - val_q8_loss: 0.0352\n",
      "Epoch 268/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.2979 - q0_loss: 0.0234 - q1_loss: 0.0157 - q2_loss: 0.0185 - q3_loss: 0.0231 - q4_loss: 0.0835 - q5_loss: 0.0278 - q6_loss: 0.0317 - q7_loss: 0.0346 - q8_loss: 0.0360 - val_loss: 0.2454 - val_q0_loss: 0.0154 - val_q1_loss: 0.0164 - val_q2_loss: 0.0166 - val_q3_loss: 0.0193 - val_q4_loss: 0.0439 - val_q5_loss: 0.0257 - val_q6_loss: 0.0240 - val_q7_loss: 0.0329 - val_q8_loss: 0.0319\n",
      "Epoch 269/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.2307 - q0_loss: 0.0193 - q1_loss: 0.0186 - q2_loss: 0.0108 - q3_loss: 0.0149 - q4_loss: 0.0825 - q5_loss: 0.0173 - q6_loss: 0.0200 - q7_loss: 0.0218 - q8_loss: 0.0274 - val_loss: 0.2230 - val_q0_loss: 0.0219 - val_q1_loss: 0.0138 - val_q2_loss: 0.0119 - val_q3_loss: 0.0192 - val_q4_loss: 0.0536 - val_q5_loss: 0.0217 - val_q6_loss: 0.0290 - val_q7_loss: 0.0255 - val_q8_loss: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 0.2570 - q0_loss: 0.0199 - q1_loss: 0.0202 - q2_loss: 0.0104 - q3_loss: 0.0201 - q4_loss: 0.0832 - q5_loss: 0.0240 - q6_loss: 0.0312 - q7_loss: 0.0270 - q8_loss: 0.0221 - val_loss: 0.3023 - val_q0_loss: 0.0187 - val_q1_loss: 0.0178 - val_q2_loss: 0.0154 - val_q3_loss: 0.0310 - val_q4_loss: 0.0445 - val_q5_loss: 0.0402 - val_q6_loss: 0.0463 - val_q7_loss: 0.0433 - val_q8_loss: 0.0220\n",
      "Epoch 271/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.3023 - q0_loss: 0.0227 - q1_loss: 0.0267 - q2_loss: 0.0170 - q3_loss: 0.0244 - q4_loss: 0.0817 - q5_loss: 0.0293 - q6_loss: 0.0362 - q7_loss: 0.0342 - q8_loss: 0.0324 - val_loss: 0.3016 - val_q0_loss: 0.0190 - val_q1_loss: 0.0387 - val_q2_loss: 0.0252 - val_q3_loss: 0.0193 - val_q4_loss: 0.0506 - val_q5_loss: 0.0256 - val_q6_loss: 0.0199 - val_q7_loss: 0.0309 - val_q8_loss: 0.0450\n",
      "Epoch 272/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.2923 - q0_loss: 0.0211 - q1_loss: 0.0301 - q2_loss: 0.0150 - q3_loss: 0.0220 - q4_loss: 0.0788 - q5_loss: 0.0265 - q6_loss: 0.0321 - q7_loss: 0.0320 - q8_loss: 0.0337 - val_loss: 0.1788 - val_q0_loss: 0.0169 - val_q1_loss: 0.0177 - val_q2_loss: 0.0060 - val_q3_loss: 0.0103 - val_q4_loss: 0.0491 - val_q5_loss: 0.0138 - val_q6_loss: 0.0177 - val_q7_loss: 0.0146 - val_q8_loss: 0.0183\n",
      "Epoch 273/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.2885 - q0_loss: 0.0224 - q1_loss: 0.0166 - q2_loss: 0.0172 - q3_loss: 0.0256 - q4_loss: 0.0762 - q5_loss: 0.0315 - q6_loss: 0.0379 - q7_loss: 0.0368 - q8_loss: 0.0340 - val_loss: 0.3206 - val_q0_loss: 0.0164 - val_q1_loss: 0.0315 - val_q2_loss: 0.0144 - val_q3_loss: 0.0358 - val_q4_loss: 0.0460 - val_q5_loss: 0.0455 - val_q6_loss: 0.0585 - val_q7_loss: 0.0493 - val_q8_loss: 0.0211\n",
      "Epoch 274/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.2598 - q0_loss: 0.0210 - q1_loss: 0.0271 - q2_loss: 0.0145 - q3_loss: 0.0175 - q4_loss: 0.0747 - q5_loss: 0.0211 - q6_loss: 0.0251 - q7_loss: 0.0255 - q8_loss: 0.0296 - val_loss: 0.2105 - val_q0_loss: 0.0182 - val_q1_loss: 0.0354 - val_q2_loss: 0.0119 - val_q3_loss: 0.0093 - val_q4_loss: 0.0448 - val_q5_loss: 0.0108 - val_q6_loss: 0.0174 - val_q7_loss: 0.0130 - val_q8_loss: 0.0244\n",
      "Epoch 275/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.2706 - q0_loss: 0.0216 - q1_loss: 0.0231 - q2_loss: 0.0172 - q3_loss: 0.0192 - q4_loss: 0.0738 - q5_loss: 0.0227 - q6_loss: 0.0255 - q7_loss: 0.0289 - q8_loss: 0.0345 - val_loss: 0.2884 - val_q0_loss: 0.0180 - val_q1_loss: 0.0245 - val_q2_loss: 0.0126 - val_q3_loss: 0.0298 - val_q4_loss: 0.0423 - val_q5_loss: 0.0371 - val_q6_loss: 0.0465 - val_q7_loss: 0.0420 - val_q8_loss: 0.0173\n",
      "Epoch 276/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3299 - q0_loss: 0.0226 - q1_loss: 0.0333 - q2_loss: 0.0198 - q3_loss: 0.0283 - q4_loss: 0.0727 - q5_loss: 0.0347 - q6_loss: 0.0416 - q7_loss: 0.0415 - q8_loss: 0.0396 - val_loss: 0.2850 - val_q0_loss: 0.0212 - val_q1_loss: 0.0216 - val_q2_loss: 0.0195 - val_q3_loss: 0.0241 - val_q4_loss: 0.0461 - val_q5_loss: 0.0299 - val_q6_loss: 0.0334 - val_q7_loss: 0.0332 - val_q8_loss: 0.0323\n",
      "Epoch 277/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.2997 - q0_loss: 0.0242 - q1_loss: 0.0264 - q2_loss: 0.0194 - q3_loss: 0.0226 - q4_loss: 0.0724 - q5_loss: 0.0271 - q6_loss: 0.0318 - q7_loss: 0.0337 - q8_loss: 0.0362 - val_loss: 0.2352 - val_q0_loss: 0.0170 - val_q1_loss: 0.0330 - val_q2_loss: 0.0064 - val_q3_loss: 0.0191 - val_q4_loss: 0.0490 - val_q5_loss: 0.0239 - val_q6_loss: 0.0326 - val_q7_loss: 0.0246 - val_q8_loss: 0.0176\n",
      "Epoch 278/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.2460 - q0_loss: 0.0201 - q1_loss: 0.0263 - q2_loss: 0.0122 - q3_loss: 0.0176 - q4_loss: 0.0711 - q5_loss: 0.0215 - q6_loss: 0.0267 - q7_loss: 0.0262 - q8_loss: 0.0285 - val_loss: 0.2789 - val_q0_loss: 0.0202 - val_q1_loss: 0.0430 - val_q2_loss: 0.0159 - val_q3_loss: 0.0201 - val_q4_loss: 0.0423 - val_q5_loss: 0.0236 - val_q6_loss: 0.0328 - val_q7_loss: 0.0252 - val_q8_loss: 0.0306\n",
      "Epoch 279/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.3213 - q0_loss: 0.0222 - q1_loss: 0.0296 - q2_loss: 0.0169 - q3_loss: 0.0266 - q4_loss: 0.0658 - q5_loss: 0.0343 - q6_loss: 0.0417 - q7_loss: 0.0403 - q8_loss: 0.0345 - val_loss: 0.3781 - val_q0_loss: 0.0219 - val_q1_loss: 0.0138 - val_q2_loss: 0.0264 - val_q3_loss: 0.0420 - val_q4_loss: 0.0430 - val_q5_loss: 0.0523 - val_q6_loss: 0.0613 - val_q7_loss: 0.0584 - val_q8_loss: 0.0396\n",
      "Epoch 280/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.3070 - q0_loss: 0.0233 - q1_loss: 0.0175 - q2_loss: 0.0173 - q3_loss: 0.0282 - q4_loss: 0.0664 - q5_loss: 0.0363 - q6_loss: 0.0442 - q7_loss: 0.0410 - q8_loss: 0.0316 - val_loss: 0.3485 - val_q0_loss: 0.0202 - val_q1_loss: 0.0172 - val_q2_loss: 0.0287 - val_q3_loss: 0.0359 - val_q4_loss: 0.0423 - val_q5_loss: 0.0437 - val_q6_loss: 0.0470 - val_q7_loss: 0.0511 - val_q8_loss: 0.0457\n",
      "Epoch 281/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.3966 - q0_loss: 0.0273 - q1_loss: 0.0281 - q2_loss: 0.0234 - q3_loss: 0.0395 - q4_loss: 0.0678 - q5_loss: 0.0484 - q6_loss: 0.0598 - q7_loss: 0.0556 - q8_loss: 0.0415 - val_loss: 0.4849 - val_q0_loss: 0.0370 - val_q1_loss: 0.0446 - val_q2_loss: 0.0448 - val_q3_loss: 0.0433 - val_q4_loss: 0.0722 - val_q5_loss: 0.0557 - val_q6_loss: 0.0584 - val_q7_loss: 0.0668 - val_q8_loss: 0.0784\n",
      "Epoch 282/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.4008 - q0_loss: 0.0281 - q1_loss: 0.0326 - q2_loss: 0.0303 - q3_loss: 0.0346 - q4_loss: 0.0696 - q5_loss: 0.0443 - q6_loss: 0.0476 - q7_loss: 0.0528 - q8_loss: 0.0565 - val_loss: 0.3677 - val_q0_loss: 0.0240 - val_q1_loss: 0.0237 - val_q2_loss: 0.0307 - val_q3_loss: 0.0349 - val_q4_loss: 0.0410 - val_q5_loss: 0.0424 - val_q6_loss: 0.0446 - val_q7_loss: 0.0505 - val_q8_loss: 0.0503\n",
      "Epoch 283/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.2927 - q0_loss: 0.0248 - q1_loss: 0.0188 - q2_loss: 0.0187 - q3_loss: 0.0246 - q4_loss: 0.0623 - q5_loss: 0.0300 - q6_loss: 0.0345 - q7_loss: 0.0373 - q8_loss: 0.0369 - val_loss: 0.2027 - val_q0_loss: 0.0196 - val_q1_loss: 0.0183 - val_q2_loss: 0.0119 - val_q3_loss: 0.0142 - val_q4_loss: 0.0385 - val_q5_loss: 0.0173 - val_q6_loss: 0.0193 - val_q7_loss: 0.0209 - val_q8_loss: 0.0207\n",
      "Epoch 284/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1946 - q0_loss: 0.0194 - q1_loss: 0.0161 - q2_loss: 0.0090 - q3_loss: 0.0126 - q4_loss: 0.0586 - q5_loss: 0.0148 - q6_loss: 0.0178 - q7_loss: 0.0197 - q8_loss: 0.0239 - val_loss: 0.1710 - val_q0_loss: 0.0193 - val_q1_loss: 0.0117 - val_q2_loss: 0.0079 - val_q3_loss: 0.0112 - val_q4_loss: 0.0457 - val_q5_loss: 0.0139 - val_q6_loss: 0.0179 - val_q7_loss: 0.0153 - val_q8_loss: 0.0175\n",
      "Epoch 285/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.1714 - q0_loss: 0.0192 - q1_loss: 0.0147 - q2_loss: 0.0080 - q3_loss: 0.0094 - q4_loss: 0.0601 - q5_loss: 0.0102 - q6_loss: 0.0121 - q7_loss: 0.0158 - q8_loss: 0.0240 - val_loss: 0.1449 - val_q0_loss: 0.0171 - val_q1_loss: 0.0140 - val_q2_loss: 0.0072 - val_q3_loss: 0.0076 - val_q4_loss: 0.0359 - val_q5_loss: 0.0095 - val_q6_loss: 0.0088 - val_q7_loss: 0.0132 - val_q8_loss: 0.0197\n",
      "Epoch 286/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.1687 - q0_loss: 0.0189 - q1_loss: 0.0144 - q2_loss: 0.0080 - q3_loss: 0.0094 - q4_loss: 0.0549 - q5_loss: 0.0113 - q6_loss: 0.0132 - q7_loss: 0.0161 - q8_loss: 0.0227 - val_loss: 0.1479 - val_q0_loss: 0.0173 - val_q1_loss: 0.0171 - val_q2_loss: 0.0073 - val_q3_loss: 0.0084 - val_q4_loss: 0.0313 - val_q5_loss: 0.0084 - val_q6_loss: 0.0118 - val_q7_loss: 0.0126 - val_q8_loss: 0.0168\n",
      "Epoch 287/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1865 - q0_loss: 0.0195 - q1_loss: 0.0135 - q2_loss: 0.0112 - q3_loss: 0.0138 - q4_loss: 0.0558 - q5_loss: 0.0159 - q6_loss: 0.0189 - q7_loss: 0.0222 - q8_loss: 0.0263 - val_loss: 0.3324 - val_q0_loss: 0.0224 - val_q1_loss: 0.0109 - val_q2_loss: 0.0237 - val_q3_loss: 0.0346 - val_q4_loss: 0.0394 - val_q5_loss: 0.0432 - val_q6_loss: 0.0497 - val_q7_loss: 0.0510 - val_q8_loss: 0.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.3378 - q0_loss: 0.0277 - q1_loss: 0.0135 - q2_loss: 0.0252 - q3_loss: 0.0372 - q4_loss: 0.0591 - q5_loss: 0.0463 - q6_loss: 0.0537 - q7_loss: 0.0522 - q8_loss: 0.0398 - val_loss: 0.2815 - val_q0_loss: 0.0226 - val_q1_loss: 0.0219 - val_q2_loss: 0.0130 - val_q3_loss: 0.0316 - val_q4_loss: 0.0381 - val_q5_loss: 0.0377 - val_q6_loss: 0.0506 - val_q7_loss: 0.0396 - val_q8_loss: 0.0224\n",
      "Epoch 289/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.4033 - q0_loss: 0.0283 - q1_loss: 0.0271 - q2_loss: 0.0291 - q3_loss: 0.0409 - q4_loss: 0.0584 - q5_loss: 0.0514 - q6_loss: 0.0595 - q7_loss: 0.0583 - q8_loss: 0.0496 - val_loss: 0.1759 - val_q0_loss: 0.0175 - val_q1_loss: 0.0203 - val_q2_loss: 0.0078 - val_q3_loss: 0.0117 - val_q4_loss: 0.0338 - val_q5_loss: 0.0158 - val_q6_loss: 0.0173 - val_q7_loss: 0.0192 - val_q8_loss: 0.0204\n",
      "Epoch 290/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.4009 - q0_loss: 0.0305 - q1_loss: 0.0246 - q2_loss: 0.0344 - q3_loss: 0.0427 - q4_loss: 0.0568 - q5_loss: 0.0518 - q6_loss: 0.0576 - q7_loss: 0.0609 - q8_loss: 0.0575 - val_loss: 0.3483 - val_q0_loss: 0.0286 - val_q1_loss: 0.0134 - val_q2_loss: 0.0248 - val_q3_loss: 0.0408 - val_q4_loss: 0.0559 - val_q5_loss: 0.0483 - val_q6_loss: 0.0602 - val_q7_loss: 0.0536 - val_q8_loss: 0.0394\n",
      "Epoch 291/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.3060 - q0_loss: 0.0255 - q1_loss: 0.0187 - q2_loss: 0.0224 - q3_loss: 0.0270 - q4_loss: 0.0530 - q5_loss: 0.0329 - q6_loss: 0.0369 - q7_loss: 0.0404 - q8_loss: 0.0406 - val_loss: 0.1623 - val_q0_loss: 0.0187 - val_q1_loss: 0.0169 - val_q2_loss: 0.0097 - val_q3_loss: 0.0098 - val_q4_loss: 0.0454 - val_q5_loss: 0.0123 - val_q6_loss: 0.0129 - val_q7_loss: 0.0149 - val_q8_loss: 0.0221\n",
      "Epoch 292/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1767 - q0_loss: 0.0184 - q1_loss: 0.0199 - q2_loss: 0.0090 - q3_loss: 0.0109 - q4_loss: 0.0472 - q5_loss: 0.0122 - q6_loss: 0.0156 - q7_loss: 0.0197 - q8_loss: 0.0259 - val_loss: 0.1516 - val_q0_loss: 0.0166 - val_q1_loss: 0.0207 - val_q2_loss: 0.0071 - val_q3_loss: 0.0076 - val_q4_loss: 0.0344 - val_q5_loss: 0.0086 - val_q6_loss: 0.0125 - val_q7_loss: 0.0118 - val_q8_loss: 0.0178\n",
      "Epoch 293/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1684 - q0_loss: 0.0193 - q1_loss: 0.0207 - q2_loss: 0.0095 - q3_loss: 0.0091 - q4_loss: 0.0431 - q5_loss: 0.0103 - q6_loss: 0.0123 - q7_loss: 0.0158 - q8_loss: 0.0266 - val_loss: 0.1709 - val_q0_loss: 0.0174 - val_q1_loss: 0.0305 - val_q2_loss: 0.0093 - val_q3_loss: 0.0082 - val_q4_loss: 0.0327 - val_q5_loss: 0.0094 - val_q6_loss: 0.0161 - val_q7_loss: 0.0119 - val_q8_loss: 0.0200\n",
      "Epoch 294/300\n",
      "269/269 [==============================] - 0s 181us/sample - loss: 0.1847 - q0_loss: 0.0192 - q1_loss: 0.0224 - q2_loss: 0.0107 - q3_loss: 0.0115 - q4_loss: 0.0427 - q5_loss: 0.0132 - q6_loss: 0.0169 - q7_loss: 0.0181 - q8_loss: 0.0271 - val_loss: 0.1766 - val_q0_loss: 0.0217 - val_q1_loss: 0.0130 - val_q2_loss: 0.0135 - val_q3_loss: 0.0140 - val_q4_loss: 0.0388 - val_q5_loss: 0.0170 - val_q6_loss: 0.0175 - val_q7_loss: 0.0219 - val_q8_loss: 0.0249\n",
      "Epoch 295/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.1727 - q0_loss: 0.0186 - q1_loss: 0.0191 - q2_loss: 0.0081 - q3_loss: 0.0120 - q4_loss: 0.0369 - q5_loss: 0.0149 - q6_loss: 0.0182 - q7_loss: 0.0194 - q8_loss: 0.0238 - val_loss: 0.1911 - val_q0_loss: 0.0173 - val_q1_loss: 0.0249 - val_q2_loss: 0.0077 - val_q3_loss: 0.0171 - val_q4_loss: 0.0297 - val_q5_loss: 0.0208 - val_q6_loss: 0.0265 - val_q7_loss: 0.0247 - val_q8_loss: 0.0212\n",
      "Epoch 296/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.2223 - q0_loss: 0.0214 - q1_loss: 0.0244 - q2_loss: 0.0139 - q3_loss: 0.0187 - q4_loss: 0.0412 - q5_loss: 0.0233 - q6_loss: 0.0282 - q7_loss: 0.0271 - q8_loss: 0.0309 - val_loss: 0.2046 - val_q0_loss: 0.0219 - val_q1_loss: 0.0296 - val_q2_loss: 0.0170 - val_q3_loss: 0.0134 - val_q4_loss: 0.0378 - val_q5_loss: 0.0154 - val_q6_loss: 0.0156 - val_q7_loss: 0.0212 - val_q8_loss: 0.0379\n",
      "Epoch 297/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.2257 - q0_loss: 0.0197 - q1_loss: 0.0209 - q2_loss: 0.0155 - q3_loss: 0.0182 - q4_loss: 0.0388 - q5_loss: 0.0226 - q6_loss: 0.0253 - q7_loss: 0.0291 - q8_loss: 0.0342 - val_loss: 0.2195 - val_q0_loss: 0.0228 - val_q1_loss: 0.0159 - val_q2_loss: 0.0160 - val_q3_loss: 0.0221 - val_q4_loss: 0.0341 - val_q5_loss: 0.0260 - val_q6_loss: 0.0296 - val_q7_loss: 0.0314 - val_q8_loss: 0.0292\n",
      "Epoch 298/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1933 - q0_loss: 0.0199 - q1_loss: 0.0188 - q2_loss: 0.0114 - q3_loss: 0.0151 - q4_loss: 0.0365 - q5_loss: 0.0177 - q6_loss: 0.0211 - q7_loss: 0.0225 - q8_loss: 0.0273 - val_loss: 0.1781 - val_q0_loss: 0.0170 - val_q1_loss: 0.0255 - val_q2_loss: 0.0062 - val_q3_loss: 0.0147 - val_q4_loss: 0.0287 - val_q5_loss: 0.0183 - val_q6_loss: 0.0247 - val_q7_loss: 0.0203 - val_q8_loss: 0.0183\n",
      "Epoch 299/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.2201 - q0_loss: 0.0205 - q1_loss: 0.0235 - q2_loss: 0.0144 - q3_loss: 0.0186 - q4_loss: 0.0351 - q5_loss: 0.0226 - q6_loss: 0.0263 - q7_loss: 0.0285 - q8_loss: 0.0332 - val_loss: 0.1422 - val_q0_loss: 0.0178 - val_q1_loss: 0.0136 - val_q2_loss: 0.0059 - val_q3_loss: 0.0096 - val_q4_loss: 0.0246 - val_q5_loss: 0.0108 - val_q6_loss: 0.0160 - val_q7_loss: 0.0160 - val_q8_loss: 0.0179\n",
      "Epoch 300/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1695 - q0_loss: 0.0193 - q1_loss: 0.0181 - q2_loss: 0.0091 - q3_loss: 0.0127 - q4_loss: 0.0305 - q5_loss: 0.0146 - q6_loss: 0.0185 - q7_loss: 0.0195 - q8_loss: 0.0262 - val_loss: 0.1773 - val_q0_loss: 0.0166 - val_q1_loss: 0.0135 - val_q2_loss: 0.0136 - val_q3_loss: 0.0145 - val_q4_loss: 0.0197 - val_q5_loss: 0.0179 - val_q6_loss: 0.0189 - val_q7_loss: 0.0225 - val_q8_loss: 0.0264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_mo, epochs=300,\n",
    "                    validation_data=(X_val, y_val_mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4055748 , 0.47743964, 0.60120326, 0.6377    , 0.74691874,\n",
       "        0.8046563 , 0.8431643 , 0.9648038 , 1.0393609 ],\n",
       "       [0.85474133, 1.025546  , 1.2492846 , 1.3207661 , 1.4387442 ,\n",
       "        1.6559818 , 1.7261361 , 1.9803336 , 2.1380525 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# revert multi output format to (n_samples, quantiles)\n",
    "y_pred = np.array(list(zip(*y_pred))).squeeze()\n",
    "y_pred[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: training seems slower! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employ pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Daniel Sch., at:\n",
    "# https://stackoverflow.com/questions/43151694/define-pinball-loss-function-in-keras-with-tensorflow-backend\n",
    "def create_pinball_loss(tau=0.5):\n",
    "    def pinball_loss(y_true, y_pred):\n",
    "        err = y_true - y_pred\n",
    "        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)\n",
    "    return pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q0': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q1': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q2': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q3': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q4': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q5': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q6': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q7': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q8': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = {'q'+str(i): create_pinball_loss(tau=q) for (i, q) in enumerate(quantiles)}\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           176         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           544         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           2112        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            130         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q0 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q1 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q2 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q3 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q4 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q5 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q6 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q7 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q8 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,989\n",
      "Trainable params: 2,989\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(inp_shape=(train_df.columns.size,), quantiles=quantiles)\n",
    "model.compile(optimizer=\"adam\", loss=losses)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 269 samples, validate on 68 samples\n",
      "Epoch 1/300\n",
      "269/269 [==============================] - 3s 12ms/sample - loss: 7.0769 - q0_loss: 0.8913 - q1_loss: 0.3594 - q2_loss: 0.2427 - q3_loss: 0.9209 - q4_loss: 0.9328 - q5_loss: 0.5843 - q6_loss: 0.5614 - q7_loss: 1.6276 - q8_loss: 0.7763 - val_loss: 4.1472 - val_q0_loss: 0.0193 - val_q1_loss: 0.0166 - val_q2_loss: 0.1467 - val_q3_loss: 2.2790 - val_q4_loss: 1.2020 - val_q5_loss: 0.2534 - val_q6_loss: 0.1728 - val_q7_loss: 0.2249 - val_q8_loss: 0.0736\n",
      "Epoch 2/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 4.1032 - q0_loss: 0.0188 - q1_loss: 0.0203 - q2_loss: 0.1641 - q3_loss: 2.0511 - q4_loss: 1.0213 - q5_loss: 0.1994 - q6_loss: 0.1688 - q7_loss: 0.3025 - q8_loss: 0.1106 - val_loss: 2.7499 - val_q0_loss: 0.0118 - val_q1_loss: 0.0349 - val_q2_loss: 0.1239 - val_q3_loss: 1.0181 - val_q4_loss: 0.7105 - val_q5_loss: 0.2546 - val_q6_loss: 0.1864 - val_q7_loss: 0.5118 - val_q8_loss: 0.0831\n",
      "Epoch 3/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 2.5545 - q0_loss: 0.0063 - q1_loss: 0.0652 - q2_loss: 0.1891 - q3_loss: 0.3098 - q4_loss: 0.3015 - q5_loss: 0.1815 - q6_loss: 0.1559 - q7_loss: 1.1215 - q8_loss: 0.2028 - val_loss: 2.1088 - val_q0_loss: 0.0043 - val_q1_loss: 0.0296 - val_q2_loss: 0.1746 - val_q3_loss: 0.1319 - val_q4_loss: 0.1860 - val_q5_loss: 0.1274 - val_q6_loss: 0.1133 - val_q7_loss: 1.0905 - val_q8_loss: 0.1889\n",
      "Epoch 4/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 2.1588 - q0_loss: 0.0075 - q1_loss: 0.0144 - q2_loss: 0.1641 - q3_loss: 0.3150 - q4_loss: 0.2534 - q5_loss: 0.1313 - q6_loss: 0.1202 - q7_loss: 0.9811 - q8_loss: 0.1719 - val_loss: 2.0107 - val_q0_loss: 0.0098 - val_q1_loss: 0.0107 - val_q2_loss: 0.1037 - val_q3_loss: 0.6959 - val_q4_loss: 0.4019 - val_q5_loss: 0.1008 - val_q6_loss: 0.0829 - val_q7_loss: 0.5530 - val_q8_loss: 0.1077\n",
      "Epoch 5/300\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 1.9606 - q0_loss: 0.0083 - q1_loss: 0.0081 - q2_loss: 0.1522 - q3_loss: 0.3581 - q4_loss: 0.2541 - q5_loss: 0.0928 - q6_loss: 0.0788 - q7_loss: 0.8900 - q8_loss: 0.1296 - val_loss: 1.7097 - val_q0_loss: 0.0058 - val_q1_loss: 0.0041 - val_q2_loss: 0.1563 - val_q3_loss: 0.1803 - val_q4_loss: 0.1820 - val_q5_loss: 0.0834 - val_q6_loss: 0.0652 - val_q7_loss: 0.9244 - val_q8_loss: 0.1034\n",
      "Epoch 6/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 1.7973 - q0_loss: 0.0065 - q1_loss: 0.0125 - q2_loss: 0.1739 - q3_loss: 0.1760 - q4_loss: 0.1497 - q5_loss: 0.0706 - q6_loss: 0.0582 - q7_loss: 1.0443 - q8_loss: 0.1039 - val_loss: 1.6781 - val_q0_loss: 0.0075 - val_q1_loss: 0.0056 - val_q2_loss: 0.1401 - val_q3_loss: 0.3444 - val_q4_loss: 0.2658 - val_q5_loss: 0.0822 - val_q6_loss: 0.0565 - val_q7_loss: 0.7561 - val_q8_loss: 0.0320\n",
      "Epoch 7/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 1.6607 - q0_loss: 0.0075 - q1_loss: 0.0068 - q2_loss: 0.1596 - q3_loss: 0.2274 - q4_loss: 0.1749 - q5_loss: 0.0567 - q6_loss: 0.0428 - q7_loss: 0.9302 - q8_loss: 0.0575 - val_loss: 1.4884 - val_q0_loss: 0.0065 - val_q1_loss: 0.0052 - val_q2_loss: 0.1441 - val_q3_loss: 0.2158 - val_q4_loss: 0.1740 - val_q5_loss: 0.0537 - val_q6_loss: 0.0387 - val_q7_loss: 0.8214 - val_q8_loss: 0.0270\n",
      "Epoch 8/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 1.5171 - q0_loss: 0.0070 - q1_loss: 0.0070 - q2_loss: 0.1593 - q3_loss: 0.1751 - q4_loss: 0.1250 - q5_loss: 0.0329 - q6_loss: 0.0253 - q7_loss: 0.9502 - q8_loss: 0.0454 - val_loss: 1.3820 - val_q0_loss: 0.0068 - val_q1_loss: 0.0080 - val_q2_loss: 0.1266 - val_q3_loss: 0.2307 - val_q4_loss: 0.1391 - val_q5_loss: 0.0219 - val_q6_loss: 0.0250 - val_q7_loss: 0.7551 - val_q8_loss: 0.0392\n",
      "Epoch 9/300\n",
      "269/269 [==============================] - 0s 247us/sample - loss: 1.4189 - q0_loss: 0.0070 - q1_loss: 0.0074 - q2_loss: 0.1523 - q3_loss: 0.1525 - q4_loss: 0.1023 - q5_loss: 0.0227 - q6_loss: 0.0191 - q7_loss: 0.9096 - q8_loss: 0.0295 - val_loss: 1.3121 - val_q0_loss: 0.0071 - val_q1_loss: 0.0087 - val_q2_loss: 0.1192 - val_q3_loss: 0.2446 - val_q4_loss: 0.1365 - val_q5_loss: 0.0257 - val_q6_loss: 0.0333 - val_q7_loss: 0.7038 - val_q8_loss: 0.0238\n",
      "Epoch 10/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 1.3561 - q0_loss: 0.0071 - q1_loss: 0.0077 - q2_loss: 0.1488 - q3_loss: 0.1450 - q4_loss: 0.0940 - q5_loss: 0.0222 - q6_loss: 0.0210 - q7_loss: 0.8832 - q8_loss: 0.0179 - val_loss: 1.2192 - val_q0_loss: 0.0065 - val_q1_loss: 0.0077 - val_q2_loss: 0.1254 - val_q3_loss: 0.1556 - val_q4_loss: 0.0887 - val_q5_loss: 0.0202 - val_q6_loss: 0.0224 - val_q7_loss: 0.7494 - val_q8_loss: 0.0168\n",
      "Epoch 11/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 1.2901 - q0_loss: 0.0073 - q1_loss: 0.0081 - q2_loss: 0.1445 - q3_loss: 0.1278 - q4_loss: 0.0873 - q5_loss: 0.0197 - q6_loss: 0.0190 - q7_loss: 0.8559 - q8_loss: 0.0187 - val_loss: 1.2337 - val_q0_loss: 0.0063 - val_q1_loss: 0.0053 - val_q2_loss: 0.1363 - val_q3_loss: 0.1030 - val_q4_loss: 0.0944 - val_q5_loss: 0.0357 - val_q6_loss: 0.0300 - val_q7_loss: 0.7723 - val_q8_loss: 9.3240e-04\n",
      "Epoch 12/300\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 1.2879 - q0_loss: 0.0073 - q1_loss: 0.0076 - q2_loss: 0.1456 - q3_loss: 0.1049 - q4_loss: 0.0855 - q5_loss: 0.0350 - q6_loss: 0.0324 - q7_loss: 0.8476 - q8_loss: 0.0216 - val_loss: 1.1940 - val_q0_loss: 0.0062 - val_q1_loss: 0.0049 - val_q2_loss: 0.1363 - val_q3_loss: 0.0808 - val_q4_loss: 0.0843 - val_q5_loss: 0.0398 - val_q6_loss: 0.0336 - val_q7_loss: 0.7628 - val_q8_loss: 9.2427e-04\n",
      "Epoch 13/300\n",
      "269/269 [==============================] - 0s 217us/sample - loss: 1.2309 - q0_loss: 0.0072 - q1_loss: 0.0070 - q2_loss: 0.1466 - q3_loss: 0.0803 - q4_loss: 0.0814 - q5_loss: 0.0361 - q6_loss: 0.0304 - q7_loss: 0.8390 - q8_loss: 0.0138 - val_loss: 1.0888 - val_q0_loss: 0.0067 - val_q1_loss: 0.0066 - val_q2_loss: 0.1230 - val_q3_loss: 0.0894 - val_q4_loss: 0.0816 - val_q5_loss: 0.0215 - val_q6_loss: 0.0197 - val_q7_loss: 0.6919 - val_q8_loss: 0.0018\n",
      "Epoch 14/300\n",
      "269/269 [==============================] - 0s 225us/sample - loss: 1.2910 - q0_loss: 0.0074 - q1_loss: 0.0082 - q2_loss: 0.1460 - q3_loss: 0.0663 - q4_loss: 0.0975 - q5_loss: 0.0696 - q6_loss: 0.0586 - q7_loss: 0.8094 - q8_loss: 0.0318 - val_loss: 1.2483 - val_q0_loss: 0.0068 - val_q1_loss: 0.0100 - val_q2_loss: 0.1029 - val_q3_loss: 0.0951 - val_q4_loss: 0.0377 - val_q5_loss: 0.0995 - val_q6_loss: 0.1037 - val_q7_loss: 0.6330 - val_q8_loss: 0.1041\n",
      "Epoch 15/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 1.2347 - q0_loss: 0.0074 - q1_loss: 0.0087 - q2_loss: 0.1379 - q3_loss: 0.0587 - q4_loss: 0.0739 - q5_loss: 0.0678 - q6_loss: 0.0612 - q7_loss: 0.7741 - q8_loss: 0.0352 - val_loss: 1.2623 - val_q0_loss: 0.0065 - val_q1_loss: 0.0256 - val_q2_loss: 0.1426 - val_q3_loss: 0.0256 - val_q4_loss: 0.1244 - val_q5_loss: 0.0979 - val_q6_loss: 0.0761 - val_q7_loss: 0.7080 - val_q8_loss: 0.0024\n",
      "Epoch 16/300\n",
      "269/269 [==============================] - 0s 219us/sample - loss: 1.2251 - q0_loss: 0.0075 - q1_loss: 0.0103 - q2_loss: 0.1435 - q3_loss: 0.0446 - q4_loss: 0.0913 - q5_loss: 0.0776 - q6_loss: 0.0656 - q7_loss: 0.7705 - q8_loss: 0.0213 - val_loss: 1.1548 - val_q0_loss: 0.0067 - val_q1_loss: 0.0126 - val_q2_loss: 0.1328 - val_q3_loss: 0.0232 - val_q4_loss: 0.1151 - val_q5_loss: 0.0833 - val_q6_loss: 0.0655 - val_q7_loss: 0.6584 - val_q8_loss: 0.0021\n",
      "Epoch 17/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 1.0842 - q0_loss: 0.0076 - q1_loss: 0.0082 - q2_loss: 0.1327 - q3_loss: 0.0420 - q4_loss: 0.0671 - q5_loss: 0.0466 - q6_loss: 0.0385 - q7_loss: 0.7278 - q8_loss: 0.0109 - val_loss: 1.0091 - val_q0_loss: 0.0066 - val_q1_loss: 0.0089 - val_q2_loss: 0.1038 - val_q3_loss: 0.0214 - val_q4_loss: 0.0266 - val_q5_loss: 0.0598 - val_q6_loss: 0.0535 - val_q7_loss: 0.6112 - val_q8_loss: 0.0421\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 212us/sample - loss: 1.0141 - q0_loss: 0.0076 - q1_loss: 0.0084 - q2_loss: 0.1259 - q3_loss: 0.0309 - q4_loss: 0.0488 - q5_loss: 0.0396 - q6_loss: 0.0336 - q7_loss: 0.7026 - q8_loss: 0.0163 - val_loss: 0.9046 - val_q0_loss: 0.0070 - val_q1_loss: 0.0072 - val_q2_loss: 0.1075 - val_q3_loss: 0.0487 - val_q4_loss: 0.0544 - val_q5_loss: 0.0244 - val_q6_loss: 0.0221 - val_q7_loss: 0.5711 - val_q8_loss: 9.1811e-04\n",
      "Epoch 19/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 0.9483 - q0_loss: 0.0077 - q1_loss: 0.0089 - q2_loss: 0.1213 - q3_loss: 0.0328 - q4_loss: 0.0385 - q5_loss: 0.0274 - q6_loss: 0.0233 - q7_loss: 0.6792 - q8_loss: 0.0111 - val_loss: 0.9073 - val_q0_loss: 0.0070 - val_q1_loss: 0.0067 - val_q2_loss: 0.1070 - val_q3_loss: 0.0481 - val_q4_loss: 0.0619 - val_q5_loss: 0.0351 - val_q6_loss: 0.0302 - val_q7_loss: 0.5496 - val_q8_loss: 0.0012\n",
      "Epoch 20/300\n",
      "269/269 [==============================] - 0s 225us/sample - loss: 0.9150 - q0_loss: 0.0077 - q1_loss: 0.0088 - q2_loss: 0.1173 - q3_loss: 0.0372 - q4_loss: 0.0375 - q5_loss: 0.0258 - q6_loss: 0.0217 - q7_loss: 0.6453 - q8_loss: 0.0067 - val_loss: 0.8092 - val_q0_loss: 0.0067 - val_q1_loss: 0.0069 - val_q2_loss: 0.1055 - val_q3_loss: 0.0071 - val_q4_loss: 0.0245 - val_q5_loss: 0.0226 - val_q6_loss: 0.0216 - val_q7_loss: 0.5612 - val_q8_loss: 8.9825e-04\n",
      "Epoch 21/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.8612 - q0_loss: 0.0079 - q1_loss: 0.0095 - q2_loss: 0.1125 - q3_loss: 0.0537 - q4_loss: 0.0303 - q5_loss: 0.0192 - q6_loss: 0.0177 - q7_loss: 0.6172 - q8_loss: 0.0024 - val_loss: 0.7438 - val_q0_loss: 0.0071 - val_q1_loss: 0.0087 - val_q2_loss: 0.0921 - val_q3_loss: 0.0482 - val_q4_loss: 0.0236 - val_q5_loss: 0.0106 - val_q6_loss: 0.0073 - val_q7_loss: 0.4963 - val_q8_loss: 9.9931e-04\n",
      "Epoch 22/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.8490 - q0_loss: 0.0077 - q1_loss: 0.0088 - q2_loss: 0.1116 - q3_loss: 0.0407 - q4_loss: 0.0234 - q5_loss: 0.0260 - q6_loss: 0.0210 - q7_loss: 0.6062 - q8_loss: 0.0037 - val_loss: 0.8055 - val_q0_loss: 0.0068 - val_q1_loss: 0.0059 - val_q2_loss: 0.1046 - val_q3_loss: 0.0080 - val_q4_loss: 0.0315 - val_q5_loss: 0.0422 - val_q6_loss: 0.0353 - val_q7_loss: 0.5245 - val_q8_loss: 0.0013\n",
      "Epoch 23/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.8645 - q0_loss: 0.0079 - q1_loss: 0.0089 - q2_loss: 0.1080 - q3_loss: 0.0568 - q4_loss: 0.0282 - q5_loss: 0.0390 - q6_loss: 0.0360 - q7_loss: 0.5707 - q8_loss: 0.0086 - val_loss: 0.7784 - val_q0_loss: 0.0079 - val_q1_loss: 0.0104 - val_q2_loss: 0.0731 - val_q3_loss: 0.1607 - val_q4_loss: 0.0446 - val_q5_loss: 0.0284 - val_q6_loss: 0.0279 - val_q7_loss: 0.3698 - val_q8_loss: 0.0019\n",
      "Epoch 24/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.8110 - q0_loss: 0.0083 - q1_loss: 0.0099 - q2_loss: 0.0984 - q3_loss: 0.0952 - q4_loss: 0.0436 - q5_loss: 0.0228 - q6_loss: 0.0194 - q7_loss: 0.5122 - q8_loss: 0.0043 - val_loss: 0.6830 - val_q0_loss: 0.0077 - val_q1_loss: 0.0093 - val_q2_loss: 0.0769 - val_q3_loss: 0.1074 - val_q4_loss: 0.0348 - val_q5_loss: 0.0065 - val_q6_loss: 0.0073 - val_q7_loss: 0.3815 - val_q8_loss: 6.6287e-04\n",
      "Epoch 25/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.7780 - q0_loss: 0.0081 - q1_loss: 0.0093 - q2_loss: 0.0996 - q3_loss: 0.0511 - q4_loss: 0.0377 - q5_loss: 0.0331 - q6_loss: 0.0283 - q7_loss: 0.5156 - q8_loss: 0.0079 - val_loss: 0.6269 - val_q0_loss: 0.0071 - val_q1_loss: 0.0088 - val_q2_loss: 0.0810 - val_q3_loss: 0.0163 - val_q4_loss: 0.0167 - val_q5_loss: 0.0095 - val_q6_loss: 0.0040 - val_q7_loss: 0.4286 - val_q8_loss: 4.1436e-04\n",
      "Epoch 26/300\n",
      "269/269 [==============================] - 0s 238us/sample - loss: 0.7377 - q0_loss: 0.0082 - q1_loss: 0.0088 - q2_loss: 0.0976 - q3_loss: 0.0421 - q4_loss: 0.0347 - q5_loss: 0.0312 - q6_loss: 0.0252 - q7_loss: 0.4858 - q8_loss: 0.0023 - val_loss: 0.6419 - val_q0_loss: 0.0075 - val_q1_loss: 0.0080 - val_q2_loss: 0.0790 - val_q3_loss: 0.0468 - val_q4_loss: 0.0330 - val_q5_loss: 0.0233 - val_q6_loss: 0.0199 - val_q7_loss: 0.3722 - val_q8_loss: 0.0010\n",
      "Epoch 27/300\n",
      "269/269 [==============================] - 0s 236us/sample - loss: 0.6556 - q0_loss: 0.0082 - q1_loss: 0.0096 - q2_loss: 0.0913 - q3_loss: 0.0298 - q4_loss: 0.0201 - q5_loss: 0.0167 - q6_loss: 0.0137 - q7_loss: 0.4640 - q8_loss: 0.0013 - val_loss: 0.5686 - val_q0_loss: 0.0074 - val_q1_loss: 0.0090 - val_q2_loss: 0.0723 - val_q3_loss: 0.0243 - val_q4_loss: 0.0170 - val_q5_loss: 0.0188 - val_q6_loss: 0.0146 - val_q7_loss: 0.3597 - val_q8_loss: 5.8904e-04\n",
      "Epoch 28/300\n",
      "269/269 [==============================] - 0s 223us/sample - loss: 0.6509 - q0_loss: 0.0083 - q1_loss: 0.0095 - q2_loss: 0.0864 - q3_loss: 0.0430 - q4_loss: 0.0270 - q5_loss: 0.0286 - q6_loss: 0.0241 - q7_loss: 0.4212 - q8_loss: 0.0039 - val_loss: 0.6396 - val_q0_loss: 0.0072 - val_q1_loss: 0.0063 - val_q2_loss: 0.0826 - val_q3_loss: 0.0198 - val_q4_loss: 0.0244 - val_q5_loss: 0.0441 - val_q6_loss: 0.0358 - val_q7_loss: 0.3658 - val_q8_loss: 0.0015\n",
      "Epoch 29/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 0.6284 - q0_loss: 0.0085 - q1_loss: 0.0099 - q2_loss: 0.0825 - q3_loss: 0.0546 - q4_loss: 0.0219 - q5_loss: 0.0255 - q6_loss: 0.0230 - q7_loss: 0.3995 - q8_loss: 0.0026 - val_loss: 0.5275 - val_q0_loss: 0.0078 - val_q1_loss: 0.0086 - val_q2_loss: 0.0645 - val_q3_loss: 0.0658 - val_q4_loss: 0.0295 - val_q5_loss: 0.0197 - val_q6_loss: 0.0169 - val_q7_loss: 0.2727 - val_q8_loss: 0.0010\n",
      "Epoch 30/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 0.5532 - q0_loss: 0.0085 - q1_loss: 0.0104 - q2_loss: 0.0731 - q3_loss: 0.0648 - q4_loss: 0.0174 - q5_loss: 0.0130 - q6_loss: 0.0112 - q7_loss: 0.3418 - q8_loss: 6.1080e-04 - val_loss: 0.4743 - val_q0_loss: 0.0076 - val_q1_loss: 0.0096 - val_q2_loss: 0.0589 - val_q3_loss: 0.0275 - val_q4_loss: 0.0125 - val_q5_loss: 0.0189 - val_q6_loss: 0.0150 - val_q7_loss: 0.2747 - val_q8_loss: 6.7138e-04\n",
      "Epoch 31/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 0.5341 - q0_loss: 0.0084 - q1_loss: 0.0094 - q2_loss: 0.0757 - q3_loss: 0.0208 - q4_loss: 0.0164 - q5_loss: 0.0241 - q6_loss: 0.0199 - q7_loss: 0.3448 - q8_loss: 0.0023 - val_loss: 0.4761 - val_q0_loss: 0.0075 - val_q1_loss: 0.0093 - val_q2_loss: 0.0586 - val_q3_loss: 0.0096 - val_q4_loss: 0.0216 - val_q5_loss: 0.0273 - val_q6_loss: 0.0256 - val_q7_loss: 0.2702 - val_q8_loss: 0.0024\n",
      "Epoch 32/300\n",
      "269/269 [==============================] - 0s 232us/sample - loss: 0.5290 - q0_loss: 0.0088 - q1_loss: 0.0103 - q2_loss: 0.0673 - q3_loss: 0.0683 - q4_loss: 0.0299 - q5_loss: 0.0275 - q6_loss: 0.0247 - q7_loss: 0.2873 - q8_loss: 0.0036 - val_loss: 0.4158 - val_q0_loss: 0.0082 - val_q1_loss: 0.0097 - val_q2_loss: 0.0470 - val_q3_loss: 0.0927 - val_q4_loss: 0.0279 - val_q5_loss: 0.0118 - val_q6_loss: 0.0102 - val_q7_loss: 0.1629 - val_q8_loss: 8.2512e-04\n",
      "Epoch 33/300\n",
      "269/269 [==============================] - 0s 260us/sample - loss: 0.4653 - q0_loss: 0.0089 - q1_loss: 0.0106 - q2_loss: 0.0615 - q3_loss: 0.0638 - q4_loss: 0.0215 - q5_loss: 0.0220 - q6_loss: 0.0203 - q7_loss: 0.2532 - q8_loss: 0.0018 - val_loss: 0.4023 - val_q0_loss: 0.0082 - val_q1_loss: 0.0089 - val_q2_loss: 0.0477 - val_q3_loss: 0.0727 - val_q4_loss: 0.0357 - val_q5_loss: 0.0239 - val_q6_loss: 0.0196 - val_q7_loss: 0.1464 - val_q8_loss: 0.0011\n",
      "Epoch 34/300\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 0.4148 - q0_loss: 0.0089 - q1_loss: 0.0107 - q2_loss: 0.0589 - q3_loss: 0.0481 - q4_loss: 0.0220 - q5_loss: 0.0157 - q6_loss: 0.0135 - q7_loss: 0.2415 - q8_loss: 0.0022 - val_loss: 0.3585 - val_q0_loss: 0.0082 - val_q1_loss: 0.0088 - val_q2_loss: 0.0449 - val_q3_loss: 0.0544 - val_q4_loss: 0.0269 - val_q5_loss: 0.0227 - val_q6_loss: 0.0189 - val_q7_loss: 0.1304 - val_q8_loss: 0.0011\n",
      "Epoch 35/300\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 0.4063 - q0_loss: 0.0090 - q1_loss: 0.0103 - q2_loss: 0.0546 - q3_loss: 0.0572 - q4_loss: 0.0312 - q5_loss: 0.0210 - q6_loss: 0.0163 - q7_loss: 0.1982 - q8_loss: 0.0012 - val_loss: 0.3351 - val_q0_loss: 0.0076 - val_q1_loss: 0.0087 - val_q2_loss: 0.0475 - val_q3_loss: 0.0126 - val_q4_loss: 0.0210 - val_q5_loss: 0.0105 - val_q6_loss: 0.0103 - val_q7_loss: 0.1771 - val_q8_loss: 7.3391e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300\n",
      "269/269 [==============================] - 0s 232us/sample - loss: 0.3520 - q0_loss: 0.0091 - q1_loss: 0.0108 - q2_loss: 0.0514 - q3_loss: 0.0497 - q4_loss: 0.0207 - q5_loss: 0.0117 - q6_loss: 0.0103 - q7_loss: 0.1947 - q8_loss: 9.1429e-04 - val_loss: 0.3254 - val_q0_loss: 0.0082 - val_q1_loss: 0.0109 - val_q2_loss: 0.0298 - val_q3_loss: 0.0375 - val_q4_loss: 0.0188 - val_q5_loss: 0.0473 - val_q6_loss: 0.0472 - val_q7_loss: 0.0928 - val_q8_loss: 0.0024\n",
      "Epoch 37/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.3160 - q0_loss: 0.0089 - q1_loss: 0.0104 - q2_loss: 0.0476 - q3_loss: 0.0195 - q4_loss: 0.0142 - q5_loss: 0.0218 - q6_loss: 0.0201 - q7_loss: 0.1670 - q8_loss: 0.0013 - val_loss: 0.2219 - val_q0_loss: 0.0083 - val_q1_loss: 0.0102 - val_q2_loss: 0.0286 - val_q3_loss: 0.0350 - val_q4_loss: 0.0070 - val_q5_loss: 0.0100 - val_q6_loss: 0.0083 - val_q7_loss: 0.0749 - val_q8_loss: 5.7857e-04\n",
      "Epoch 38/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.2889 - q0_loss: 0.0090 - q1_loss: 0.0103 - q2_loss: 0.0445 - q3_loss: 0.0188 - q4_loss: 0.0167 - q5_loss: 0.0199 - q6_loss: 0.0162 - q7_loss: 0.1487 - q8_loss: 0.0012 - val_loss: 0.2232 - val_q0_loss: 0.0081 - val_q1_loss: 0.0084 - val_q2_loss: 0.0347 - val_q3_loss: 0.0060 - val_q4_loss: 0.0103 - val_q5_loss: 0.0231 - val_q6_loss: 0.0193 - val_q7_loss: 0.0791 - val_q8_loss: 0.0011\n",
      "Epoch 39/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.2630 - q0_loss: 0.0092 - q1_loss: 0.0103 - q2_loss: 0.0423 - q3_loss: 0.0191 - q4_loss: 0.0102 - q5_loss: 0.0172 - q6_loss: 0.0146 - q7_loss: 0.1435 - q8_loss: 0.0012 - val_loss: 0.2835 - val_q0_loss: 0.0085 - val_q1_loss: 0.0111 - val_q2_loss: 0.0225 - val_q3_loss: 0.0456 - val_q4_loss: 0.0148 - val_q5_loss: 0.0441 - val_q6_loss: 0.0464 - val_q7_loss: 0.0636 - val_q8_loss: 0.0010\n",
      "Epoch 40/300\n",
      "269/269 [==============================] - 0s 253us/sample - loss: 0.2589 - q0_loss: 0.0091 - q1_loss: 0.0103 - q2_loss: 0.0377 - q3_loss: 0.0139 - q4_loss: 0.0147 - q5_loss: 0.0216 - q6_loss: 0.0194 - q7_loss: 0.1303 - q8_loss: 0.0013 - val_loss: 0.2232 - val_q0_loss: 0.0082 - val_q1_loss: 0.0101 - val_q2_loss: 0.0198 - val_q3_loss: 0.0079 - val_q4_loss: 0.0202 - val_q5_loss: 0.0292 - val_q6_loss: 0.0273 - val_q7_loss: 0.0639 - val_q8_loss: 0.0011\n",
      "Epoch 41/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.2275 - q0_loss: 0.0092 - q1_loss: 0.0106 - q2_loss: 0.0325 - q3_loss: 0.0108 - q4_loss: 0.0136 - q5_loss: 0.0157 - q6_loss: 0.0137 - q7_loss: 0.1216 - q8_loss: 8.3409e-04 - val_loss: 0.1659 - val_q0_loss: 0.0083 - val_q1_loss: 0.0093 - val_q2_loss: 0.0182 - val_q3_loss: 0.0107 - val_q4_loss: 0.0074 - val_q5_loss: 0.0112 - val_q6_loss: 0.0104 - val_q7_loss: 0.0590 - val_q8_loss: 8.3194e-04\n",
      "Epoch 42/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.2221 - q0_loss: 0.0093 - q1_loss: 0.0106 - q2_loss: 0.0305 - q3_loss: 0.0180 - q4_loss: 0.0164 - q5_loss: 0.0114 - q6_loss: 0.0094 - q7_loss: 0.1168 - q8_loss: 0.0012 - val_loss: 0.2505 - val_q0_loss: 0.0082 - val_q1_loss: 0.0105 - val_q2_loss: 0.0203 - val_q3_loss: 0.0065 - val_q4_loss: 0.0291 - val_q5_loss: 0.0407 - val_q6_loss: 0.0415 - val_q7_loss: 0.0587 - val_q8_loss: 0.0043\n",
      "Epoch 43/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.2781 - q0_loss: 0.0093 - q1_loss: 0.0098 - q2_loss: 0.0303 - q3_loss: 0.0169 - q4_loss: 0.0325 - q5_loss: 0.0357 - q6_loss: 0.0312 - q7_loss: 0.1071 - q8_loss: 0.0033 - val_loss: 0.2218 - val_q0_loss: 0.0085 - val_q1_loss: 0.0078 - val_q2_loss: 0.0179 - val_q3_loss: 0.0097 - val_q4_loss: 0.0311 - val_q5_loss: 0.0373 - val_q6_loss: 0.0293 - val_q7_loss: 0.0500 - val_q8_loss: 0.0015\n",
      "Epoch 44/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.2110 - q0_loss: 0.0093 - q1_loss: 0.0101 - q2_loss: 0.0283 - q3_loss: 0.0136 - q4_loss: 0.0186 - q5_loss: 0.0168 - q6_loss: 0.0138 - q7_loss: 0.0980 - q8_loss: 0.0012 - val_loss: 0.1958 - val_q0_loss: 0.0083 - val_q1_loss: 0.0079 - val_q2_loss: 0.0183 - val_q3_loss: 0.0105 - val_q4_loss: 0.0177 - val_q5_loss: 0.0298 - val_q6_loss: 0.0246 - val_q7_loss: 0.0507 - val_q8_loss: 0.0013\n",
      "Epoch 45/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.2434 - q0_loss: 0.0093 - q1_loss: 0.0095 - q2_loss: 0.0332 - q3_loss: 0.0157 - q4_loss: 0.0247 - q5_loss: 0.0303 - q6_loss: 0.0242 - q7_loss: 0.0944 - q8_loss: 0.0011 - val_loss: 0.2111 - val_q0_loss: 0.0082 - val_q1_loss: 0.0096 - val_q2_loss: 0.0190 - val_q3_loss: 0.0153 - val_q4_loss: 0.0315 - val_q5_loss: 0.0259 - val_q6_loss: 0.0227 - val_q7_loss: 0.0491 - val_q8_loss: 8.0067e-04\n",
      "Epoch 46/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.2170 - q0_loss: 0.0094 - q1_loss: 0.0103 - q2_loss: 0.0342 - q3_loss: 0.0293 - q4_loss: 0.0198 - q5_loss: 0.0161 - q6_loss: 0.0149 - q7_loss: 0.0894 - q8_loss: 7.7630e-04 - val_loss: 0.2615 - val_q0_loss: 0.0090 - val_q1_loss: 0.0102 - val_q2_loss: 0.0546 - val_q3_loss: 0.0762 - val_q4_loss: 0.0208 - val_q5_loss: 0.0164 - val_q6_loss: 0.0173 - val_q7_loss: 0.0300 - val_q8_loss: 8.1212e-04\n",
      "Epoch 47/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.2490 - q0_loss: 0.0093 - q1_loss: 0.0101 - q2_loss: 0.0407 - q3_loss: 0.0476 - q4_loss: 0.0302 - q5_loss: 0.0147 - q6_loss: 0.0131 - q7_loss: 0.0805 - q8_loss: 8.7762e-04 - val_loss: 0.1900 - val_q0_loss: 0.0080 - val_q1_loss: 0.0081 - val_q2_loss: 0.0222 - val_q3_loss: 0.0279 - val_q4_loss: 0.0299 - val_q5_loss: 0.0121 - val_q6_loss: 0.0126 - val_q7_loss: 0.0477 - val_q8_loss: 8.5825e-04\n",
      "Epoch 48/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.2294 - q0_loss: 0.0093 - q1_loss: 0.0099 - q2_loss: 0.0396 - q3_loss: 0.0450 - q4_loss: 0.0235 - q5_loss: 0.0169 - q6_loss: 0.0166 - q7_loss: 0.0721 - q8_loss: 8.5233e-04 - val_loss: 0.2339 - val_q0_loss: 0.0091 - val_q1_loss: 0.0089 - val_q2_loss: 0.0279 - val_q3_loss: 0.0653 - val_q4_loss: 0.0400 - val_q5_loss: 0.0246 - val_q6_loss: 0.0197 - val_q7_loss: 0.0192 - val_q8_loss: 0.0013\n",
      "Epoch 49/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.2346 - q0_loss: 0.0095 - q1_loss: 0.0093 - q2_loss: 0.0341 - q3_loss: 0.0439 - q4_loss: 0.0282 - q5_loss: 0.0274 - q6_loss: 0.0234 - q7_loss: 0.0544 - q8_loss: 0.0011 - val_loss: 0.1608 - val_q0_loss: 0.0082 - val_q1_loss: 0.0082 - val_q2_loss: 0.0197 - val_q3_loss: 0.0268 - val_q4_loss: 0.0245 - val_q5_loss: 0.0130 - val_q6_loss: 0.0130 - val_q7_loss: 0.0313 - val_q8_loss: 9.1138e-04\n",
      "Epoch 50/300\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 0.2007 - q0_loss: 0.0095 - q1_loss: 0.0099 - q2_loss: 0.0253 - q3_loss: 0.0278 - q4_loss: 0.0273 - q5_loss: 0.0244 - q6_loss: 0.0214 - q7_loss: 0.0509 - q8_loss: 0.0012 - val_loss: 0.1939 - val_q0_loss: 0.0088 - val_q1_loss: 0.0076 - val_q2_loss: 0.0187 - val_q3_loss: 0.0145 - val_q4_loss: 0.0340 - val_q5_loss: 0.0362 - val_q6_loss: 0.0293 - val_q7_loss: 0.0224 - val_q8_loss: 0.0015\n",
      "Epoch 51/300\n",
      "269/269 [==============================] - 0s 219us/sample - loss: 0.2034 - q0_loss: 0.0096 - q1_loss: 0.0094 - q2_loss: 0.0274 - q3_loss: 0.0229 - q4_loss: 0.0315 - q5_loss: 0.0290 - q6_loss: 0.0233 - q7_loss: 0.0473 - q8_loss: 0.0013 - val_loss: 0.1946 - val_q0_loss: 0.0086 - val_q1_loss: 0.0082 - val_q2_loss: 0.0169 - val_q3_loss: 0.0118 - val_q4_loss: 0.0260 - val_q5_loss: 0.0363 - val_q6_loss: 0.0314 - val_q7_loss: 0.0273 - val_q8_loss: 0.0029\n",
      "Epoch 52/300\n",
      "269/269 [==============================] - 0s 273us/sample - loss: 0.1724 - q0_loss: 0.0096 - q1_loss: 0.0097 - q2_loss: 0.0261 - q3_loss: 0.0171 - q4_loss: 0.0222 - q5_loss: 0.0218 - q6_loss: 0.0186 - q7_loss: 0.0461 - q8_loss: 0.0020 - val_loss: 0.1479 - val_q0_loss: 0.0084 - val_q1_loss: 0.0079 - val_q2_loss: 0.0178 - val_q3_loss: 0.0202 - val_q4_loss: 0.0228 - val_q5_loss: 0.0153 - val_q6_loss: 0.0151 - val_q7_loss: 0.0284 - val_q8_loss: 9.9116e-04\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 284us/sample - loss: 0.1473 - q0_loss: 0.0096 - q1_loss: 0.0096 - q2_loss: 0.0274 - q3_loss: 0.0135 - q4_loss: 0.0148 - q5_loss: 0.0134 - q6_loss: 0.0121 - q7_loss: 0.0431 - q8_loss: 9.0938e-04 - val_loss: 0.1224 - val_q0_loss: 0.0086 - val_q1_loss: 0.0091 - val_q2_loss: 0.0143 - val_q3_loss: 0.0125 - val_q4_loss: 0.0254 - val_q5_loss: 0.0136 - val_q6_loss: 0.0082 - val_q7_loss: 0.0228 - val_q8_loss: 6.5733e-04\n",
      "Epoch 54/300\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 0.1473 - q0_loss: 0.0098 - q1_loss: 0.0098 - q2_loss: 0.0279 - q3_loss: 0.0193 - q4_loss: 0.0186 - q5_loss: 0.0140 - q6_loss: 0.0120 - q7_loss: 0.0351 - q8_loss: 9.0581e-04 - val_loss: 0.1719 - val_q0_loss: 0.0087 - val_q1_loss: 0.0097 - val_q2_loss: 0.0238 - val_q3_loss: 0.0096 - val_q4_loss: 0.0284 - val_q5_loss: 0.0342 - val_q6_loss: 0.0281 - val_q7_loss: 0.0212 - val_q8_loss: 4.6519e-04\n",
      "Epoch 55/300\n",
      "269/269 [==============================] - 0s 256us/sample - loss: 0.1906 - q0_loss: 0.0098 - q1_loss: 0.0091 - q2_loss: 0.0301 - q3_loss: 0.0130 - q4_loss: 0.0300 - q5_loss: 0.0380 - q6_loss: 0.0327 - q7_loss: 0.0269 - q8_loss: 0.0026 - val_loss: 0.1974 - val_q0_loss: 0.0090 - val_q1_loss: 0.0064 - val_q2_loss: 0.0186 - val_q3_loss: 0.0103 - val_q4_loss: 0.0427 - val_q5_loss: 0.0498 - val_q6_loss: 0.0392 - val_q7_loss: 0.0103 - val_q8_loss: 0.0019\n",
      "Epoch 56/300\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 0.1710 - q0_loss: 0.0099 - q1_loss: 0.0089 - q2_loss: 0.0282 - q3_loss: 0.0125 - q4_loss: 0.0280 - q5_loss: 0.0320 - q6_loss: 0.0272 - q7_loss: 0.0175 - q8_loss: 0.0017 - val_loss: 0.1767 - val_q0_loss: 0.0087 - val_q1_loss: 0.0095 - val_q2_loss: 0.0208 - val_q3_loss: 0.0091 - val_q4_loss: 0.0285 - val_q5_loss: 0.0376 - val_q6_loss: 0.0325 - val_q7_loss: 0.0133 - val_q8_loss: 0.0015\n",
      "Epoch 57/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.1596 - q0_loss: 0.0098 - q1_loss: 0.0092 - q2_loss: 0.0290 - q3_loss: 0.0121 - q4_loss: 0.0222 - q5_loss: 0.0305 - q6_loss: 0.0261 - q7_loss: 0.0169 - q8_loss: 0.0013 - val_loss: 0.1292 - val_q0_loss: 0.0088 - val_q1_loss: 0.0070 - val_q2_loss: 0.0185 - val_q3_loss: 0.0109 - val_q4_loss: 0.0116 - val_q5_loss: 0.0295 - val_q6_loss: 0.0256 - val_q7_loss: 0.0116 - val_q8_loss: 0.0014\n",
      "Epoch 58/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.1234 - q0_loss: 0.0099 - q1_loss: 0.0094 - q2_loss: 0.0306 - q3_loss: 0.0143 - q4_loss: 0.0122 - q5_loss: 0.0167 - q6_loss: 0.0151 - q7_loss: 0.0135 - q8_loss: 0.0013 - val_loss: 0.0855 - val_q0_loss: 0.0089 - val_q1_loss: 0.0087 - val_q2_loss: 0.0152 - val_q3_loss: 0.0106 - val_q4_loss: 0.0166 - val_q5_loss: 0.0054 - val_q6_loss: 0.0064 - val_q7_loss: 0.0070 - val_q8_loss: 8.6089e-04\n",
      "Epoch 59/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.1083 - q0_loss: 0.0098 - q1_loss: 0.0094 - q2_loss: 0.0260 - q3_loss: 0.0121 - q4_loss: 0.0160 - q5_loss: 0.0124 - q6_loss: 0.0111 - q7_loss: 0.0094 - q8_loss: 9.1431e-04 - val_loss: 0.1370 - val_q0_loss: 0.0092 - val_q1_loss: 0.0080 - val_q2_loss: 0.0201 - val_q3_loss: 0.0261 - val_q4_loss: 0.0196 - val_q5_loss: 0.0192 - val_q6_loss: 0.0167 - val_q7_loss: 0.0078 - val_q8_loss: 0.0012\n",
      "Epoch 60/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.1309 - q0_loss: 0.0099 - q1_loss: 0.0091 - q2_loss: 0.0322 - q3_loss: 0.0141 - q4_loss: 0.0132 - q5_loss: 0.0239 - q6_loss: 0.0212 - q7_loss: 0.0106 - q8_loss: 0.0011 - val_loss: 0.1082 - val_q0_loss: 0.0089 - val_q1_loss: 0.0073 - val_q2_loss: 0.0174 - val_q3_loss: 0.0100 - val_q4_loss: 0.0102 - val_q5_loss: 0.0210 - val_q6_loss: 0.0185 - val_q7_loss: 0.0072 - val_q8_loss: 0.0013\n",
      "Epoch 61/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.1286 - q0_loss: 0.0099 - q1_loss: 0.0087 - q2_loss: 0.0293 - q3_loss: 0.0101 - q4_loss: 0.0158 - q5_loss: 0.0245 - q6_loss: 0.0215 - q7_loss: 0.0076 - q8_loss: 0.0011 - val_loss: 0.1099 - val_q0_loss: 0.0092 - val_q1_loss: 0.0075 - val_q2_loss: 0.0137 - val_q3_loss: 0.0090 - val_q4_loss: 0.0161 - val_q5_loss: 0.0224 - val_q6_loss: 0.0193 - val_q7_loss: 0.0080 - val_q8_loss: 0.0013\n",
      "Epoch 62/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1214 - q0_loss: 0.0100 - q1_loss: 0.0086 - q2_loss: 0.0319 - q3_loss: 0.0164 - q4_loss: 0.0123 - q5_loss: 0.0183 - q6_loss: 0.0159 - q7_loss: 0.0088 - q8_loss: 0.0011 - val_loss: 0.1604 - val_q0_loss: 0.0089 - val_q1_loss: 0.0090 - val_q2_loss: 0.0219 - val_q3_loss: 0.0082 - val_q4_loss: 0.0284 - val_q5_loss: 0.0365 - val_q6_loss: 0.0293 - val_q7_loss: 0.0084 - val_q8_loss: 5.7453e-04\n",
      "Epoch 63/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1409 - q0_loss: 0.0099 - q1_loss: 0.0085 - q2_loss: 0.0301 - q3_loss: 0.0181 - q4_loss: 0.0210 - q5_loss: 0.0233 - q6_loss: 0.0198 - q7_loss: 0.0101 - q8_loss: 0.0011 - val_loss: 0.0951 - val_q0_loss: 0.0090 - val_q1_loss: 0.0080 - val_q2_loss: 0.0156 - val_q3_loss: 0.0059 - val_q4_loss: 0.0151 - val_q5_loss: 0.0160 - val_q6_loss: 0.0124 - val_q7_loss: 0.0077 - val_q8_loss: 9.3402e-04\n",
      "Epoch 64/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1167 - q0_loss: 0.0100 - q1_loss: 0.0087 - q2_loss: 0.0279 - q3_loss: 0.0127 - q4_loss: 0.0171 - q5_loss: 0.0169 - q6_loss: 0.0146 - q7_loss: 0.0075 - q8_loss: 0.0011 - val_loss: 0.0931 - val_q0_loss: 0.0088 - val_q1_loss: 0.0078 - val_q2_loss: 0.0164 - val_q3_loss: 0.0133 - val_q4_loss: 0.0218 - val_q5_loss: 0.0063 - val_q6_loss: 0.0052 - val_q7_loss: 0.0080 - val_q8_loss: 8.2340e-04\n",
      "Epoch 65/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1227 - q0_loss: 0.0099 - q1_loss: 0.0083 - q2_loss: 0.0284 - q3_loss: 0.0112 - q4_loss: 0.0182 - q5_loss: 0.0212 - q6_loss: 0.0169 - q7_loss: 0.0075 - q8_loss: 0.0011 - val_loss: 0.1179 - val_q0_loss: 0.0087 - val_q1_loss: 0.0068 - val_q2_loss: 0.0197 - val_q3_loss: 0.0189 - val_q4_loss: 0.0168 - val_q5_loss: 0.0128 - val_q6_loss: 0.0137 - val_q7_loss: 0.0115 - val_q8_loss: 0.0011\n",
      "Epoch 66/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1132 - q0_loss: 0.0099 - q1_loss: 0.0084 - q2_loss: 0.0322 - q3_loss: 0.0183 - q4_loss: 0.0150 - q5_loss: 0.0112 - q6_loss: 0.0097 - q7_loss: 0.0089 - q8_loss: 9.3775e-04 - val_loss: 0.0995 - val_q0_loss: 0.0089 - val_q1_loss: 0.0071 - val_q2_loss: 0.0172 - val_q3_loss: 0.0116 - val_q4_loss: 0.0126 - val_q5_loss: 0.0150 - val_q6_loss: 0.0132 - val_q7_loss: 0.0073 - val_q8_loss: 0.0010\n",
      "Epoch 67/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1008 - q0_loss: 0.0100 - q1_loss: 0.0085 - q2_loss: 0.0287 - q3_loss: 0.0123 - q4_loss: 0.0139 - q5_loss: 0.0114 - q6_loss: 0.0096 - q7_loss: 0.0071 - q8_loss: 9.6498e-04 - val_loss: 0.1116 - val_q0_loss: 0.0089 - val_q1_loss: 0.0062 - val_q2_loss: 0.0189 - val_q3_loss: 0.0098 - val_q4_loss: 0.0098 - val_q5_loss: 0.0248 - val_q6_loss: 0.0206 - val_q7_loss: 0.0077 - val_q8_loss: 0.0014\n",
      "Epoch 68/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1226 - q0_loss: 0.0099 - q1_loss: 0.0077 - q2_loss: 0.0300 - q3_loss: 0.0107 - q4_loss: 0.0151 - q5_loss: 0.0218 - q6_loss: 0.0185 - q7_loss: 0.0079 - q8_loss: 0.0013 - val_loss: 0.1319 - val_q0_loss: 0.0090 - val_q1_loss: 0.0057 - val_q2_loss: 0.0190 - val_q3_loss: 0.0072 - val_q4_loss: 0.0193 - val_q5_loss: 0.0319 - val_q6_loss: 0.0253 - val_q7_loss: 0.0080 - val_q8_loss: 0.0015\n",
      "Epoch 69/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.1208 - q0_loss: 0.0098 - q1_loss: 0.0073 - q2_loss: 0.0300 - q3_loss: 0.0101 - q4_loss: 0.0117 - q5_loss: 0.0261 - q6_loss: 0.0227 - q7_loss: 0.0071 - q8_loss: 0.0014 - val_loss: 0.2073 - val_q0_loss: 0.0085 - val_q1_loss: 0.0076 - val_q2_loss: 0.0312 - val_q3_loss: 0.0308 - val_q4_loss: 0.0137 - val_q5_loss: 0.0472 - val_q6_loss: 0.0378 - val_q7_loss: 0.0136 - val_q8_loss: 0.0018\n",
      "Epoch 70/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 203us/sample - loss: 0.1543 - q0_loss: 0.0097 - q1_loss: 0.0074 - q2_loss: 0.0369 - q3_loss: 0.0250 - q4_loss: 0.0135 - q5_loss: 0.0268 - q6_loss: 0.0231 - q7_loss: 0.0112 - q8_loss: 0.0012 - val_loss: 0.1472 - val_q0_loss: 0.0090 - val_q1_loss: 0.0055 - val_q2_loss: 0.0228 - val_q3_loss: 0.0214 - val_q4_loss: 0.0155 - val_q5_loss: 0.0310 - val_q6_loss: 0.0254 - val_q7_loss: 0.0081 - val_q8_loss: 0.0015\n",
      "Epoch 71/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1553 - q0_loss: 0.0099 - q1_loss: 0.0071 - q2_loss: 0.0344 - q3_loss: 0.0178 - q4_loss: 0.0211 - q5_loss: 0.0306 - q6_loss: 0.0255 - q7_loss: 0.0079 - q8_loss: 0.0014 - val_loss: 0.1720 - val_q0_loss: 0.0089 - val_q1_loss: 0.0078 - val_q2_loss: 0.0219 - val_q3_loss: 0.0083 - val_q4_loss: 0.0305 - val_q5_loss: 0.0465 - val_q6_loss: 0.0449 - val_q7_loss: 0.0077 - val_q8_loss: 0.0023\n",
      "Epoch 72/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.1470 - q0_loss: 0.0098 - q1_loss: 0.0069 - q2_loss: 0.0330 - q3_loss: 0.0178 - q4_loss: 0.0149 - q5_loss: 0.0315 - q6_loss: 0.0273 - q7_loss: 0.0078 - q8_loss: 0.0017 - val_loss: 0.1781 - val_q0_loss: 0.0084 - val_q1_loss: 0.0037 - val_q2_loss: 0.0311 - val_q3_loss: 0.0335 - val_q4_loss: 0.0083 - val_q5_loss: 0.0435 - val_q6_loss: 0.0362 - val_q7_loss: 0.0096 - val_q8_loss: 0.0018\n",
      "Epoch 73/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.1639 - q0_loss: 0.0098 - q1_loss: 0.0064 - q2_loss: 0.0363 - q3_loss: 0.0216 - q4_loss: 0.0158 - q5_loss: 0.0330 - q6_loss: 0.0287 - q7_loss: 0.0087 - q8_loss: 0.0013 - val_loss: 0.2417 - val_q0_loss: 0.0088 - val_q1_loss: 0.0082 - val_q2_loss: 0.0208 - val_q3_loss: 0.0100 - val_q4_loss: 0.0449 - val_q5_loss: 0.0717 - val_q6_loss: 0.0680 - val_q7_loss: 0.0076 - val_q8_loss: 0.0020\n",
      "Epoch 74/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1544 - q0_loss: 0.0099 - q1_loss: 0.0070 - q2_loss: 0.0283 - q3_loss: 0.0138 - q4_loss: 0.0245 - q5_loss: 0.0327 - q6_loss: 0.0283 - q7_loss: 0.0079 - q8_loss: 0.0017 - val_loss: 0.1314 - val_q0_loss: 0.0090 - val_q1_loss: 0.0049 - val_q2_loss: 0.0183 - val_q3_loss: 0.0093 - val_q4_loss: 0.0171 - val_q5_loss: 0.0304 - val_q6_loss: 0.0262 - val_q7_loss: 0.0082 - val_q8_loss: 0.0015\n",
      "Epoch 75/300\n",
      "269/269 [==============================] - 0s 183us/sample - loss: 0.1392 - q0_loss: 0.0098 - q1_loss: 0.0064 - q2_loss: 0.0322 - q3_loss: 0.0133 - q4_loss: 0.0133 - q5_loss: 0.0301 - q6_loss: 0.0255 - q7_loss: 0.0075 - q8_loss: 0.0012 - val_loss: 0.1085 - val_q0_loss: 0.0092 - val_q1_loss: 0.0065 - val_q2_loss: 0.0278 - val_q3_loss: 0.0176 - val_q4_loss: 0.0058 - val_q5_loss: 0.0123 - val_q6_loss: 0.0119 - val_q7_loss: 0.0092 - val_q8_loss: 0.0011\n",
      "Epoch 76/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1276 - q0_loss: 0.0098 - q1_loss: 0.0065 - q2_loss: 0.0330 - q3_loss: 0.0182 - q4_loss: 0.0129 - q5_loss: 0.0182 - q6_loss: 0.0168 - q7_loss: 0.0088 - q8_loss: 0.0011 - val_loss: 0.1271 - val_q0_loss: 0.0093 - val_q1_loss: 0.0067 - val_q2_loss: 0.0363 - val_q3_loss: 0.0316 - val_q4_loss: 0.0079 - val_q5_loss: 0.0095 - val_q6_loss: 0.0095 - val_q7_loss: 0.0098 - val_q8_loss: 0.0010\n",
      "Epoch 77/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1127 - q0_loss: 0.0099 - q1_loss: 0.0067 - q2_loss: 0.0295 - q3_loss: 0.0146 - q4_loss: 0.0138 - q5_loss: 0.0158 - q6_loss: 0.0140 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.0814 - val_q0_loss: 0.0089 - val_q1_loss: 0.0061 - val_q2_loss: 0.0143 - val_q3_loss: 0.0097 - val_q4_loss: 0.0171 - val_q5_loss: 0.0059 - val_q6_loss: 0.0061 - val_q7_loss: 0.0080 - val_q8_loss: 8.8077e-04\n",
      "Epoch 78/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0985 - q0_loss: 0.0098 - q1_loss: 0.0067 - q2_loss: 0.0273 - q3_loss: 0.0133 - q4_loss: 0.0139 - q5_loss: 0.0104 - q6_loss: 0.0091 - q7_loss: 0.0077 - q8_loss: 9.6090e-04 - val_loss: 0.0726 - val_q0_loss: 0.0089 - val_q1_loss: 0.0059 - val_q2_loss: 0.0139 - val_q3_loss: 0.0071 - val_q4_loss: 0.0102 - val_q5_loss: 0.0051 - val_q6_loss: 0.0071 - val_q7_loss: 0.0083 - val_q8_loss: 9.5258e-04\n",
      "Epoch 79/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1489 - q0_loss: 0.0097 - q1_loss: 0.0062 - q2_loss: 0.0355 - q3_loss: 0.0334 - q4_loss: 0.0275 - q5_loss: 0.0147 - q6_loss: 0.0124 - q7_loss: 0.0081 - q8_loss: 0.0010 - val_loss: 0.0963 - val_q0_loss: 0.0090 - val_q1_loss: 0.0054 - val_q2_loss: 0.0181 - val_q3_loss: 0.0137 - val_q4_loss: 0.0089 - val_q5_loss: 0.0127 - val_q6_loss: 0.0116 - val_q7_loss: 0.0087 - val_q8_loss: 0.0011\n",
      "Epoch 80/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1403 - q0_loss: 0.0098 - q1_loss: 0.0060 - q2_loss: 0.0320 - q3_loss: 0.0183 - q4_loss: 0.0199 - q5_loss: 0.0251 - q6_loss: 0.0221 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.1408 - val_q0_loss: 0.0088 - val_q1_loss: 0.0036 - val_q2_loss: 0.0225 - val_q3_loss: 0.0165 - val_q4_loss: 0.0173 - val_q5_loss: 0.0320 - val_q6_loss: 0.0268 - val_q7_loss: 0.0078 - val_q8_loss: 0.0016\n",
      "Epoch 81/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1275 - q0_loss: 0.0099 - q1_loss: 0.0060 - q2_loss: 0.0298 - q3_loss: 0.0113 - q4_loss: 0.0148 - q5_loss: 0.0238 - q6_loss: 0.0212 - q7_loss: 0.0072 - q8_loss: 0.0011 - val_loss: 0.1081 - val_q0_loss: 0.0090 - val_q1_loss: 0.0043 - val_q2_loss: 0.0168 - val_q3_loss: 0.0071 - val_q4_loss: 0.0138 - val_q5_loss: 0.0226 - val_q6_loss: 0.0197 - val_q7_loss: 0.0085 - val_q8_loss: 0.0014\n",
      "Epoch 82/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.1234 - q0_loss: 0.0099 - q1_loss: 0.0055 - q2_loss: 0.0280 - q3_loss: 0.0077 - q4_loss: 0.0191 - q5_loss: 0.0265 - q6_loss: 0.0219 - q7_loss: 0.0074 - q8_loss: 0.0013 - val_loss: 0.0913 - val_q0_loss: 0.0088 - val_q1_loss: 0.0045 - val_q2_loss: 0.0172 - val_q3_loss: 0.0139 - val_q4_loss: 0.0114 - val_q5_loss: 0.0125 - val_q6_loss: 0.0127 - val_q7_loss: 0.0077 - val_q8_loss: 0.0011\n",
      "Epoch 83/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1144 - q0_loss: 0.0099 - q1_loss: 0.0054 - q2_loss: 0.0286 - q3_loss: 0.0114 - q4_loss: 0.0147 - q5_loss: 0.0196 - q6_loss: 0.0173 - q7_loss: 0.0080 - q8_loss: 0.0011 - val_loss: 0.1115 - val_q0_loss: 0.0088 - val_q1_loss: 0.0057 - val_q2_loss: 0.0171 - val_q3_loss: 0.0073 - val_q4_loss: 0.0263 - val_q5_loss: 0.0228 - val_q6_loss: 0.0141 - val_q7_loss: 0.0081 - val_q8_loss: 6.7564e-04\n",
      "Epoch 84/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1174 - q0_loss: 0.0099 - q1_loss: 0.0053 - q2_loss: 0.0286 - q3_loss: 0.0123 - q4_loss: 0.0146 - q5_loss: 0.0211 - q6_loss: 0.0180 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.0990 - val_q0_loss: 0.0089 - val_q1_loss: 0.0050 - val_q2_loss: 0.0194 - val_q3_loss: 0.0070 - val_q4_loss: 0.0164 - val_q5_loss: 0.0172 - val_q6_loss: 0.0135 - val_q7_loss: 0.0083 - val_q8_loss: 8.8626e-04\n",
      "Epoch 85/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1002 - q0_loss: 0.0099 - q1_loss: 0.0053 - q2_loss: 0.0281 - q3_loss: 0.0102 - q4_loss: 0.0098 - q5_loss: 0.0161 - q6_loss: 0.0132 - q7_loss: 0.0075 - q8_loss: 0.0010 - val_loss: 0.1046 - val_q0_loss: 0.0088 - val_q1_loss: 0.0035 - val_q2_loss: 0.0190 - val_q3_loss: 0.0094 - val_q4_loss: 0.0068 - val_q5_loss: 0.0222 - val_q6_loss: 0.0200 - val_q7_loss: 0.0082 - val_q8_loss: 0.0014\n",
      "Epoch 86/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1082 - q0_loss: 0.0099 - q1_loss: 0.0052 - q2_loss: 0.0324 - q3_loss: 0.0142 - q4_loss: 0.0083 - q5_loss: 0.0162 - q6_loss: 0.0149 - q7_loss: 0.0077 - q8_loss: 0.0010 - val_loss: 0.0869 - val_q0_loss: 0.0088 - val_q1_loss: 0.0042 - val_q2_loss: 0.0163 - val_q3_loss: 0.0103 - val_q4_loss: 0.0106 - val_q5_loss: 0.0126 - val_q6_loss: 0.0113 - val_q7_loss: 0.0079 - val_q8_loss: 0.0010\n",
      "Epoch 87/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1107 - q0_loss: 0.0098 - q1_loss: 0.0051 - q2_loss: 0.0286 - q3_loss: 0.0151 - q4_loss: 0.0172 - q5_loss: 0.0167 - q6_loss: 0.0137 - q7_loss: 0.0071 - q8_loss: 9.6403e-04 - val_loss: 0.1089 - val_q0_loss: 0.0088 - val_q1_loss: 0.0031 - val_q2_loss: 0.0182 - val_q3_loss: 0.0112 - val_q4_loss: 0.0128 - val_q5_loss: 0.0214 - val_q6_loss: 0.0195 - val_q7_loss: 0.0080 - val_q8_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.1613 - q0_loss: 0.0099 - q1_loss: 0.0045 - q2_loss: 0.0295 - q3_loss: 0.0190 - q4_loss: 0.0351 - q5_loss: 0.0328 - q6_loss: 0.0259 - q7_loss: 0.0072 - q8_loss: 0.0014 - val_loss: 0.1501 - val_q0_loss: 0.0087 - val_q1_loss: 0.0088 - val_q2_loss: 0.0223 - val_q3_loss: 0.0178 - val_q4_loss: 0.0135 - val_q5_loss: 0.0360 - val_q6_loss: 0.0306 - val_q7_loss: 0.0083 - val_q8_loss: 0.0017\n",
      "Epoch 89/300\n",
      "269/269 [==============================] - 0s 194us/sample - loss: 0.1433 - q0_loss: 0.0097 - q1_loss: 0.0048 - q2_loss: 0.0305 - q3_loss: 0.0159 - q4_loss: 0.0214 - q5_loss: 0.0280 - q6_loss: 0.0247 - q7_loss: 0.0084 - q8_loss: 0.0018 - val_loss: 0.1359 - val_q0_loss: 0.0091 - val_q1_loss: 0.0028 - val_q2_loss: 0.0186 - val_q3_loss: 0.0117 - val_q4_loss: 0.0253 - val_q5_loss: 0.0299 - val_q6_loss: 0.0253 - val_q7_loss: 0.0091 - val_q8_loss: 0.0016\n",
      "Epoch 90/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1327 - q0_loss: 0.0098 - q1_loss: 0.0068 - q2_loss: 0.0294 - q3_loss: 0.0103 - q4_loss: 0.0181 - q5_loss: 0.0268 - q6_loss: 0.0221 - q7_loss: 0.0072 - q8_loss: 0.0013 - val_loss: 0.0920 - val_q0_loss: 0.0088 - val_q1_loss: 0.0034 - val_q2_loss: 0.0149 - val_q3_loss: 0.0101 - val_q4_loss: 0.0097 - val_q5_loss: 0.0166 - val_q6_loss: 0.0163 - val_q7_loss: 0.0080 - val_q8_loss: 0.0012\n",
      "Epoch 91/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1236 - q0_loss: 0.0097 - q1_loss: 0.0066 - q2_loss: 0.0322 - q3_loss: 0.0151 - q4_loss: 0.0104 - q5_loss: 0.0228 - q6_loss: 0.0192 - q7_loss: 0.0071 - q8_loss: 0.0012 - val_loss: 0.0853 - val_q0_loss: 0.0090 - val_q1_loss: 0.0046 - val_q2_loss: 0.0248 - val_q3_loss: 0.0125 - val_q4_loss: 0.0075 - val_q5_loss: 0.0060 - val_q6_loss: 0.0070 - val_q7_loss: 0.0092 - val_q8_loss: 9.8140e-04\n",
      "Epoch 92/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.1046 - q0_loss: 0.0097 - q1_loss: 0.0047 - q2_loss: 0.0293 - q3_loss: 0.0138 - q4_loss: 0.0085 - q5_loss: 0.0149 - q6_loss: 0.0141 - q7_loss: 0.0072 - q8_loss: 0.0012 - val_loss: 0.0914 - val_q0_loss: 0.0090 - val_q1_loss: 0.0043 - val_q2_loss: 0.0175 - val_q3_loss: 0.0123 - val_q4_loss: 0.0116 - val_q5_loss: 0.0105 - val_q6_loss: 0.0112 - val_q7_loss: 0.0092 - val_q8_loss: 0.0011\n",
      "Epoch 93/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0977 - q0_loss: 0.0097 - q1_loss: 0.0049 - q2_loss: 0.0279 - q3_loss: 0.0131 - q4_loss: 0.0142 - q5_loss: 0.0112 - q6_loss: 0.0103 - q7_loss: 0.0075 - q8_loss: 9.9388e-04 - val_loss: 0.1281 - val_q0_loss: 0.0087 - val_q1_loss: 0.0026 - val_q2_loss: 0.0204 - val_q3_loss: 0.0135 - val_q4_loss: 0.0158 - val_q5_loss: 0.0280 - val_q6_loss: 0.0245 - val_q7_loss: 0.0078 - val_q8_loss: 0.0015\n",
      "Epoch 94/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1026 - q0_loss: 0.0097 - q1_loss: 0.0046 - q2_loss: 0.0267 - q3_loss: 0.0098 - q4_loss: 0.0121 - q5_loss: 0.0160 - q6_loss: 0.0134 - q7_loss: 0.0074 - q8_loss: 0.0011 - val_loss: 0.0916 - val_q0_loss: 0.0087 - val_q1_loss: 0.0034 - val_q2_loss: 0.0177 - val_q3_loss: 0.0130 - val_q4_loss: 0.0094 - val_q5_loss: 0.0130 - val_q6_loss: 0.0126 - val_q7_loss: 0.0077 - val_q8_loss: 0.0011\n",
      "Epoch 95/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1289 - q0_loss: 0.0097 - q1_loss: 0.0046 - q2_loss: 0.0316 - q3_loss: 0.0136 - q4_loss: 0.0124 - q5_loss: 0.0251 - q6_loss: 0.0222 - q7_loss: 0.0069 - q8_loss: 0.0011 - val_loss: 0.1135 - val_q0_loss: 0.0086 - val_q1_loss: 0.0026 - val_q2_loss: 0.0208 - val_q3_loss: 0.0160 - val_q4_loss: 0.0112 - val_q5_loss: 0.0224 - val_q6_loss: 0.0195 - val_q7_loss: 0.0081 - val_q8_loss: 0.0013\n",
      "Epoch 96/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1252 - q0_loss: 0.0096 - q1_loss: 0.0052 - q2_loss: 0.0304 - q3_loss: 0.0127 - q4_loss: 0.0115 - q5_loss: 0.0240 - q6_loss: 0.0204 - q7_loss: 0.0072 - q8_loss: 0.0012 - val_loss: 0.1589 - val_q0_loss: 0.0089 - val_q1_loss: 0.0053 - val_q2_loss: 0.0269 - val_q3_loss: 0.0088 - val_q4_loss: 0.0184 - val_q5_loss: 0.0396 - val_q6_loss: 0.0369 - val_q7_loss: 0.0088 - val_q8_loss: 5.5698e-04\n",
      "Epoch 97/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.1310 - q0_loss: 0.0097 - q1_loss: 0.0041 - q2_loss: 0.0285 - q3_loss: 0.0113 - q4_loss: 0.0196 - q5_loss: 0.0274 - q6_loss: 0.0237 - q7_loss: 0.0076 - q8_loss: 0.0013 - val_loss: 0.1388 - val_q0_loss: 0.0088 - val_q1_loss: 0.0060 - val_q2_loss: 0.0189 - val_q3_loss: 0.0069 - val_q4_loss: 0.0200 - val_q5_loss: 0.0340 - val_q6_loss: 0.0281 - val_q7_loss: 0.0084 - val_q8_loss: 0.0016\n",
      "Epoch 98/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.1388 - q0_loss: 0.0097 - q1_loss: 0.0040 - q2_loss: 0.0289 - q3_loss: 0.0121 - q4_loss: 0.0196 - q5_loss: 0.0294 - q6_loss: 0.0246 - q7_loss: 0.0075 - q8_loss: 0.0016 - val_loss: 0.1187 - val_q0_loss: 0.0090 - val_q1_loss: 0.0036 - val_q2_loss: 0.0203 - val_q3_loss: 0.0153 - val_q4_loss: 0.0151 - val_q5_loss: 0.0205 - val_q6_loss: 0.0174 - val_q7_loss: 0.0093 - val_q8_loss: 0.0012\n",
      "Epoch 99/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1202 - q0_loss: 0.0095 - q1_loss: 0.0038 - q2_loss: 0.0296 - q3_loss: 0.0162 - q4_loss: 0.0120 - q5_loss: 0.0199 - q6_loss: 0.0176 - q7_loss: 0.0076 - q8_loss: 0.0011 - val_loss: 0.1730 - val_q0_loss: 0.0092 - val_q1_loss: 0.0038 - val_q2_loss: 0.0348 - val_q3_loss: 0.0420 - val_q4_loss: 0.0151 - val_q5_loss: 0.0250 - val_q6_loss: 0.0228 - val_q7_loss: 0.0100 - val_q8_loss: 0.0012\n",
      "Epoch 100/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1824 - q0_loss: 0.0097 - q1_loss: 0.0104 - q2_loss: 0.0402 - q3_loss: 0.0323 - q4_loss: 0.0087 - q5_loss: 0.0360 - q6_loss: 0.0323 - q7_loss: 0.0096 - q8_loss: 0.0013 - val_loss: 0.2611 - val_q0_loss: 0.0082 - val_q1_loss: 0.0562 - val_q2_loss: 0.0339 - val_q3_loss: 0.0359 - val_q4_loss: 0.0118 - val_q5_loss: 0.0573 - val_q6_loss: 0.0475 - val_q7_loss: 0.0111 - val_q8_loss: 0.0021\n",
      "Epoch 101/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1914 - q0_loss: 0.0094 - q1_loss: 0.0139 - q2_loss: 0.0410 - q3_loss: 0.0377 - q4_loss: 0.0151 - q5_loss: 0.0321 - q6_loss: 0.0277 - q7_loss: 0.0110 - q8_loss: 0.0014 - val_loss: 0.1188 - val_q0_loss: 0.0083 - val_q1_loss: 0.0035 - val_q2_loss: 0.0224 - val_q3_loss: 0.0262 - val_q4_loss: 0.0233 - val_q5_loss: 0.0139 - val_q6_loss: 0.0144 - val_q7_loss: 0.0067 - val_q8_loss: 0.0011\n",
      "Epoch 102/300\n",
      "269/269 [==============================] - 0s 213us/sample - loss: 0.1273 - q0_loss: 0.0096 - q1_loss: 0.0053 - q2_loss: 0.0348 - q3_loss: 0.0315 - q4_loss: 0.0214 - q5_loss: 0.0093 - q6_loss: 0.0094 - q7_loss: 0.0085 - q8_loss: 9.4209e-04 - val_loss: 0.1291 - val_q0_loss: 0.0092 - val_q1_loss: 0.0056 - val_q2_loss: 0.0395 - val_q3_loss: 0.0425 - val_q4_loss: 0.0133 - val_q5_loss: 0.0067 - val_q6_loss: 0.0045 - val_q7_loss: 0.0103 - val_q8_loss: 8.9753e-04\n",
      "Epoch 103/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1505 - q0_loss: 0.0096 - q1_loss: 0.0052 - q2_loss: 0.0389 - q3_loss: 0.0318 - q4_loss: 0.0141 - q5_loss: 0.0221 - q6_loss: 0.0201 - q7_loss: 0.0094 - q8_loss: 0.0012 - val_loss: 0.1802 - val_q0_loss: 0.0082 - val_q1_loss: 0.0126 - val_q2_loss: 0.0320 - val_q3_loss: 0.0376 - val_q4_loss: 0.0101 - val_q5_loss: 0.0414 - val_q6_loss: 0.0352 - val_q7_loss: 0.0065 - val_q8_loss: 0.0018\n",
      "Epoch 104/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1400 - q0_loss: 0.0096 - q1_loss: 0.0058 - q2_loss: 0.0330 - q3_loss: 0.0243 - q4_loss: 0.0159 - q5_loss: 0.0229 - q6_loss: 0.0204 - q7_loss: 0.0068 - q8_loss: 0.0011 - val_loss: 0.1551 - val_q0_loss: 0.0092 - val_q1_loss: 0.0044 - val_q2_loss: 0.0235 - val_q3_loss: 0.0325 - val_q4_loss: 0.0356 - val_q5_loss: 0.0230 - val_q6_loss: 0.0192 - val_q7_loss: 0.0105 - val_q8_loss: 0.0014\n",
      "Epoch 105/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1442 - q0_loss: 0.0096 - q1_loss: 0.0051 - q2_loss: 0.0305 - q3_loss: 0.0240 - q4_loss: 0.0270 - q5_loss: 0.0214 - q6_loss: 0.0171 - q7_loss: 0.0089 - q8_loss: 0.0013 - val_loss: 0.1875 - val_q0_loss: 0.0077 - val_q1_loss: 0.0034 - val_q2_loss: 0.0323 - val_q3_loss: 0.0556 - val_q4_loss: 0.0527 - val_q5_loss: 0.0074 - val_q6_loss: 0.0102 - val_q7_loss: 0.0123 - val_q8_loss: 8.8424e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1656 - q0_loss: 0.0093 - q1_loss: 0.0050 - q2_loss: 0.0374 - q3_loss: 0.0437 - q4_loss: 0.0317 - q5_loss: 0.0123 - q6_loss: 0.0126 - q7_loss: 0.0114 - q8_loss: 9.8372e-04 - val_loss: 0.1270 - val_q0_loss: 0.0082 - val_q1_loss: 0.0044 - val_q2_loss: 0.0221 - val_q3_loss: 0.0330 - val_q4_loss: 0.0336 - val_q5_loss: 0.0077 - val_q6_loss: 0.0044 - val_q7_loss: 0.0085 - val_q8_loss: 7.8360e-04\n",
      "Epoch 107/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1415 - q0_loss: 0.0097 - q1_loss: 0.0051 - q2_loss: 0.0366 - q3_loss: 0.0320 - q4_loss: 0.0174 - q5_loss: 0.0150 - q6_loss: 0.0141 - q7_loss: 0.0098 - q8_loss: 0.0011 - val_loss: 0.1972 - val_q0_loss: 0.0089 - val_q1_loss: 0.0062 - val_q2_loss: 0.0314 - val_q3_loss: 0.0145 - val_q4_loss: 0.0159 - val_q5_loss: 0.0538 - val_q6_loss: 0.0530 - val_q7_loss: 0.0095 - val_q8_loss: 5.4655e-04\n",
      "Epoch 108/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1334 - q0_loss: 0.0096 - q1_loss: 0.0049 - q2_loss: 0.0303 - q3_loss: 0.0142 - q4_loss: 0.0152 - q5_loss: 0.0263 - q6_loss: 0.0238 - q7_loss: 0.0078 - q8_loss: 0.0013 - val_loss: 0.0832 - val_q0_loss: 0.0085 - val_q1_loss: 0.0042 - val_q2_loss: 0.0176 - val_q3_loss: 0.0171 - val_q4_loss: 0.0122 - val_q5_loss: 0.0062 - val_q6_loss: 0.0070 - val_q7_loss: 0.0081 - val_q8_loss: 9.3492e-04\n",
      "Epoch 109/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.1254 - q0_loss: 0.0096 - q1_loss: 0.0049 - q2_loss: 0.0279 - q3_loss: 0.0157 - q4_loss: 0.0165 - q5_loss: 0.0214 - q6_loss: 0.0196 - q7_loss: 0.0077 - q8_loss: 0.0013 - val_loss: 0.0997 - val_q0_loss: 0.0085 - val_q1_loss: 0.0035 - val_q2_loss: 0.0192 - val_q3_loss: 0.0205 - val_q4_loss: 0.0112 - val_q5_loss: 0.0119 - val_q6_loss: 0.0127 - val_q7_loss: 0.0078 - val_q8_loss: 0.0011\n",
      "Epoch 110/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.1337 - q0_loss: 0.0095 - q1_loss: 0.0046 - q2_loss: 0.0293 - q3_loss: 0.0234 - q4_loss: 0.0251 - q5_loss: 0.0180 - q6_loss: 0.0151 - q7_loss: 0.0071 - q8_loss: 9.7504e-04 - val_loss: 0.1190 - val_q0_loss: 0.0087 - val_q1_loss: 0.0027 - val_q2_loss: 0.0171 - val_q3_loss: 0.0093 - val_q4_loss: 0.0170 - val_q5_loss: 0.0272 - val_q6_loss: 0.0235 - val_q7_loss: 0.0090 - val_q8_loss: 0.0015\n",
      "Epoch 111/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.1255 - q0_loss: 0.0097 - q1_loss: 0.0045 - q2_loss: 0.0262 - q3_loss: 0.0120 - q4_loss: 0.0197 - q5_loss: 0.0245 - q6_loss: 0.0208 - q7_loss: 0.0080 - q8_loss: 0.0012 - val_loss: 0.0899 - val_q0_loss: 0.0087 - val_q1_loss: 0.0032 - val_q2_loss: 0.0150 - val_q3_loss: 0.0084 - val_q4_loss: 0.0084 - val_q5_loss: 0.0172 - val_q6_loss: 0.0164 - val_q7_loss: 0.0089 - val_q8_loss: 0.0013\n",
      "Epoch 112/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.1009 - q0_loss: 0.0096 - q1_loss: 0.0042 - q2_loss: 0.0252 - q3_loss: 0.0099 - q4_loss: 0.0127 - q5_loss: 0.0164 - q6_loss: 0.0136 - q7_loss: 0.0080 - q8_loss: 0.0011 - val_loss: 0.1036 - val_q0_loss: 0.0085 - val_q1_loss: 0.0026 - val_q2_loss: 0.0187 - val_q3_loss: 0.0158 - val_q4_loss: 0.0055 - val_q5_loss: 0.0201 - val_q6_loss: 0.0191 - val_q7_loss: 0.0081 - val_q8_loss: 0.0013\n",
      "Epoch 113/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0926 - q0_loss: 0.0096 - q1_loss: 0.0041 - q2_loss: 0.0274 - q3_loss: 0.0117 - q4_loss: 0.0074 - q5_loss: 0.0133 - q6_loss: 0.0115 - q7_loss: 0.0078 - q8_loss: 0.0010 - val_loss: 0.1504 - val_q0_loss: 0.0084 - val_q1_loss: 0.0155 - val_q2_loss: 0.0246 - val_q3_loss: 0.0230 - val_q4_loss: 0.0061 - val_q5_loss: 0.0333 - val_q6_loss: 0.0287 - val_q7_loss: 0.0079 - val_q8_loss: 0.0016\n",
      "Epoch 114/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1425 - q0_loss: 0.0093 - q1_loss: 0.0042 - q2_loss: 0.0352 - q3_loss: 0.0279 - q4_loss: 0.0177 - q5_loss: 0.0200 - q6_loss: 0.0189 - q7_loss: 0.0079 - q8_loss: 0.0011 - val_loss: 0.0860 - val_q0_loss: 0.0087 - val_q1_loss: 0.0036 - val_q2_loss: 0.0192 - val_q3_loss: 0.0165 - val_q4_loss: 0.0116 - val_q5_loss: 0.0050 - val_q6_loss: 0.0068 - val_q7_loss: 0.0088 - val_q8_loss: 9.5632e-04\n",
      "Epoch 115/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1203 - q0_loss: 0.0097 - q1_loss: 0.0043 - q2_loss: 0.0334 - q3_loss: 0.0264 - q4_loss: 0.0162 - q5_loss: 0.0101 - q6_loss: 0.0098 - q7_loss: 0.0097 - q8_loss: 9.5977e-04 - val_loss: 0.1178 - val_q0_loss: 0.0083 - val_q1_loss: 0.0029 - val_q2_loss: 0.0241 - val_q3_loss: 0.0255 - val_q4_loss: 0.0084 - val_q5_loss: 0.0196 - val_q6_loss: 0.0185 - val_q7_loss: 0.0073 - val_q8_loss: 0.0013\n",
      "Epoch 116/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1651 - q0_loss: 0.0093 - q1_loss: 0.0035 - q2_loss: 0.0342 - q3_loss: 0.0358 - q4_loss: 0.0312 - q5_loss: 0.0219 - q6_loss: 0.0176 - q7_loss: 0.0083 - q8_loss: 0.0011 - val_loss: 0.1212 - val_q0_loss: 0.0081 - val_q1_loss: 0.0032 - val_q2_loss: 0.0235 - val_q3_loss: 0.0334 - val_q4_loss: 0.0316 - val_q5_loss: 0.0102 - val_q6_loss: 0.0034 - val_q7_loss: 0.0069 - val_q8_loss: 7.6208e-04\n",
      "Epoch 117/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1118 - q0_loss: 0.0095 - q1_loss: 0.0039 - q2_loss: 0.0296 - q3_loss: 0.0195 - q4_loss: 0.0142 - q5_loss: 0.0141 - q6_loss: 0.0122 - q7_loss: 0.0076 - q8_loss: 0.0010 - val_loss: 0.0842 - val_q0_loss: 0.0088 - val_q1_loss: 0.0033 - val_q2_loss: 0.0167 - val_q3_loss: 0.0114 - val_q4_loss: 0.0133 - val_q5_loss: 0.0087 - val_q6_loss: 0.0089 - val_q7_loss: 0.0095 - val_q8_loss: 0.0011\n",
      "Epoch 118/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1032 - q0_loss: 0.0094 - q1_loss: 0.0037 - q2_loss: 0.0283 - q3_loss: 0.0189 - q4_loss: 0.0139 - q5_loss: 0.0108 - q6_loss: 0.0094 - q7_loss: 0.0082 - q8_loss: 9.7469e-04 - val_loss: 0.1056 - val_q0_loss: 0.0087 - val_q1_loss: 0.0023 - val_q2_loss: 0.0159 - val_q3_loss: 0.0089 - val_q4_loss: 0.0195 - val_q5_loss: 0.0199 - val_q6_loss: 0.0169 - val_q7_loss: 0.0092 - val_q8_loss: 0.0013\n",
      "Epoch 119/300\n",
      "269/269 [==============================] - 0s 243us/sample - loss: 0.1332 - q0_loss: 0.0095 - q1_loss: 0.0044 - q2_loss: 0.0338 - q3_loss: 0.0219 - q4_loss: 0.0110 - q5_loss: 0.0199 - q6_loss: 0.0196 - q7_loss: 0.0084 - q8_loss: 9.9619e-04 - val_loss: 0.1066 - val_q0_loss: 0.0084 - val_q1_loss: 0.0024 - val_q2_loss: 0.0213 - val_q3_loss: 0.0214 - val_q4_loss: 0.0081 - val_q5_loss: 0.0145 - val_q6_loss: 0.0136 - val_q7_loss: 0.0086 - val_q8_loss: 0.0012\n",
      "Epoch 120/300\n",
      "269/269 [==============================] - 0s 225us/sample - loss: 0.1305 - q0_loss: 0.0094 - q1_loss: 0.0043 - q2_loss: 0.0304 - q3_loss: 0.0181 - q4_loss: 0.0165 - q5_loss: 0.0257 - q6_loss: 0.0238 - q7_loss: 0.0084 - q8_loss: 0.0021 - val_loss: 0.0929 - val_q0_loss: 0.0086 - val_q1_loss: 0.0035 - val_q2_loss: 0.0201 - val_q3_loss: 0.0179 - val_q4_loss: 0.0110 - val_q5_loss: 0.0064 - val_q6_loss: 0.0067 - val_q7_loss: 0.0088 - val_q8_loss: 8.8145e-04\n",
      "Epoch 121/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.1536 - q0_loss: 0.0096 - q1_loss: 0.0070 - q2_loss: 0.0316 - q3_loss: 0.0128 - q4_loss: 0.0228 - q5_loss: 0.0336 - q6_loss: 0.0299 - q7_loss: 0.0079 - q8_loss: 0.0025 - val_loss: 0.1391 - val_q0_loss: 0.0085 - val_q1_loss: 0.0082 - val_q2_loss: 0.0213 - val_q3_loss: 0.0166 - val_q4_loss: 0.0153 - val_q5_loss: 0.0323 - val_q6_loss: 0.0271 - val_q7_loss: 0.0083 - val_q8_loss: 0.0016\n",
      "Epoch 122/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1327 - q0_loss: 0.0094 - q1_loss: 0.0044 - q2_loss: 0.0331 - q3_loss: 0.0206 - q4_loss: 0.0111 - q5_loss: 0.0237 - q6_loss: 0.0223 - q7_loss: 0.0082 - q8_loss: 0.0013 - val_loss: 0.0825 - val_q0_loss: 0.0086 - val_q1_loss: 0.0033 - val_q2_loss: 0.0145 - val_q3_loss: 0.0065 - val_q4_loss: 0.0080 - val_q5_loss: 0.0147 - val_q6_loss: 0.0141 - val_q7_loss: 0.0091 - val_q8_loss: 0.0012\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1196 - q0_loss: 0.0095 - q1_loss: 0.0041 - q2_loss: 0.0306 - q3_loss: 0.0221 - q4_loss: 0.0120 - q5_loss: 0.0172 - q6_loss: 0.0159 - q7_loss: 0.0082 - q8_loss: 0.0011 - val_loss: 0.0995 - val_q0_loss: 0.0083 - val_q1_loss: 0.0039 - val_q2_loss: 0.0182 - val_q3_loss: 0.0182 - val_q4_loss: 0.0219 - val_q5_loss: 0.0069 - val_q6_loss: 0.0069 - val_q7_loss: 0.0078 - val_q8_loss: 8.9042e-04\n",
      "Epoch 124/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.1385 - q0_loss: 0.0096 - q1_loss: 0.0045 - q2_loss: 0.0321 - q3_loss: 0.0263 - q4_loss: 0.0233 - q5_loss: 0.0206 - q6_loss: 0.0168 - q7_loss: 0.0079 - q8_loss: 0.0011 - val_loss: 0.1503 - val_q0_loss: 0.0089 - val_q1_loss: 0.0032 - val_q2_loss: 0.0231 - val_q3_loss: 0.0322 - val_q4_loss: 0.0246 - val_q5_loss: 0.0212 - val_q6_loss: 0.0187 - val_q7_loss: 0.0102 - val_q8_loss: 0.0014\n",
      "Epoch 125/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.1346 - q0_loss: 0.0094 - q1_loss: 0.0043 - q2_loss: 0.0286 - q3_loss: 0.0213 - q4_loss: 0.0229 - q5_loss: 0.0210 - q6_loss: 0.0174 - q7_loss: 0.0076 - q8_loss: 0.0011 - val_loss: 0.1386 - val_q0_loss: 0.0082 - val_q1_loss: 0.0086 - val_q2_loss: 0.0243 - val_q3_loss: 0.0269 - val_q4_loss: 0.0063 - val_q5_loss: 0.0286 - val_q6_loss: 0.0257 - val_q7_loss: 0.0083 - val_q8_loss: 0.0015\n",
      "Epoch 126/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.1544 - q0_loss: 0.0094 - q1_loss: 0.0065 - q2_loss: 0.0313 - q3_loss: 0.0176 - q4_loss: 0.0168 - q5_loss: 0.0333 - q6_loss: 0.0293 - q7_loss: 0.0074 - q8_loss: 0.0018 - val_loss: 0.1235 - val_q0_loss: 0.0084 - val_q1_loss: 0.0045 - val_q2_loss: 0.0178 - val_q3_loss: 0.0189 - val_q4_loss: 0.0262 - val_q5_loss: 0.0248 - val_q6_loss: 0.0123 - val_q7_loss: 0.0082 - val_q8_loss: 6.9321e-04\n",
      "Epoch 127/300\n",
      "269/269 [==============================] - 0s 216us/sample - loss: 0.1155 - q0_loss: 0.0094 - q1_loss: 0.0044 - q2_loss: 0.0256 - q3_loss: 0.0139 - q4_loss: 0.0172 - q5_loss: 0.0202 - q6_loss: 0.0157 - q7_loss: 0.0079 - q8_loss: 0.0011 - val_loss: 0.1234 - val_q0_loss: 0.0084 - val_q1_loss: 0.0041 - val_q2_loss: 0.0179 - val_q3_loss: 0.0146 - val_q4_loss: 0.0151 - val_q5_loss: 0.0271 - val_q6_loss: 0.0222 - val_q7_loss: 0.0083 - val_q8_loss: 0.0014\n",
      "Epoch 128/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.1349 - q0_loss: 0.0093 - q1_loss: 0.0044 - q2_loss: 0.0276 - q3_loss: 0.0138 - q4_loss: 0.0187 - q5_loss: 0.0299 - q6_loss: 0.0251 - q7_loss: 0.0074 - q8_loss: 0.0017 - val_loss: 0.1601 - val_q0_loss: 0.0090 - val_q1_loss: 0.0032 - val_q2_loss: 0.0218 - val_q3_loss: 0.0352 - val_q4_loss: 0.0301 - val_q5_loss: 0.0260 - val_q6_loss: 0.0226 - val_q7_loss: 0.0107 - val_q8_loss: 0.0015\n",
      "Epoch 129/300\n",
      "269/269 [==============================] - 0s 223us/sample - loss: 0.1437 - q0_loss: 0.0095 - q1_loss: 0.0044 - q2_loss: 0.0302 - q3_loss: 0.0249 - q4_loss: 0.0236 - q5_loss: 0.0215 - q6_loss: 0.0189 - q7_loss: 0.0084 - q8_loss: 0.0012 - val_loss: 0.1757 - val_q0_loss: 0.0077 - val_q1_loss: 0.0029 - val_q2_loss: 0.0268 - val_q3_loss: 0.0423 - val_q4_loss: 0.0460 - val_q5_loss: 0.0175 - val_q6_loss: 0.0153 - val_q7_loss: 0.0089 - val_q8_loss: 9.6162e-04\n",
      "Epoch 130/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.1390 - q0_loss: 0.0093 - q1_loss: 0.0040 - q2_loss: 0.0309 - q3_loss: 0.0251 - q4_loss: 0.0220 - q5_loss: 0.0190 - q6_loss: 0.0171 - q7_loss: 0.0086 - q8_loss: 0.0012 - val_loss: 0.1317 - val_q0_loss: 0.0086 - val_q1_loss: 0.0055 - val_q2_loss: 0.0201 - val_q3_loss: 0.0080 - val_q4_loss: 0.0180 - val_q5_loss: 0.0310 - val_q6_loss: 0.0250 - val_q7_loss: 0.0090 - val_q8_loss: 0.0015\n",
      "Epoch 131/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1256 - q0_loss: 0.0095 - q1_loss: 0.0046 - q2_loss: 0.0272 - q3_loss: 0.0067 - q4_loss: 0.0156 - q5_loss: 0.0287 - q6_loss: 0.0250 - q7_loss: 0.0079 - q8_loss: 0.0016 - val_loss: 0.1236 - val_q0_loss: 0.0086 - val_q1_loss: 0.0022 - val_q2_loss: 0.0158 - val_q3_loss: 0.0038 - val_q4_loss: 0.0236 - val_q5_loss: 0.0325 - val_q6_loss: 0.0276 - val_q7_loss: 0.0093 - val_q8_loss: 0.0017\n",
      "Epoch 132/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1172 - q0_loss: 0.0094 - q1_loss: 0.0038 - q2_loss: 0.0268 - q3_loss: 0.0076 - q4_loss: 0.0146 - q5_loss: 0.0236 - q6_loss: 0.0198 - q7_loss: 0.0080 - q8_loss: 0.0013 - val_loss: 0.1816 - val_q0_loss: 0.0086 - val_q1_loss: 0.0048 - val_q2_loss: 0.0285 - val_q3_loss: 0.0147 - val_q4_loss: 0.0169 - val_q5_loss: 0.0409 - val_q6_loss: 0.0394 - val_q7_loss: 0.0093 - val_q8_loss: 0.0014\n",
      "Epoch 133/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1373 - q0_loss: 0.0095 - q1_loss: 0.0057 - q2_loss: 0.0337 - q3_loss: 0.0173 - q4_loss: 0.0114 - q5_loss: 0.0266 - q6_loss: 0.0237 - q7_loss: 0.0079 - q8_loss: 0.0012 - val_loss: 0.1289 - val_q0_loss: 0.0081 - val_q1_loss: 0.0033 - val_q2_loss: 0.0238 - val_q3_loss: 0.0267 - val_q4_loss: 0.0141 - val_q5_loss: 0.0224 - val_q6_loss: 0.0215 - val_q7_loss: 0.0069 - val_q8_loss: 0.0014\n",
      "Epoch 134/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1237 - q0_loss: 0.0092 - q1_loss: 0.0038 - q2_loss: 0.0316 - q3_loss: 0.0246 - q4_loss: 0.0112 - q5_loss: 0.0163 - q6_loss: 0.0165 - q7_loss: 0.0078 - q8_loss: 0.0012 - val_loss: 0.1248 - val_q0_loss: 0.0089 - val_q1_loss: 0.0047 - val_q2_loss: 0.0359 - val_q3_loss: 0.0362 - val_q4_loss: 0.0059 - val_q5_loss: 0.0144 - val_q6_loss: 0.0086 - val_q7_loss: 0.0104 - val_q8_loss: 8.7717e-04\n",
      "Epoch 135/300\n",
      "269/269 [==============================] - 0s 192us/sample - loss: 0.1299 - q0_loss: 0.0094 - q1_loss: 0.0043 - q2_loss: 0.0345 - q3_loss: 0.0331 - q4_loss: 0.0183 - q5_loss: 0.0112 - q6_loss: 0.0110 - q7_loss: 0.0081 - q8_loss: 0.0010 - val_loss: 0.0990 - val_q0_loss: 0.0082 - val_q1_loss: 0.0028 - val_q2_loss: 0.0202 - val_q3_loss: 0.0217 - val_q4_loss: 0.0150 - val_q5_loss: 0.0101 - val_q6_loss: 0.0127 - val_q7_loss: 0.0074 - val_q8_loss: 0.0011\n",
      "Epoch 136/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1101 - q0_loss: 0.0091 - q1_loss: 0.0042 - q2_loss: 0.0287 - q3_loss: 0.0202 - q4_loss: 0.0135 - q5_loss: 0.0130 - q6_loss: 0.0121 - q7_loss: 0.0071 - q8_loss: 0.0011 - val_loss: 0.0764 - val_q0_loss: 0.0083 - val_q1_loss: 0.0033 - val_q2_loss: 0.0157 - val_q3_loss: 0.0138 - val_q4_loss: 0.0095 - val_q5_loss: 0.0064 - val_q6_loss: 0.0072 - val_q7_loss: 0.0082 - val_q8_loss: 0.0010\n",
      "Epoch 137/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1228 - q0_loss: 0.0093 - q1_loss: 0.0039 - q2_loss: 0.0309 - q3_loss: 0.0239 - q4_loss: 0.0142 - q5_loss: 0.0173 - q6_loss: 0.0157 - q7_loss: 0.0083 - q8_loss: 0.0011 - val_loss: 0.0693 - val_q0_loss: 0.0086 - val_q1_loss: 0.0039 - val_q2_loss: 0.0171 - val_q3_loss: 0.0086 - val_q4_loss: 0.0052 - val_q5_loss: 0.0050 - val_q6_loss: 0.0043 - val_q7_loss: 0.0093 - val_q8_loss: 8.9830e-04\n",
      "Epoch 138/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1194 - q0_loss: 0.0093 - q1_loss: 0.0057 - q2_loss: 0.0335 - q3_loss: 0.0210 - q4_loss: 0.0086 - q5_loss: 0.0164 - q6_loss: 0.0151 - q7_loss: 0.0085 - q8_loss: 0.0011 - val_loss: 0.1099 - val_q0_loss: 0.0081 - val_q1_loss: 0.0028 - val_q2_loss: 0.0207 - val_q3_loss: 0.0252 - val_q4_loss: 0.0143 - val_q5_loss: 0.0140 - val_q6_loss: 0.0132 - val_q7_loss: 0.0072 - val_q8_loss: 0.0011\n",
      "Epoch 139/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1075 - q0_loss: 0.0092 - q1_loss: 0.0039 - q2_loss: 0.0260 - q3_loss: 0.0172 - q4_loss: 0.0158 - q5_loss: 0.0149 - q6_loss: 0.0125 - q7_loss: 0.0075 - q8_loss: 0.0011 - val_loss: 0.1041 - val_q0_loss: 0.0085 - val_q1_loss: 0.0031 - val_q2_loss: 0.0231 - val_q3_loss: 0.0170 - val_q4_loss: 0.0092 - val_q5_loss: 0.0143 - val_q6_loss: 0.0125 - val_q7_loss: 0.0090 - val_q8_loss: 0.0012\n",
      "Epoch 140/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1163 - q0_loss: 0.0094 - q1_loss: 0.0045 - q2_loss: 0.0278 - q3_loss: 0.0122 - q4_loss: 0.0154 - q5_loss: 0.0204 - q6_loss: 0.0164 - q7_loss: 0.0077 - q8_loss: 0.0012 - val_loss: 0.1782 - val_q0_loss: 0.0084 - val_q1_loss: 0.0048 - val_q2_loss: 0.0236 - val_q3_loss: 0.0091 - val_q4_loss: 0.0209 - val_q5_loss: 0.0461 - val_q6_loss: 0.0476 - val_q7_loss: 0.0088 - val_q8_loss: 7.3076e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0968 - q0_loss: 0.0094 - q1_loss: 0.0044 - q2_loss: 0.0265 - q3_loss: 0.0090 - q4_loss: 0.0101 - q5_loss: 0.0145 - q6_loss: 0.0134 - q7_loss: 0.0078 - q8_loss: 0.0013 - val_loss: 0.0963 - val_q0_loss: 0.0085 - val_q1_loss: 0.0030 - val_q2_loss: 0.0147 - val_q3_loss: 0.0115 - val_q4_loss: 0.0125 - val_q5_loss: 0.0162 - val_q6_loss: 0.0142 - val_q7_loss: 0.0092 - val_q8_loss: 0.0013\n",
      "Epoch 142/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0993 - q0_loss: 0.0093 - q1_loss: 0.0049 - q2_loss: 0.0241 - q3_loss: 0.0063 - q4_loss: 0.0143 - q5_loss: 0.0195 - q6_loss: 0.0165 - q7_loss: 0.0080 - q8_loss: 0.0011 - val_loss: 0.1365 - val_q0_loss: 0.0085 - val_q1_loss: 0.0061 - val_q2_loss: 0.0171 - val_q3_loss: 0.0071 - val_q4_loss: 0.0241 - val_q5_loss: 0.0340 - val_q6_loss: 0.0273 - val_q7_loss: 0.0090 - val_q8_loss: 0.0017\n",
      "Epoch 143/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1700 - q0_loss: 0.0094 - q1_loss: 0.0123 - q2_loss: 0.0267 - q3_loss: 0.0062 - q4_loss: 0.0305 - q5_loss: 0.0382 - q6_loss: 0.0309 - q7_loss: 0.0079 - q8_loss: 0.0015 - val_loss: 0.2393 - val_q0_loss: 0.0084 - val_q1_loss: 0.0058 - val_q2_loss: 0.0272 - val_q3_loss: 0.0031 - val_q4_loss: 0.0342 - val_q5_loss: 0.0725 - val_q6_loss: 0.0749 - val_q7_loss: 0.0087 - val_q8_loss: 0.0036\n",
      "Epoch 144/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1747 - q0_loss: 0.0094 - q1_loss: 0.0099 - q2_loss: 0.0278 - q3_loss: 0.0047 - q4_loss: 0.0273 - q5_loss: 0.0422 - q6_loss: 0.0370 - q7_loss: 0.0078 - q8_loss: 0.0024 - val_loss: 0.1137 - val_q0_loss: 0.0084 - val_q1_loss: 0.0032 - val_q2_loss: 0.0161 - val_q3_loss: 0.0056 - val_q4_loss: 0.0119 - val_q5_loss: 0.0284 - val_q6_loss: 0.0240 - val_q7_loss: 0.0087 - val_q8_loss: 0.0015\n",
      "Epoch 145/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1031 - q0_loss: 0.0093 - q1_loss: 0.0051 - q2_loss: 0.0258 - q3_loss: 0.0076 - q4_loss: 0.0126 - q5_loss: 0.0178 - q6_loss: 0.0155 - q7_loss: 0.0076 - q8_loss: 0.0011 - val_loss: 0.1119 - val_q0_loss: 0.0085 - val_q1_loss: 0.0038 - val_q2_loss: 0.0149 - val_q3_loss: 0.0095 - val_q4_loss: 0.0142 - val_q5_loss: 0.0252 - val_q6_loss: 0.0218 - val_q7_loss: 0.0092 - val_q8_loss: 0.0015\n",
      "Epoch 146/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.1006 - q0_loss: 0.0092 - q1_loss: 0.0054 - q2_loss: 0.0265 - q3_loss: 0.0143 - q4_loss: 0.0127 - q5_loss: 0.0113 - q6_loss: 0.0108 - q7_loss: 0.0074 - q8_loss: 0.0010 - val_loss: 0.0977 - val_q0_loss: 0.0086 - val_q1_loss: 0.0056 - val_q2_loss: 0.0273 - val_q3_loss: 0.0253 - val_q4_loss: 0.0047 - val_q5_loss: 0.0056 - val_q6_loss: 0.0044 - val_q7_loss: 0.0097 - val_q8_loss: 9.0298e-04\n",
      "Epoch 147/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.0963 - q0_loss: 0.0092 - q1_loss: 0.0053 - q2_loss: 0.0281 - q3_loss: 0.0164 - q4_loss: 0.0065 - q5_loss: 0.0124 - q6_loss: 0.0111 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.0849 - val_q0_loss: 0.0082 - val_q1_loss: 0.0041 - val_q2_loss: 0.0165 - val_q3_loss: 0.0124 - val_q4_loss: 0.0057 - val_q5_loss: 0.0128 - val_q6_loss: 0.0129 - val_q7_loss: 0.0080 - val_q8_loss: 0.0012\n",
      "Epoch 148/300\n",
      "269/269 [==============================] - 0s 219us/sample - loss: 0.0992 - q0_loss: 0.0093 - q1_loss: 0.0054 - q2_loss: 0.0276 - q3_loss: 0.0142 - q4_loss: 0.0116 - q5_loss: 0.0116 - q6_loss: 0.0099 - q7_loss: 0.0080 - q8_loss: 0.0010 - val_loss: 0.1021 - val_q0_loss: 0.0081 - val_q1_loss: 0.0050 - val_q2_loss: 0.0151 - val_q3_loss: 0.0157 - val_q4_loss: 0.0182 - val_q5_loss: 0.0189 - val_q6_loss: 0.0112 - val_q7_loss: 0.0076 - val_q8_loss: 7.4395e-04\n",
      "Epoch 149/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.1108 - q0_loss: 0.0092 - q1_loss: 0.0048 - q2_loss: 0.0258 - q3_loss: 0.0114 - q4_loss: 0.0176 - q5_loss: 0.0198 - q6_loss: 0.0159 - q7_loss: 0.0073 - q8_loss: 0.0012 - val_loss: 0.1086 - val_q0_loss: 0.0081 - val_q1_loss: 0.0042 - val_q2_loss: 0.0184 - val_q3_loss: 0.0169 - val_q4_loss: 0.0113 - val_q5_loss: 0.0190 - val_q6_loss: 0.0167 - val_q7_loss: 0.0076 - val_q8_loss: 9.6632e-04\n",
      "Epoch 150/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1146 - q0_loss: 0.0091 - q1_loss: 0.0048 - q2_loss: 0.0259 - q3_loss: 0.0136 - q4_loss: 0.0153 - q5_loss: 0.0198 - q6_loss: 0.0174 - q7_loss: 0.0070 - q8_loss: 0.0010 - val_loss: 0.0759 - val_q0_loss: 0.0084 - val_q1_loss: 0.0046 - val_q2_loss: 0.0187 - val_q3_loss: 0.0131 - val_q4_loss: 0.0084 - val_q5_loss: 0.0027 - val_q6_loss: 0.0035 - val_q7_loss: 0.0088 - val_q8_loss: 9.0995e-04\n",
      "Epoch 151/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1191 - q0_loss: 0.0092 - q1_loss: 0.0053 - q2_loss: 0.0263 - q3_loss: 0.0115 - q4_loss: 0.0172 - q5_loss: 0.0218 - q6_loss: 0.0181 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.0751 - val_q0_loss: 0.0082 - val_q1_loss: 0.0037 - val_q2_loss: 0.0144 - val_q3_loss: 0.0099 - val_q4_loss: 0.0038 - val_q5_loss: 0.0123 - val_q6_loss: 0.0115 - val_q7_loss: 0.0081 - val_q8_loss: 0.0011\n",
      "Epoch 152/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0794 - q0_loss: 0.0092 - q1_loss: 0.0049 - q2_loss: 0.0239 - q3_loss: 0.0084 - q4_loss: 0.0072 - q5_loss: 0.0089 - q6_loss: 0.0083 - q7_loss: 0.0073 - q8_loss: 9.9061e-04 - val_loss: 0.0744 - val_q0_loss: 0.0081 - val_q1_loss: 0.0041 - val_q2_loss: 0.0129 - val_q3_loss: 0.0108 - val_q4_loss: 0.0135 - val_q5_loss: 0.0062 - val_q6_loss: 0.0053 - val_q7_loss: 0.0078 - val_q8_loss: 8.7929e-04\n",
      "Epoch 153/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0869 - q0_loss: 0.0092 - q1_loss: 0.0047 - q2_loss: 0.0237 - q3_loss: 0.0066 - q4_loss: 0.0105 - q5_loss: 0.0131 - q6_loss: 0.0116 - q7_loss: 0.0072 - q8_loss: 9.9779e-04 - val_loss: 0.1104 - val_q0_loss: 0.0084 - val_q1_loss: 0.0048 - val_q2_loss: 0.0276 - val_q3_loss: 0.0130 - val_q4_loss: 0.0083 - val_q5_loss: 0.0208 - val_q6_loss: 0.0178 - val_q7_loss: 0.0091 - val_q8_loss: 7.4936e-04\n",
      "Epoch 154/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1022 - q0_loss: 0.0092 - q1_loss: 0.0045 - q2_loss: 0.0271 - q3_loss: 0.0125 - q4_loss: 0.0138 - q5_loss: 0.0174 - q6_loss: 0.0157 - q7_loss: 0.0069 - q8_loss: 9.7183e-04 - val_loss: 0.0760 - val_q0_loss: 0.0083 - val_q1_loss: 0.0036 - val_q2_loss: 0.0164 - val_q3_loss: 0.0065 - val_q4_loss: 0.0062 - val_q5_loss: 0.0097 - val_q6_loss: 0.0092 - val_q7_loss: 0.0088 - val_q8_loss: 0.0011\n",
      "Epoch 155/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.0960 - q0_loss: 0.0091 - q1_loss: 0.0041 - q2_loss: 0.0253 - q3_loss: 0.0086 - q4_loss: 0.0118 - q5_loss: 0.0163 - q6_loss: 0.0142 - q7_loss: 0.0073 - q8_loss: 0.0010 - val_loss: 0.1154 - val_q0_loss: 0.0085 - val_q1_loss: 0.0034 - val_q2_loss: 0.0219 - val_q3_loss: 0.0260 - val_q4_loss: 0.0183 - val_q5_loss: 0.0140 - val_q6_loss: 0.0124 - val_q7_loss: 0.0095 - val_q8_loss: 0.0012\n",
      "Epoch 156/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1004 - q0_loss: 0.0092 - q1_loss: 0.0042 - q2_loss: 0.0267 - q3_loss: 0.0172 - q4_loss: 0.0159 - q5_loss: 0.0112 - q6_loss: 0.0089 - q7_loss: 0.0076 - q8_loss: 9.5012e-04 - val_loss: 0.1451 - val_q0_loss: 0.0081 - val_q1_loss: 0.0134 - val_q2_loss: 0.0190 - val_q3_loss: 0.0115 - val_q4_loss: 0.0207 - val_q5_loss: 0.0368 - val_q6_loss: 0.0299 - val_q7_loss: 0.0078 - val_q8_loss: 0.0017\n",
      "Epoch 157/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1298 - q0_loss: 0.0092 - q1_loss: 0.0042 - q2_loss: 0.0250 - q3_loss: 0.0119 - q4_loss: 0.0211 - q5_loss: 0.0255 - q6_loss: 0.0219 - q7_loss: 0.0072 - q8_loss: 0.0020 - val_loss: 0.2756 - val_q0_loss: 0.0078 - val_q1_loss: 0.0049 - val_q2_loss: 0.0152 - val_q3_loss: 0.0209 - val_q4_loss: 0.0529 - val_q5_loss: 0.0824 - val_q6_loss: 0.0838 - val_q7_loss: 0.0071 - val_q8_loss: 0.0076\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1472 - q0_loss: 0.0089 - q1_loss: 0.0055 - q2_loss: 0.0231 - q3_loss: 0.0117 - q4_loss: 0.0238 - q5_loss: 0.0322 - q6_loss: 0.0289 - q7_loss: 0.0072 - q8_loss: 0.0027 - val_loss: 0.1156 - val_q0_loss: 0.0082 - val_q1_loss: 0.0028 - val_q2_loss: 0.0139 - val_q3_loss: 0.0074 - val_q4_loss: 0.0188 - val_q5_loss: 0.0271 - val_q6_loss: 0.0225 - val_q7_loss: 0.0086 - val_q8_loss: 0.0015\n",
      "Epoch 159/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.1068 - q0_loss: 0.0091 - q1_loss: 0.0039 - q2_loss: 0.0256 - q3_loss: 0.0094 - q4_loss: 0.0130 - q5_loss: 0.0203 - q6_loss: 0.0171 - q7_loss: 0.0074 - q8_loss: 0.0012 - val_loss: 0.0757 - val_q0_loss: 0.0081 - val_q1_loss: 0.0032 - val_q2_loss: 0.0129 - val_q3_loss: 0.0069 - val_q4_loss: 0.0085 - val_q5_loss: 0.0128 - val_q6_loss: 0.0108 - val_q7_loss: 0.0081 - val_q8_loss: 0.0011\n",
      "Epoch 160/300\n",
      "269/269 [==============================] - 0s 187us/sample - loss: 0.0959 - q0_loss: 0.0091 - q1_loss: 0.0038 - q2_loss: 0.0230 - q3_loss: 0.0074 - q4_loss: 0.0122 - q5_loss: 0.0167 - q6_loss: 0.0141 - q7_loss: 0.0072 - q8_loss: 0.0012 - val_loss: 0.1416 - val_q0_loss: 0.0081 - val_q1_loss: 0.0045 - val_q2_loss: 0.0190 - val_q3_loss: 0.0052 - val_q4_loss: 0.0229 - val_q5_loss: 0.0369 - val_q6_loss: 0.0287 - val_q7_loss: 0.0081 - val_q8_loss: 6.2409e-04\n",
      "Epoch 161/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1098 - q0_loss: 0.0090 - q1_loss: 0.0053 - q2_loss: 0.0247 - q3_loss: 0.0086 - q4_loss: 0.0121 - q5_loss: 0.0234 - q6_loss: 0.0202 - q7_loss: 0.0072 - q8_loss: 0.0013 - val_loss: 0.0911 - val_q0_loss: 0.0080 - val_q1_loss: 0.0034 - val_q2_loss: 0.0176 - val_q3_loss: 0.0103 - val_q4_loss: 0.0139 - val_q5_loss: 0.0143 - val_q6_loss: 0.0114 - val_q7_loss: 0.0077 - val_q8_loss: 9.4963e-04\n",
      "Epoch 162/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1170 - q0_loss: 0.0090 - q1_loss: 0.0040 - q2_loss: 0.0281 - q3_loss: 0.0129 - q4_loss: 0.0126 - q5_loss: 0.0222 - q6_loss: 0.0198 - q7_loss: 0.0068 - q8_loss: 0.0011 - val_loss: 0.1061 - val_q0_loss: 0.0079 - val_q1_loss: 0.0040 - val_q2_loss: 0.0191 - val_q3_loss: 0.0168 - val_q4_loss: 0.0037 - val_q5_loss: 0.0222 - val_q6_loss: 0.0208 - val_q7_loss: 0.0074 - val_q8_loss: 0.0014\n",
      "Epoch 163/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1070 - q0_loss: 0.0090 - q1_loss: 0.0038 - q2_loss: 0.0310 - q3_loss: 0.0189 - q4_loss: 0.0074 - q5_loss: 0.0140 - q6_loss: 0.0132 - q7_loss: 0.0080 - q8_loss: 0.0011 - val_loss: 0.1018 - val_q0_loss: 0.0081 - val_q1_loss: 0.0031 - val_q2_loss: 0.0206 - val_q3_loss: 0.0199 - val_q4_loss: 0.0055 - val_q5_loss: 0.0140 - val_q6_loss: 0.0133 - val_q7_loss: 0.0082 - val_q8_loss: 0.0012\n",
      "Epoch 164/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0993 - q0_loss: 0.0090 - q1_loss: 0.0037 - q2_loss: 0.0262 - q3_loss: 0.0125 - q4_loss: 0.0106 - q5_loss: 0.0162 - q6_loss: 0.0143 - q7_loss: 0.0070 - q8_loss: 0.0011 - val_loss: 0.1000 - val_q0_loss: 0.0079 - val_q1_loss: 0.0027 - val_q2_loss: 0.0176 - val_q3_loss: 0.0140 - val_q4_loss: 0.0086 - val_q5_loss: 0.0190 - val_q6_loss: 0.0183 - val_q7_loss: 0.0077 - val_q8_loss: 0.0014\n",
      "Epoch 165/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1029 - q0_loss: 0.0089 - q1_loss: 0.0037 - q2_loss: 0.0275 - q3_loss: 0.0179 - q4_loss: 0.0123 - q5_loss: 0.0141 - q6_loss: 0.0120 - q7_loss: 0.0073 - q8_loss: 0.0011 - val_loss: 0.0697 - val_q0_loss: 0.0082 - val_q1_loss: 0.0033 - val_q2_loss: 0.0152 - val_q3_loss: 0.0081 - val_q4_loss: 0.0073 - val_q5_loss: 0.0063 - val_q6_loss: 0.0073 - val_q7_loss: 0.0088 - val_q8_loss: 0.0011\n",
      "Epoch 166/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1356 - q0_loss: 0.0086 - q1_loss: 0.0040 - q2_loss: 0.0294 - q3_loss: 0.0253 - q4_loss: 0.0191 - q5_loss: 0.0166 - q6_loss: 0.0154 - q7_loss: 0.0138 - q8_loss: 0.0013 - val_loss: 0.1098 - val_q0_loss: 0.0077 - val_q1_loss: 0.0043 - val_q2_loss: 0.0206 - val_q3_loss: 0.0226 - val_q4_loss: 0.0068 - val_q5_loss: 0.0189 - val_q6_loss: 0.0180 - val_q7_loss: 0.0069 - val_q8_loss: 0.0013\n",
      "Epoch 167/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1141 - q0_loss: 0.0090 - q1_loss: 0.0046 - q2_loss: 0.0264 - q3_loss: 0.0123 - q4_loss: 0.0144 - q5_loss: 0.0247 - q6_loss: 0.0223 - q7_loss: 0.0071 - q8_loss: 0.0016 - val_loss: 0.1352 - val_q0_loss: 0.0081 - val_q1_loss: 0.0045 - val_q2_loss: 0.0226 - val_q3_loss: 0.0042 - val_q4_loss: 0.0129 - val_q5_loss: 0.0375 - val_q6_loss: 0.0327 - val_q7_loss: 0.0086 - val_q8_loss: 6.1782e-04\n",
      "Epoch 168/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.2030 - q0_loss: 0.0089 - q1_loss: 0.0178 - q2_loss: 0.0299 - q3_loss: 0.0092 - q4_loss: 0.0306 - q5_loss: 0.0494 - q6_loss: 0.0429 - q7_loss: 0.0072 - q8_loss: 0.0028 - val_loss: 0.2460 - val_q0_loss: 0.0081 - val_q1_loss: 0.0362 - val_q2_loss: 0.0194 - val_q3_loss: 0.0105 - val_q4_loss: 0.0518 - val_q5_loss: 0.0617 - val_q6_loss: 0.0487 - val_q7_loss: 0.0088 - val_q8_loss: 0.0024\n",
      "Epoch 169/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1923 - q0_loss: 0.0089 - q1_loss: 0.0112 - q2_loss: 0.0263 - q3_loss: 0.0109 - q4_loss: 0.0349 - q5_loss: 0.0481 - q6_loss: 0.0404 - q7_loss: 0.0073 - q8_loss: 0.0022 - val_loss: 0.1579 - val_q0_loss: 0.0078 - val_q1_loss: 0.0107 - val_q2_loss: 0.0212 - val_q3_loss: 0.0160 - val_q4_loss: 0.0137 - val_q5_loss: 0.0405 - val_q6_loss: 0.0346 - val_q7_loss: 0.0076 - val_q8_loss: 0.0019\n",
      "Epoch 170/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.1441 - q0_loss: 0.0087 - q1_loss: 0.0048 - q2_loss: 0.0309 - q3_loss: 0.0226 - q4_loss: 0.0131 - q5_loss: 0.0284 - q6_loss: 0.0247 - q7_loss: 0.0083 - q8_loss: 0.0014 - val_loss: 0.1488 - val_q0_loss: 0.0083 - val_q1_loss: 0.0049 - val_q2_loss: 0.0285 - val_q3_loss: 0.0368 - val_q4_loss: 0.0143 - val_q5_loss: 0.0205 - val_q6_loss: 0.0184 - val_q7_loss: 0.0096 - val_q8_loss: 0.0013\n",
      "Epoch 171/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1510 - q0_loss: 0.0088 - q1_loss: 0.0059 - q2_loss: 0.0311 - q3_loss: 0.0237 - q4_loss: 0.0153 - q5_loss: 0.0305 - q6_loss: 0.0270 - q7_loss: 0.0074 - q8_loss: 0.0015 - val_loss: 0.0917 - val_q0_loss: 0.0079 - val_q1_loss: 0.0052 - val_q2_loss: 0.0155 - val_q3_loss: 0.0120 - val_q4_loss: 0.0184 - val_q5_loss: 0.0123 - val_q6_loss: 0.0090 - val_q7_loss: 0.0077 - val_q8_loss: 9.7032e-04\n",
      "Epoch 172/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1061 - q0_loss: 0.0089 - q1_loss: 0.0056 - q2_loss: 0.0231 - q3_loss: 0.0137 - q4_loss: 0.0142 - q5_loss: 0.0171 - q6_loss: 0.0161 - q7_loss: 0.0073 - q8_loss: 0.0012 - val_loss: 0.1208 - val_q0_loss: 0.0076 - val_q1_loss: 0.0053 - val_q2_loss: 0.0166 - val_q3_loss: 0.0219 - val_q4_loss: 0.0336 - val_q5_loss: 0.0168 - val_q6_loss: 0.0067 - val_q7_loss: 0.0068 - val_q8_loss: 7.8264e-04\n",
      "Epoch 173/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1147 - q0_loss: 0.0088 - q1_loss: 0.0056 - q2_loss: 0.0281 - q3_loss: 0.0159 - q4_loss: 0.0172 - q5_loss: 0.0173 - q6_loss: 0.0140 - q7_loss: 0.0072 - q8_loss: 0.0011 - val_loss: 0.1133 - val_q0_loss: 0.0077 - val_q1_loss: 0.0035 - val_q2_loss: 0.0201 - val_q3_loss: 0.0193 - val_q4_loss: 0.0057 - val_q5_loss: 0.0241 - val_q6_loss: 0.0229 - val_q7_loss: 0.0074 - val_q8_loss: 0.0015\n",
      "Epoch 174/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1185 - q0_loss: 0.0089 - q1_loss: 0.0054 - q2_loss: 0.0285 - q3_loss: 0.0138 - q4_loss: 0.0122 - q5_loss: 0.0217 - q6_loss: 0.0194 - q7_loss: 0.0068 - q8_loss: 0.0014 - val_loss: 0.1135 - val_q0_loss: 0.0077 - val_q1_loss: 0.0043 - val_q2_loss: 0.0213 - val_q3_loss: 0.0172 - val_q4_loss: 0.0092 - val_q5_loss: 0.0227 - val_q6_loss: 0.0197 - val_q7_loss: 0.0078 - val_q8_loss: 0.0012\n",
      "Epoch 175/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.1100 - q0_loss: 0.0087 - q1_loss: 0.0052 - q2_loss: 0.0272 - q3_loss: 0.0165 - q4_loss: 0.0061 - q5_loss: 0.0193 - q6_loss: 0.0178 - q7_loss: 0.0078 - q8_loss: 0.0012 - val_loss: 0.1178 - val_q0_loss: 0.0076 - val_q1_loss: 0.0029 - val_q2_loss: 0.0210 - val_q3_loss: 0.0215 - val_q4_loss: 0.0050 - val_q5_loss: 0.0284 - val_q6_loss: 0.0256 - val_q7_loss: 0.0070 - val_q8_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.1185 - q0_loss: 0.0088 - q1_loss: 0.0050 - q2_loss: 0.0270 - q3_loss: 0.0114 - q4_loss: 0.0117 - q5_loss: 0.0251 - q6_loss: 0.0225 - q7_loss: 0.0070 - q8_loss: 0.0012 - val_loss: 0.0779 - val_q0_loss: 0.0078 - val_q1_loss: 0.0042 - val_q2_loss: 0.0158 - val_q3_loss: 0.0109 - val_q4_loss: 0.0046 - val_q5_loss: 0.0104 - val_q6_loss: 0.0113 - val_q7_loss: 0.0079 - val_q8_loss: 0.0012\n",
      "Epoch 177/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1009 - q0_loss: 0.0088 - q1_loss: 0.0049 - q2_loss: 0.0251 - q3_loss: 0.0109 - q4_loss: 0.0088 - q5_loss: 0.0174 - q6_loss: 0.0157 - q7_loss: 0.0069 - q8_loss: 0.0012 - val_loss: 0.0846 - val_q0_loss: 0.0081 - val_q1_loss: 0.0052 - val_q2_loss: 0.0236 - val_q3_loss: 0.0149 - val_q4_loss: 0.0054 - val_q5_loss: 0.0099 - val_q6_loss: 0.0053 - val_q7_loss: 0.0091 - val_q8_loss: 9.1100e-04\n",
      "Epoch 178/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0911 - q0_loss: 0.0089 - q1_loss: 0.0051 - q2_loss: 0.0256 - q3_loss: 0.0106 - q4_loss: 0.0079 - q5_loss: 0.0136 - q6_loss: 0.0119 - q7_loss: 0.0072 - q8_loss: 0.0011 - val_loss: 0.0889 - val_q0_loss: 0.0077 - val_q1_loss: 0.0043 - val_q2_loss: 0.0149 - val_q3_loss: 0.0152 - val_q4_loss: 0.0162 - val_q5_loss: 0.0096 - val_q6_loss: 0.0085 - val_q7_loss: 0.0073 - val_q8_loss: 9.2619e-04\n",
      "Epoch 179/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.1040 - q0_loss: 0.0088 - q1_loss: 0.0048 - q2_loss: 0.0238 - q3_loss: 0.0110 - q4_loss: 0.0149 - q5_loss: 0.0177 - q6_loss: 0.0149 - q7_loss: 0.0070 - q8_loss: 0.0011 - val_loss: 0.0896 - val_q0_loss: 0.0078 - val_q1_loss: 0.0033 - val_q2_loss: 0.0147 - val_q3_loss: 0.0110 - val_q4_loss: 0.0096 - val_q5_loss: 0.0166 - val_q6_loss: 0.0154 - val_q7_loss: 0.0077 - val_q8_loss: 0.0013\n",
      "Epoch 180/300\n",
      "269/269 [==============================] - 0s 192us/sample - loss: 0.1081 - q0_loss: 0.0087 - q1_loss: 0.0044 - q2_loss: 0.0252 - q3_loss: 0.0144 - q4_loss: 0.0143 - q5_loss: 0.0185 - q6_loss: 0.0161 - q7_loss: 0.0070 - q8_loss: 0.0012 - val_loss: 0.0962 - val_q0_loss: 0.0079 - val_q1_loss: 0.0031 - val_q2_loss: 0.0126 - val_q3_loss: 0.0041 - val_q4_loss: 0.0156 - val_q5_loss: 0.0206 - val_q6_loss: 0.0180 - val_q7_loss: 0.0085 - val_q8_loss: 0.0014\n",
      "Epoch 181/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1116 - q0_loss: 0.0085 - q1_loss: 0.0041 - q2_loss: 0.0263 - q3_loss: 0.0212 - q4_loss: 0.0207 - q5_loss: 0.0116 - q6_loss: 0.0103 - q7_loss: 0.0082 - q8_loss: 0.0011 - val_loss: 0.0889 - val_q0_loss: 0.0075 - val_q1_loss: 0.0033 - val_q2_loss: 0.0171 - val_q3_loss: 0.0200 - val_q4_loss: 0.0170 - val_q5_loss: 0.0074 - val_q6_loss: 0.0092 - val_q7_loss: 0.0068 - val_q8_loss: 0.0010\n",
      "Epoch 182/300\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 0.1035 - q0_loss: 0.0088 - q1_loss: 0.0044 - q2_loss: 0.0263 - q3_loss: 0.0192 - q4_loss: 0.0116 - q5_loss: 0.0121 - q6_loss: 0.0110 - q7_loss: 0.0071 - q8_loss: 0.0010 - val_loss: 0.0729 - val_q0_loss: 0.0077 - val_q1_loss: 0.0033 - val_q2_loss: 0.0143 - val_q3_loss: 0.0125 - val_q4_loss: 0.0068 - val_q5_loss: 0.0082 - val_q6_loss: 0.0092 - val_q7_loss: 0.0076 - val_q8_loss: 0.0011\n",
      "Epoch 183/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.1173 - q0_loss: 0.0086 - q1_loss: 0.0068 - q2_loss: 0.0261 - q3_loss: 0.0148 - q4_loss: 0.0116 - q5_loss: 0.0221 - q6_loss: 0.0185 - q7_loss: 0.0072 - q8_loss: 0.0012 - val_loss: 0.1071 - val_q0_loss: 0.0081 - val_q1_loss: 0.0041 - val_q2_loss: 0.0330 - val_q3_loss: 0.0287 - val_q4_loss: 0.0148 - val_q5_loss: 0.0062 - val_q6_loss: 0.0058 - val_q7_loss: 0.0096 - val_q8_loss: 0.0010\n",
      "Epoch 184/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0870 - q0_loss: 0.0088 - q1_loss: 0.0045 - q2_loss: 0.0254 - q3_loss: 0.0120 - q4_loss: 0.0112 - q5_loss: 0.0092 - q6_loss: 0.0082 - q7_loss: 0.0071 - q8_loss: 9.9837e-04 - val_loss: 0.0650 - val_q0_loss: 0.0079 - val_q1_loss: 0.0041 - val_q2_loss: 0.0181 - val_q3_loss: 0.0075 - val_q4_loss: 0.0061 - val_q5_loss: 0.0046 - val_q6_loss: 0.0038 - val_q7_loss: 0.0085 - val_q8_loss: 9.0876e-04\n",
      "Epoch 185/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1040 - q0_loss: 0.0087 - q1_loss: 0.0043 - q2_loss: 0.0226 - q3_loss: 0.0076 - q4_loss: 0.0142 - q5_loss: 0.0201 - q6_loss: 0.0177 - q7_loss: 0.0071 - q8_loss: 0.0011 - val_loss: 0.0944 - val_q0_loss: 0.0079 - val_q1_loss: 0.0030 - val_q2_loss: 0.0115 - val_q3_loss: 0.0049 - val_q4_loss: 0.0150 - val_q5_loss: 0.0186 - val_q6_loss: 0.0162 - val_q7_loss: 0.0086 - val_q8_loss: 0.0013\n",
      "Epoch 186/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0818 - q0_loss: 0.0087 - q1_loss: 0.0043 - q2_loss: 0.0231 - q3_loss: 0.0090 - q4_loss: 0.0094 - q5_loss: 0.0099 - q6_loss: 0.0085 - q7_loss: 0.0071 - q8_loss: 9.8409e-04 - val_loss: 0.0913 - val_q0_loss: 0.0074 - val_q1_loss: 0.0032 - val_q2_loss: 0.0167 - val_q3_loss: 0.0196 - val_q4_loss: 0.0199 - val_q5_loss: 0.0057 - val_q6_loss: 0.0064 - val_q7_loss: 0.0075 - val_q8_loss: 9.3665e-04\n",
      "Epoch 187/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0936 - q0_loss: 0.0085 - q1_loss: 0.0039 - q2_loss: 0.0268 - q3_loss: 0.0175 - q4_loss: 0.0108 - q5_loss: 0.0090 - q6_loss: 0.0083 - q7_loss: 0.0069 - q8_loss: 9.8233e-04 - val_loss: 0.0758 - val_q0_loss: 0.0078 - val_q1_loss: 0.0031 - val_q2_loss: 0.0128 - val_q3_loss: 0.0075 - val_q4_loss: 0.0101 - val_q5_loss: 0.0114 - val_q6_loss: 0.0105 - val_q7_loss: 0.0085 - val_q8_loss: 0.0011\n",
      "Epoch 188/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.0934 - q0_loss: 0.0087 - q1_loss: 0.0040 - q2_loss: 0.0270 - q3_loss: 0.0165 - q4_loss: 0.0135 - q5_loss: 0.0094 - q6_loss: 0.0081 - q7_loss: 0.0074 - q8_loss: 9.8007e-04 - val_loss: 0.1277 - val_q0_loss: 0.0076 - val_q1_loss: 0.0036 - val_q2_loss: 0.0185 - val_q3_loss: 0.0194 - val_q4_loss: 0.0195 - val_q5_loss: 0.0261 - val_q6_loss: 0.0212 - val_q7_loss: 0.0077 - val_q8_loss: 0.0015\n",
      "Epoch 189/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.1040 - q0_loss: 0.0085 - q1_loss: 0.0034 - q2_loss: 0.0262 - q3_loss: 0.0174 - q4_loss: 0.0143 - q5_loss: 0.0143 - q6_loss: 0.0123 - q7_loss: 0.0067 - q8_loss: 0.0011 - val_loss: 0.0869 - val_q0_loss: 0.0075 - val_q1_loss: 0.0028 - val_q2_loss: 0.0189 - val_q3_loss: 0.0170 - val_q4_loss: 0.0098 - val_q5_loss: 0.0080 - val_q6_loss: 0.0074 - val_q7_loss: 0.0082 - val_q8_loss: 9.6234e-04\n",
      "Epoch 190/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0989 - q0_loss: 0.0086 - q1_loss: 0.0034 - q2_loss: 0.0230 - q3_loss: 0.0115 - q4_loss: 0.0151 - q5_loss: 0.0163 - q6_loss: 0.0147 - q7_loss: 0.0074 - q8_loss: 0.0010 - val_loss: 0.0899 - val_q0_loss: 0.0076 - val_q1_loss: 0.0020 - val_q2_loss: 0.0152 - val_q3_loss: 0.0104 - val_q4_loss: 0.0091 - val_q5_loss: 0.0176 - val_q6_loss: 0.0150 - val_q7_loss: 0.0077 - val_q8_loss: 0.0013\n",
      "Epoch 191/300\n",
      "269/269 [==============================] - 0s 230us/sample - loss: 0.0887 - q0_loss: 0.0085 - q1_loss: 0.0033 - q2_loss: 0.0239 - q3_loss: 0.0117 - q4_loss: 0.0113 - q5_loss: 0.0121 - q6_loss: 0.0096 - q7_loss: 0.0068 - q8_loss: 0.0010 - val_loss: 0.0794 - val_q0_loss: 0.0078 - val_q1_loss: 0.0032 - val_q2_loss: 0.0153 - val_q3_loss: 0.0082 - val_q4_loss: 0.0100 - val_q5_loss: 0.0120 - val_q6_loss: 0.0093 - val_q7_loss: 0.0083 - val_q8_loss: 8.3674e-04\n",
      "Epoch 192/300\n",
      "269/269 [==============================] - 0s 204us/sample - loss: 0.0896 - q0_loss: 0.0086 - q1_loss: 0.0033 - q2_loss: 0.0213 - q3_loss: 0.0059 - q4_loss: 0.0112 - q5_loss: 0.0163 - q6_loss: 0.0142 - q7_loss: 0.0071 - q8_loss: 9.8257e-04 - val_loss: 0.1001 - val_q0_loss: 0.0074 - val_q1_loss: 0.0028 - val_q2_loss: 0.0151 - val_q3_loss: 0.0181 - val_q4_loss: 0.0264 - val_q5_loss: 0.0140 - val_q6_loss: 0.0052 - val_q7_loss: 0.0070 - val_q8_loss: 7.1616e-04\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 206us/sample - loss: 0.1005 - q0_loss: 0.0085 - q1_loss: 0.0030 - q2_loss: 0.0224 - q3_loss: 0.0113 - q4_loss: 0.0150 - q5_loss: 0.0166 - q6_loss: 0.0137 - q7_loss: 0.0076 - q8_loss: 0.0010 - val_loss: 0.0727 - val_q0_loss: 0.0075 - val_q1_loss: 0.0023 - val_q2_loss: 0.0126 - val_q3_loss: 0.0093 - val_q4_loss: 0.0114 - val_q5_loss: 0.0082 - val_q6_loss: 0.0077 - val_q7_loss: 0.0075 - val_q8_loss: 9.4618e-04\n",
      "Epoch 194/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1091 - q0_loss: 0.0085 - q1_loss: 0.0040 - q2_loss: 0.0250 - q3_loss: 0.0138 - q4_loss: 0.0148 - q5_loss: 0.0192 - q6_loss: 0.0162 - q7_loss: 0.0071 - q8_loss: 0.0011 - val_loss: 0.1290 - val_q0_loss: 0.0072 - val_q1_loss: 0.0068 - val_q2_loss: 0.0211 - val_q3_loss: 0.0259 - val_q4_loss: 0.0213 - val_q5_loss: 0.0182 - val_q6_loss: 0.0171 - val_q7_loss: 0.0097 - val_q8_loss: 0.0012\n",
      "Epoch 195/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1248 - q0_loss: 0.0083 - q1_loss: 0.0029 - q2_loss: 0.0260 - q3_loss: 0.0222 - q4_loss: 0.0239 - q5_loss: 0.0155 - q6_loss: 0.0136 - q7_loss: 0.0091 - q8_loss: 0.0012 - val_loss: 0.1001 - val_q0_loss: 0.0076 - val_q1_loss: 0.0026 - val_q2_loss: 0.0131 - val_q3_loss: 0.0168 - val_q4_loss: 0.0176 - val_q5_loss: 0.0140 - val_q6_loss: 0.0104 - val_q7_loss: 0.0081 - val_q8_loss: 9.4990e-04\n",
      "Epoch 196/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.0924 - q0_loss: 0.0085 - q1_loss: 0.0032 - q2_loss: 0.0215 - q3_loss: 0.0142 - q4_loss: 0.0140 - q5_loss: 0.0115 - q6_loss: 0.0097 - q7_loss: 0.0072 - q8_loss: 9.4421e-04 - val_loss: 0.0761 - val_q0_loss: 0.0076 - val_q1_loss: 0.0022 - val_q2_loss: 0.0115 - val_q3_loss: 0.0097 - val_q4_loss: 0.0121 - val_q5_loss: 0.0107 - val_q6_loss: 0.0101 - val_q7_loss: 0.0083 - val_q8_loss: 0.0011\n",
      "Epoch 197/300\n",
      "269/269 [==============================] - 0s 183us/sample - loss: 0.0967 - q0_loss: 0.0086 - q1_loss: 0.0036 - q2_loss: 0.0224 - q3_loss: 0.0093 - q4_loss: 0.0143 - q5_loss: 0.0166 - q6_loss: 0.0136 - q7_loss: 0.0069 - q8_loss: 0.0010 - val_loss: 0.0817 - val_q0_loss: 0.0075 - val_q1_loss: 0.0027 - val_q2_loss: 0.0142 - val_q3_loss: 0.0127 - val_q4_loss: 0.0064 - val_q5_loss: 0.0145 - val_q6_loss: 0.0123 - val_q7_loss: 0.0076 - val_q8_loss: 0.0011\n",
      "Epoch 198/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0808 - q0_loss: 0.0086 - q1_loss: 0.0030 - q2_loss: 0.0248 - q3_loss: 0.0087 - q4_loss: 0.0066 - q5_loss: 0.0119 - q6_loss: 0.0107 - q7_loss: 0.0069 - q8_loss: 9.7108e-04 - val_loss: 0.0842 - val_q0_loss: 0.0073 - val_q1_loss: 0.0019 - val_q2_loss: 0.0158 - val_q3_loss: 0.0185 - val_q4_loss: 0.0133 - val_q5_loss: 0.0083 - val_q6_loss: 0.0088 - val_q7_loss: 0.0068 - val_q8_loss: 9.8400e-04\n",
      "Epoch 199/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0802 - q0_loss: 0.0084 - q1_loss: 0.0030 - q2_loss: 0.0219 - q3_loss: 0.0117 - q4_loss: 0.0109 - q5_loss: 0.0086 - q6_loss: 0.0074 - q7_loss: 0.0069 - q8_loss: 8.9631e-04 - val_loss: 0.0800 - val_q0_loss: 0.0077 - val_q1_loss: 0.0018 - val_q2_loss: 0.0110 - val_q3_loss: 0.0053 - val_q4_loss: 0.0144 - val_q5_loss: 0.0147 - val_q6_loss: 0.0126 - val_q7_loss: 0.0086 - val_q8_loss: 0.0012\n",
      "Epoch 200/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0902 - q0_loss: 0.0085 - q1_loss: 0.0034 - q2_loss: 0.0216 - q3_loss: 0.0090 - q4_loss: 0.0122 - q5_loss: 0.0146 - q6_loss: 0.0124 - q7_loss: 0.0070 - q8_loss: 9.9712e-04 - val_loss: 0.0628 - val_q0_loss: 0.0075 - val_q1_loss: 0.0018 - val_q2_loss: 0.0122 - val_q3_loss: 0.0076 - val_q4_loss: 0.0035 - val_q5_loss: 0.0100 - val_q6_loss: 0.0094 - val_q7_loss: 0.0077 - val_q8_loss: 0.0010\n",
      "Epoch 201/300\n",
      "269/269 [==============================] - 0s 220us/sample - loss: 0.0771 - q0_loss: 0.0083 - q1_loss: 0.0028 - q2_loss: 0.0236 - q3_loss: 0.0117 - q4_loss: 0.0100 - q5_loss: 0.0064 - q6_loss: 0.0057 - q7_loss: 0.0070 - q8_loss: 8.5858e-04 - val_loss: 0.0810 - val_q0_loss: 0.0074 - val_q1_loss: 0.0042 - val_q2_loss: 0.0154 - val_q3_loss: 0.0128 - val_q4_loss: 0.0040 - val_q5_loss: 0.0142 - val_q6_loss: 0.0127 - val_q7_loss: 0.0072 - val_q8_loss: 0.0011\n",
      "Epoch 202/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0904 - q0_loss: 0.0083 - q1_loss: 0.0035 - q2_loss: 0.0253 - q3_loss: 0.0149 - q4_loss: 0.0077 - q5_loss: 0.0122 - q6_loss: 0.0104 - q7_loss: 0.0067 - q8_loss: 9.9842e-04 - val_loss: 0.1176 - val_q0_loss: 0.0075 - val_q1_loss: 0.0031 - val_q2_loss: 0.0180 - val_q3_loss: 0.0134 - val_q4_loss: 0.0089 - val_q5_loss: 0.0237 - val_q6_loss: 0.0250 - val_q7_loss: 0.0080 - val_q8_loss: 6.3252e-04\n",
      "Epoch 203/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.1161 - q0_loss: 0.0084 - q1_loss: 0.0055 - q2_loss: 0.0264 - q3_loss: 0.0147 - q4_loss: 0.0125 - q5_loss: 0.0211 - q6_loss: 0.0186 - q7_loss: 0.0067 - q8_loss: 0.0010 - val_loss: 0.0995 - val_q0_loss: 0.0071 - val_q1_loss: 0.0021 - val_q2_loss: 0.0190 - val_q3_loss: 0.0227 - val_q4_loss: 0.0195 - val_q5_loss: 0.0082 - val_q6_loss: 0.0081 - val_q7_loss: 0.0072 - val_q8_loss: 8.6556e-04\n",
      "Epoch 204/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.1002 - q0_loss: 0.0083 - q1_loss: 0.0031 - q2_loss: 0.0281 - q3_loss: 0.0217 - q4_loss: 0.0127 - q5_loss: 0.0101 - q6_loss: 0.0090 - q7_loss: 0.0075 - q8_loss: 9.2181e-04 - val_loss: 0.0752 - val_q0_loss: 0.0075 - val_q1_loss: 0.0025 - val_q2_loss: 0.0155 - val_q3_loss: 0.0106 - val_q4_loss: 0.0079 - val_q5_loss: 0.0087 - val_q6_loss: 0.0084 - val_q7_loss: 0.0081 - val_q8_loss: 9.9135e-04\n",
      "Epoch 205/300\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 0.0855 - q0_loss: 0.0083 - q1_loss: 0.0032 - q2_loss: 0.0248 - q3_loss: 0.0136 - q4_loss: 0.0108 - q5_loss: 0.0084 - q6_loss: 0.0077 - q7_loss: 0.0073 - q8_loss: 8.7102e-04 - val_loss: 0.1036 - val_q0_loss: 0.0073 - val_q1_loss: 0.0028 - val_q2_loss: 0.0162 - val_q3_loss: 0.0131 - val_q4_loss: 0.0127 - val_q5_loss: 0.0175 - val_q6_loss: 0.0166 - val_q7_loss: 0.0072 - val_q8_loss: 7.7013e-04\n",
      "Epoch 206/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.0886 - q0_loss: 0.0083 - q1_loss: 0.0031 - q2_loss: 0.0237 - q3_loss: 0.0110 - q4_loss: 0.0103 - q5_loss: 0.0127 - q6_loss: 0.0116 - q7_loss: 0.0067 - q8_loss: 0.0011 - val_loss: 0.0628 - val_q0_loss: 0.0075 - val_q1_loss: 0.0029 - val_q2_loss: 0.0145 - val_q3_loss: 0.0087 - val_q4_loss: 0.0080 - val_q5_loss: 0.0059 - val_q6_loss: 0.0031 - val_q7_loss: 0.0080 - val_q8_loss: 7.6559e-04\n",
      "Epoch 207/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0913 - q0_loss: 0.0082 - q1_loss: 0.0031 - q2_loss: 0.0254 - q3_loss: 0.0160 - q4_loss: 0.0127 - q5_loss: 0.0086 - q6_loss: 0.0074 - q7_loss: 0.0077 - q8_loss: 8.4116e-04 - val_loss: 0.0883 - val_q0_loss: 0.0071 - val_q1_loss: 0.0016 - val_q2_loss: 0.0179 - val_q3_loss: 0.0199 - val_q4_loss: 0.0095 - val_q5_loss: 0.0109 - val_q6_loss: 0.0106 - val_q7_loss: 0.0069 - val_q8_loss: 0.0010\n",
      "Epoch 208/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0870 - q0_loss: 0.0082 - q1_loss: 0.0027 - q2_loss: 0.0231 - q3_loss: 0.0101 - q4_loss: 0.0079 - q5_loss: 0.0142 - q6_loss: 0.0130 - q7_loss: 0.0067 - q8_loss: 0.0010 - val_loss: 0.0759 - val_q0_loss: 0.0075 - val_q1_loss: 0.0027 - val_q2_loss: 0.0199 - val_q3_loss: 0.0108 - val_q4_loss: 0.0045 - val_q5_loss: 0.0080 - val_q6_loss: 0.0071 - val_q7_loss: 0.0085 - val_q8_loss: 7.7408e-04\n",
      "Epoch 209/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.0802 - q0_loss: 0.0082 - q1_loss: 0.0028 - q2_loss: 0.0225 - q3_loss: 0.0102 - q4_loss: 0.0076 - q5_loss: 0.0106 - q6_loss: 0.0095 - q7_loss: 0.0069 - q8_loss: 8.9276e-04 - val_loss: 0.0714 - val_q0_loss: 0.0075 - val_q1_loss: 0.0023 - val_q2_loss: 0.0153 - val_q3_loss: 0.0101 - val_q4_loss: 0.0082 - val_q5_loss: 0.0064 - val_q6_loss: 0.0056 - val_q7_loss: 0.0084 - val_q8_loss: 8.7212e-04\n",
      "Epoch 210/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 201us/sample - loss: 0.0732 - q0_loss: 0.0082 - q1_loss: 0.0027 - q2_loss: 0.0226 - q3_loss: 0.0126 - q4_loss: 0.0094 - q5_loss: 0.0049 - q6_loss: 0.0046 - q7_loss: 0.0072 - q8_loss: 7.9740e-04 - val_loss: 0.0752 - val_q0_loss: 0.0072 - val_q1_loss: 0.0022 - val_q2_loss: 0.0133 - val_q3_loss: 0.0127 - val_q4_loss: 0.0139 - val_q5_loss: 0.0087 - val_q6_loss: 0.0054 - val_q7_loss: 0.0071 - val_q8_loss: 7.1439e-04\n",
      "Epoch 211/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0868 - q0_loss: 0.0082 - q1_loss: 0.0026 - q2_loss: 0.0225 - q3_loss: 0.0102 - q4_loss: 0.0094 - q5_loss: 0.0134 - q6_loss: 0.0119 - q7_loss: 0.0069 - q8_loss: 8.5263e-04 - val_loss: 0.0664 - val_q0_loss: 0.0073 - val_q1_loss: 0.0021 - val_q2_loss: 0.0151 - val_q3_loss: 0.0109 - val_q4_loss: 0.0081 - val_q5_loss: 0.0039 - val_q6_loss: 0.0041 - val_q7_loss: 0.0078 - val_q8_loss: 7.8696e-04\n",
      "Epoch 212/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.0851 - q0_loss: 0.0082 - q1_loss: 0.0025 - q2_loss: 0.0219 - q3_loss: 0.0114 - q4_loss: 0.0126 - q5_loss: 0.0108 - q6_loss: 0.0090 - q7_loss: 0.0068 - q8_loss: 8.6656e-04 - val_loss: 0.0992 - val_q0_loss: 0.0075 - val_q1_loss: 0.0016 - val_q2_loss: 0.0193 - val_q3_loss: 0.0185 - val_q4_loss: 0.0179 - val_q5_loss: 0.0126 - val_q6_loss: 0.0103 - val_q7_loss: 0.0088 - val_q8_loss: 0.0011\n",
      "Epoch 213/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0967 - q0_loss: 0.0082 - q1_loss: 0.0031 - q2_loss: 0.0224 - q3_loss: 0.0122 - q4_loss: 0.0131 - q5_loss: 0.0152 - q6_loss: 0.0132 - q7_loss: 0.0069 - q8_loss: 0.0011 - val_loss: 0.0824 - val_q0_loss: 0.0073 - val_q1_loss: 0.0066 - val_q2_loss: 0.0133 - val_q3_loss: 0.0075 - val_q4_loss: 0.0091 - val_q5_loss: 0.0162 - val_q6_loss: 0.0141 - val_q7_loss: 0.0077 - val_q8_loss: 0.0011\n",
      "Epoch 214/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0900 - q0_loss: 0.0082 - q1_loss: 0.0053 - q2_loss: 0.0213 - q3_loss: 0.0065 - q4_loss: 0.0111 - q5_loss: 0.0160 - q6_loss: 0.0132 - q7_loss: 0.0068 - q8_loss: 9.4328e-04 - val_loss: 0.0648 - val_q0_loss: 0.0072 - val_q1_loss: 0.0023 - val_q2_loss: 0.0118 - val_q3_loss: 0.0067 - val_q4_loss: 0.0069 - val_q5_loss: 0.0084 - val_q6_loss: 0.0074 - val_q7_loss: 0.0075 - val_q8_loss: 8.1611e-04\n",
      "Epoch 215/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0767 - q0_loss: 0.0082 - q1_loss: 0.0031 - q2_loss: 0.0212 - q3_loss: 0.0056 - q4_loss: 0.0085 - q5_loss: 0.0122 - q6_loss: 0.0101 - q7_loss: 0.0066 - q8_loss: 8.4343e-04 - val_loss: 0.0825 - val_q0_loss: 0.0074 - val_q1_loss: 0.0020 - val_q2_loss: 0.0137 - val_q3_loss: 0.0093 - val_q4_loss: 0.0108 - val_q5_loss: 0.0139 - val_q6_loss: 0.0127 - val_q7_loss: 0.0082 - val_q8_loss: 0.0011\n",
      "Epoch 216/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0791 - q0_loss: 0.0082 - q1_loss: 0.0036 - q2_loss: 0.0232 - q3_loss: 0.0103 - q4_loss: 0.0075 - q5_loss: 0.0116 - q6_loss: 0.0101 - q7_loss: 0.0070 - q8_loss: 9.2244e-04 - val_loss: 0.0915 - val_q0_loss: 0.0071 - val_q1_loss: 0.0070 - val_q2_loss: 0.0160 - val_q3_loss: 0.0115 - val_q4_loss: 0.0037 - val_q5_loss: 0.0179 - val_q6_loss: 0.0162 - val_q7_loss: 0.0071 - val_q8_loss: 0.0011\n",
      "Epoch 217/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.1029 - q0_loss: 0.0080 - q1_loss: 0.0037 - q2_loss: 0.0257 - q3_loss: 0.0190 - q4_loss: 0.0099 - q5_loss: 0.0139 - q6_loss: 0.0134 - q7_loss: 0.0076 - q8_loss: 8.3471e-04 - val_loss: 0.0705 - val_q0_loss: 0.0073 - val_q1_loss: 0.0024 - val_q2_loss: 0.0113 - val_q3_loss: 0.0095 - val_q4_loss: 0.0083 - val_q5_loss: 0.0085 - val_q6_loss: 0.0087 - val_q7_loss: 0.0079 - val_q8_loss: 9.2028e-04\n",
      "Epoch 218/300\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 0.0987 - q0_loss: 0.0080 - q1_loss: 0.0034 - q2_loss: 0.0257 - q3_loss: 0.0182 - q4_loss: 0.0109 - q5_loss: 0.0133 - q6_loss: 0.0115 - q7_loss: 0.0071 - q8_loss: 9.2827e-04 - val_loss: 0.0770 - val_q0_loss: 0.0069 - val_q1_loss: 0.0022 - val_q2_loss: 0.0165 - val_q3_loss: 0.0183 - val_q4_loss: 0.0116 - val_q5_loss: 0.0070 - val_q6_loss: 0.0081 - val_q7_loss: 0.0065 - val_q8_loss: 8.5084e-04\n",
      "Epoch 219/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.1023 - q0_loss: 0.0080 - q1_loss: 0.0033 - q2_loss: 0.0248 - q3_loss: 0.0194 - q4_loss: 0.0129 - q5_loss: 0.0122 - q6_loss: 0.0113 - q7_loss: 0.0072 - q8_loss: 9.9128e-04 - val_loss: 0.0659 - val_q0_loss: 0.0070 - val_q1_loss: 0.0026 - val_q2_loss: 0.0134 - val_q3_loss: 0.0128 - val_q4_loss: 0.0067 - val_q5_loss: 0.0056 - val_q6_loss: 0.0063 - val_q7_loss: 0.0071 - val_q8_loss: 8.0961e-04\n",
      "Epoch 220/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.0790 - q0_loss: 0.0081 - q1_loss: 0.0032 - q2_loss: 0.0211 - q3_loss: 0.0080 - q4_loss: 0.0092 - q5_loss: 0.0120 - q6_loss: 0.0104 - q7_loss: 0.0067 - q8_loss: 8.4707e-04 - val_loss: 0.1110 - val_q0_loss: 0.0072 - val_q1_loss: 0.0031 - val_q2_loss: 0.0162 - val_q3_loss: 0.0055 - val_q4_loss: 0.0092 - val_q5_loss: 0.0240 - val_q6_loss: 0.0211 - val_q7_loss: 0.0080 - val_q8_loss: 0.0010\n",
      "Epoch 221/300\n",
      "269/269 [==============================] - 0s 214us/sample - loss: 0.1012 - q0_loss: 0.0080 - q1_loss: 0.0033 - q2_loss: 0.0238 - q3_loss: 0.0108 - q4_loss: 0.0126 - q5_loss: 0.0185 - q6_loss: 0.0161 - q7_loss: 0.0071 - q8_loss: 9.6298e-04 - val_loss: 0.0770 - val_q0_loss: 0.0071 - val_q1_loss: 0.0026 - val_q2_loss: 0.0127 - val_q3_loss: 0.0088 - val_q4_loss: 0.0086 - val_q5_loss: 0.0111 - val_q6_loss: 0.0101 - val_q7_loss: 0.0074 - val_q8_loss: 7.7226e-04\n",
      "Epoch 222/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 0.1150 - q0_loss: 0.0079 - q1_loss: 0.0038 - q2_loss: 0.0277 - q3_loss: 0.0237 - q4_loss: 0.0161 - q5_loss: 0.0153 - q6_loss: 0.0132 - q7_loss: 0.0080 - q8_loss: 8.3733e-04 - val_loss: 0.0755 - val_q0_loss: 0.0069 - val_q1_loss: 0.0023 - val_q2_loss: 0.0147 - val_q3_loss: 0.0146 - val_q4_loss: 0.0106 - val_q5_loss: 0.0068 - val_q6_loss: 0.0076 - val_q7_loss: 0.0069 - val_q8_loss: 8.3773e-04\n",
      "Epoch 223/300\n",
      "269/269 [==============================] - 0s 283us/sample - loss: 0.0850 - q0_loss: 0.0079 - q1_loss: 0.0039 - q2_loss: 0.0224 - q3_loss: 0.0120 - q4_loss: 0.0079 - q5_loss: 0.0117 - q6_loss: 0.0102 - q7_loss: 0.0065 - q8_loss: 8.6708e-04 - val_loss: 0.0850 - val_q0_loss: 0.0073 - val_q1_loss: 0.0029 - val_q2_loss: 0.0176 - val_q3_loss: 0.0182 - val_q4_loss: 0.0115 - val_q5_loss: 0.0057 - val_q6_loss: 0.0063 - val_q7_loss: 0.0087 - val_q8_loss: 8.5361e-04\n",
      "Epoch 224/300\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 0.0872 - q0_loss: 0.0080 - q1_loss: 0.0032 - q2_loss: 0.0208 - q3_loss: 0.0089 - q4_loss: 0.0117 - q5_loss: 0.0152 - q6_loss: 0.0131 - q7_loss: 0.0070 - q8_loss: 0.0011 - val_loss: 0.0926 - val_q0_loss: 0.0071 - val_q1_loss: 0.0018 - val_q2_loss: 0.0136 - val_q3_loss: 0.0084 - val_q4_loss: 0.0120 - val_q5_loss: 0.0200 - val_q6_loss: 0.0167 - val_q7_loss: 0.0077 - val_q8_loss: 0.0012\n",
      "Epoch 225/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0917 - q0_loss: 0.0080 - q1_loss: 0.0034 - q2_loss: 0.0240 - q3_loss: 0.0115 - q4_loss: 0.0094 - q5_loss: 0.0145 - q6_loss: 0.0129 - q7_loss: 0.0069 - q8_loss: 8.3611e-04 - val_loss: 0.0699 - val_q0_loss: 0.0072 - val_q1_loss: 0.0024 - val_q2_loss: 0.0128 - val_q3_loss: 0.0059 - val_q4_loss: 0.0101 - val_q5_loss: 0.0111 - val_q6_loss: 0.0097 - val_q7_loss: 0.0083 - val_q8_loss: 9.5391e-04\n",
      "Epoch 226/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0692 - q0_loss: 0.0079 - q1_loss: 0.0034 - q2_loss: 0.0211 - q3_loss: 0.0086 - q4_loss: 0.0081 - q5_loss: 0.0063 - q6_loss: 0.0055 - q7_loss: 0.0067 - q8_loss: 7.5992e-04 - val_loss: 0.0500 - val_q0_loss: 0.0071 - val_q1_loss: 0.0028 - val_q2_loss: 0.0108 - val_q3_loss: 0.0058 - val_q4_loss: 0.0050 - val_q5_loss: 0.0033 - val_q6_loss: 0.0028 - val_q7_loss: 0.0077 - val_q8_loss: 6.9792e-04\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 191us/sample - loss: 0.0871 - q0_loss: 0.0079 - q1_loss: 0.0032 - q2_loss: 0.0205 - q3_loss: 0.0070 - q4_loss: 0.0132 - q5_loss: 0.0174 - q6_loss: 0.0159 - q7_loss: 0.0067 - q8_loss: 0.0015 - val_loss: 0.0563 - val_q0_loss: 0.0071 - val_q1_loss: 0.0025 - val_q2_loss: 0.0113 - val_q3_loss: 0.0055 - val_q4_loss: 0.0055 - val_q5_loss: 0.0055 - val_q6_loss: 0.0051 - val_q7_loss: 0.0077 - val_q8_loss: 7.9275e-04\n",
      "Epoch 228/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0813 - q0_loss: 0.0079 - q1_loss: 0.0029 - q2_loss: 0.0202 - q3_loss: 0.0064 - q4_loss: 0.0100 - q5_loss: 0.0138 - q6_loss: 0.0122 - q7_loss: 0.0068 - q8_loss: 8.3843e-04 - val_loss: 0.0893 - val_q0_loss: 0.0073 - val_q1_loss: 0.0027 - val_q2_loss: 0.0247 - val_q3_loss: 0.0219 - val_q4_loss: 0.0101 - val_q5_loss: 0.0080 - val_q6_loss: 0.0066 - val_q7_loss: 0.0087 - val_q8_loss: 8.0787e-04\n",
      "Epoch 229/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0757 - q0_loss: 0.0078 - q1_loss: 0.0028 - q2_loss: 0.0213 - q3_loss: 0.0100 - q4_loss: 0.0082 - q5_loss: 0.0089 - q6_loss: 0.0079 - q7_loss: 0.0068 - q8_loss: 8.2364e-04 - val_loss: 0.1381 - val_q0_loss: 0.0071 - val_q1_loss: 0.0034 - val_q2_loss: 0.0213 - val_q3_loss: 0.0062 - val_q4_loss: 0.0126 - val_q5_loss: 0.0388 - val_q6_loss: 0.0399 - val_q7_loss: 0.0080 - val_q8_loss: 4.0733e-04\n",
      "Epoch 230/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0872 - q0_loss: 0.0078 - q1_loss: 0.0031 - q2_loss: 0.0213 - q3_loss: 0.0076 - q4_loss: 0.0096 - q5_loss: 0.0149 - q6_loss: 0.0142 - q7_loss: 0.0066 - q8_loss: 0.0011 - val_loss: 0.0664 - val_q0_loss: 0.0070 - val_q1_loss: 0.0025 - val_q2_loss: 0.0132 - val_q3_loss: 0.0091 - val_q4_loss: 0.0102 - val_q5_loss: 0.0090 - val_q6_loss: 0.0057 - val_q7_loss: 0.0074 - val_q8_loss: 6.7275e-04\n",
      "Epoch 231/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0850 - q0_loss: 0.0077 - q1_loss: 0.0027 - q2_loss: 0.0209 - q3_loss: 0.0106 - q4_loss: 0.0107 - q5_loss: 0.0124 - q6_loss: 0.0109 - q7_loss: 0.0068 - q8_loss: 9.3606e-04 - val_loss: 0.1192 - val_q0_loss: 0.0071 - val_q1_loss: 0.0101 - val_q2_loss: 0.0123 - val_q3_loss: 0.0110 - val_q4_loss: 0.0238 - val_q5_loss: 0.0255 - val_q6_loss: 0.0208 - val_q7_loss: 0.0080 - val_q8_loss: 0.0013\n",
      "Epoch 232/300\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 0.1134 - q0_loss: 0.0079 - q1_loss: 0.0048 - q2_loss: 0.0217 - q3_loss: 0.0104 - q4_loss: 0.0202 - q5_loss: 0.0242 - q6_loss: 0.0213 - q7_loss: 0.0072 - q8_loss: 0.0014 - val_loss: 0.0917 - val_q0_loss: 0.0070 - val_q1_loss: 0.0029 - val_q2_loss: 0.0161 - val_q3_loss: 0.0042 - val_q4_loss: 0.0109 - val_q5_loss: 0.0226 - val_q6_loss: 0.0198 - val_q7_loss: 0.0075 - val_q8_loss: 5.7640e-04\n",
      "Epoch 233/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.1235 - q0_loss: 0.0078 - q1_loss: 0.0068 - q2_loss: 0.0227 - q3_loss: 0.0118 - q4_loss: 0.0193 - q5_loss: 0.0252 - q6_loss: 0.0212 - q7_loss: 0.0064 - q8_loss: 0.0011 - val_loss: 0.0957 - val_q0_loss: 0.0066 - val_q1_loss: 0.0022 - val_q2_loss: 0.0164 - val_q3_loss: 0.0186 - val_q4_loss: 0.0091 - val_q5_loss: 0.0153 - val_q6_loss: 0.0150 - val_q7_loss: 0.0072 - val_q8_loss: 0.0011\n",
      "Epoch 234/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.1007 - q0_loss: 0.0077 - q1_loss: 0.0031 - q2_loss: 0.0247 - q3_loss: 0.0167 - q4_loss: 0.0131 - q5_loss: 0.0139 - q6_loss: 0.0125 - q7_loss: 0.0075 - q8_loss: 9.0203e-04 - val_loss: 0.0703 - val_q0_loss: 0.0068 - val_q1_loss: 0.0025 - val_q2_loss: 0.0138 - val_q3_loss: 0.0103 - val_q4_loss: 0.0056 - val_q5_loss: 0.0092 - val_q6_loss: 0.0101 - val_q7_loss: 0.0073 - val_q8_loss: 9.6293e-04\n",
      "Epoch 235/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.0812 - q0_loss: 0.0077 - q1_loss: 0.0034 - q2_loss: 0.0209 - q3_loss: 0.0111 - q4_loss: 0.0123 - q5_loss: 0.0104 - q6_loss: 0.0089 - q7_loss: 0.0065 - q8_loss: 8.5409e-04 - val_loss: 0.0815 - val_q0_loss: 0.0069 - val_q1_loss: 0.0022 - val_q2_loss: 0.0107 - val_q3_loss: 0.0050 - val_q4_loss: 0.0126 - val_q5_loss: 0.0158 - val_q6_loss: 0.0141 - val_q7_loss: 0.0078 - val_q8_loss: 0.0011\n",
      "Epoch 236/300\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 0.0861 - q0_loss: 0.0078 - q1_loss: 0.0034 - q2_loss: 0.0188 - q3_loss: 0.0062 - q4_loss: 0.0116 - q5_loss: 0.0160 - q6_loss: 0.0142 - q7_loss: 0.0066 - q8_loss: 8.4789e-04 - val_loss: 0.0886 - val_q0_loss: 0.0069 - val_q1_loss: 0.0019 - val_q2_loss: 0.0105 - val_q3_loss: 0.0037 - val_q4_loss: 0.0168 - val_q5_loss: 0.0199 - val_q6_loss: 0.0169 - val_q7_loss: 0.0079 - val_q8_loss: 0.0012\n",
      "Epoch 237/300\n",
      "269/269 [==============================] - 0s 217us/sample - loss: 0.1027 - q0_loss: 0.0077 - q1_loss: 0.0037 - q2_loss: 0.0239 - q3_loss: 0.0108 - q4_loss: 0.0135 - q5_loss: 0.0206 - q6_loss: 0.0183 - q7_loss: 0.0073 - q8_loss: 9.5218e-04 - val_loss: 0.1222 - val_q0_loss: 0.0070 - val_q1_loss: 0.0037 - val_q2_loss: 0.0290 - val_q3_loss: 0.0189 - val_q4_loss: 0.0091 - val_q5_loss: 0.0239 - val_q6_loss: 0.0205 - val_q7_loss: 0.0082 - val_q8_loss: 5.4623e-04\n",
      "Epoch 238/300\n",
      "269/269 [==============================] - 0s 232us/sample - loss: 0.1430 - q0_loss: 0.0077 - q1_loss: 0.0108 - q2_loss: 0.0275 - q3_loss: 0.0178 - q4_loss: 0.0162 - q5_loss: 0.0308 - q6_loss: 0.0262 - q7_loss: 0.0061 - q8_loss: 0.0015 - val_loss: 0.1466 - val_q0_loss: 0.0064 - val_q1_loss: 0.0193 - val_q2_loss: 0.0219 - val_q3_loss: 0.0258 - val_q4_loss: 0.0059 - val_q5_loss: 0.0310 - val_q6_loss: 0.0272 - val_q7_loss: 0.0079 - val_q8_loss: 0.0014\n",
      "Epoch 239/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.1105 - q0_loss: 0.0076 - q1_loss: 0.0048 - q2_loss: 0.0276 - q3_loss: 0.0218 - q4_loss: 0.0112 - q5_loss: 0.0139 - q6_loss: 0.0128 - q7_loss: 0.0079 - q8_loss: 8.6768e-04 - val_loss: 0.1012 - val_q0_loss: 0.0070 - val_q1_loss: 0.0036 - val_q2_loss: 0.0202 - val_q3_loss: 0.0242 - val_q4_loss: 0.0133 - val_q5_loss: 0.0088 - val_q6_loss: 0.0094 - val_q7_loss: 0.0086 - val_q8_loss: 9.3012e-04\n",
      "Epoch 240/300\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 0.0864 - q0_loss: 0.0077 - q1_loss: 0.0042 - q2_loss: 0.0210 - q3_loss: 0.0134 - q4_loss: 0.0118 - q5_loss: 0.0110 - q6_loss: 0.0100 - q7_loss: 0.0066 - q8_loss: 8.2374e-04 - val_loss: 0.0793 - val_q0_loss: 0.0068 - val_q1_loss: 0.0029 - val_q2_loss: 0.0113 - val_q3_loss: 0.0068 - val_q4_loss: 0.0102 - val_q5_loss: 0.0161 - val_q6_loss: 0.0152 - val_q7_loss: 0.0076 - val_q8_loss: 0.0011\n",
      "Epoch 241/300\n",
      "269/269 [==============================] - 0s 219us/sample - loss: 0.0945 - q0_loss: 0.0076 - q1_loss: 0.0041 - q2_loss: 0.0192 - q3_loss: 0.0057 - q4_loss: 0.0119 - q5_loss: 0.0192 - q6_loss: 0.0164 - q7_loss: 0.0067 - q8_loss: 9.9872e-04 - val_loss: 0.0913 - val_q0_loss: 0.0069 - val_q1_loss: 0.0026 - val_q2_loss: 0.0100 - val_q3_loss: 0.0042 - val_q4_loss: 0.0177 - val_q5_loss: 0.0203 - val_q6_loss: 0.0180 - val_q7_loss: 0.0081 - val_q8_loss: 0.0012\n",
      "Epoch 242/300\n",
      "269/269 [==============================] - 0s 191us/sample - loss: 0.0969 - q0_loss: 0.0076 - q1_loss: 0.0037 - q2_loss: 0.0220 - q3_loss: 0.0133 - q4_loss: 0.0139 - q5_loss: 0.0150 - q6_loss: 0.0135 - q7_loss: 0.0067 - q8_loss: 0.0011 - val_loss: 0.0602 - val_q0_loss: 0.0067 - val_q1_loss: 0.0033 - val_q2_loss: 0.0111 - val_q3_loss: 0.0073 - val_q4_loss: 0.0062 - val_q5_loss: 0.0068 - val_q6_loss: 0.0072 - val_q7_loss: 0.0073 - val_q8_loss: 8.1302e-04\n",
      "Epoch 243/300\n",
      "269/269 [==============================] - 0s 181us/sample - loss: 0.0916 - q0_loss: 0.0075 - q1_loss: 0.0038 - q2_loss: 0.0231 - q3_loss: 0.0150 - q4_loss: 0.0093 - q5_loss: 0.0118 - q6_loss: 0.0107 - q7_loss: 0.0076 - q8_loss: 8.7159e-04 - val_loss: 0.0644 - val_q0_loss: 0.0066 - val_q1_loss: 0.0031 - val_q2_loss: 0.0128 - val_q3_loss: 0.0113 - val_q4_loss: 0.0077 - val_q5_loss: 0.0054 - val_q6_loss: 0.0066 - val_q7_loss: 0.0070 - val_q8_loss: 8.0447e-04\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0777 - q0_loss: 0.0076 - q1_loss: 0.0039 - q2_loss: 0.0208 - q3_loss: 0.0091 - q4_loss: 0.0070 - q5_loss: 0.0111 - q6_loss: 0.0102 - q7_loss: 0.0067 - q8_loss: 7.7691e-04 - val_loss: 0.0815 - val_q0_loss: 0.0066 - val_q1_loss: 0.0022 - val_q2_loss: 0.0135 - val_q3_loss: 0.0099 - val_q4_loss: 0.0065 - val_q5_loss: 0.0164 - val_q6_loss: 0.0146 - val_q7_loss: 0.0072 - val_q8_loss: 0.0011\n",
      "Epoch 245/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.0991 - q0_loss: 0.0074 - q1_loss: 0.0044 - q2_loss: 0.0233 - q3_loss: 0.0131 - q4_loss: 0.0095 - q5_loss: 0.0167 - q6_loss: 0.0140 - q7_loss: 0.0075 - q8_loss: 9.7946e-04 - val_loss: 0.1300 - val_q0_loss: 0.0071 - val_q1_loss: 0.0035 - val_q2_loss: 0.0344 - val_q3_loss: 0.0416 - val_q4_loss: 0.0194 - val_q5_loss: 0.0064 - val_q6_loss: 0.0057 - val_q7_loss: 0.0094 - val_q8_loss: 8.5539e-04\n",
      "Epoch 246/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1142 - q0_loss: 0.0075 - q1_loss: 0.0035 - q2_loss: 0.0246 - q3_loss: 0.0235 - q4_loss: 0.0216 - q5_loss: 0.0152 - q6_loss: 0.0121 - q7_loss: 0.0079 - q8_loss: 8.6492e-04 - val_loss: 0.1030 - val_q0_loss: 0.0062 - val_q1_loss: 0.0023 - val_q2_loss: 0.0194 - val_q3_loss: 0.0266 - val_q4_loss: 0.0219 - val_q5_loss: 0.0072 - val_q6_loss: 0.0083 - val_q7_loss: 0.0072 - val_q8_loss: 8.2579e-04\n",
      "Epoch 247/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.1059 - q0_loss: 0.0074 - q1_loss: 0.0032 - q2_loss: 0.0228 - q3_loss: 0.0162 - q4_loss: 0.0149 - q5_loss: 0.0173 - q6_loss: 0.0149 - q7_loss: 0.0069 - q8_loss: 0.0011 - val_loss: 0.1099 - val_q0_loss: 0.0068 - val_q1_loss: 0.0040 - val_q2_loss: 0.0193 - val_q3_loss: 0.0096 - val_q4_loss: 0.0080 - val_q5_loss: 0.0268 - val_q6_loss: 0.0231 - val_q7_loss: 0.0083 - val_q8_loss: 4.8745e-04\n",
      "Epoch 248/300\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.1006 - q0_loss: 0.0068 - q1_loss: 0.0041 - q2_loss: 0.0192 - q3_loss: 0.0102 - q4_loss: 0.0067 - q5_loss: 0.0238 - q6_loss: 0.0211 - q7_loss: 0.0083 - q8_loss: 4.5329e-0 - 0s 455us/sample - loss: 0.0881 - q0_loss: 0.0075 - q1_loss: 0.0036 - q2_loss: 0.0211 - q3_loss: 0.0113 - q4_loss: 0.0094 - q5_loss: 0.0145 - q6_loss: 0.0127 - q7_loss: 0.0070 - q8_loss: 8.0562e-04 - val_loss: 0.0779 - val_q0_loss: 0.0065 - val_q1_loss: 0.0027 - val_q2_loss: 0.0163 - val_q3_loss: 0.0136 - val_q4_loss: 0.0089 - val_q5_loss: 0.0102 - val_q6_loss: 0.0093 - val_q7_loss: 0.0072 - val_q8_loss: 8.0242e-04\n",
      "Epoch 249/300\n",
      "269/269 [==============================] - 0s 1ms/sample - loss: 0.0801 - q0_loss: 0.0075 - q1_loss: 0.0034 - q2_loss: 0.0218 - q3_loss: 0.0099 - q4_loss: 0.0087 - q5_loss: 0.0113 - q6_loss: 0.0094 - q7_loss: 0.0068 - q8_loss: 8.1330e-04 - val_loss: 0.0683 - val_q0_loss: 0.0066 - val_q1_loss: 0.0024 - val_q2_loss: 0.0112 - val_q3_loss: 0.0080 - val_q4_loss: 0.0051 - val_q5_loss: 0.0111 - val_q6_loss: 0.0112 - val_q7_loss: 0.0076 - val_q8_loss: 9.4927e-04\n",
      "Epoch 250/300\n",
      "269/269 [==============================] - 0s 333us/sample - loss: 0.0693 - q0_loss: 0.0074 - q1_loss: 0.0033 - q2_loss: 0.0195 - q3_loss: 0.0057 - q4_loss: 0.0057 - q5_loss: 0.0104 - q6_loss: 0.0096 - q7_loss: 0.0068 - q8_loss: 8.1085e-04 - val_loss: 0.0565 - val_q0_loss: 0.0066 - val_q1_loss: 0.0026 - val_q2_loss: 0.0105 - val_q3_loss: 0.0064 - val_q4_loss: 0.0063 - val_q5_loss: 0.0058 - val_q6_loss: 0.0064 - val_q7_loss: 0.0076 - val_q8_loss: 7.9542e-04\n",
      "Epoch 251/300\n",
      "269/269 [==============================] - 0s 268us/sample - loss: 0.0753 - q0_loss: 0.0074 - q1_loss: 0.0033 - q2_loss: 0.0221 - q3_loss: 0.0102 - q4_loss: 0.0057 - q5_loss: 0.0113 - q6_loss: 0.0099 - q7_loss: 0.0064 - q8_loss: 8.1864e-04 - val_loss: 0.0743 - val_q0_loss: 0.0063 - val_q1_loss: 0.0020 - val_q2_loss: 0.0153 - val_q3_loss: 0.0162 - val_q4_loss: 0.0092 - val_q5_loss: 0.0089 - val_q6_loss: 0.0094 - val_q7_loss: 0.0065 - val_q8_loss: 8.7013e-04\n",
      "Epoch 252/300\n",
      "269/269 [==============================] - 0s 299us/sample - loss: 0.0975 - q0_loss: 0.0073 - q1_loss: 0.0033 - q2_loss: 0.0259 - q3_loss: 0.0190 - q4_loss: 0.0092 - q5_loss: 0.0123 - q6_loss: 0.0114 - q7_loss: 0.0080 - q8_loss: 7.9996e-04 - val_loss: 0.0683 - val_q0_loss: 0.0064 - val_q1_loss: 0.0020 - val_q2_loss: 0.0136 - val_q3_loss: 0.0125 - val_q4_loss: 0.0058 - val_q5_loss: 0.0086 - val_q6_loss: 0.0091 - val_q7_loss: 0.0069 - val_q8_loss: 8.6817e-04\n",
      "Epoch 253/300\n",
      "269/269 [==============================] - 0s 428us/sample - loss: 0.0819 - q0_loss: 0.0073 - q1_loss: 0.0029 - q2_loss: 0.0216 - q3_loss: 0.0157 - q4_loss: 0.0105 - q5_loss: 0.0084 - q6_loss: 0.0080 - q7_loss: 0.0062 - q8_loss: 7.5358e-04 - val_loss: 0.0821 - val_q0_loss: 0.0065 - val_q1_loss: 0.0030 - val_q2_loss: 0.0109 - val_q3_loss: 0.0090 - val_q4_loss: 0.0114 - val_q5_loss: 0.0174 - val_q6_loss: 0.0113 - val_q7_loss: 0.0073 - val_q8_loss: 5.2296e-04\n",
      "Epoch 254/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.0853 - q0_loss: 0.0073 - q1_loss: 0.0034 - q2_loss: 0.0175 - q3_loss: 0.0068 - q4_loss: 0.0128 - q5_loss: 0.0165 - q6_loss: 0.0139 - q7_loss: 0.0068 - q8_loss: 9.9635e-04 - val_loss: 0.0705 - val_q0_loss: 0.0066 - val_q1_loss: 0.0028 - val_q2_loss: 0.0196 - val_q3_loss: 0.0078 - val_q4_loss: 0.0058 - val_q5_loss: 0.0079 - val_q6_loss: 0.0070 - val_q7_loss: 0.0081 - val_q8_loss: 6.4976e-04\n",
      "Epoch 255/300\n",
      "269/269 [==============================] - 0s 212us/sample - loss: 0.0990 - q0_loss: 0.0073 - q1_loss: 0.0052 - q2_loss: 0.0199 - q3_loss: 0.0058 - q4_loss: 0.0139 - q5_loss: 0.0216 - q6_loss: 0.0185 - q7_loss: 0.0067 - q8_loss: 9.5545e-04 - val_loss: 0.1308 - val_q0_loss: 0.0065 - val_q1_loss: 0.0027 - val_q2_loss: 0.0100 - val_q3_loss: 0.0062 - val_q4_loss: 0.0204 - val_q5_loss: 0.0290 - val_q6_loss: 0.0273 - val_q7_loss: 0.0074 - val_q8_loss: 0.0034\n",
      "Epoch 256/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.0870 - q0_loss: 0.0072 - q1_loss: 0.0032 - q2_loss: 0.0190 - q3_loss: 0.0081 - q4_loss: 0.0114 - q5_loss: 0.0150 - q6_loss: 0.0137 - q7_loss: 0.0065 - q8_loss: 0.0018 - val_loss: 0.0718 - val_q0_loss: 0.0065 - val_q1_loss: 0.0028 - val_q2_loss: 0.0152 - val_q3_loss: 0.0105 - val_q4_loss: 0.0096 - val_q5_loss: 0.0084 - val_q6_loss: 0.0074 - val_q7_loss: 0.0079 - val_q8_loss: 8.0483e-04\n",
      "Epoch 257/300\n",
      "269/269 [==============================] - 0s 251us/sample - loss: 0.0747 - q0_loss: 0.0072 - q1_loss: 0.0033 - q2_loss: 0.0211 - q3_loss: 0.0101 - q4_loss: 0.0081 - q5_loss: 0.0107 - q6_loss: 0.0090 - q7_loss: 0.0067 - q8_loss: 8.1287e-04 - val_loss: 0.0670 - val_q0_loss: 0.0065 - val_q1_loss: 0.0026 - val_q2_loss: 0.0123 - val_q3_loss: 0.0082 - val_q4_loss: 0.0091 - val_q5_loss: 0.0092 - val_q6_loss: 0.0087 - val_q7_loss: 0.0079 - val_q8_loss: 8.9493e-04\n",
      "Epoch 258/300\n",
      "269/269 [==============================] - 0s 236us/sample - loss: 0.0845 - q0_loss: 0.0072 - q1_loss: 0.0037 - q2_loss: 0.0221 - q3_loss: 0.0141 - q4_loss: 0.0068 - q5_loss: 0.0120 - q6_loss: 0.0112 - q7_loss: 0.0060 - q8_loss: 8.4820e-04 - val_loss: 0.1041 - val_q0_loss: 0.0066 - val_q1_loss: 0.0025 - val_q2_loss: 0.0183 - val_q3_loss: 0.0182 - val_q4_loss: 0.0185 - val_q5_loss: 0.0140 - val_q6_loss: 0.0116 - val_q7_loss: 0.0083 - val_q8_loss: 0.0010\n",
      "Epoch 259/300\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 0.0980 - q0_loss: 0.0071 - q1_loss: 0.0031 - q2_loss: 0.0225 - q3_loss: 0.0186 - q4_loss: 0.0175 - q5_loss: 0.0112 - q6_loss: 0.0097 - q7_loss: 0.0083 - q8_loss: 8.0371e-04 - val_loss: 0.1031 - val_q0_loss: 0.0059 - val_q1_loss: 0.0054 - val_q2_loss: 0.0201 - val_q3_loss: 0.0264 - val_q4_loss: 0.0096 - val_q5_loss: 0.0157 - val_q6_loss: 0.0151 - val_q7_loss: 0.0060 - val_q8_loss: 0.0010\n",
      "Epoch 260/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.1147 - q0_loss: 0.0071 - q1_loss: 0.0043 - q2_loss: 0.0227 - q3_loss: 0.0174 - q4_loss: 0.0172 - q5_loss: 0.0191 - q6_loss: 0.0165 - q7_loss: 0.0073 - q8_loss: 9.9880e-04 - val_loss: 0.1546 - val_q0_loss: 0.0063 - val_q1_loss: 0.0039 - val_q2_loss: 0.0115 - val_q3_loss: 0.0088 - val_q4_loss: 0.0185 - val_q5_loss: 0.0429 - val_q6_loss: 0.0437 - val_q7_loss: 0.0071 - val_q8_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.0990 - q0_loss: 0.0072 - q1_loss: 0.0034 - q2_loss: 0.0198 - q3_loss: 0.0124 - q4_loss: 0.0142 - q5_loss: 0.0168 - q6_loss: 0.0163 - q7_loss: 0.0061 - q8_loss: 0.0013 - val_loss: 0.0945 - val_q0_loss: 0.0061 - val_q1_loss: 0.0027 - val_q2_loss: 0.0152 - val_q3_loss: 0.0198 - val_q4_loss: 0.0195 - val_q5_loss: 0.0089 - val_q6_loss: 0.0060 - val_q7_loss: 0.0081 - val_q8_loss: 7.0183e-04\n",
      "Epoch 262/300\n",
      "269/269 [==============================] - 0s 336us/sample - loss: 0.0808 - q0_loss: 0.0071 - q1_loss: 0.0034 - q2_loss: 0.0222 - q3_loss: 0.0142 - q4_loss: 0.0095 - q5_loss: 0.0091 - q6_loss: 0.0082 - q7_loss: 0.0067 - q8_loss: 7.5427e-04 - val_loss: 0.0690 - val_q0_loss: 0.0062 - val_q1_loss: 0.0022 - val_q2_loss: 0.0118 - val_q3_loss: 0.0107 - val_q4_loss: 0.0073 - val_q5_loss: 0.0114 - val_q6_loss: 0.0109 - val_q7_loss: 0.0072 - val_q8_loss: 9.8618e-04\n",
      "Epoch 263/300\n",
      "269/269 [==============================] - 0s 219us/sample - loss: 0.0754 - q0_loss: 0.0071 - q1_loss: 0.0031 - q2_loss: 0.0205 - q3_loss: 0.0112 - q4_loss: 0.0074 - q5_loss: 0.0099 - q6_loss: 0.0088 - q7_loss: 0.0066 - q8_loss: 8.5804e-04 - val_loss: 0.0550 - val_q0_loss: 0.0063 - val_q1_loss: 0.0029 - val_q2_loss: 0.0136 - val_q3_loss: 0.0056 - val_q4_loss: 0.0047 - val_q5_loss: 0.0060 - val_q6_loss: 0.0046 - val_q7_loss: 0.0076 - val_q8_loss: 7.1630e-04\n",
      "Epoch 264/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.0642 - q0_loss: 0.0072 - q1_loss: 0.0032 - q2_loss: 0.0188 - q3_loss: 0.0054 - q4_loss: 0.0069 - q5_loss: 0.0090 - q6_loss: 0.0076 - q7_loss: 0.0065 - q8_loss: 7.8928e-04 - val_loss: 0.0687 - val_q0_loss: 0.0062 - val_q1_loss: 0.0019 - val_q2_loss: 0.0117 - val_q3_loss: 0.0075 - val_q4_loss: 0.0072 - val_q5_loss: 0.0131 - val_q6_loss: 0.0112 - val_q7_loss: 0.0072 - val_q8_loss: 9.8185e-04\n",
      "Epoch 265/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.0926 - q0_loss: 0.0070 - q1_loss: 0.0046 - q2_loss: 0.0199 - q3_loss: 0.0099 - q4_loss: 0.0122 - q5_loss: 0.0176 - q6_loss: 0.0151 - q7_loss: 0.0064 - q8_loss: 0.0012 - val_loss: 0.1051 - val_q0_loss: 0.0059 - val_q1_loss: 0.0072 - val_q2_loss: 0.0191 - val_q3_loss: 0.0223 - val_q4_loss: 0.0133 - val_q5_loss: 0.0140 - val_q6_loss: 0.0136 - val_q7_loss: 0.0081 - val_q8_loss: 0.0010\n",
      "Epoch 266/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.1127 - q0_loss: 0.0069 - q1_loss: 0.0032 - q2_loss: 0.0247 - q3_loss: 0.0220 - q4_loss: 0.0202 - q5_loss: 0.0136 - q6_loss: 0.0107 - q7_loss: 0.0087 - q8_loss: 8.7369e-04 - val_loss: 0.1057 - val_q0_loss: 0.0064 - val_q1_loss: 0.0023 - val_q2_loss: 0.0159 - val_q3_loss: 0.0241 - val_q4_loss: 0.0164 - val_q5_loss: 0.0123 - val_q6_loss: 0.0104 - val_q7_loss: 0.0084 - val_q8_loss: 0.0010\n",
      "Epoch 267/300\n",
      "269/269 [==============================] - 0s 284us/sample - loss: 0.0973 - q0_loss: 0.0071 - q1_loss: 0.0029 - q2_loss: 0.0216 - q3_loss: 0.0183 - q4_loss: 0.0133 - q5_loss: 0.0133 - q6_loss: 0.0115 - q7_loss: 0.0064 - q8_loss: 8.4137e-04 - val_loss: 0.0833 - val_q0_loss: 0.0061 - val_q1_loss: 0.0033 - val_q2_loss: 0.0135 - val_q3_loss: 0.0107 - val_q4_loss: 0.0082 - val_q5_loss: 0.0163 - val_q6_loss: 0.0143 - val_q7_loss: 0.0070 - val_q8_loss: 0.0011\n",
      "Epoch 268/300\n",
      "269/269 [==============================] - 0s 236us/sample - loss: 0.0909 - q0_loss: 0.0069 - q1_loss: 0.0029 - q2_loss: 0.0208 - q3_loss: 0.0098 - q4_loss: 0.0116 - q5_loss: 0.0175 - q6_loss: 0.0163 - q7_loss: 0.0063 - q8_loss: 8.7663e-04 - val_loss: 0.0671 - val_q0_loss: 0.0063 - val_q1_loss: 0.0024 - val_q2_loss: 0.0165 - val_q3_loss: 0.0094 - val_q4_loss: 0.0092 - val_q5_loss: 0.0064 - val_q6_loss: 0.0066 - val_q7_loss: 0.0080 - val_q8_loss: 8.5136e-04\n",
      "Epoch 269/300\n",
      "269/269 [==============================] - 0s 290us/sample - loss: 0.0856 - q0_loss: 0.0070 - q1_loss: 0.0029 - q2_loss: 0.0209 - q3_loss: 0.0112 - q4_loss: 0.0110 - q5_loss: 0.0136 - q6_loss: 0.0117 - q7_loss: 0.0068 - q8_loss: 9.4025e-04 - val_loss: 0.1173 - val_q0_loss: 0.0061 - val_q1_loss: 0.0033 - val_q2_loss: 0.0115 - val_q3_loss: 0.0073 - val_q4_loss: 0.0182 - val_q5_loss: 0.0336 - val_q6_loss: 0.0296 - val_q7_loss: 0.0071 - val_q8_loss: 4.2955e-04\n",
      "Epoch 270/300\n",
      "269/269 [==============================] - 0s 333us/sample - loss: 0.1047 - q0_loss: 0.0069 - q1_loss: 0.0028 - q2_loss: 0.0225 - q3_loss: 0.0177 - q4_loss: 0.0169 - q5_loss: 0.0156 - q6_loss: 0.0130 - q7_loss: 0.0075 - q8_loss: 0.0010 - val_loss: 0.0766 - val_q0_loss: 0.0060 - val_q1_loss: 0.0017 - val_q2_loss: 0.0135 - val_q3_loss: 0.0126 - val_q4_loss: 0.0080 - val_q5_loss: 0.0126 - val_q6_loss: 0.0126 - val_q7_loss: 0.0068 - val_q8_loss: 0.0010\n",
      "Epoch 271/300\n",
      "269/269 [==============================] - 0s 206us/sample - loss: 0.0869 - q0_loss: 0.0068 - q1_loss: 0.0030 - q2_loss: 0.0207 - q3_loss: 0.0144 - q4_loss: 0.0084 - q5_loss: 0.0135 - q6_loss: 0.0121 - q7_loss: 0.0061 - q8_loss: 8.7719e-04 - val_loss: 0.0727 - val_q0_loss: 0.0062 - val_q1_loss: 0.0018 - val_q2_loss: 0.0125 - val_q3_loss: 0.0051 - val_q4_loss: 0.0115 - val_q5_loss: 0.0124 - val_q6_loss: 0.0118 - val_q7_loss: 0.0078 - val_q8_loss: 0.0010\n",
      "Epoch 272/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0734 - q0_loss: 0.0071 - q1_loss: 0.0029 - q2_loss: 0.0195 - q3_loss: 0.0077 - q4_loss: 0.0095 - q5_loss: 0.0103 - q6_loss: 0.0095 - q7_loss: 0.0063 - q8_loss: 8.0712e-04 - val_loss: 0.0556 - val_q0_loss: 0.0062 - val_q1_loss: 0.0024 - val_q2_loss: 0.0130 - val_q3_loss: 0.0040 - val_q4_loss: 0.0053 - val_q5_loss: 0.0066 - val_q6_loss: 0.0054 - val_q7_loss: 0.0078 - val_q8_loss: 7.8259e-04\n",
      "Epoch 273/300\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 0.0870 - q0_loss: 0.0069 - q1_loss: 0.0028 - q2_loss: 0.0202 - q3_loss: 0.0086 - q4_loss: 0.0122 - q5_loss: 0.0163 - q6_loss: 0.0139 - q7_loss: 0.0068 - q8_loss: 0.0010 - val_loss: 0.0880 - val_q0_loss: 0.0060 - val_q1_loss: 0.0024 - val_q2_loss: 0.0117 - val_q3_loss: 0.0100 - val_q4_loss: 0.0107 - val_q5_loss: 0.0208 - val_q6_loss: 0.0179 - val_q7_loss: 0.0069 - val_q8_loss: 7.5529e-04\n",
      "Epoch 274/300\n",
      "269/269 [==============================] - 0s 244us/sample - loss: 0.1088 - q0_loss: 0.0069 - q1_loss: 0.0051 - q2_loss: 0.0197 - q3_loss: 0.0067 - q4_loss: 0.0143 - q5_loss: 0.0246 - q6_loss: 0.0216 - q7_loss: 0.0065 - q8_loss: 0.0015 - val_loss: 0.0719 - val_q0_loss: 0.0059 - val_q1_loss: 0.0018 - val_q2_loss: 0.0129 - val_q3_loss: 0.0107 - val_q4_loss: 0.0050 - val_q5_loss: 0.0122 - val_q6_loss: 0.0122 - val_q7_loss: 0.0067 - val_q8_loss: 9.9342e-04\n",
      "Epoch 275/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0752 - q0_loss: 0.0069 - q1_loss: 0.0030 - q2_loss: 0.0201 - q3_loss: 0.0096 - q4_loss: 0.0073 - q5_loss: 0.0108 - q6_loss: 0.0100 - q7_loss: 0.0065 - q8_loss: 8.2854e-04 - val_loss: 0.0621 - val_q0_loss: 0.0059 - val_q1_loss: 0.0023 - val_q2_loss: 0.0121 - val_q3_loss: 0.0094 - val_q4_loss: 0.0068 - val_q5_loss: 0.0074 - val_q6_loss: 0.0083 - val_q7_loss: 0.0068 - val_q8_loss: 8.7656e-04\n",
      "Epoch 276/300\n",
      "269/269 [==============================] - 0s 243us/sample - loss: 0.0752 - q0_loss: 0.0068 - q1_loss: 0.0031 - q2_loss: 0.0188 - q3_loss: 0.0096 - q4_loss: 0.0087 - q5_loss: 0.0114 - q6_loss: 0.0100 - q7_loss: 0.0061 - q8_loss: 7.9254e-04 - val_loss: 0.0902 - val_q0_loss: 0.0060 - val_q1_loss: 0.0040 - val_q2_loss: 0.0108 - val_q3_loss: 0.0043 - val_q4_loss: 0.0175 - val_q5_loss: 0.0202 - val_q6_loss: 0.0176 - val_q7_loss: 0.0075 - val_q8_loss: 0.0012\n",
      "Epoch 277/300\n",
      "269/269 [==============================] - 0s 240us/sample - loss: 0.0911 - q0_loss: 0.0067 - q1_loss: 0.0031 - q2_loss: 0.0194 - q3_loss: 0.0115 - q4_loss: 0.0144 - q5_loss: 0.0157 - q6_loss: 0.0125 - q7_loss: 0.0075 - q8_loss: 0.0010 - val_loss: 0.1313 - val_q0_loss: 0.0063 - val_q1_loss: 0.0023 - val_q2_loss: 0.0311 - val_q3_loss: 0.0348 - val_q4_loss: 0.0247 - val_q5_loss: 0.0128 - val_q6_loss: 0.0110 - val_q7_loss: 0.0088 - val_q8_loss: 0.0010\n",
      "Epoch 278/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 245us/sample - loss: 0.1075 - q0_loss: 0.0067 - q1_loss: 0.0030 - q2_loss: 0.0235 - q3_loss: 0.0225 - q4_loss: 0.0193 - q5_loss: 0.0135 - q6_loss: 0.0109 - q7_loss: 0.0072 - q8_loss: 8.7685e-04 - val_loss: 0.0901 - val_q0_loss: 0.0056 - val_q1_loss: 0.0037 - val_q2_loss: 0.0170 - val_q3_loss: 0.0214 - val_q4_loss: 0.0072 - val_q5_loss: 0.0144 - val_q6_loss: 0.0139 - val_q7_loss: 0.0061 - val_q8_loss: 0.0010\n",
      "Epoch 279/300\n",
      "269/269 [==============================] - 0s 242us/sample - loss: 0.0973 - q0_loss: 0.0067 - q1_loss: 0.0045 - q2_loss: 0.0199 - q3_loss: 0.0113 - q4_loss: 0.0135 - q5_loss: 0.0187 - q6_loss: 0.0159 - q7_loss: 0.0065 - q8_loss: 9.7023e-04 - val_loss: 0.0966 - val_q0_loss: 0.0058 - val_q1_loss: 0.0034 - val_q2_loss: 0.0119 - val_q3_loss: 0.0097 - val_q4_loss: 0.0163 - val_q5_loss: 0.0248 - val_q6_loss: 0.0184 - val_q7_loss: 0.0069 - val_q8_loss: 4.9998e-04\n",
      "Epoch 280/300\n",
      "269/269 [==============================] - 0s 452us/sample - loss: 0.0938 - q0_loss: 0.0066 - q1_loss: 0.0029 - q2_loss: 0.0168 - q3_loss: 0.0075 - q4_loss: 0.0145 - q5_loss: 0.0195 - q6_loss: 0.0165 - q7_loss: 0.0066 - q8_loss: 0.0012 - val_loss: 0.1087 - val_q0_loss: 0.0056 - val_q1_loss: 0.0031 - val_q2_loss: 0.0131 - val_q3_loss: 0.0186 - val_q4_loss: 0.0272 - val_q5_loss: 0.0205 - val_q6_loss: 0.0140 - val_q7_loss: 0.0062 - val_q8_loss: 5.3603e-04\n",
      "Epoch 281/300\n",
      "269/269 [==============================] - 0s 266us/sample - loss: 0.0865 - q0_loss: 0.0066 - q1_loss: 0.0031 - q2_loss: 0.0185 - q3_loss: 0.0107 - q4_loss: 0.0136 - q5_loss: 0.0148 - q6_loss: 0.0121 - q7_loss: 0.0062 - q8_loss: 8.6119e-04 - val_loss: 0.0781 - val_q0_loss: 0.0058 - val_q1_loss: 0.0031 - val_q2_loss: 0.0099 - val_q3_loss: 0.0099 - val_q4_loss: 0.0182 - val_q5_loss: 0.0165 - val_q6_loss: 0.0121 - val_q7_loss: 0.0067 - val_q8_loss: 5.9679e-04\n",
      "Epoch 282/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0827 - q0_loss: 0.0067 - q1_loss: 0.0032 - q2_loss: 0.0212 - q3_loss: 0.0125 - q4_loss: 0.0092 - q5_loss: 0.0114 - q6_loss: 0.0103 - q7_loss: 0.0065 - q8_loss: 8.1694e-04 - val_loss: 0.0759 - val_q0_loss: 0.0056 - val_q1_loss: 0.0022 - val_q2_loss: 0.0137 - val_q3_loss: 0.0148 - val_q4_loss: 0.0090 - val_q5_loss: 0.0107 - val_q6_loss: 0.0117 - val_q7_loss: 0.0063 - val_q8_loss: 9.5760e-04\n",
      "Epoch 283/300\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 0.0758 - q0_loss: 0.0067 - q1_loss: 0.0029 - q2_loss: 0.0181 - q3_loss: 0.0090 - q4_loss: 0.0086 - q5_loss: 0.0130 - q6_loss: 0.0113 - q7_loss: 0.0062 - q8_loss: 8.5101e-04 - val_loss: 0.0635 - val_q0_loss: 0.0058 - val_q1_loss: 0.0025 - val_q2_loss: 0.0124 - val_q3_loss: 0.0080 - val_q4_loss: 0.0035 - val_q5_loss: 0.0086 - val_q6_loss: 0.0083 - val_q7_loss: 0.0072 - val_q8_loss: 7.8340e-04\n",
      "Epoch 284/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0879 - q0_loss: 0.0065 - q1_loss: 0.0029 - q2_loss: 0.0220 - q3_loss: 0.0135 - q4_loss: 0.0092 - q5_loss: 0.0142 - q6_loss: 0.0130 - q7_loss: 0.0076 - q8_loss: 9.1221e-04 - val_loss: 0.0936 - val_q0_loss: 0.0055 - val_q1_loss: 0.0016 - val_q2_loss: 0.0163 - val_q3_loss: 0.0209 - val_q4_loss: 0.0142 - val_q5_loss: 0.0097 - val_q6_loss: 0.0105 - val_q7_loss: 0.0088 - val_q8_loss: 9.0928e-04\n",
      "Epoch 285/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1024 - q0_loss: 0.0064 - q1_loss: 0.0033 - q2_loss: 0.0249 - q3_loss: 0.0244 - q4_loss: 0.0137 - q5_loss: 0.0104 - q6_loss: 0.0096 - q7_loss: 0.0072 - q8_loss: 8.0637e-04 - val_loss: 0.0979 - val_q0_loss: 0.0059 - val_q1_loss: 0.0027 - val_q2_loss: 0.0244 - val_q3_loss: 0.0262 - val_q4_loss: 0.0115 - val_q5_loss: 0.0058 - val_q6_loss: 0.0060 - val_q7_loss: 0.0082 - val_q8_loss: 7.4343e-04\n",
      "Epoch 286/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0830 - q0_loss: 0.0066 - q1_loss: 0.0029 - q2_loss: 0.0222 - q3_loss: 0.0166 - q4_loss: 0.0127 - q5_loss: 0.0073 - q6_loss: 0.0065 - q7_loss: 0.0069 - q8_loss: 8.0843e-04 - val_loss: 0.0634 - val_q0_loss: 0.0055 - val_q1_loss: 0.0022 - val_q2_loss: 0.0133 - val_q3_loss: 0.0156 - val_q4_loss: 0.0111 - val_q5_loss: 0.0036 - val_q6_loss: 0.0042 - val_q7_loss: 0.0064 - val_q8_loss: 7.1978e-04\n",
      "Epoch 287/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0745 - q0_loss: 0.0066 - q1_loss: 0.0030 - q2_loss: 0.0198 - q3_loss: 0.0127 - q4_loss: 0.0099 - q5_loss: 0.0102 - q6_loss: 0.0088 - q7_loss: 0.0063 - q8_loss: 7.7668e-04 - val_loss: 0.0811 - val_q0_loss: 0.0057 - val_q1_loss: 0.0029 - val_q2_loss: 0.0130 - val_q3_loss: 0.0090 - val_q4_loss: 0.0135 - val_q5_loss: 0.0152 - val_q6_loss: 0.0128 - val_q7_loss: 0.0075 - val_q8_loss: 0.0010\n",
      "Epoch 288/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.0847 - q0_loss: 0.0064 - q1_loss: 0.0025 - q2_loss: 0.0196 - q3_loss: 0.0123 - q4_loss: 0.0136 - q5_loss: 0.0128 - q6_loss: 0.0106 - q7_loss: 0.0065 - q8_loss: 8.4306e-04 - val_loss: 0.0648 - val_q0_loss: 0.0057 - val_q1_loss: 0.0018 - val_q2_loss: 0.0108 - val_q3_loss: 0.0087 - val_q4_loss: 0.0074 - val_q5_loss: 0.0099 - val_q6_loss: 0.0091 - val_q7_loss: 0.0073 - val_q8_loss: 9.0169e-04\n",
      "Epoch 289/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0618 - q0_loss: 0.0064 - q1_loss: 0.0027 - q2_loss: 0.0170 - q3_loss: 0.0068 - q4_loss: 0.0063 - q5_loss: 0.0079 - q6_loss: 0.0071 - q7_loss: 0.0065 - q8_loss: 7.2990e-04 - val_loss: 0.0483 - val_q0_loss: 0.0057 - val_q1_loss: 0.0020 - val_q2_loss: 0.0098 - val_q3_loss: 0.0053 - val_q4_loss: 0.0027 - val_q5_loss: 0.0060 - val_q6_loss: 0.0057 - val_q7_loss: 0.0074 - val_q8_loss: 7.8156e-04\n",
      "Epoch 290/300\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 0.0753 - q0_loss: 0.0064 - q1_loss: 0.0029 - q2_loss: 0.0193 - q3_loss: 0.0099 - q4_loss: 0.0080 - q5_loss: 0.0120 - q6_loss: 0.0109 - q7_loss: 0.0063 - q8_loss: 8.9241e-04 - val_loss: 0.0969 - val_q0_loss: 0.0053 - val_q1_loss: 0.0020 - val_q2_loss: 0.0157 - val_q3_loss: 0.0206 - val_q4_loss: 0.0251 - val_q5_loss: 0.0122 - val_q6_loss: 0.0057 - val_q7_loss: 0.0066 - val_q8_loss: 5.6550e-04\n",
      "Epoch 291/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.0954 - q0_loss: 0.0063 - q1_loss: 0.0034 - q2_loss: 0.0226 - q3_loss: 0.0202 - q4_loss: 0.0142 - q5_loss: 0.0115 - q6_loss: 0.0095 - q7_loss: 0.0073 - q8_loss: 7.8111e-04 - val_loss: 0.0839 - val_q0_loss: 0.0055 - val_q1_loss: 0.0025 - val_q2_loss: 0.0114 - val_q3_loss: 0.0115 - val_q4_loss: 0.0159 - val_q5_loss: 0.0165 - val_q6_loss: 0.0099 - val_q7_loss: 0.0066 - val_q8_loss: 5.2667e-04\n",
      "Epoch 292/300\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 0.1097 - q0_loss: 0.0063 - q1_loss: 0.0048 - q2_loss: 0.0203 - q3_loss: 0.0126 - q4_loss: 0.0148 - q5_loss: 0.0215 - q6_loss: 0.0194 - q7_loss: 0.0063 - q8_loss: 0.0028 - val_loss: 0.1123 - val_q0_loss: 0.0052 - val_q1_loss: 0.0023 - val_q2_loss: 0.0172 - val_q3_loss: 0.0237 - val_q4_loss: 0.0251 - val_q5_loss: 0.0184 - val_q6_loss: 0.0146 - val_q7_loss: 0.0056 - val_q8_loss: 6.9611e-04\n",
      "Epoch 293/300\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0966 - q0_loss: 0.0063 - q1_loss: 0.0030 - q2_loss: 0.0214 - q3_loss: 0.0158 - q4_loss: 0.0161 - q5_loss: 0.0145 - q6_loss: 0.0121 - q7_loss: 0.0060 - q8_loss: 8.0159e-04 - val_loss: 0.0645 - val_q0_loss: 0.0055 - val_q1_loss: 0.0029 - val_q2_loss: 0.0130 - val_q3_loss: 0.0115 - val_q4_loss: 0.0113 - val_q5_loss: 0.0040 - val_q6_loss: 0.0041 - val_q7_loss: 0.0071 - val_q8_loss: 7.1035e-04\n",
      "Epoch 294/300\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 0.0930 - q0_loss: 0.0064 - q1_loss: 0.0035 - q2_loss: 0.0186 - q3_loss: 0.0107 - q4_loss: 0.0161 - q5_loss: 0.0165 - q6_loss: 0.0137 - q7_loss: 0.0061 - q8_loss: 9.3488e-04 - val_loss: 0.0944 - val_q0_loss: 0.0055 - val_q1_loss: 0.0024 - val_q2_loss: 0.0109 - val_q3_loss: 0.0073 - val_q4_loss: 0.0157 - val_q5_loss: 0.0238 - val_q6_loss: 0.0198 - val_q7_loss: 0.0073 - val_q8_loss: 0.0013\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 182us/sample - loss: 0.0860 - q0_loss: 0.0063 - q1_loss: 0.0031 - q2_loss: 0.0184 - q3_loss: 0.0102 - q4_loss: 0.0127 - q5_loss: 0.0155 - q6_loss: 0.0131 - q7_loss: 0.0062 - q8_loss: 8.5818e-04 - val_loss: 0.0787 - val_q0_loss: 0.0057 - val_q1_loss: 0.0030 - val_q2_loss: 0.0192 - val_q3_loss: 0.0177 - val_q4_loss: 0.0073 - val_q5_loss: 0.0055 - val_q6_loss: 0.0060 - val_q7_loss: 0.0080 - val_q8_loss: 7.9088e-04\n",
      "Epoch 296/300\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 0.0725 - q0_loss: 0.0063 - q1_loss: 0.0031 - q2_loss: 0.0182 - q3_loss: 0.0100 - q4_loss: 0.0097 - q5_loss: 0.0101 - q6_loss: 0.0089 - q7_loss: 0.0064 - q8_loss: 8.9652e-04 - val_loss: 0.0917 - val_q0_loss: 0.0054 - val_q1_loss: 0.0025 - val_q2_loss: 0.0107 - val_q3_loss: 0.0116 - val_q4_loss: 0.0169 - val_q5_loss: 0.0183 - val_q6_loss: 0.0150 - val_q7_loss: 0.0068 - val_q8_loss: 8.1357e-04\n",
      "Epoch 297/300\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 0.0770 - q0_loss: 0.0063 - q1_loss: 0.0031 - q2_loss: 0.0178 - q3_loss: 0.0087 - q4_loss: 0.0117 - q5_loss: 0.0122 - q6_loss: 0.0106 - q7_loss: 0.0061 - q8_loss: 8.0346e-04 - val_loss: 0.0583 - val_q0_loss: 0.0053 - val_q1_loss: 0.0025 - val_q2_loss: 0.0103 - val_q3_loss: 0.0117 - val_q4_loss: 0.0119 - val_q5_loss: 0.0047 - val_q6_loss: 0.0033 - val_q7_loss: 0.0065 - val_q8_loss: 6.9148e-04\n",
      "Epoch 298/300\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 0.0743 - q0_loss: 0.0062 - q1_loss: 0.0028 - q2_loss: 0.0190 - q3_loss: 0.0116 - q4_loss: 0.0110 - q5_loss: 0.0089 - q6_loss: 0.0068 - q7_loss: 0.0061 - q8_loss: 7.8192e-04 - val_loss: 0.0572 - val_q0_loss: 0.0054 - val_q1_loss: 0.0020 - val_q2_loss: 0.0109 - val_q3_loss: 0.0083 - val_q4_loss: 0.0054 - val_q5_loss: 0.0071 - val_q6_loss: 0.0073 - val_q7_loss: 0.0068 - val_q8_loss: 8.4791e-04\n",
      "Epoch 299/300\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 0.0644 - q0_loss: 0.0062 - q1_loss: 0.0027 - q2_loss: 0.0163 - q3_loss: 0.0072 - q4_loss: 0.0077 - q5_loss: 0.0096 - q6_loss: 0.0080 - q7_loss: 0.0061 - q8_loss: 7.6949e-04 - val_loss: 0.0799 - val_q0_loss: 0.0054 - val_q1_loss: 0.0033 - val_q2_loss: 0.0099 - val_q3_loss: 0.0045 - val_q4_loss: 0.0147 - val_q5_loss: 0.0174 - val_q6_loss: 0.0142 - val_q7_loss: 0.0073 - val_q8_loss: 0.0011\n",
      "Epoch 300/300\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 0.0877 - q0_loss: 0.0062 - q1_loss: 0.0035 - q2_loss: 0.0167 - q3_loss: 0.0064 - q4_loss: 0.0125 - q5_loss: 0.0192 - q6_loss: 0.0173 - q7_loss: 0.0062 - q8_loss: 0.0011 - val_loss: 0.0947 - val_q0_loss: 0.0055 - val_q1_loss: 0.0028 - val_q2_loss: 0.0137 - val_q3_loss: 0.0117 - val_q4_loss: 0.0188 - val_q5_loss: 0.0183 - val_q6_loss: 0.0148 - val_q7_loss: 0.0077 - val_q8_loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_mo, epochs=300,\n",
    "                    validation_data=(X_val, y_val_mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAgAAAFlCAYAAABmy9o5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXiU9bn/8fczk5nsISxhBwFRZF+MuKAC7rhvdame4261e2vbY9tzqj9bW1tbq7Yuba24tNVa11atW11xB0UUEAVBhbCENfsymef3xwSMyBIwySDzfl0X10wyzzy5ZxJj5jP39/4GYRgiSZIkSZIyWyTdBUiSJEmSpPQzIJAkSZIkSQYEkiRJkiTJgECSJEmSJGFAIEmSJEmSMCCQJEmSJElAVnuctFu3buGAAQPa49SSJEmSJGk7zZgxY2UYhiWbuq1dAoIBAwYwffr09ji1JEmSJEnaTkEQfLi521xiIEmSJEmSDAgkSZIkSZIBgSRJkiRJop1mEEiSJEmS1FqNjY0sXryYurq6dJey08jJyaFv377EYrFW38eAQJIkSZKUVosXL6awsJABAwYQBEG6y/nCC8OQVatWsXjxYgYOHNjq+7nEQJIkSZKUVnV1dXTt2tVwoI0EQUDXrl23uSPDgECSJEmSlHaGA21re55PAwJJkiRJUkZbtWoVY8aMYcyYMfTs2ZM+ffps+LihoaFV5zjnnHOYN29eO1favpxBIEmSJEnKaF27dmXmzJkAXH755RQUFPC9733vU8eEYUgYhkQim36fferUqe1eZ3uzg0CSJEmSpE2YP38+I0aM4KKLLmLcuHEsXbqUCy+8kNLSUoYPH84VV1yx4dj999+fmTNnkkgkKC4u5tJLL2X06NHsu+++rFixIo2PovXsIJAkSZIk7TD+379mM6esok3POax3EZcdM3y77jtnzhymTp3KzTffDMBVV11Fly5dSCQSTJ48mZNPPplhw4Z96j7r1q1j4sSJXHXVVXz3u9/l1ltv5dJLL/3cj6O92UEgSZIkSdJm7Lrrruy1114bPr7rrrsYN24c48aNY+7cucyZM+cz98nNzWXKlCkA7LnnnixatKijyv1c7CAAHnhzMU/OWc6NZ+yZ7lIkSZIkKaNt7zv97SU/P3/D9ffff5/rrruO1157jeLiYs4888xNbiUYj8c3XI9GoyQSiQ6p9fPaagdBEARDgiCY2eJfRRAE3+6I4jrKghXVPPbOsnSXIUmSJEnagVVUVFBYWEhRURFLly7l8ccfT3dJbWqrHQRhGM4DxgAEQRAFlgAPtHNdHSoWjZAMoSkZEo2496YkSZIk6bPGjRvHsGHDGDFiBIMGDWLChAnpLqlNbesSg4OBBWEYftgexaRLLCsVCjQ2JYlGommuRpIkSZKULpdffvmG64MHD96w/SFAEATceeedm7zftGnTNlxfu3bthuunnXYap512WtsX2g62dUjhacBdm7ohCIILgyCYHgTB9PLy8s9fWQeKR1NPQ0NTMs2VSJIkSZKUHq0OCIIgiAPHAv/Y1O1hGP4xDMPSMAxLS0pK2qq+DhFrDggaEwYEkiRJkqTMtC0dBFOAN8IwXN5exaTLhoCgKUxzJZIkSZIkpce2BASns5nlBV90segnMwgkSZIkScpErQoIgiDIAw4F7m/fctIjnuUMAkmSJElSZmvVLgZhGNYAXdu5lrT5ZImBAYEkSZIkKTNt6y4GO6VPhhQ6g0CSJEmSMs2kSZN4/PHHP/W5a6+9lq9+9aubvU9BQQEAZWVlnHzyyZs97/Tp07f4ta+99lpqamo2fHzkkUd+apvEjmRAwCczCFxiIEmSJEmZ5/TTT+fuu+/+1OfuvvtuTj/99K3et3fv3tx7773b/bU3DggeffRRiouLt/t8n4cBARB3iYEkSZIkZayTTz6Zhx9+mPr6egAWLVpEWVkZY8aM4eCDD2bcuHGMHDmShx566DP3XbRoESNGjACgtraW0047jVGjRnHqqadSW1u74biLL76Y0tJShg8fzmWXXQbA9ddfT1lZGZMnT2by5MkADBgwgJUrVwJwzTXXMGLECEaMGMG111674esNHTqUCy64gOHDh3PYYYd96ut8Hq2aQbCzizUPKUy4zaEkSZIkpde/L4Vlb7ftOXuOhClXbfbmrl27Mn78eB577DGOO+447r77bk499VRyc3N54IEHKCoqYuXKleyzzz4ce+yxBEGwyfPcdNNN5OXlMWvWLGbNmsW4ceM23HbllVfSpUsXmpqaOPjgg5k1axbf/OY3ueaaa3jmmWfo1q3bp841Y8YMpk6dyquvvkoYhuy9995MnDiRzp078/7773PXXXfxpz/9iVNOOYX77ruPM88883M/TXYQ4JBCSZIkScp0LZcZrF9eEIYhP/rRjxg1ahSHHHIIS5YsYfny5Zs9x/PPP7/hhfqoUaMYNWrUhtvuuecexo0bx9ixY5k9ezZz5szZYj3Tpk3jhBNOID8/n4KCAk488UReeOEFAAYOHMiYMWMA2HPPPVm0aNHneegb2EGAMwgkSZIkaYexhXf629Pxxx/Pd7/7Xd544w1qa2sZN24ct912G+Xl5cyYMYNYLMaAAQOoq6vb4nk21V2wcOFCfv3rX/P666/TuXNnzj777K2eJww33+GenZ294Xo0Gm2zJQZ2EOAMAkmSJEnKdAUFBUyaNIlzzz13w3DCdevW0b17d2KxGM888wwffvjhFs9x4IEH8te//hWAd955h1mzZgFQUVFBfn4+nTp1Yvny5fz73//ecJ/CwkIqKys3ea4HH3yQmpoaqqureeCBBzjggAPa6uFukh0EuMRAkiRJkpRaZnDiiSduWGpwxhlncMwxx1BaWsqYMWPYY489tnj/iy++mHPOOYdRo0YxZswYxo8fD8Do0aMZO3Ysw4cPZ9CgQUyYMGHDfS688EKmTJlCr169eOaZZzZ8fty4cZx99tkbznH++eczduzYNltOsCnBltoWtldpaWm4tb0edyRL1tYy4aqn+dVJozhlr37pLkeSJEmSMsrcuXMZOnRousvY6WzqeQ2CYEYYhqWbOt4lBjiDQJIkSZIkAwKcQSBJkiRJkgEBziCQJEmSJMmAgJYBQdvPY5AkSZIkbV17zMfLZNvzfBoQ0GIGQcIOAkmSJEnqaDk5OaxatcqQoI2EYciqVavIycnZpvu5zSEQBAGxaOASA0mSJElKg759+7J48WLKy8vTXcpOIycnh759+27TfQwImsWiEQMCSZIkSUqDWCzGwIED011GxnOJQbNUQGA7iyRJkiQpMxkQNItFIzTYQSBJkiRJylAGBM3i0YBGhxRKkiRJkjKUAUGzWJYzCCRJkiRJmcuAoJkzCCRJkiRJmcyAoJkzCCRJkiRJmcyAoFk8GrjEQJIkSZKUsQwImqWWGBgQSJIkSZIykwFBs1g0QmPCGQSSJEmSpMxkQNAsluUMAkmSJElS5jIgaOYMAkmSJElSJjMgaOYMAkmSJElSJjMgaJYKCJxBIEmSJEnKTAYEzWLRCA0JOwgkSZIkSZnJgKBZPMsZBJIkSZKkzGVA0MwZBJIkSZKkTGZA0MwZBJIkSZKkTGZA0CwWjdBgB4EkSZIkKUMZEDSLR1MzCMLQLgJJkiRJUuZpVUAQBEFxEAT3BkHwbhAEc4Mg2Le9C+tosWiEMISmpAGBJEmSJCnzZLXyuOuAx8IwPDkIgjiQ1441pUUsK5WVNDaFZEXTXIwkSZIkSR1sqwFBEARFwIHA2QBhGDYADe1bVseLRVMBQUNTklxMCCRJkiRJmaU1SwwGAeXA1CAI3gyC4JYgCPI3PigIgguDIJgeBMH08vLyNi+0vcWjAYBbHUqSJEmSMlJrAoIsYBxwUxiGY4Fq4NKNDwrD8I9hGJaGYVhaUlLSxmW2v/UdBAYEkiRJkqRM1JqAYDGwOAzDV5s/vpdUYLBT2RAQJBxSKEmSJEnKPFsNCMIwXAZ8HATBkOZPHQzMadeq0mD9kMIGOwgkSZIkSRmotbsYfAP4a/MOBh8A57RfSenhDAJJkiRJUiZrVUAQhuFMoLSda0krZxBIkiRJkjJZa2YQZAQDAkmSJElSJjMgaLY+IGhwSKEkSZIkKQMZEDSLZzmDQJIkSZKUuQwImrnEQJIkSZKUyQwImhkQSJIkSZIymQFBsw0zCJqcQSBJkiRJyjwGBM3i6zsIEnYQSJIkSZIyjwFBs5hDCiVJkiRJGcyAoJkzCCRJkiRJmcyAoJkzCCRJkiRJmcyAoFncDgJJkiRJUgYzIGgWizbPIHBIoSRJkiQpAxkQNItGAoLADgJJkiRJUmYyIGgWBAGxaMQZBJIkSZKkjGRA0EI8GrGDQJIkSZKUkQwIWohFAwMCSZIkSVJGMiBoIWYHgSRJkiQpQxkQtBCLRmhIOINAkiRJkpR5DAhaiGfZQSBJkiRJykwGBC04g0CSJEmSlKkMCFpwBoEkSZIkKVMZELQQi0ZoaHIGgSRJkiQp8xgQtBCPRmhM2EEgSZIkSco8BgQtxLKcQSBJkiRJykwGBC04g0CSJEmSlKkMCFpwBoEkSZIkKVMZELQQt4NAkiRJkpShDAhaiEWdQSBJkiRJykwGBC3E3MVAkiRJkpShDAhaiGU5g0CSJEmSlJkMCFqIRyMkknYQSJIkSZIyjwFBC7Fo4BIDSZIkSVJGMiBoIRaN0OgSA0mSJElSBjIgaCEWjdDQlCQMDQkkSZIkSZnFgKCFeFbq6UgkDQgkSZIkSZklqzUHBUGwCKgEmoBEGIal7VlUusSiAQCNTUliUbMTSZIkSVLmaFVA0GxyGIYr262SHcD6UKAxEUI8zcVIkiRJktSBfJu8hfUBQUOTOxlIkiRJkjJLawOCEHgiCIIZQRBcuKkDgiC4MAiC6UEQTC8vL2+7CjtQfH0HgQGBJEmSJCnDtDYgmBCG4ThgCvC1IAgO3PiAMAz/GIZhaRiGpSUlJW1aZEeJZX0yg0CSJEmSpEzSqoAgDMOy5ssVwAPA+PYsKl1idhBIkiRJkjLUVgOCIAjygyAoXH8dOAx4p70LS4cNMwgSbnMoSZIkScosrdnFoAfwQBAE64//WxiGj7VrVWniDAJJkiRJUqbaakAQhuEHwOgOqCXtXGIgSZIkScpUbnPYQiyaGlLoNoeSJEmSpExjQNBCLGt9B4EzCCRJkiRJmcWAoIUNMwgSdhBIkiRJkjKLAUELziCQJEmSJGUqA4IWnEEgSZIkScpUBgQtfNJB4AwCSZIkSVJmMSBoIZ7lEgNJkiRJUmYyIGjBGQSSJEmSpExlQNDChhkE7mIgSZIkScowBgQtOINAkiRJkpSpDAhacImBJEmSJClTGRC0EI0ERCOBAYEkSZIkKeMYEGwkFg1oMCCQJEmSJGUYA4KNxKIRGhPOIJAkSZIkZRYDgo3EoxGXGEiSJEmSMo4BwUZiBgSSJEmSpAxkQLCRWJYzCCRJkiRJmceAYCOpDgJnEEiSJEmSMosBwUbi0QiNCTsIJEmSJEmZxYBgI84gkCRJkiRlIgOCjcSiziCQJEmSJGUeA4KN2EEgSZIkScpEBgQbiWc5pFCSJEmSlHkMCDZiB4EkSZIkKRMZEGwkFg1ocBcDSZIkSVKGMSDYiB0EkiRJkqRMZECwkXjUGQSSJEmSpMxjQLAROwgkSZIkSZnIgGAjsazAgECSJEmSlHEMCDYSi0YcUihJkiRJyjgGBABNCahbBziDQJIkSZKUmQwIAJ6+Aq7eDXAGgSRJkiQpMxkQAMQLoKkemhqJRSMkkiHJpF0EkiRJkqTMYUAAqYAAoL6SWFYAQINdBJIkSZKkDGJAAJDdHBA0VJEbiwJQ19iUxoIkSZIkSepYrQ4IgiCIBkHwZhAED7dnQWmxvoOgoZq8eCogqGkwIJAkSZIkZY5t6SD4FjC3vQpJqw1LDKrIi2cBUNOQSGNBkiRJkiR1rFYFBEEQ9AWOAm5p33LSZMMSg0o7CCRJkiRJGam1HQTXAj8ANju5LwiCC4MgmB4EwfTy8vI2Ka7DfGqJQaqDoLregECSJEmSlDm2GhAEQXA0sCIMwxlbOi4Mwz+GYVgahmFpSUlJmxXYIbJbLjFY30HgEgNJkiRJUuZoTQfBBODYIAgWAXcDBwVB8Jd2raqjxT/ZxSA/2yUGkiRJkqTMs9WAIAzDH4Zh2DcMwwHAacDTYRie2e6VdaQNQworyXVIoSRJkiQpA23LLgY7r1guBBFoqCbfIYWSJEmSpAyUtS0Hh2H4LPBsu1SSTkEA8UJoqCLXgECSJEmSlIHsIFgvng/1VcSjEbIigUsMJEmSJEkZxYBgvewCaKgkCAJy41G3OZQkSZIkZRQDgvXiBdBQDUB+PItalxhIkiRJkjKIAcF62QVQXwVAXjxKtUsMJEmSJEkZxIBgvXgBNDQHBNlROwgkSZIkSRnFgGC9eAHUVwKQF8uyg0CSJEmSlFEMCNbL/mQGgR0EkiRJkqRMY0CwXsslBvEo1QYEkiRJkqQMYkCwXrwAEnXQlCDPXQwkSZIkSRnGgGC97ILUZUOluxhIkiRJkjKOAcF68fUBQTV58Sxq7CCQJEmSJGUQA4L11ncQ1FeRF4/SkEiSaEqmtyZJkiRJkjqIAcF6GzoIUgEBQE2jXQSSJEmSpMxgQLDe+oCgvpK8eBYANfUGBJIkSZKkzGBAsF72JzMI8rObOwgcVChJkiRJyhAGBOu1WGKQG1sfENhBIEmSJEnKDAYE67VYYpCf3bzEwIBAkiRJkpQhDAjWy27RQdA8pLDaJQaSJEmSpAxhQLBeLA+CSGoGQfOQwlo7CCRJkiRJGcKAYL0gSC0zqP9km8PqejsIJEmSJEmZwYCgpXg+NFRuCAhqG+0gkCRJkiRlBgOCluIF0FBNXvMSg+p6AwJJkiRJUmYwIGgpO7XEICcWIQig1iGFkiRJkqQMYUDQUrwAGqoIgoC8WJRqhxRKkiRJkjKEAUFLzUMKAfKys6gxIJAkSZIkZQgDgpayUx0EAHnxKDUuMZAkSZIkZQgDgpbiLQMCOwgkSZIkSZnDgKCl7BZLDOwgkCRJkiRlEAOCluIFkKiFpkRzQGAHgSRJkiQpMxgQtBQvSF02VqcCgnoDAkmSJElSZjAgaCm7OSCoryI/nkVNo0sMJEmSJEmZwYCgpfUdBA1V5NpBIEmSJEnKIAYELcVbdBBku4uBJEmSJClzGBC0lN2igyAWpbaxiWQyTG9NkiRJkiR1AAOCllosMcjPjgJQ22gXgSRJkiRp57fVgCAIgpwgCF4LguCtIAhmB0Hw/zqisLTILkxd1leRG88CoLrBQYWSJEmSpJ1fViuOqQcOCsOwKgiCGDAtCIJ/h2H4SjvX1vHi+anLhkry480dBM4hkCRJkiRlgK12EIQpVc0fxpr/7ZwL8zcsMagmrzkgqHYnA0mSJElSBmjVDIIgCKJBEMwEVgBPhmH46iaOuTAIgulBEEwvLy9v6zo7RjwfCKC+irzmJQa1jS4xkCRJkiTt/FoVEIRh2BSG4RigLzA+CIIRmzjmj2EYloZhWFpSUtLWdXaMIEh1ETRU2UEgSZIkScoo27SLQRiGa4FngSPapZodQTwf6is3dBDUOINAkiRJkpQBWrOLQUkQBMXN13OBQ4B327uwtMku+NQMghp3MZAkSZIkZYDW7GLQC7g9CIIoqUDhnjAMH27fstJo/RKD7PUBgR0EkiRJkqSd31YDgjAMZwFjO6CWHUN24aeGFNpBIEmSJEnKBNs0gyAjxPOhoZLcmB0EkiRJkqTMYUCwsXhqBkE0EpATixgQSJIkSZIyggHBxrILoL4KgPx4FtX1LjGQJEmSJO38DAg21jykECA3HqXWDgJJkiRJUgYwINhYvAAaayDZlOogcEihJEmSJCkDGBBsLK9L6rJmNbnxqDMIJEmSJEkZwYBgY0W9U5eVZeRnGxBIkiRJkjKDAcHG1gcEFWXkxrIMCCRJkiRJGcGAYGOF6wOCJc0dBM4gkCRJkiTt/AwINlbQHYIoVJSR5wwCSZIkSVKGMCDYWCQKhb2gYil58Sxq6u0gkCRJkiTt/AwINqWoN1QsSXUQNDYRhmG6K5IkSZIkqV0ZEGxKUa/mJQZZhCHUNSbTXZEkSZIkSe3KgGBTivpARRkF8dTTU1nXmOaCJEmSJElqXwYEm1LUGxqrGViU6hxYUF6d5oIkSZIkSWpfBgSbUpTa6nCPvEoA5i2rSGc1kiRJkiS1OwOCTSlMBQRdm1ZSnBdj3vLKNBckSZIkSVL7MiDYlOYOgqCyjCE9Cnl3mQGBJEmSJGnnZkCwKYW9UpcVZezRs5D3llWSTLrVoSRJkiRp52VAsClZccjvDhVlDOlZRHVDE0vW1qa7KkmSJEmS2o0BweYU9WoOCAoBXGYgSZIkSdqpGRBsTlGfTwUE7mQgSZIkSdqZGRBsTlFvqFhCQXYWfTvn2kEgSZIkSdqpGRBsTlFvqFsLDTXs0bOQeQYEkiRJkqSdmAHB5hSmtjqkcilDehbywcpq6hNN6a1JkiRJkqR2YkCwOUXNAUHFEob0LKIpGbJgRXV6a5IkSZIkqZ0YEGxOUZ/UZUUZe6wfVLjcQYWSJEmSpJ2TAcHmFPVKXVYsYWC3fGLRwEGFkiRJkqSdlgHB5sTzIacTVCwlFo2wa0mBgwolSZIkSTstA4ItKeoDFWUA7NGzkPcMCCRJkiRJOykDgi0p6g0VSwAY0rOIsnV1rKtpTHNRkiRJkiS1PQOCLSnqvaGDYK8BnQF49r0V6axIkiRJkqR2YUCwJYW9oXoFJOoZ178zfYpzeWhmWbqrkiRJkiSpzRkQbEnvsanLV24kEgk4ZnRvnn+vnNXVDemtS5IkSZKkNmZAsCW7Hw7DjoOnr4SyNzluTG8SyZBH316a7sokSZIkSWpTWw0IgiDoFwTBM0EQzA2CYHYQBN/qiMJ2CEEAR18L+SVw3wXs0TXKbt0L+KfLDCRJkiRJO5nWdBAkgEvCMBwK7AN8LQiCYe1b1g4krwuccDOsmk/wxP9y3JjevLZoNUvW1qa7MkmSJEmS2sxWA4IwDJeGYfhG8/VKYC7Qp70L26EMmgj7fg2m38qJu9QD8K+37CKQJEmSJO08tmkGQRAEA4CxwKubuO3CIAimB0Ewvby8vG2q25HseTYAvde9wdj+xe5mIEmSJEnaqbQ6IAiCoAC4D/h2GIYVG98ehuEfwzAsDcOwtKSkpC1r3DF0HQx5XeGjVzludG/mLq1g7tLPPA2SJEmSJH0htSogCIIgRioc+GsYhve3b0k7qCCAfnvDRy9z3Jg+ZGdFuPOVD9NdlSRJkiRJbaI1uxgEwJ+BuWEYXtP+Je3A+u0NqxfQOVzHcWN688AbS1hX05juqiRJkiRJ+txa00EwAfgv4KAgCGY2/zuynevaMfXfJ3X58auctd8Aahub+MeMj9NbkyRJkiRJbaA1uxhMC8MwCMNwVBiGY5r/PdoRxe1weo2BaBw+foXhvTux14DO3PHyhzQlw3RXJkmSJEnS57JNuxhkvFgO9B4HH6U2cThrvwF8tLqGZ+etSHNhkiRJkiR9PgYE26r/3lD2JjTWcvjwnvQsyuG2lxaluypJkiRJkj4XA4Jt1W8fSDZC2ZvEohHO2Ls/L7y/kveXV6a7MkmSJEmStpsBwbbqt3fq8qNXADhjn13Ii0e5/un5aSxKkiRJkqTPx4BgW+V3ha67wcepOQRd8uOcvd8AHp5VxrxldhFIkiRJkr6YDAi2R/+9UwFBMgnAhQcOIj+exbVPvZfmwiRJkiRJ2j4GBNuj/75QuwYe+hqsmEtxXpxz9x/Iv99ZxuyydemuTpIkSZKkbWZAsD1Gfgn2ugBmPwA37gN/O5Xz9upKYU4W1z71frqrkyRJkiRpmxkQbI+sbDjq1/Cd2TDxf+C9x+g09+9ccMAgnpyznLcX20UgSZIkSfpiMSD4PPK7wuQfQa8x8NZdnDNhAEU5WfzuabsIJEmSJElfLAYEbWH06bBsFoXr3uecCQN5Ys5y3l1Wke6qJEmSJElqNQOCtjDiJIhkway7OWfCAPLjUW54ZkG6q5IkSZIkqdUMCNpCQQkMPhRm3UNxTpT/2ncAD88qY0F5VborkyRJkiSpVQwI2sro06ByKSx8jvMPGEh2VoSbnrWLQJIkSZL0xWBA0FZ2PwJyOsFbd9OtIJvTx/fngTeX8NGqmnRXJkmSJEnSVhkQtJVYDgw/Aeb+C+qr+MqBu5KdFeHS+2eRTIbprk6SJEmSpC0yIGhLY86Axhp45SZ6dsrhsmOG8dKCVdwy7YN0VyZJkiRJ0hYZELSlfuNh+Inw/K9gxbucUtqPw4f34OrH5zG7bF26q5MkSZIkabMMCNrakVdDvAAe+hpBmOSqE0fROS/Ot+6eSW1DU7qrkyRJkiRpkwwI2lp+N5jyK1gyHV69mc75cX5zymjmr6jiwjunU9OQSHeFkiRJkiR9hgFBexh5cmpXg//8FMrnccBuJfzq5FG8OH8lZ97yKmtrGtJdoSRJkiRJn2JA0B6CAI7+LWQXwO3Hwsr5nFLajxvP2JN3llRw6h9eYUVFXbqrlCRJkiRpAwOC9lLUG876FyQTcPvRsGoBR4zoydRz9mLxmhpOuvklPlxVne4qJUmSJEkCDAjaV/ehqZCgqQFuOxpWL2TC4G787YJ9qKpLcPLNLzN3aUW6q5QkSZIkiSAMwzY/aWlpaTh9+vQ2P+8X1vLZMPVIKO4P5z0JsRzmr6jkzFteo6YhwQlj+5ATi5IdizJlRE+G9iracNcwDLntpUV0zotz/Ng+aXwQkiRJkqQvuiAIZoRhWLrJ2wwIOsi8f8Ndp8FeF8BRvwZg8ZoavnHXmyxcWU19Y5K6RBPxaIRfnTyK48b0oT7RxA/uncVDM8sAuHjPAi4ZWUNWt8HQbbd0PhpJkiRJ0hfQlgKCrI4uJmMNmQL7fh1e/j0M2B+GH0/fznk8cO5IiBdAJMLKqnq++pc3+NbdM5ldVsHMj9by2qLV3LXHNEYs+QeFs8thNiTyexD9+qsEuZ3T/agkSZIkSTsJOwg6UqIBpk6Ble/BrgdB2Ruw9iPoORKOuAoG7E9DIsll/3yHu177mHg0wg1HdgeMXpgAACAASURBVOHQp46A/vvyduEB3PFWJVdFbuS+cDJ/7vwdTt2rH+fuPzDdj0ySJEmS9AVgB8GOIisOX5oKtxySCgd6j4NRp8HMv8FtR8HQY4hP+RU/P2Ek+w8uoW/nXEbPuRoI4MQ/MbJTHy6aWMW7j1RzyqLbeCs8hCsfreKQoT3o3zUv3Y9OkiRJkvQFZgdBOoQhBMEnHzfWwku/h2nXQMkeqUGG0Syor4RrhsNuh8DJt35yfEMN3DyBRFMT41ZdwZFjB3HVSaM6/nFIkiRJkr5QttRB4DaH6dAyHACI5cLE78Nxv091Frz8+9TnZ94F9etgn69++vh4HhxzPVnrPuSm3o9x74zFfLy6pmNqlyRJkiTtlAwIdiTDT4Shx8AzP4cV78KrN0GfUui7iXBn4AEw+svst+p+ugfruOm5BR1fryRJkiRpp2FAsCMJAjjqmlSHwB3HwuoPYJ+LN3/8gd8jSDbyyz7P84/pH1O2trbjapUkSZIk7VQMCHY0Bd1hytVQtRwKe8Ow4zZ/bNddYfiJTFjzEJ2o4ndPz++4OiVJkiRJO5Wt7mIQBMGtwNHAijAMR7R/SWLkybB6AfQaDdHYlo/d/ztE3rmXq/u/yjmv5TOoWz4XHDioY+qUJEmSJO00WtNBcBtwRDvXoZaCACZdCkOmbP3YniNg9ylMWnsfJw4v5spH53LLCx+0f42SJEmSpJ3KVgOCMAyfB1Z3QC3aXgdcQlC7hqsHzuDIkT352SOGBJIkSZKkbbPVJQb6Aui3Fww8kOhL13LdRacB8LNH5lKfSPLVSbsSbLytoiRJkiRJG2mzIYVBEFwYBMH0IAiml5eXt9Vp1VpH/BLqK4k9/gOuP20sJ4ztw9WPz+Oqx94lDMN0VydJkiRJ2sG1WUAQhuEfwzAsDcOwtKSkpK1Oq9bqMQwm/g/MfoCsd//Jb740mjP27s8fnvuA7987i5VV9emuUJIkSZK0A3Obw53JhG9DrzHwyCVEalfxs+NH8NVJu3LfG4uZcNXTXP7P2ZStrU13lZIkSZKkHdBWA4IgCO4CXgaGBEGwOAiC89q/LG2XaBYcfxPUrYPbjyH4y4n8oOzbvDX2EY4f1Z2/vPIhB/3mWR54c3G6K5UkSZIk7WBas4vB6WEY9grDMBaGYd8wDP/cEYVpO/UYBsdcC0EU6ishDCma81d+2f1Jnv3+JEb3LeY7f3+L/33wbeoTTemuVpIkSZK0gwjaY4BdaWlpOH369DY/r7bT/V+Bt++Bcx8n0buUqx+fxx+e/4DduhcwYXA3hvQspFtBNm8vWcebH62hvLKeHx45lIm7O0tCkiRJknYmQRDMCMOwdJO3GRBkgLoKuHkCEMBF0yCniMfeWcbNzy3gveWV1DSkOgkiAezeo5CGRJKFq6r55kG78c2DdyMacZtESZIkSdoZGBAIPnoFpk6BkV+CE/4AQepFfzIZsqR8NTUfvEqf0ZMoyMujtqGJHz/4Nve/sYQDduvGZccMY3D3wjQ/AEmSJEnS57WlgMBdDDJF/31S2yDO+js8cgkkkwBEalfT71+nMuTx0ym4YRQ88X/kVizkN18azVUnjmT6ojUc+tvnuejOGcxavDbND0KSJEmS1F7sIMgkYQhPXQYvXgcjT0kFBn87BdYthsk/gsWvw3uPpY77r/th0CRWVdVz20uLuP2lRVTUJThqVC9+OGUP+nbOS/ejkSRJkiRtI5cY6NNe+A3854rUTgfZhfDlv6c6DAAql8PtR6fmFlz8IuR3S326rpE/T1vIzc8tIAzhoom78rXJg4ln2YQiSZIkSV8ULjHQpx1wCRx1DfTZE8574pNwAKCwB5w8FWrXwIMXb1iKUJgT49uH7M5/LpnEYcN7ct1/3ufS+2bRHgGTJEmSJKnjGRBkqr3Og/OfhJIhn72t5wg4/Ep4/wl49eZP3dSnOJffnT6W7x66O/e/uYQbnpnfQQVLkiRJktpTVroL0A5qr/NhwTPw5E+gUx8Ydtynbv7GQYNZuLKaXz/xHgO65XP0qN5pKlSSJEmS1BacQaDNq1mdGmK4+HU44Hsw+ccQiaSGGNZXUp+Vzxl/epW3l6xj0pASinPjFOdmUTqwKwfs1o2cWDTdj0CSJEmS1IJDCrX9EvWpbRHfvBMGHACxXFg8HWpXw6Qfsar02/zw/rf5cFUNfatn8/PGX3JN4mQejh7CpD26851Ddmdw94J0PwpJkiRJEgYE+rzCEF6/JbXzQVEf6Lsn1K6Fdx+Gw66E/b4OS96AO46H+nUksvK5ere/cNfcRnJiUe69aD/6d3VbREmSJElKNwMCtY0whCBIXU82wb3nwpwHYf/vwPSpkFMEx90Ifz0Zdj+c9ybewCl/eJlOuTH+cdG+dC/MSW/9kiRJkpTh3OZQbWN9OAAQicKJf4LdDodpv4V4AZz1MAw8AA78Psx5iN3XvczUs/eivLKe//7za6yoqEtf7ZIkSZKkLbKDQJ9PYy28chOMOBE6D0h9LtEAN+8PiVr46qu88GE15972Oo1NISP6FHHAbiXs3qOA4rw4nfPi7NGz0IGGkiRJktQBXGKgjrfoRbjtSNj1YDjpFt6vjPHYO8t44f2VvPHRGhLJT37udu9RwB3n7k3PTi5BkCRJkqT2ZECg9JhxGzz6fcjvDqfcDn1TP4PV9QmWV9SxpqaRhSurueyhdyjOi3PneeMZVOKOB5IkSZLUXgwIlD5lb8I9/w0VS6HHcGhqgKbG1JKEiZdCJMLbi9dx9tTXCIGpZ+/F6H7F6a5akiRJknZKDilU+vQeC195HsaeCQXdocsgKOoFz/0S7jsXGusY2bcT9168H3nxKF+6+WVunbaQ9giuJEmSJEmbZweBOl4YwkvXw5M/gX77wIl/hOL+rK5p5Af3vsVTc1dw0B7dufyY4fTpnEs0Emz9nJIkSZKkrXKJgXZM79wPD1wETfWQXwI9RxEOPZY76g/kyn/PoyGRJCsS0Ks4h/0Hl/B/Rw8lL56V7qolSZIk6QvLgEA7rpXvw4KnYeksWPw6rJwH/fbm4wk/5/l1JSxZU8uiVdX8+51l7N69kJvOHOcgQ0mSJEnaTgYE+mIIQ3jrLnj8x1BfAePOglGnQN/xPD9/Fd+6+00STSG/OGkkR43sRRC49ECSJEmStoUBgb5YqlfBUz+BWf9ILT8o6gO7TmZdbj9ufjvk3vJ+9Ok3kO8dNoQJg7saFEiSJElSKxkQ6IupvhLmPQazH4Al06FqOQB18c6cxG+YXZFD6S6dOX18f6aM7Ol8AkmSJEnaCgMC7Rzqq2DJDPjryTQNPow7+v2U21/+kEWraijIzuLoUb34UmlfxnVtIlg2C3Y9CFrZXbC2poHivHg7PwBJEmHY6t/NkiSp7W0pIIh0dDHSdssugEETYfKPic57mHOKZvDM9yZxz1f2ZcqInvzzrTIuvfkfrPjNvvCXE3n3lvO57/WFvDh/JU3JTQdhDYkk//fgO4y54klueGb+5r92UyLVyVCzup0enLSNkk3w/lPQ1JjuSqTWW7UAruoPc/+V7kokSdIm2JOtL579vgHvPgyPfo9g4AGMH9iT8QO7cMWolUT/cQXVyRh/bTyYM5bcS/lH73Jx47fo0rWE8w4YxMnj+pIbj8K8x2h65Hv8JzGWl9fsz9Bew7j68XnUNjRxyWG7EwQBb328lodmlrFP1yoOmfNjIotfI9ljJP8YfiN/eauCHkU5TBxSwsG96sku7s2aelhX28huPQooyoml+1nacS18AWpWwvAT0l3JF9t/roAXr4WDfwIHXJLuapRuH76UmtfSeZd0V7JlT/8sNYT2hd/AHkenr5NgwdMw799w+M8h6u9rSZLWc4mBvphWvg837w+d+kFxv9S7qB+9DN12hy/fQ0NBHxpm3En+45dQld+P78V+zONlueTGouxdsJyb6v6HijCXzmEF8SBBuMsE7mmaxOXzd+XoPQezZG0t0xcsY0r0dX6adSuRIOTFLicxefXdzE3256ddfsG62ia+XH07Z0Wf4OXkMM5t/D71xCnMzuKs/QZw3v4D6ZyfAcsWkkmItLIZaebf4KGvAyFc8DT0Htuupe205jwE9/w3xPIglgvffhvi+emuSulSNhNuORi6DoaLXoToDpr9l82EP05M/Z5e+R6c+wT037vj66hZDb8vhZpVsPdFMOWXHV+DJElp5AwC7ZzevhdevgEiUYhkQZdd4YifQ06nT45Z9CL8/QxCAt6ddBP/XFLEuXPPI9ZUx0+6/46LDxnG0GUPwfSpsPZD6iO5PNk4il2y1jCMhUTDRiq7jua64kv5+4Io55XM45sr/x9Bj2GpPy4rylhcMpF+5c+yrMck3jngBu5/azlPvrOYY2PTGV1YQTKRIJFsYlXX8Rx46HHsM6jLlndeqCqncsZdVK1aSrfRRxIbsM+O+w5X5XK4/ejUO5dfmgq5nTd/7IvXw5P/BwMnQvk8KOgOFzyz476Y2VGteDf1YrD7UMKDLyO4/WgW7/Vj3tv1LPbbtRs5sWjrzlO1AnKKIWujEGvm36CwZ2qGh3Z8iXr4w0RY+yE01sAx18GeZ6e7qk2780QoexMufglu2BsGHwRfuq3j63joayRn3s3LsfFMaHiJh3e9nPi40zl0WA93xZEkZQQDAmW2VQvgb6fCmkXQbbfUx2c/Av32+uSYZBI+eplw5t9IvPck0a6DiPQfD33Hw+6Hf/oF+px/wj/OhpIhcMz1qfO8/md45Luptvn++9H4wrXEqpZ8ppQ7E4fwYMlXOHW/oUwZ2ZPClksRFr5A8qXrYf5/iIRNJMIIWUGS6kgBi3sdyrr9fszA/v3pVhDfMf6IrV0Ltx0Nq+ZDMgFdBsIZ/4DOA6CuAt59BJa9DdXlsG4xfPQSDD+RmqN+T8OcRyl++Hw47GepJSNfEGEYpve5r14Jtx4OdeuYdvB9fOPh5fyu8XKGRBazf/11jNylB38+ay865TX/XC17G574v9QL/lGnpMKZFXNg2rWpmRo9R8CX72FxooiC7CyKp1+XagHPLoKvT4fCHu36cJLJkKUVdfQpzm3Xr7PNKpfBx6/Cx69BvAD2+zpkF372uGQSnr8a3v0XHH0t9N3k/2c/n9o18OgPYPSpMPiQz97+5GXw4rXMO/hWiqZfT2HNR/xmyN1MGDaAQ4a17/dvmyx8Hm4/Bg67MvV8PvG/8PKN8O1Z0Klvx9WxaBrcdhQ3Nx3L/Z3O4le1lzEk8R4nNVxOzyHjueqkkXQvzOm4eiRJSgMDAql2Taole+HzcPzNMOb0z3e+ijLIL/l0cPDS71J/9AL02ye1LnzggakOh6YGEv+5kuirN7IsKOHy+jOYFtmTycP6ML5fPnsu+D3DF93ByqAL9zTuz5J+xzJhzzGseftxOn/8FIc0Pc9aCvmfxgt4r2g/vjp5V04p7Ucs2srW/jCEV26Cab+Fw68kHPkl1tQ00jkvtn0veBtq4C8nwuLp8OW/Q1Y2TXedQW1TwOzYCMbWvkqcBuqDHKpjnWnI7sb8wr24puEEZpVVkUgmuTV+DftG3uFnu0yl/6A9GNu/MyP7dErNiGiF8sp6/vVWGcV5Mfp2zqNfUUDPLsXt8gJ+5ocrefyu64k2VBDtM45+w8YzYmBvdumS3+p6t6ixDp77Jcz9ZyqU2u3Q1Dv4ucWEYUgiGRJb+kbqZ7hmFU+X3swFz2ezR89Cvj5wGVNmnM8bwy7l1LdGs2tJAXecsxcl795J+MT/UhfJIxo2kp2ooim7mGj9Wppi+SzvfxTdFv6LNWEBZ9Z9n8Oib/D9rLtZ2nMyPctfJBx2PJGT/rT9j2nxjNT2pHudTyIMWFFZT69OORu+Px+UV/HD+9/m1YWrOXu/AfzoyKHEs1r381xdn+A/767g+XeXsUu3Qg4e2oOhvQo/+71PNpF84y9Qt45Ij6FQsgdrsrrz/PyVTHt/JT2Kcrhw4qBPZoZ88Bw8/VNY/Hrq7pE4QbKRREEvqg7+Jfkjj/6kxoYaePCi1HKPeCEk6lKB195fabt19Q3VcMfxsPg1iOXDuY9Br1Gf3P7x63DrYSzqfwKT3zuJ0cznweyfcGN4Er9uOInfnjqG48b0aZtaPo9EPUydkgpevvEGxHII13wI149h/m7nUXT0z+hRtNGL8to1qee1LTuMEvUkbtiP5WsqOD//9/z9GwdRlFhD+IeJNNRWMb1hF5ZFutN32D4s6HcSy6uaCMOQs/YbQNeC7LarQ+pIHbVrSLKJqveepym3K512GbX143dmYQjT/5zq+Dv0Cojnpbsi6TMMCCRI7USwZmGqi6C9zH4w1Tq/y36bvv2jVwgf/CrB6gVUZxXzz8S+jErOYXjkQ+5IHMqfcs7hh8eNY8qInhte7IRhyKr5M8h95Kvkr53HUzmH8d21J1PcpTsXT9qV/QcV03fmbwlm30/lgMP4d86RPL2iiGgkIDsrQteggi8vvYqBa16kPrsrsfrV/DZ2Ib+rnMiArnkcM7o3R47sRSwaYVVVPZVrV9KpuAu7dCukpDD70y+6KpeRmPc4ta/eRkH5m8ze77eU73IU/5pZxttvvc4fYr+ha6Sal3In8VLeQcxMDqZsXR2rqhuIRyOM7teJ8QO70KMoh7VlH3DhO6fzQdCP6+qO5tnkaBqCOGOK6zmqYB7985tg7H8xakAPenb69IuH594r55J73mJlVT1dqOAnsTs4PvoSLzOSJ7t8mUT/A+hSkE1hToyinCx6F+fSr3MevYpzCIDaxibqGpN0zY8TiWz+D6dkMuSf/7qXITOuYGjkow2fbwoDnk2O4bLEWSQK+7NL1zwGdM1nl255DO1ZxN6DupAXb35hE4apYWhrP4QxX96wBKamIcFj7yyjfM5znLT4KrrVfcSSTnvSuep98poqaCLCO5E9eCoxmvpkwPez7qE6uzv3D/4FV8yIccBu3bjpzD0pyM6CW6fAmkXMGft/PPrsNPaPzmafcCbPNI3m+4mLqAxzOSjyJodHX+f9ZF/ubDqECgoYHV3Ibdm/oZAaspJ1PB45kItrLuRbWffxrawH+EbsCpZ3HU/v4hx6FecSCWDJmlrWrF5FU1OCTl2607s4hyE9izh0WA865cZSYcezv4CXrocwSfXgY/jvteczY3E1/bvkcfiw7vRkJQ++MpfirHpG9evKDe8XM7Z/Z2748jh6t+gmqGlI8MCbS3hoZhnJZEhuPJr6u2vRSr4UPsH/xP7Ow4m9+UniHLp1KmTPAV0Y3ruIIT0KWbFkIaNe/wFD62Z+6nu6OixgZnIw70Z354PGzuTFYxw+vITRa56iYMkLrIx04/bkEUyr343Z4QBGBAv5RewWhkQW82pyKCtyBhAp7sf42hfoVvkuy/b+EWt2O5XcR7/GwNUv8BKjKM8bTGGnLmQX92JO0f4sbiigtrGJ0l26MHFICT2Kckg0JflgZTUflFeRFYmQn51FYU4Wu3TNS3UWJepTnU8Ln6PxiF+R9eK1BGEyNbujsCe89xg8cgk1jUn2WftThg/sx81n7knRIxfAvMe4qMufeGpxlN+fPpYpI3tt7TfXZjU2JamsS1BZ10h2VvQz/y1uUcVSmH4rzLgNqlcQHncjr3U6gr9P/5iX5q/istpfsE9kLgeHN3Le5OGct//A1BKZBc/A3V9O/a4+6VboNnjDKavqE8SiAdlZWw/mpi9azc3PfcCqdes4p9s8Jlc9TGHZi5zf9EN+8PWvsXuP5q6QZe/AtN9SV76AuhUfUByu4/mmkXwj8Q0qKaBTbozLj9qNY7uvJMjrAoW9CGO51DY2UVWXoLaxiZKCGHlhber7ll9CfVOS8sp6ehblkNXaILcV6hqbiEaC1ofDLS17G+Y/BXueA7nF219EzWp47U9UFg9hdsG+fLSmgb0HdWGXrm04B6UpAclGiOUShiHJEKJb+F2tTWhKwIu/TXXqHH3NZwcD16xO/f8okvpvaV1tIwtXVrN4TQ179CxicPeC1n2dpbNIvPEX6mfeS37jKprCgBdLTmOXk37KLr1KPv/j+OiVVBA7+BAYNLn1M48+r6ZEqkOsuB+MPbP196tZnZq1NO+R1Me9x6XeSCno3j51rtdQk5pJ1B5hUGNt6k2m+grY75uQ16Xtv4Y6nAGBtCNpakxN0H7rLsJ3HyWMF1J1xLU07noYRbmxzf/hl6iHZ39B+OL1NGR35v+3d+dhclV1wse/p27t1VVdXdX73lm7k3QWkpCFLAQkQEBBBQRRURB4R3gVxHEbnRHHV4F5HNFXZGQQYUBBBJVFwha2AFkgZOtsnd6S3vfuqura7z3zxy2SzkoCaULwfJ6nn+6691b16epfnar7u79zzn9qV/NUfym/tP+auZZ6dmiTmZBuwCZ06iyTSQgnFpmi0mjDLWP8e/oL/Flfyt2O/89ZYgNrKr/GQ4lFvNkSQZM652hvc7H2BvMsOxmSHt40prJBTKU8y6DW1kFFupngiLkUZIcM8PPUZTxuLAHAZdO4cl451y6uosDrOOQNPJbUEYJDx8dveRRWfgdiA6StboZtBQRjzft2NxjFfDt1HW1Ztcwo8zOzzE9vOMH9b7ZQne/i3lnNFK37d0QyQlPRBRR0r8ab7mebHMfK9GzeMqrZJiuotTSzzLKJeZYd9EsfO2U5u4xSvA4LM3JSTPSlGXaVsUmbzs64n3R0mCkja5kbeYVF+jr6rfk4L7gdz/gFyI6NDO16He/W3yMNnefyruZBLqBpIEFvOAGATRPMqQjwaf9uzmr/L3KH6wBI2rOpq7qaF+R8krteYKmxjkVaHZ0yl++kvsrrRi3ZDgtLPC0ss2xibmoDZYndALxjn8O1kevpNzx8ZlYJt312+v6r2Y0vw4MX73veBoWfldmXoS28geVTi7EIQWNfhJa+ESxC4HVa8TptTC7wkp3sNCsT8qdiXHgnG9vD1Lf1cv5rF5OQVm4K3EXnUIy88A4WijrOsm1lmqxHInjNupB742ezPj2OKVonny3u5eLYX8mONDIy7Uqa0nnU7ryTN5nO5vl3QsMLLOl9mKmi5YAwGMqZxrcGLmadmM7sIgdnWuuYFNtIZ98Aelon221j0FnOLss4+qWXm/X7qYpsRBZMQ3TX0eefwX/4f8DrXVYGhwY5y7KRW2334xZJnim9me7is3EPNeANNzBJb2BCcgfOod0I9r//Dcgs7kpfzFt5n2FGZQHlATelOS6ynFbCI1GKt/83RW3P4Yl3kmWECUsX30jdwEvGaZlHkPxr4CU+m3oSZyqEAzMW0tLCG2IWf7cs5cloLXEclAfcdIXiJNPGvt+/wLKN67WnMRDEbDmMs/VTk9jCj8QN3B87gzP9Xfw2+S8kfOOQ7gDZHasZ8lTx5aFrsJfP4f6vzDWTUgPN8Ou5SM3OkG4nqmsIbyHhwFRGAlOI59ZCXjVutwdNCJIjg9jb10D3dmKDXchINwNJKw9xPhsSpcRT+9soBFw2u4xbzp1kluGnE7DhAWhcRaLmM7yTtYyGvihBLcrMpnsorH8IYaTpL17KxsLP8fOmUnZ2hfE5rSyZlMcn/S2cu/4rbHIv5MbByxA5FdxUspuLG/+FpLccLdYH6ST3+2/kxXg1xZFtVBv1eEQcYfNgd2Xh8PjwZHnxerOJB6fQ6ZxAOJ7m+e1d7Ghp5xbnU1wqVpElI3RLP/emV1B72Q/51Iziw3azKd2g97V7KVr9ffCX0bboNta8+BeWjawkTwzvOy4sXehYEEgEkiziWIQZT2vETH4Y/zwNshSPXWNuVYAF44JUF/moDLop8bvoiyTZ0RliR1eIvlCCVCyEJdpDKKXRlvIynDT71WK/i6JsF+F4isa2Dub1P4HVZkPO/SpXnjGJQp+Tlv4obzX1YESHWDyljJK84L6TBCkl4XgK28bf41z1Q4SeIOUMsmHC11njOw+f20GO20bAY6cy6KE0x7U/oRHpgc7NDOeeRv2woL47zHDLZj5b/20K9E4A2mWQP6bP5m/GYmbVTuP/LB1PedBNKJYiHE9T7HeZicNjpadg44Pw6h3IkV7aPVN5PjaZ5+LTMErmMKsiwGnlfmaVZVPQu8Ycwjb1M4fOpfJ+6WmzgiingrirgL0DUdx2jTyv4z2TUkPRJC9s7yYcT+Nz2fA6rUgpiSR0osk0xdkuFpcKHK/+FJIR0vNuZH2ilPXNA9S1D7O1fRirxcLn55VzxenlBEZPcny8VQADzfDX682hUp58iA3AZQ9C9QrzOV71Y3jzV6S9JazLXsEdPXPZEXLgJYpLJOiUQcYXZHPetCLOqSlgarHvkGS63LOG2Et34N7zEkmsrNJn0V6ygtrUJub1P0GzUcDThTdQNf8izppWui9pHk/pDIwkiWcS9QA5Hhs5bvuBnxHSSXjlp8jX7wRAIOmx5PGscTp+m06JdRifliY04SJKllxFYcB3zE+PlJLG3gg5bvvhq4MSYdJ/+jLWphfNpsy5DuuK2/YlU0Y9kDmcsmMjUlgYjOk4t/4Be6KP/7JdRVM6yM+k+Zmt84IHGT91zrElurrqiG34I519g7QPRuke0enMmYtt0tnUVhZS7HcR8NjxOa0IKWHtXfDirRgVi9hS+z1eGwxQ7HexYHzwqEP4osk0r9X3smpHD/k+B19eWEWed9TzIaW5athz34ehvUhhIWXzsaroWla5VzAhYGNSVpQy0Yc/XI9neDc2UtjmfNm8UHYsMZsIM9TfTXNrB91DIYprFjCtNHDUizeHFe4GYYGsPPojCbY0d5Lc/DjlbU/SZy9jx7RbmFheQkmOiyyHFY9V4rVbsNg/4JAyQzdfb6MS2acKlSBQlI+qRNicYNF2HGOwOzfDk1+Hzk0YFju6sPKnwm+xUpzB8nLBRcaL+NteNjtKzQ4uP6nF36HHPYHhaIoJQQf2p2+ArX8+5KGjvvFExl+IPtyOr+N1PPEuALrIZYdeQp11Kslx5zBt1gLKhu7ogAAAF05JREFUAh6SukFKN5iQl/X+V2zQ07DndbP6YrgVKs6A8ctIhnqQT92MfaSDtf4LWB2rYmPYhyEt3FSyk/nx1YhIF5TNM+eCyK82r15vfhje/h2yq+6AE0DdYqMjqxZnOkwg1owm0/v2GVLs+3DfLXIJyCFspBm2+GkbfzlTLv1XxMGrBAy3wd+/BfUrzfJvbyG6p4BwCpLD3djjffjlMO0yyJ3pz7LLKOOb1sc4U9u87yHivkocMy5BLLoZ3eYhpRuHJlFCnTDQCOULiaQMWgeiTC7wHvrm2bzaXNUgOO7ok0Ueq/rn4Y+XQu5kGNoL6RgSgSiaARPONq8obPwDJIaRQkNIHTBPGL6f+iqvGjMA+OeCt/la6E6ExQp6Ej0wgf6aL5BfMs4c3z/cZl6lGW6lwzGeYKINBwmi0kHSmoXL6cAuDPN//S6HD877Gcy80ryy9Ld/Mq+E+YqRHZsQUicZnIL98gcgb9Lh/754CGIDSClZ3zJIp+5j4eRS8g8udT8MmYgwFEvTPiJoG4yR1A0WjAse8MHKSCUYattB9u6/oG19FMKdGFYXzTln8Ko4HYLjKSytYnyOlYL1P8PfspKYq5CwloMt3o9NH+Hx7K+ws/xz5HmdbO8IYW18nrvEHURw8Yv0JTykf4KZFXk8cPXpeByjSvHrn4OGVSSTMd7c2Y4r2k6N2INPxABISo3d0hz3XyP27ov9kHQT0nIIykFcMkpj9nx2Fn8aq8uLy+6gZSDOs9u7sVg0rqiKsqjjfrJT3QwLH9kyRINRzHPGHD6vvUQ2IzyqL+U3+kXsleZcCDVFPr68sIJPzSgxh+ZIaS7V+eodGHqaV22LWBx/hTpZxVXJ7+AiwS/tv2GeZce+P00XNhKaB6sewy4Th/xv1hnV3Jc+j3J3ipstj+BO9sPUzxCacgXPxyajaRqfnnUMcx7sXQt/+gKM9CIRtOYu5oHI6fgdkip7iEIthEMzr+RbNAvDupOetJN0NMTy0F9wGDEayi+hIZ3PYF8XItpHQETIEWEChLGTwoLEIgxyiOAW+/8WA0FY89NuLecdOZnV8XGcpjXyBZ7BI0cAaJEF3Jr+Mnud1Zwbf5YrrS9SIvr33T9izWGHZRKvJ8Yz2WjkQm0tr+gzuEe/gJutjzHXUk+LUUAcOy4SaMKg1cinmSLSDj+zja3UGLuxIIlKB3/X57FVVvFd6yPENTePVPyYid4Uc3oeJ6frDQA2yBqeSJ9OSHoIihA5IkwWcQpckkIP2B1OklYvCauXVlHM6tRktgw5cFotLA2GWGKtY1rrH8iOtbJNq2Z1YiILLNuotbRgwaDHks9fUwsYNFxcrr1MpaUbgHatlLtd1/KmnEFlYhfL0y9RI5votJbQ6RjHkGccwhPEnpWDx5tNgdOgwJHCY0mxO5bFW4NumrpDLIm+wKdG/kx+2kx+tBgFrDVqWGtMYZ1RQ8xdSG2uxnJvM7PZjj+6B9dIG+5oBx2WQp6ITucF/TQGpJc8MUSeGGIEFw1GCX34uNCyllttD+AXIyQtTlzGCC/qs/ibsYgcn4+SoI9YLEKkq5lyrY9pnmECqR7y9C6QktWWOTyrn856bRYLq8s4f1oh00uz2dg6xJrGfnZ0hiiyRbkw9gSL+/8MFgtbZvyQ4bJPMP2lqwiEd/Fb39c5K/osNaltvOY6GzHSw2LL1kPCP2rP5SXbEu4enENSWpnl6mZpYJBC2Ycr3kN2spOS1B76pZffpVfwVu6nueWi05k/LgjA4LYX4cmvk5NoJyxdrJYzCbnLKIg3M87YQxqNB/VzeFQ/kyj7+1yf08qSwiTL3Q0s6HmYvMguHtGXcXvqcyyz7+Aq52pqk5uIWrLoEzmgJ6mkky6Zw9/sn6QvMAsZnEhObiGVuR7G52VRGfQQT+n0R2IM7d3G2pYQTzWk2DUsKKGPs7I7WOTtwrB7aNUq6DKy+Xzn7VTqe/jX9FcYJzr4qnUla7TZPF76XYqLy5hc5Kegby0VG+8gL7wdAwsWzGRHk1HIDyzfwF01l2yXnVDTev5f7Cf4CfMas9mefz5MWE5OtpeA206e18G4PA9Bjx2jr5G+p/6NvL1/JyU187kRFtwiiUPGGZEOXjFm8KYxjbeNSUQsXn5uv4f5cjN19hmUJRpwE+d/9OW8bMwkIl14s3PIr6impjSXKUU+hqNJQjtfYkLzQwyNJFmvT2K7bQobEqXomosrTi9n+WQ/uXufpbD+D/h6N9DpqOI/xNXUDdv5se1+5lt2kMCGg9QBcdMvvWgY+MUI9ZbxvOE9l7QjB83uQnP5MHInkxUoxm3XSOx6gYnNf6A2tv6Ax9htlPB77RIiEz/F5DwntcYuymI76bEVslFWUx/1MKXIx4raIrPi0NBJvfpzrK/djpBpBiwBtqeLqRVNZIsoHaKQAtlDpwzwz6nraTEK+YL1BS7XXsZLlF2W8TQ6puLweKkWeyiK7sZid9Mx5Rqaij9JEitOm4bLpuFz2Sj3O/B0rUc2rCLcuBZHz2YcRpTELU04vMH3fm/5CPnACQIhxHnALwENuFdKedvRjlcJAkUZY4YO6+8x51RY/hMIjj/O+xtm+dtIr5mlN9JQuQiKZuzP+EppnrA7s8GZzeBIEq/TekLLZd9TImxOwvbOA2Yb36U5zHH6tZdAzUWHLzmMDphXTzq3QGGtOR+EI1MymU7CQJM5h4Q7SE/KjmuwgazONxGta81VGaovhLLTD71iMNq7wweaX4NIl5nBNtJmKaEnDz1/Kv0TL6UnJogmdfxuG3n9G/ANbUObcLY50eVHYcLJI3n6ZnPW+fIF5lfFQvDk7t+fHDFXExlohMLp6IUzaDbyaR9O0jEUw65ZuHhWCVr9SvOq4KwvwqTzDv1/pRNmKfrWx6BkNlSvQJYvRIy+KhgdgK4t5qSYk86H7FFj67u2mkkzq8NsY8VCqFxy4q4qflCGDi2rzQlOdz4Nke4D99vcsPibsOD/gu3ICYpEWqd+8xrC9nysWbm4bBrVRd6jlptLKYkmdUYSSRI9TcjOzVi7t+DoqwNDZ6RwHrGSBTjLZ1NakGte3YoNmeNn195t9hFHsEVO4CHPl+gJzuOzrg0s676frOF6oiVn0DDr+3Q4x+O2W/G5bOS4bZQH3IefI2S4HVbdClv+hKw4gz3n/p6mEAQ8Dqrz3TjrHjbneCiZY06saXXsf15TUVLxCL19/dganyOn7vdYQ63m/rJ5cN5tUHLaob/zWAy3mZN51nzSnHz1WI30wcs/hQ2/B2mAxYrhChC35RDRfAxJL5rDSbbbic/twO4JmBOCevJBT5hJwVC7Ge9ddZBJvlF9ISz9NsQGST31TWyDjaSxYiVNtOQM4lXnsLujnz1dvbhjXcy27KZIb8cQGm+Pu4EtFVdht1mpDLiZOvAcOY1/Q8dGwuIikdZhoAV3uBmXHmKPs4bt3gV0uauZn1zDxN7nsaZHkCWzEZ97CHyjKjD6G6HuL+hb/4zWt2vfZkNoJDU3MWljJG1FI42PETyjkiFdtjLsRpyAbsbZdqOC39mvZKhkGXPHBbl4ZgmF9rg5pGbrY8jGlxBSp8t/GiudK+iMWbg6ci+FegfDWpBsvZ+UsNPhqcEfbyc73fee/y5dCpIWBy4Zp946iSedn6TSEWWm3EZ5eBP2VMgMB1sentQAVnSSUmOPLKRV5tEpg8ywtTJVHliVNJphz8KSjNDqquam2FfplEF+kLeaTww/jj01fMjxCYuLTpFPv7WAIXsRbpFg+sibePQQCeFkrZzCi6npbDQm4BUxiq0hlnn28onYszhJ8Jwxl1uTX6QDs7/2EeFR58+oppm4cHJX1td5xb6UMyfnceVkSWHrSvP15Mw23xd3v2AmGo0DTwB78TMgAgxbg7TlzCM54wvMnlDKhPysQ1/b6QR64yv0vfU4npbncKVD9DvKGfZNxJ/uJW9wEymbj97CJejJOCRCuKNtBJMdAPRIP7/13oh35kWcVZ3PlCKf+flj1NLKhm6wd8Pfsa35FSWD+080B2QWTbKYJqOIdplLjWUv8y3b8YuR/f+TUSf1BgLLqP9dTLh5dsrteKeea84BtPF+zmy8HQ0DQwoiOPGJGO0yyG8tn2NH3gqmFPuZVuKltjSHSQUHVlz0tDURevlOCvY8jTfdT0Q62SYr2WKMo1MGmSRamWltYSJ7SUgbj1guIDz7n1g2cxLTirOxyDS0rCax9QnYtRJHbP97SErYeTjwNZ7UlnNavs6XRh6kpPnPB8RiHDsb9Im8Iyey2LKFmZYmBoQfafcSTLTuO27Imkd9MsgE0UZARGg2CrhPP59n7OcxqzKPOZU5zK3wMz30CraOt0k6g/RKPz0iQI9rPAP4iUTCFLY8wZyuRyhK7R+a+a4+6SOOnVLRR7/IYUPgAux54ynILyDPnsS+7tf4wg30ECBbhnGIA2NwL4WsS09ivazGkjuBL0XuY6q+k6f0+WySE1iU1clUrQ0tbyLuhdfimrgU2t5G/8t1aINNGMJMTu/NO5MeWzG5Q1soje5AQ6fJKGK7rKBKdDLd0kyHDPCkfgZR6SCNhVLRy3JtA7kiRAor241y6phAsnAWF152PXm5/0AJAiGEBtQD5wBtwFvAFVLK7Ue6j0oQKIpyQukp8wPz4B5IRqByMTiPvZxQUT4yDB2668yT4kiXWclQe+mBCY+PilQMureZSS9DN09UDR2kQdLqxl4x/8AEl2GYr9Ps0veX+BpsAW/xB0vsGDrsft78edJ5JzcBFx0wK7mc2e+/HYkIdLwDWQVmQvFd6YSZJA53mYm3/OrD33+kD/TkgSf07yWd2J+E2deOMHRsgtK5R01i0d9oJk49QXBk7zuRk1IiJRhSYqST2HrrEHvegD1vmr+raikDhQuR/iqCR1tFYqTPbEug6sD2rv0N7F1nltBPuWj/csfRATOpGBuC+DDJaIiQYWcgZSecFpRbQ+SmuxCxfvN+VUsPimndfA3secMceuCvwKhYTJu3lqTFhdNmwWnTCHrsiJFeaFhlJnmyMgmfxLC5rG9fPeTVwJyrSWM+J1bNYiZZB5rNE3E9ZVb9+cvNKrCDY0ZPmatw7HoGWf88YqjlwP1CM/uSRTch86oJxdMMjCSJxNOU5rjIERFzouJZXzxyZdVo0QGzfN7qMGMvOPH9T7ZnGGY/Mvq13foWrPm1Odmxw2u+p2flmytBlS0knD2ZgPc4qisH95jPdf9u0j27SHTtQhtowJnoI+wsZiB/PomS+ZTnenEmBsylqn3FUDwLCqaa/V3vTujbbVYyHlwy3v4O7F1LeqSf4YE+4r5KPAuvwe87js8iehqaXkHftRKj7R203m1Y9ARxm5+9jknstlVjW3AtZ5427ciT9kpp9pWt68z2Tv8c5NcceMzQXnMy7UTYnPC1/R3SzavReraR9JVjOeMb2E670nwtR3r2P9ZAM8meBsK2IN0TLydUtJBcr5NxuVnHX/JvGBBqMys703GIDZDs2Eayow4Z6cYx8zLs0w8zPMgwzAmbNz9M2l9FX+7ptHpqKTQ6KRrehLV1LfqeN9HigwBEhYdXJn4XbcZlzK0MHDg0Z7Rk1KxYSydgztWQU7F/XzoJUmcwqbG9M8RAJEHl0Fqqdv6WrK51+w+zumnOWcQaxyI2u+ayZGoFZ9cUmHNBnYI+aIJgAfAjKeW5mdvfA5BS/uxI91EJAkVRFEVRFEUZA1KayZjuOnPCOE8++Ir2J0aU/VKx4xvG+WHSU+YJvCfvw0lmJkfA6vrwJnocK1KaiZzOzWbF4Fgm2KU0K8GMtJmEO5Er65xkR0sQHMtfWQK0jrrdBsw7EQ1TFEVRFEVRFOU4CGFe4T4FJ0b70H1UkwNgDucY69UNRjt4LqVTlRBmFcyxVMKciN8ltKMPN/0YOpYEweFSWoeUHQghrgOuy9yMCCF2HXzMR1wu8N6D1RTl/VMxpow1FWPKWFLxpYw1FWPKWFMxpoylUym+Ko6041gSBG1A2ajbpUDHwQdJKe8B7jnupn1ECCHePlKZhaKcCCrGlLGmYkwZSyq+lLGmYkwZayrGlLH0cYmvYxmE8hYwUQhRJYSwA5cDT45tsxRFURRFURRFURRF+TC9ZwWBlDIthLgReA5zmcP7pJTbxrxliqIoiqIoiqIoiqJ8aI5pKkYp5TPAM2PclpPtlB0eoZwyVIwpY03FmDKWVHwpY03FmDLWVIwpY+ljEV/vucyhoiiKoiiKoiiKoigff6f4QpiKoiiKoiiKoiiKopwIKkEACCHOE0LsEkI0CCG+e7Lbo5z6hBAtQoitQohNQoi3M9sCQogXhBC7M99zTnY7lVOHEOI+IUSPEKJu1LbDxpQw/SrTp20RQpx28lqunCqOEGM/EkK0Z/qyTUKIFaP2fS8TY7uEEOeenFYrpwohRJkQ4mUhxA4hxDYhxDcy21U/ppwQR4kx1Y8pJ4QQwimEWC+E2JyJsVsz26uEEOsy/difMhP7I4RwZG43ZPZXnsz2H6t/+ASBEEID7gLOB6YAVwghppzcVikfE8uklDNHLXfyXWCVlHIisCpzW1GO1f3AeQdtO1JMnQ9MzHxdB9z9IbVRObXdz6ExBvCLTF82MzMnEZn3ycuBqZn7/CbzfqooR5IGbpFS1gDzgRsycaT6MeVEOVKMgerHlBMjAZwlpZwBzATOE0LMB27HjLGJwCBwTeb4a4BBKeUE4BeZ4z7y/uETBMDpQIOUsklKmQQeAS46yW1SPp4uAh7I/PwAcPFJbItyipFSvgYMHLT5SDF1EfA/0rQW8Ashij6cliqnqiPE2JFcBDwipUxIKZuBBsz3U0U5LCllp5TynczPYWAHUILqx5QT5CgxdiSqH1OOS6Y/imRu2jJfEjgLeCyz/eB+7N3+7THgbCGE+JCa+76pBIHZcbSOut3G0TsTRTkWEnheCLFBCHFdZluBlLITzDcxIP+ktU75uDhSTKl+TTmRbsyUeN83amiUijHlfcuU2c4C1qH6MWUMHBRjoPox5QQRQmhCiE1AD/AC0AgMSSnTmUNGx9G+GMvsHwaCH26Lj59KEMDhsjhqaQflgzpDSnkaZonkDUKIJSe7Qco/FNWvKSfK3cB4zFLKTuDnme0qxpT3RQiRBTwO3CSlDB3t0MNsUzGmvKfDxJjqx5QTRkqpSylnAqWYFSc1hzss8/2UjDGVIDCzPGWjbpcCHSepLcrHhJSyI/O9B/grZgfS/W55ZOZ7z8lrofIxcaSYUv2ackJIKbszH4YM4L/ZX36rYkw5bkIIG+aJ2x+klH/JbFb9mHLCHC7GVD+mjAUp5RDwCuZ8F34hhDWza3Qc7YuxzP5sjn0o30mjEgTwFjAxM/ukHXOykidPcpuUU5gQwiOE8L77M7AcqMOMq6syh10FPHFyWqh8jBwppp4EvpSZBXw+MPxuCa+iHI+Dxnx/GrMvAzPGLs/M0FyFOZHc+g+7fcqpIzPu9nfADinlf47apfox5YQ4Uoypfkw5UYQQeUIIf+ZnF/AJzLkuXgYuyRx2cD/2bv92CfCSlPIjX0Fgfe9DPt6klGkhxI3Ac4AG3Cel3HaSm6Wc2gqAv2bmILECf5RSPiuEeAt4VAhxDbAXuPQktlE5xQghHgbOBHKFEG3AvwG3cfiYegZYgTnhUhT4yofeYOWUc4QYO1MIMROzJLIFuB5ASrlNCPEosB1z5vAbpJT6yWi3cso4A/gisDUzfhfg+6h+TDlxjhRjV6h+TDlBioAHMqtdWIBHpZRPCyG2A48IIX4CbMRMVJH5/qAQogGzcuDyk9Ho4yVOgSSGoiiKoiiKoiiKoihjTA0xUBRFURRFURRFURRFJQgURVEURVEURVEURVEJAkVRFEVRFEVRFEVRUAkCRVEURVEURVEURVFQCQJFURRFURRFURRFUVAJAkVRFEVRFEVRFEVRUAkCRVEURVEURVEURVFQCQJFURRFURRFURRFUYD/Bfxy2oiiTSwfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52282083,  0.46084997,  0.6364301 ,  0.68321276,  0.7931512 ,\n",
       "         0.91513795,  0.969381  ,  1.3604157 ,  1.3047167 ],\n",
       "       [-1.1545297 ,  0.8134768 ,  0.9801931 ,  1.3430848 ,  1.5174346 ,\n",
       "         1.7105336 ,  1.7925899 ,  2.0654776 ,  2.3022878 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation set\n",
    "y_pred = model.predict(X_val)\n",
    "# revert multi output format to (n_samples, quantiles)\n",
    "y_pred = np.array(list(zip(*y_pred))).squeeze()\n",
    "y_pred[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the distribution of predictions is wider than when trained with the MAE. This is in line with what we would expect: over-predicting the lower quantiles is punished much harder than before, and the same for under-predicting the higher quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/keras-team/keras/pull/8033/files\n",
    "def test_pinball_loss():\n",
    "    y_pred = K.variable(np.array([0.3, 0.6, 0.1]))\n",
    "    y_true = K.variable(np.array([0.3, 0.4, 0.5]))\n",
    "    quantile = 0.25\n",
    "    loss_fcn = create_pinball_loss(tau=quantile)#losses.PinballLoss(quantile)\n",
    "    expected_loss = (quantile * 0.4 + (1 - quantile) * 0.2) / 3\n",
    "    loss = K.eval(loss_fcn(y_true, y_pred))\n",
    "    assert np.isclose(expected_loss, loss)\n",
    "\n",
    "test_pinball_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"custom_layer/features2.csv\", index_col=0)\n",
    "target_df = pd.read_csv(\"custom_layer/targets2.csv\", index_col=0, header=None, names=['target'])\n",
    "quantiles = [0.005, 0.025, 0.165, 0.25, 0.5, 0.75, 0.835, 0.975, 0.995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "      <th>w_4</th>\n",
       "      <th>w_5</th>\n",
       "      <th>w_6</th>\n",
       "      <th>w_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wday  month  snap_CA  w_1  w_2  w_3  w_4  w_5  w_6  w_7\n",
       "date                                                               \n",
       "2011-01-29     1      1        0    1    0    0    0    0    0    0\n",
       "2011-01-30     2      1        0    0    1    0    0    0    0    0\n",
       "2011-01-31     3      1        0    0    0    1    0    0    0    0\n",
       "2011-02-01     4      2        1    0    0    0    1    0    0    0\n",
       "2011-02-02     5      2        1    0    0    0    0    1    0    0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>0.751272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>1.175314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>1.527411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>0.952662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>0.595021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target\n",
       "2011-01-29  0.751272\n",
       "2011-01-30  1.175314\n",
       "2011-01-31  1.527411\n",
       "2011-02-01  0.952662\n",
       "2011-02-02  0.595021"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Daniel Sch., at:\n",
    "# https://stackoverflow.com/questions/43151694/define-pinball-loss-function-in-keras-with-tensorflow-backend\n",
    "def create_pinball_loss(tau=0.5):\n",
    "    def pinball_loss(y_true, y_pred):\n",
    "        err = y_true - y_pred\n",
    "        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)\n",
    "    return pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.values\n",
    "y = target_df.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_mo = {'q'+str(i): y_train for i in range(len(quantiles))}\n",
    "y_val_mo = {'q'+str(i): y_val for i in range(len(quantiles))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp_shape, quantiles):\n",
    "    # clear previous sessions\n",
    "    K.clear_session()\n",
    "\n",
    "    inp = Input(inp_shape, name=\"input\")\n",
    "    x = inp\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dense(2)(x)  # represents mu, sigma\n",
    "    \n",
    "    out_q0 = Dense(1, name=\"q0\")(x)  # DistributionLayer(quantile=quantiles[0])(x)\n",
    "    out_q1 = Dense(1, name=\"q1\")(x)  # DistributionLayer(quantile=quantiles[1])(x)\n",
    "    out_q2 = Dense(1, name=\"q2\")(x)  # ...\n",
    "    out_q3 = Dense(1, name=\"q3\")(x)\n",
    "    out_q4 = Dense(1, name=\"q4\")(x)\n",
    "    out_q5 = Dense(1, name=\"q5\")(x)\n",
    "    out_q6 = Dense(1, name=\"q6\")(x)\n",
    "    out_q7 = Dense(1, name=\"q7\")(x)\n",
    "    out_q8 = Dense(1, name=\"q8\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=[out_q0, out_q1, out_q2, out_q3, out_q4, out_q5, out_q6, out_q7, out_q8])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q0': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q1': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q2': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q3': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q4': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q5': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q6': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q7': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>,\n",
       " 'q8': <function __main__.create_pinball_loss.<locals>.pinball_loss(y_true, y_pred)>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = {'q'+str(i): create_pinball_loss(tau=q) for (i, q) in enumerate(quantiles)}\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           176         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           544         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           2112        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            130         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q0 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q1 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q2 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q3 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q4 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q5 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q6 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q7 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q8 (Dense)                      (None, 1)            3           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,989\n",
      "Trainable params: 2,989\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(inp_shape=(X_train.shape[1],), quantiles=quantiles)\n",
    "model.compile(optimizer=\"adam\", loss=losses)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1575 samples, validate on 394 samples\n",
      "Epoch 1/300\n",
      "1575/1575 [==============================] - 4s 2ms/sample - loss: 4.2071 - q0_loss: 0.0099 - q1_loss: 0.0911 - q2_loss: 0.2464 - q3_loss: 0.1672 - q4_loss: 0.6883 - q5_loss: 0.6114 - q6_loss: 0.8452 - q7_loss: 1.0800 - q8_loss: 0.4631 - val_loss: 3.5987 - val_q0_loss: 0.0037 - val_q1_loss: 0.0147 - val_q2_loss: 0.0938 - val_q3_loss: 0.0862 - val_q4_loss: 0.7248 - val_q5_loss: 0.4696 - val_q6_loss: 0.8725 - val_q7_loss: 1.0189 - val_q8_loss: 0.2895\n",
      "Epoch 2/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 3.2800 - q0_loss: 0.0034 - q1_loss: 0.0209 - q2_loss: 0.0850 - q3_loss: 0.0823 - q4_loss: 0.7526 - q5_loss: 0.3410 - q6_loss: 0.8824 - q7_loss: 0.9511 - q8_loss: 0.1613 - val_loss: 3.1080 - val_q0_loss: 0.0035 - val_q1_loss: 0.0174 - val_q2_loss: 0.0703 - val_q3_loss: 0.0693 - val_q4_loss: 0.7612 - val_q5_loss: 0.2655 - val_q6_loss: 0.8952 - val_q7_loss: 0.9008 - val_q8_loss: 0.1004\n",
      "Epoch 3/300\n",
      "1575/1575 [==============================] - 0s 132us/sample - loss: 2.8529 - q0_loss: 0.0034 - q1_loss: 0.0188 - q2_loss: 0.0693 - q3_loss: 0.0670 - q4_loss: 0.7312 - q5_loss: 0.2042 - q6_loss: 0.8616 - q7_loss: 0.8160 - q8_loss: 0.0763 - val_loss: 2.7662 - val_q0_loss: 0.0032 - val_q1_loss: 0.0281 - val_q2_loss: 0.0712 - val_q3_loss: 0.0810 - val_q4_loss: 0.7786 - val_q5_loss: 0.1283 - val_q6_loss: 0.8606 - val_q7_loss: 0.7855 - val_q8_loss: 0.0115\n",
      "Epoch 4/300\n",
      "1575/1575 [==============================] - 0s 130us/sample - loss: 2.4924 - q0_loss: 0.0035 - q1_loss: 0.0158 - q2_loss: 0.0525 - q3_loss: 0.0654 - q4_loss: 0.6916 - q5_loss: 0.1150 - q6_loss: 0.8351 - q7_loss: 0.6769 - q8_loss: 0.0507 - val_loss: 2.3945 - val_q0_loss: 0.0032 - val_q1_loss: 0.0147 - val_q2_loss: 0.0457 - val_q3_loss: 0.0656 - val_q4_loss: 0.7165 - val_q5_loss: 0.0741 - val_q6_loss: 0.7982 - val_q7_loss: 0.6484 - val_q8_loss: 0.0101\n",
      "Epoch 5/300\n",
      "1575/1575 [==============================] - 0s 126us/sample - loss: 2.1891 - q0_loss: 0.0035 - q1_loss: 0.0141 - q2_loss: 0.0474 - q3_loss: 0.0611 - q4_loss: 0.6395 - q5_loss: 0.0745 - q6_loss: 0.7722 - q7_loss: 0.5485 - q8_loss: 0.0286 - val_loss: 2.0923 - val_q0_loss: 0.0037 - val_q1_loss: 0.0112 - val_q2_loss: 0.0466 - val_q3_loss: 0.0571 - val_q4_loss: 0.6086 - val_q5_loss: 0.0615 - val_q6_loss: 0.7936 - val_q7_loss: 0.4606 - val_q8_loss: 0.0326\n",
      "Epoch 6/300\n",
      "1575/1575 [==============================] - 0s 126us/sample - loss: 1.9252 - q0_loss: 0.0035 - q1_loss: 0.0127 - q2_loss: 0.0460 - q3_loss: 0.0587 - q4_loss: 0.5851 - q5_loss: 0.0619 - q6_loss: 0.7062 - q7_loss: 0.4286 - q8_loss: 0.0205 - val_loss: 1.8501 - val_q0_loss: 0.0038 - val_q1_loss: 0.0100 - val_q2_loss: 0.0412 - val_q3_loss: 0.0623 - val_q4_loss: 0.5465 - val_q5_loss: 0.0574 - val_q6_loss: 0.7179 - val_q7_loss: 0.3593 - val_q8_loss: 0.0358\n",
      "Epoch 7/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 1.6802 - q0_loss: 0.0034 - q1_loss: 0.0121 - q2_loss: 0.0465 - q3_loss: 0.0569 - q4_loss: 0.5345 - q5_loss: 0.0603 - q6_loss: 0.6362 - q7_loss: 0.3205 - q8_loss: 0.0145 - val_loss: 1.6251 - val_q0_loss: 0.0032 - val_q1_loss: 0.0102 - val_q2_loss: 0.0489 - val_q3_loss: 0.0522 - val_q4_loss: 0.5339 - val_q5_loss: 0.0605 - val_q6_loss: 0.5508 - val_q7_loss: 0.3427 - val_q8_loss: 0.0078\n",
      "Epoch 8/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 1.4685 - q0_loss: 0.0032 - q1_loss: 0.0131 - q2_loss: 0.0509 - q3_loss: 0.0582 - q4_loss: 0.4897 - q5_loss: 0.0614 - q6_loss: 0.5394 - q7_loss: 0.2374 - q8_loss: 0.0076 - val_loss: 1.4125 - val_q0_loss: 0.0033 - val_q1_loss: 0.0106 - val_q2_loss: 0.0517 - val_q3_loss: 0.0538 - val_q4_loss: 0.4732 - val_q5_loss: 0.0624 - val_q6_loss: 0.4901 - val_q7_loss: 0.2448 - val_q8_loss: 0.0093\n",
      "Epoch 9/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 1.2441 - q0_loss: 0.0031 - q1_loss: 0.0116 - q2_loss: 0.0467 - q3_loss: 0.0555 - q4_loss: 0.4485 - q5_loss: 0.0568 - q6_loss: 0.4423 - q7_loss: 0.1682 - q8_loss: 0.0040 - val_loss: 1.2042 - val_q0_loss: 0.0028 - val_q1_loss: 0.0114 - val_q2_loss: 0.0438 - val_q3_loss: 0.0769 - val_q4_loss: 0.4616 - val_q5_loss: 0.0656 - val_q6_loss: 0.3930 - val_q7_loss: 0.1319 - val_q8_loss: 0.0045\n",
      "Epoch 10/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 1.0672 - q0_loss: 0.0028 - q1_loss: 0.0130 - q2_loss: 0.0497 - q3_loss: 0.0700 - q4_loss: 0.4126 - q5_loss: 0.0596 - q6_loss: 0.3349 - q7_loss: 0.1216 - q8_loss: 0.0047 - val_loss: 1.0013 - val_q0_loss: 0.0026 - val_q1_loss: 0.0101 - val_q2_loss: 0.0468 - val_q3_loss: 0.0627 - val_q4_loss: 0.4173 - val_q5_loss: 0.0547 - val_q6_loss: 0.2574 - val_q7_loss: 0.1331 - val_q8_loss: 0.0036\n",
      "Epoch 11/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.8875 - q0_loss: 0.0026 - q1_loss: 0.0112 - q2_loss: 0.0460 - q3_loss: 0.0634 - q4_loss: 0.3706 - q5_loss: 0.0589 - q6_loss: 0.2326 - q7_loss: 0.0945 - q8_loss: 0.0032 - val_loss: 0.8385 - val_q0_loss: 0.0025 - val_q1_loss: 0.0110 - val_q2_loss: 0.0479 - val_q3_loss: 0.0540 - val_q4_loss: 0.3527 - val_q5_loss: 0.0552 - val_q6_loss: 0.2047 - val_q7_loss: 0.0952 - val_q8_loss: 0.0028\n",
      "Epoch 12/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.7428 - q0_loss: 0.0024 - q1_loss: 0.0121 - q2_loss: 0.0469 - q3_loss: 0.0645 - q4_loss: 0.3222 - q5_loss: 0.0578 - q6_loss: 0.1551 - q7_loss: 0.0710 - q8_loss: 0.0031 - val_loss: 0.7006 - val_q0_loss: 0.0025 - val_q1_loss: 0.0103 - val_q2_loss: 0.0424 - val_q3_loss: 0.0627 - val_q4_loss: 0.2939 - val_q5_loss: 0.0552 - val_q6_loss: 0.1593 - val_q7_loss: 0.0613 - val_q8_loss: 0.0026\n",
      "Epoch 13/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.6172 - q0_loss: 0.0023 - q1_loss: 0.0111 - q2_loss: 0.0449 - q3_loss: 0.0627 - q4_loss: 0.2696 - q5_loss: 0.0574 - q6_loss: 0.1109 - q7_loss: 0.0559 - q8_loss: 0.0033 - val_loss: 0.6103 - val_q0_loss: 0.0023 - val_q1_loss: 0.0131 - val_q2_loss: 0.0528 - val_q3_loss: 0.0830 - val_q4_loss: 0.2589 - val_q5_loss: 0.0698 - val_q6_loss: 0.0845 - val_q7_loss: 0.0336 - val_q8_loss: 0.0041\n",
      "Epoch 14/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.5356 - q0_loss: 0.0024 - q1_loss: 0.0122 - q2_loss: 0.0480 - q3_loss: 0.0717 - q4_loss: 0.2145 - q5_loss: 0.0612 - q6_loss: 0.0786 - q7_loss: 0.0405 - q8_loss: 0.0037 - val_loss: 0.5109 - val_q0_loss: 0.0023 - val_q1_loss: 0.0102 - val_q2_loss: 0.0432 - val_q3_loss: 0.0738 - val_q4_loss: 0.2101 - val_q5_loss: 0.0656 - val_q6_loss: 0.0632 - val_q7_loss: 0.0303 - val_q8_loss: 0.0045\n",
      "Epoch 15/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.4601 - q0_loss: 0.0024 - q1_loss: 0.0114 - q2_loss: 0.0457 - q3_loss: 0.0699 - q4_loss: 0.1750 - q5_loss: 0.0572 - q6_loss: 0.0630 - q7_loss: 0.0291 - q8_loss: 0.0038 - val_loss: 0.4407 - val_q0_loss: 0.0022 - val_q1_loss: 0.0100 - val_q2_loss: 0.0412 - val_q3_loss: 0.0597 - val_q4_loss: 0.1673 - val_q5_loss: 0.0552 - val_q6_loss: 0.0628 - val_q7_loss: 0.0285 - val_q8_loss: 0.0037\n",
      "Epoch 16/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.4240 - q0_loss: 0.0026 - q1_loss: 0.0112 - q2_loss: 0.0443 - q3_loss: 0.0680 - q4_loss: 0.1500 - q5_loss: 0.0583 - q6_loss: 0.0617 - q7_loss: 0.0251 - q8_loss: 0.0039 - val_loss: 0.4115 - val_q0_loss: 0.0020 - val_q1_loss: 0.0102 - val_q2_loss: 0.0456 - val_q3_loss: 0.0593 - val_q4_loss: 0.1513 - val_q5_loss: 0.0551 - val_q6_loss: 0.0540 - val_q7_loss: 0.0241 - val_q8_loss: 0.0041\n",
      "Epoch 17/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.3953 - q0_loss: 0.0023 - q1_loss: 0.0105 - q2_loss: 0.0437 - q3_loss: 0.0636 - q4_loss: 0.1412 - q5_loss: 0.0563 - q6_loss: 0.0593 - q7_loss: 0.0219 - q8_loss: 0.0041 - val_loss: 0.4057 - val_q0_loss: 0.0023 - val_q1_loss: 0.0108 - val_q2_loss: 0.0436 - val_q3_loss: 0.0721 - val_q4_loss: 0.1413 - val_q5_loss: 0.0580 - val_q6_loss: 0.0499 - val_q7_loss: 0.0167 - val_q8_loss: 0.0044\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.3893 - q0_loss: 0.0026 - q1_loss: 0.0113 - q2_loss: 0.0447 - q3_loss: 0.0680 - q4_loss: 0.1322 - q5_loss: 0.0557 - q6_loss: 0.0560 - q7_loss: 0.0168 - q8_loss: 0.0042 - val_loss: 0.3871 - val_q0_loss: 0.0024 - val_q1_loss: 0.0100 - val_q2_loss: 0.0401 - val_q3_loss: 0.0594 - val_q4_loss: 0.1353 - val_q5_loss: 0.0542 - val_q6_loss: 0.0582 - val_q7_loss: 0.0171 - val_q8_loss: 0.0039\n",
      "Epoch 19/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3807 - q0_loss: 0.0024 - q1_loss: 0.0107 - q2_loss: 0.0441 - q3_loss: 0.0629 - q4_loss: 0.1293 - q5_loss: 0.0559 - q6_loss: 0.0542 - q7_loss: 0.0165 - q8_loss: 0.0043 - val_loss: 0.3773 - val_q0_loss: 0.0023 - val_q1_loss: 0.0095 - val_q2_loss: 0.0425 - val_q3_loss: 0.0586 - val_q4_loss: 0.1333 - val_q5_loss: 0.0572 - val_q6_loss: 0.0492 - val_q7_loss: 0.0159 - val_q8_loss: 0.0043\n",
      "Epoch 20/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.3766 - q0_loss: 0.0024 - q1_loss: 0.0106 - q2_loss: 0.0448 - q3_loss: 0.0646 - q4_loss: 0.1277 - q5_loss: 0.0561 - q6_loss: 0.0538 - q7_loss: 0.0161 - q8_loss: 0.0042 - val_loss: 0.3883 - val_q0_loss: 0.0023 - val_q1_loss: 0.0099 - val_q2_loss: 0.0471 - val_q3_loss: 0.0597 - val_q4_loss: 0.1312 - val_q5_loss: 0.0562 - val_q6_loss: 0.0568 - val_q7_loss: 0.0170 - val_q8_loss: 0.0048\n",
      "Epoch 21/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.3782 - q0_loss: 0.0025 - q1_loss: 0.0107 - q2_loss: 0.0451 - q3_loss: 0.0667 - q4_loss: 0.1238 - q5_loss: 0.0558 - q6_loss: 0.0522 - q7_loss: 0.0151 - q8_loss: 0.0042 - val_loss: 0.3661 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0397 - val_q3_loss: 0.0563 - val_q4_loss: 0.1282 - val_q5_loss: 0.0562 - val_q6_loss: 0.0495 - val_q7_loss: 0.0157 - val_q8_loss: 0.0046\n",
      "Epoch 22/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.3680 - q0_loss: 0.0024 - q1_loss: 0.0105 - q2_loss: 0.0438 - q3_loss: 0.0635 - q4_loss: 0.1250 - q5_loss: 0.0568 - q6_loss: 0.0515 - q7_loss: 0.0153 - q8_loss: 0.0042 - val_loss: 0.3652 - val_q0_loss: 0.0021 - val_q1_loss: 0.0099 - val_q2_loss: 0.0394 - val_q3_loss: 0.0601 - val_q4_loss: 0.1241 - val_q5_loss: 0.0559 - val_q6_loss: 0.0503 - val_q7_loss: 0.0147 - val_q8_loss: 0.0047\n",
      "Epoch 23/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.3602 - q0_loss: 0.0025 - q1_loss: 0.0108 - q2_loss: 0.0436 - q3_loss: 0.0642 - q4_loss: 0.1178 - q5_loss: 0.0545 - q6_loss: 0.0466 - q7_loss: 0.0136 - q8_loss: 0.0041 - val_loss: 0.3693 - val_q0_loss: 0.0026 - val_q1_loss: 0.0106 - val_q2_loss: 0.0426 - val_q3_loss: 0.0669 - val_q4_loss: 0.1196 - val_q5_loss: 0.0561 - val_q6_loss: 0.0483 - val_q7_loss: 0.0142 - val_q8_loss: 0.0036\n",
      "Epoch 24/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3599 - q0_loss: 0.0024 - q1_loss: 0.0105 - q2_loss: 0.0444 - q3_loss: 0.0637 - q4_loss: 0.1162 - q5_loss: 0.0543 - q6_loss: 0.0492 - q7_loss: 0.0138 - q8_loss: 0.0041 - val_loss: 0.3524 - val_q0_loss: 0.0022 - val_q1_loss: 0.0099 - val_q2_loss: 0.0412 - val_q3_loss: 0.0580 - val_q4_loss: 0.1180 - val_q5_loss: 0.0543 - val_q6_loss: 0.0462 - val_q7_loss: 0.0146 - val_q8_loss: 0.0043\n",
      "Epoch 25/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.3537 - q0_loss: 0.0025 - q1_loss: 0.0105 - q2_loss: 0.0430 - q3_loss: 0.0646 - q4_loss: 0.1125 - q5_loss: 0.0557 - q6_loss: 0.0469 - q7_loss: 0.0135 - q8_loss: 0.0040 - val_loss: 0.3554 - val_q0_loss: 0.0022 - val_q1_loss: 0.0097 - val_q2_loss: 0.0427 - val_q3_loss: 0.0539 - val_q4_loss: 0.1168 - val_q5_loss: 0.0565 - val_q6_loss: 0.0502 - val_q7_loss: 0.0153 - val_q8_loss: 0.0045\n",
      "Epoch 26/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.3481 - q0_loss: 0.0026 - q1_loss: 0.0105 - q2_loss: 0.0427 - q3_loss: 0.0639 - q4_loss: 0.1105 - q5_loss: 0.0548 - q6_loss: 0.0489 - q7_loss: 0.0136 - q8_loss: 0.0040 - val_loss: 0.3562 - val_q0_loss: 0.0024 - val_q1_loss: 0.0108 - val_q2_loss: 0.0457 - val_q3_loss: 0.0629 - val_q4_loss: 0.1096 - val_q5_loss: 0.0580 - val_q6_loss: 0.0445 - val_q7_loss: 0.0141 - val_q8_loss: 0.0038\n",
      "Epoch 27/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.3444 - q0_loss: 0.0026 - q1_loss: 0.0105 - q2_loss: 0.0446 - q3_loss: 0.0638 - q4_loss: 0.1055 - q5_loss: 0.0552 - q6_loss: 0.0447 - q7_loss: 0.0133 - q8_loss: 0.0040 - val_loss: 0.3413 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0408 - val_q3_loss: 0.0541 - val_q4_loss: 0.1095 - val_q5_loss: 0.0572 - val_q6_loss: 0.0455 - val_q7_loss: 0.0149 - val_q8_loss: 0.0044\n",
      "Epoch 28/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.3455 - q0_loss: 0.0026 - q1_loss: 0.0102 - q2_loss: 0.0436 - q3_loss: 0.0617 - q4_loss: 0.1038 - q5_loss: 0.0581 - q6_loss: 0.0471 - q7_loss: 0.0139 - q8_loss: 0.0040 - val_loss: 0.3446 - val_q0_loss: 0.0027 - val_q1_loss: 0.0101 - val_q2_loss: 0.0399 - val_q3_loss: 0.0637 - val_q4_loss: 0.1026 - val_q5_loss: 0.0551 - val_q6_loss: 0.0493 - val_q7_loss: 0.0142 - val_q8_loss: 0.0034\n",
      "Epoch 29/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.3296 - q0_loss: 0.0025 - q1_loss: 0.0103 - q2_loss: 0.0428 - q3_loss: 0.0611 - q4_loss: 0.0988 - q5_loss: 0.0551 - q6_loss: 0.0436 - q7_loss: 0.0134 - q8_loss: 0.0040 - val_loss: 0.3526 - val_q0_loss: 0.0024 - val_q1_loss: 0.0109 - val_q2_loss: 0.0502 - val_q3_loss: 0.0594 - val_q4_loss: 0.0974 - val_q5_loss: 0.0611 - val_q6_loss: 0.0487 - val_q7_loss: 0.0136 - val_q8_loss: 0.0043\n",
      "Epoch 30/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.3339 - q0_loss: 0.0028 - q1_loss: 0.0106 - q2_loss: 0.0446 - q3_loss: 0.0609 - q4_loss: 0.0958 - q5_loss: 0.0564 - q6_loss: 0.0460 - q7_loss: 0.0132 - q8_loss: 0.0044 - val_loss: 0.3327 - val_q0_loss: 0.0025 - val_q1_loss: 0.0106 - val_q2_loss: 0.0458 - val_q3_loss: 0.0581 - val_q4_loss: 0.0937 - val_q5_loss: 0.0573 - val_q6_loss: 0.0439 - val_q7_loss: 0.0138 - val_q8_loss: 0.0039\n",
      "Epoch 31/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3295 - q0_loss: 0.0026 - q1_loss: 0.0102 - q2_loss: 0.0450 - q3_loss: 0.0610 - q4_loss: 0.0920 - q5_loss: 0.0583 - q6_loss: 0.0445 - q7_loss: 0.0129 - q8_loss: 0.0041 - val_loss: 0.3294 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0431 - val_q3_loss: 0.0541 - val_q4_loss: 0.0933 - val_q5_loss: 0.0588 - val_q6_loss: 0.0448 - val_q7_loss: 0.0154 - val_q8_loss: 0.0045\n",
      "Epoch 32/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3304 - q0_loss: 0.0027 - q1_loss: 0.0105 - q2_loss: 0.0466 - q3_loss: 0.0608 - q4_loss: 0.0881 - q5_loss: 0.0584 - q6_loss: 0.0451 - q7_loss: 0.0133 - q8_loss: 0.0042 - val_loss: 0.4023 - val_q0_loss: 0.0031 - val_q1_loss: 0.0101 - val_q2_loss: 0.0449 - val_q3_loss: 0.0714 - val_q4_loss: 0.0908 - val_q5_loss: 0.0642 - val_q6_loss: 0.0806 - val_q7_loss: 0.0141 - val_q8_loss: 0.0241\n",
      "Epoch 33/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.3387 - q0_loss: 0.0027 - q1_loss: 0.0104 - q2_loss: 0.0469 - q3_loss: 0.0626 - q4_loss: 0.0882 - q5_loss: 0.0606 - q6_loss: 0.0499 - q7_loss: 0.0140 - q8_loss: 0.0052 - val_loss: 0.3258 - val_q0_loss: 0.0025 - val_q1_loss: 0.0108 - val_q2_loss: 0.0474 - val_q3_loss: 0.0578 - val_q4_loss: 0.0827 - val_q5_loss: 0.0576 - val_q6_loss: 0.0452 - val_q7_loss: 0.0136 - val_q8_loss: 0.0041\n",
      "Epoch 34/300\n",
      "1575/1575 [==============================] - 0s 112us/sample - loss: 0.3188 - q0_loss: 0.0027 - q1_loss: 0.0105 - q2_loss: 0.0451 - q3_loss: 0.0589 - q4_loss: 0.0821 - q5_loss: 0.0579 - q6_loss: 0.0456 - q7_loss: 0.0137 - q8_loss: 0.0042 - val_loss: 0.3103 - val_q0_loss: 0.0025 - val_q1_loss: 0.0096 - val_q2_loss: 0.0403 - val_q3_loss: 0.0543 - val_q4_loss: 0.0791 - val_q5_loss: 0.0552 - val_q6_loss: 0.0461 - val_q7_loss: 0.0143 - val_q8_loss: 0.0042\n",
      "Epoch 35/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.3151 - q0_loss: 0.0027 - q1_loss: 0.0103 - q2_loss: 0.0449 - q3_loss: 0.0579 - q4_loss: 0.0799 - q5_loss: 0.0567 - q6_loss: 0.0452 - q7_loss: 0.0131 - q8_loss: 0.0041 - val_loss: 0.3097 - val_q0_loss: 0.0026 - val_q1_loss: 0.0099 - val_q2_loss: 0.0431 - val_q3_loss: 0.0548 - val_q4_loss: 0.0777 - val_q5_loss: 0.0561 - val_q6_loss: 0.0456 - val_q7_loss: 0.0134 - val_q8_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3118 - q0_loss: 0.0028 - q1_loss: 0.0104 - q2_loss: 0.0444 - q3_loss: 0.0572 - q4_loss: 0.0777 - q5_loss: 0.0554 - q6_loss: 0.0468 - q7_loss: 0.0127 - q8_loss: 0.0045 - val_loss: 0.3164 - val_q0_loss: 0.0029 - val_q1_loss: 0.0097 - val_q2_loss: 0.0417 - val_q3_loss: 0.0563 - val_q4_loss: 0.0746 - val_q5_loss: 0.0561 - val_q6_loss: 0.0528 - val_q7_loss: 0.0139 - val_q8_loss: 0.0038\n",
      "Epoch 37/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3029 - q0_loss: 0.0027 - q1_loss: 0.0101 - q2_loss: 0.0431 - q3_loss: 0.0558 - q4_loss: 0.0761 - q5_loss: 0.0545 - q6_loss: 0.0440 - q7_loss: 0.0129 - q8_loss: 0.0041 - val_loss: 0.3081 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0417 - val_q3_loss: 0.0523 - val_q4_loss: 0.0774 - val_q5_loss: 0.0542 - val_q6_loss: 0.0490 - val_q7_loss: 0.0139 - val_q8_loss: 0.0047\n",
      "Epoch 38/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3153 - q0_loss: 0.0028 - q1_loss: 0.0102 - q2_loss: 0.0446 - q3_loss: 0.0581 - q4_loss: 0.0766 - q5_loss: 0.0584 - q6_loss: 0.0482 - q7_loss: 0.0132 - q8_loss: 0.0054 - val_loss: 0.3001 - val_q0_loss: 0.0026 - val_q1_loss: 0.0093 - val_q2_loss: 0.0399 - val_q3_loss: 0.0517 - val_q4_loss: 0.0739 - val_q5_loss: 0.0556 - val_q6_loss: 0.0450 - val_q7_loss: 0.0141 - val_q8_loss: 0.0042\n",
      "Epoch 39/300\n",
      "1575/1575 [==============================] - 0s 112us/sample - loss: 0.2990 - q0_loss: 0.0027 - q1_loss: 0.0100 - q2_loss: 0.0433 - q3_loss: 0.0547 - q4_loss: 0.0713 - q5_loss: 0.0553 - q6_loss: 0.0448 - q7_loss: 0.0128 - q8_loss: 0.0042 - val_loss: 0.3182 - val_q0_loss: 0.0026 - val_q1_loss: 0.0109 - val_q2_loss: 0.0488 - val_q3_loss: 0.0552 - val_q4_loss: 0.0723 - val_q5_loss: 0.0630 - val_q6_loss: 0.0442 - val_q7_loss: 0.0133 - val_q8_loss: 0.0036\n",
      "Epoch 40/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3045 - q0_loss: 0.0026 - q1_loss: 0.0098 - q2_loss: 0.0453 - q3_loss: 0.0558 - q4_loss: 0.0723 - q5_loss: 0.0561 - q6_loss: 0.0448 - q7_loss: 0.0129 - q8_loss: 0.0043 - val_loss: 0.3029 - val_q0_loss: 0.0027 - val_q1_loss: 0.0093 - val_q2_loss: 0.0397 - val_q3_loss: 0.0530 - val_q4_loss: 0.0708 - val_q5_loss: 0.0552 - val_q6_loss: 0.0509 - val_q7_loss: 0.0137 - val_q8_loss: 0.0039\n",
      "Epoch 41/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3012 - q0_loss: 0.0028 - q1_loss: 0.0101 - q2_loss: 0.0438 - q3_loss: 0.0551 - q4_loss: 0.0719 - q5_loss: 0.0566 - q6_loss: 0.0452 - q7_loss: 0.0128 - q8_loss: 0.0044 - val_loss: 0.3075 - val_q0_loss: 0.0027 - val_q1_loss: 0.0096 - val_q2_loss: 0.0397 - val_q3_loss: 0.0544 - val_q4_loss: 0.0694 - val_q5_loss: 0.0568 - val_q6_loss: 0.0520 - val_q7_loss: 0.0130 - val_q8_loss: 0.0045\n",
      "Epoch 42/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3063 - q0_loss: 0.0028 - q1_loss: 0.0106 - q2_loss: 0.0463 - q3_loss: 0.0566 - q4_loss: 0.0708 - q5_loss: 0.0589 - q6_loss: 0.0450 - q7_loss: 0.0128 - q8_loss: 0.0046 - val_loss: 0.3108 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0464 - val_q3_loss: 0.0525 - val_q4_loss: 0.0719 - val_q5_loss: 0.0595 - val_q6_loss: 0.0468 - val_q7_loss: 0.0150 - val_q8_loss: 0.0046\n",
      "Epoch 43/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3170 - q0_loss: 0.0027 - q1_loss: 0.0104 - q2_loss: 0.0462 - q3_loss: 0.0565 - q4_loss: 0.0735 - q5_loss: 0.0595 - q6_loss: 0.0490 - q7_loss: 0.0127 - q8_loss: 0.0052 - val_loss: 0.3139 - val_q0_loss: 0.0029 - val_q1_loss: 0.0096 - val_q2_loss: 0.0434 - val_q3_loss: 0.0547 - val_q4_loss: 0.0694 - val_q5_loss: 0.0573 - val_q6_loss: 0.0533 - val_q7_loss: 0.0137 - val_q8_loss: 0.0043\n",
      "Epoch 44/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.3133 - q0_loss: 0.0026 - q1_loss: 0.0105 - q2_loss: 0.0473 - q3_loss: 0.0553 - q4_loss: 0.0714 - q5_loss: 0.0608 - q6_loss: 0.0471 - q7_loss: 0.0124 - q8_loss: 0.0045 - val_loss: 0.3436 - val_q0_loss: 0.0022 - val_q1_loss: 0.0097 - val_q2_loss: 0.0556 - val_q3_loss: 0.0598 - val_q4_loss: 0.0745 - val_q5_loss: 0.0708 - val_q6_loss: 0.0479 - val_q7_loss: 0.0159 - val_q8_loss: 0.0053\n",
      "Epoch 45/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2941 - q0_loss: 0.0026 - q1_loss: 0.0100 - q2_loss: 0.0427 - q3_loss: 0.0539 - q4_loss: 0.0694 - q5_loss: 0.0545 - q6_loss: 0.0432 - q7_loss: 0.0128 - q8_loss: 0.0041 - val_loss: 0.3097 - val_q0_loss: 0.0028 - val_q1_loss: 0.0097 - val_q2_loss: 0.0407 - val_q3_loss: 0.0551 - val_q4_loss: 0.0697 - val_q5_loss: 0.0569 - val_q6_loss: 0.0531 - val_q7_loss: 0.0125 - val_q8_loss: 0.0048\n",
      "Epoch 46/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2984 - q0_loss: 0.0027 - q1_loss: 0.0099 - q2_loss: 0.0437 - q3_loss: 0.0552 - q4_loss: 0.0690 - q5_loss: 0.0554 - q6_loss: 0.0449 - q7_loss: 0.0125 - q8_loss: 0.0045 - val_loss: 0.3094 - val_q0_loss: 0.0028 - val_q1_loss: 0.0099 - val_q2_loss: 0.0429 - val_q3_loss: 0.0559 - val_q4_loss: 0.0704 - val_q5_loss: 0.0587 - val_q6_loss: 0.0484 - val_q7_loss: 0.0125 - val_q8_loss: 0.0052\n",
      "Epoch 47/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.3043 - q0_loss: 0.0027 - q1_loss: 0.0102 - q2_loss: 0.0460 - q3_loss: 0.0551 - q4_loss: 0.0705 - q5_loss: 0.0590 - q6_loss: 0.0458 - q7_loss: 0.0125 - q8_loss: 0.0045 - val_loss: 0.3064 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0408 - val_q3_loss: 0.0535 - val_q4_loss: 0.0725 - val_q5_loss: 0.0575 - val_q6_loss: 0.0496 - val_q7_loss: 0.0139 - val_q8_loss: 0.0051\n",
      "Epoch 48/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.3033 - q0_loss: 0.0025 - q1_loss: 0.0100 - q2_loss: 0.0437 - q3_loss: 0.0559 - q4_loss: 0.0711 - q5_loss: 0.0559 - q6_loss: 0.0464 - q7_loss: 0.0123 - q8_loss: 0.0047 - val_loss: 0.2911 - val_q0_loss: 0.0025 - val_q1_loss: 0.0093 - val_q2_loss: 0.0413 - val_q3_loss: 0.0518 - val_q4_loss: 0.0667 - val_q5_loss: 0.0550 - val_q6_loss: 0.0443 - val_q7_loss: 0.0129 - val_q8_loss: 0.0041\n",
      "Epoch 49/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2932 - q0_loss: 0.0026 - q1_loss: 0.0097 - q2_loss: 0.0423 - q3_loss: 0.0546 - q4_loss: 0.0691 - q5_loss: 0.0549 - q6_loss: 0.0440 - q7_loss: 0.0123 - q8_loss: 0.0044 - val_loss: 0.3003 - val_q0_loss: 0.0025 - val_q1_loss: 0.0096 - val_q2_loss: 0.0465 - val_q3_loss: 0.0524 - val_q4_loss: 0.0663 - val_q5_loss: 0.0600 - val_q6_loss: 0.0432 - val_q7_loss: 0.0123 - val_q8_loss: 0.0040\n",
      "Epoch 50/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2915 - q0_loss: 0.0027 - q1_loss: 0.0098 - q2_loss: 0.0421 - q3_loss: 0.0538 - q4_loss: 0.0685 - q5_loss: 0.0548 - q6_loss: 0.0430 - q7_loss: 0.0120 - q8_loss: 0.0042 - val_loss: 0.2903 - val_q0_loss: 0.0025 - val_q1_loss: 0.0091 - val_q2_loss: 0.0398 - val_q3_loss: 0.0514 - val_q4_loss: 0.0665 - val_q5_loss: 0.0546 - val_q6_loss: 0.0441 - val_q7_loss: 0.0133 - val_q8_loss: 0.0040\n",
      "Epoch 51/300\n",
      "1575/1575 [==============================] - 0s 124us/sample - loss: 0.2908 - q0_loss: 0.0025 - q1_loss: 0.0096 - q2_loss: 0.0423 - q3_loss: 0.0537 - q4_loss: 0.0679 - q5_loss: 0.0547 - q6_loss: 0.0432 - q7_loss: 0.0121 - q8_loss: 0.0042 - val_loss: 0.2922 - val_q0_loss: 0.0024 - val_q1_loss: 0.0088 - val_q2_loss: 0.0398 - val_q3_loss: 0.0516 - val_q4_loss: 0.0674 - val_q5_loss: 0.0546 - val_q6_loss: 0.0452 - val_q7_loss: 0.0135 - val_q8_loss: 0.0046\n",
      "Epoch 52/300\n",
      "1575/1575 [==============================] - 0s 134us/sample - loss: 0.2973 - q0_loss: 0.0026 - q1_loss: 0.0098 - q2_loss: 0.0434 - q3_loss: 0.0547 - q4_loss: 0.0695 - q5_loss: 0.0561 - q6_loss: 0.0437 - q7_loss: 0.0121 - q8_loss: 0.0043 - val_loss: 0.2986 - val_q0_loss: 0.0026 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0530 - val_q4_loss: 0.0693 - val_q5_loss: 0.0557 - val_q6_loss: 0.0486 - val_q7_loss: 0.0128 - val_q8_loss: 0.0050\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.3001 - q0_loss: 0.0025 - q1_loss: 0.0097 - q2_loss: 0.0432 - q3_loss: 0.0550 - q4_loss: 0.0705 - q5_loss: 0.0574 - q6_loss: 0.0448 - q7_loss: 0.0126 - q8_loss: 0.0047 - val_loss: 0.3488 - val_q0_loss: 0.0027 - val_q1_loss: 0.0101 - val_q2_loss: 0.0450 - val_q3_loss: 0.0608 - val_q4_loss: 0.0777 - val_q5_loss: 0.0643 - val_q6_loss: 0.0595 - val_q7_loss: 0.0119 - val_q8_loss: 0.0141\n",
      "Epoch 54/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2969 - q0_loss: 0.0026 - q1_loss: 0.0097 - q2_loss: 0.0440 - q3_loss: 0.0547 - q4_loss: 0.0695 - q5_loss: 0.0560 - q6_loss: 0.0443 - q7_loss: 0.0121 - q8_loss: 0.0043 - val_loss: 0.2985 - val_q0_loss: 0.0026 - val_q1_loss: 0.0089 - val_q2_loss: 0.0406 - val_q3_loss: 0.0516 - val_q4_loss: 0.0684 - val_q5_loss: 0.0549 - val_q6_loss: 0.0492 - val_q7_loss: 0.0131 - val_q8_loss: 0.0040\n",
      "Epoch 55/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2950 - q0_loss: 0.0025 - q1_loss: 0.0099 - q2_loss: 0.0458 - q3_loss: 0.0539 - q4_loss: 0.0690 - q5_loss: 0.0566 - q6_loss: 0.0440 - q7_loss: 0.0123 - q8_loss: 0.0040 - val_loss: 0.2943 - val_q0_loss: 0.0021 - val_q1_loss: 0.0095 - val_q2_loss: 0.0428 - val_q3_loss: 0.0515 - val_q4_loss: 0.0674 - val_q5_loss: 0.0541 - val_q6_loss: 0.0457 - val_q7_loss: 0.0131 - val_q8_loss: 0.0045\n",
      "Epoch 56/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2959 - q0_loss: 0.0025 - q1_loss: 0.0099 - q2_loss: 0.0438 - q3_loss: 0.0540 - q4_loss: 0.0680 - q5_loss: 0.0565 - q6_loss: 0.0437 - q7_loss: 0.0117 - q8_loss: 0.0049 - val_loss: 0.3393 - val_q0_loss: 0.0025 - val_q1_loss: 0.0122 - val_q2_loss: 0.0603 - val_q3_loss: 0.0573 - val_q4_loss: 0.0700 - val_q5_loss: 0.0676 - val_q6_loss: 0.0452 - val_q7_loss: 0.0148 - val_q8_loss: 0.0051\n",
      "Epoch 57/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2965 - q0_loss: 0.0025 - q1_loss: 0.0099 - q2_loss: 0.0443 - q3_loss: 0.0546 - q4_loss: 0.0691 - q5_loss: 0.0561 - q6_loss: 0.0441 - q7_loss: 0.0117 - q8_loss: 0.0043 - val_loss: 0.2861 - val_q0_loss: 0.0024 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0513 - val_q4_loss: 0.0655 - val_q5_loss: 0.0547 - val_q6_loss: 0.0437 - val_q7_loss: 0.0124 - val_q8_loss: 0.0041\n",
      "Epoch 58/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2937 - q0_loss: 0.0025 - q1_loss: 0.0099 - q2_loss: 0.0438 - q3_loss: 0.0537 - q4_loss: 0.0680 - q5_loss: 0.0552 - q6_loss: 0.0437 - q7_loss: 0.0117 - q8_loss: 0.0041 - val_loss: 0.2947 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0411 - val_q3_loss: 0.0520 - val_q4_loss: 0.0686 - val_q5_loss: 0.0546 - val_q6_loss: 0.0456 - val_q7_loss: 0.0129 - val_q8_loss: 0.0046\n",
      "Epoch 59/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2964 - q0_loss: 0.0025 - q1_loss: 0.0100 - q2_loss: 0.0445 - q3_loss: 0.0548 - q4_loss: 0.0689 - q5_loss: 0.0566 - q6_loss: 0.0433 - q7_loss: 0.0117 - q8_loss: 0.0040 - val_loss: 0.2914 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0404 - val_q3_loss: 0.0521 - val_q4_loss: 0.0672 - val_q5_loss: 0.0560 - val_q6_loss: 0.0432 - val_q7_loss: 0.0132 - val_q8_loss: 0.0043\n",
      "Epoch 60/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2916 - q0_loss: 0.0025 - q1_loss: 0.0095 - q2_loss: 0.0430 - q3_loss: 0.0539 - q4_loss: 0.0685 - q5_loss: 0.0549 - q6_loss: 0.0438 - q7_loss: 0.0116 - q8_loss: 0.0041 - val_loss: 0.2923 - val_q0_loss: 0.0024 - val_q1_loss: 0.0096 - val_q2_loss: 0.0432 - val_q3_loss: 0.0518 - val_q4_loss: 0.0654 - val_q5_loss: 0.0559 - val_q6_loss: 0.0446 - val_q7_loss: 0.0121 - val_q8_loss: 0.0039\n",
      "Epoch 61/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2926 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0436 - q3_loss: 0.0534 - q4_loss: 0.0680 - q5_loss: 0.0542 - q6_loss: 0.0445 - q7_loss: 0.0116 - q8_loss: 0.0044 - val_loss: 0.3067 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0440 - val_q3_loss: 0.0544 - val_q4_loss: 0.0693 - val_q5_loss: 0.0606 - val_q6_loss: 0.0458 - val_q7_loss: 0.0136 - val_q8_loss: 0.0048\n",
      "Epoch 62/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2939 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0438 - q3_loss: 0.0541 - q4_loss: 0.0685 - q5_loss: 0.0568 - q6_loss: 0.0437 - q7_loss: 0.0115 - q8_loss: 0.0041 - val_loss: 0.2971 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0438 - val_q3_loss: 0.0521 - val_q4_loss: 0.0671 - val_q5_loss: 0.0584 - val_q6_loss: 0.0447 - val_q7_loss: 0.0124 - val_q8_loss: 0.0044\n",
      "Epoch 63/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2908 - q0_loss: 0.0025 - q1_loss: 0.0098 - q2_loss: 0.0428 - q3_loss: 0.0533 - q4_loss: 0.0672 - q5_loss: 0.0557 - q6_loss: 0.0425 - q7_loss: 0.0116 - q8_loss: 0.0044 - val_loss: 0.2956 - val_q0_loss: 0.0024 - val_q1_loss: 0.0096 - val_q2_loss: 0.0422 - val_q3_loss: 0.0517 - val_q4_loss: 0.0660 - val_q5_loss: 0.0592 - val_q6_loss: 0.0435 - val_q7_loss: 0.0116 - val_q8_loss: 0.0042\n",
      "Epoch 64/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2870 - q0_loss: 0.0025 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0531 - q4_loss: 0.0673 - q5_loss: 0.0538 - q6_loss: 0.0424 - q7_loss: 0.0114 - q8_loss: 0.0038 - val_loss: 0.3032 - val_q0_loss: 0.0021 - val_q1_loss: 0.0091 - val_q2_loss: 0.0409 - val_q3_loss: 0.0547 - val_q4_loss: 0.0712 - val_q5_loss: 0.0577 - val_q6_loss: 0.0464 - val_q7_loss: 0.0132 - val_q8_loss: 0.0047\n",
      "Epoch 65/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2951 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0433 - q3_loss: 0.0546 - q4_loss: 0.0690 - q5_loss: 0.0560 - q6_loss: 0.0442 - q7_loss: 0.0114 - q8_loss: 0.0043 - val_loss: 0.2890 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0423 - val_q3_loss: 0.0514 - val_q4_loss: 0.0657 - val_q5_loss: 0.0560 - val_q6_loss: 0.0427 - val_q7_loss: 0.0121 - val_q8_loss: 0.0040\n",
      "Epoch 66/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2955 - q0_loss: 0.0025 - q1_loss: 0.0098 - q2_loss: 0.0436 - q3_loss: 0.0535 - q4_loss: 0.0689 - q5_loss: 0.0559 - q6_loss: 0.0443 - q7_loss: 0.0114 - q8_loss: 0.0042 - val_loss: 0.2886 - val_q0_loss: 0.0024 - val_q1_loss: 0.0090 - val_q2_loss: 0.0396 - val_q3_loss: 0.0515 - val_q4_loss: 0.0659 - val_q5_loss: 0.0559 - val_q6_loss: 0.0456 - val_q7_loss: 0.0115 - val_q8_loss: 0.0039\n",
      "Epoch 67/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2885 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0426 - q3_loss: 0.0542 - q4_loss: 0.0681 - q5_loss: 0.0546 - q6_loss: 0.0430 - q7_loss: 0.0113 - q8_loss: 0.0041 - val_loss: 0.2894 - val_q0_loss: 0.0024 - val_q1_loss: 0.0091 - val_q2_loss: 0.0407 - val_q3_loss: 0.0521 - val_q4_loss: 0.0661 - val_q5_loss: 0.0549 - val_q6_loss: 0.0446 - val_q7_loss: 0.0122 - val_q8_loss: 0.0038\n",
      "Epoch 68/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2896 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0426 - q3_loss: 0.0542 - q4_loss: 0.0688 - q5_loss: 0.0539 - q6_loss: 0.0436 - q7_loss: 0.0111 - q8_loss: 0.0042 - val_loss: 0.3013 - val_q0_loss: 0.0021 - val_q1_loss: 0.0094 - val_q2_loss: 0.0437 - val_q3_loss: 0.0522 - val_q4_loss: 0.0701 - val_q5_loss: 0.0557 - val_q6_loss: 0.0486 - val_q7_loss: 0.0123 - val_q8_loss: 0.0046\n",
      "Epoch 69/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2891 - q0_loss: 0.0025 - q1_loss: 0.0095 - q2_loss: 0.0429 - q3_loss: 0.0538 - q4_loss: 0.0681 - q5_loss: 0.0540 - q6_loss: 0.0438 - q7_loss: 0.0108 - q8_loss: 0.0041 - val_loss: 0.2891 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0410 - val_q3_loss: 0.0518 - val_q4_loss: 0.0658 - val_q5_loss: 0.0552 - val_q6_loss: 0.0440 - val_q7_loss: 0.0119 - val_q8_loss: 0.0038\n",
      "Epoch 70/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2884 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0434 - q3_loss: 0.0533 - q4_loss: 0.0676 - q5_loss: 0.0553 - q6_loss: 0.0425 - q7_loss: 0.0109 - q8_loss: 0.0040 - val_loss: 0.3302 - val_q0_loss: 0.0024 - val_q1_loss: 0.0101 - val_q2_loss: 0.0476 - val_q3_loss: 0.0580 - val_q4_loss: 0.0723 - val_q5_loss: 0.0652 - val_q6_loss: 0.0491 - val_q7_loss: 0.0134 - val_q8_loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2964 - q0_loss: 0.0024 - q1_loss: 0.0098 - q2_loss: 0.0436 - q3_loss: 0.0553 - q4_loss: 0.0704 - q5_loss: 0.0574 - q6_loss: 0.0464 - q7_loss: 0.0112 - q8_loss: 0.0052 - val_loss: 0.2907 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0423 - val_q3_loss: 0.0522 - val_q4_loss: 0.0655 - val_q5_loss: 0.0563 - val_q6_loss: 0.0443 - val_q7_loss: 0.0114 - val_q8_loss: 0.0039\n",
      "Epoch 72/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2989 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0440 - q3_loss: 0.0550 - q4_loss: 0.0706 - q5_loss: 0.0563 - q6_loss: 0.0460 - q7_loss: 0.0112 - q8_loss: 0.0044 - val_loss: 0.2862 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0396 - val_q3_loss: 0.0511 - val_q4_loss: 0.0651 - val_q5_loss: 0.0556 - val_q6_loss: 0.0434 - val_q7_loss: 0.0119 - val_q8_loss: 0.0041\n",
      "Epoch 73/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2887 - q0_loss: 0.0025 - q1_loss: 0.0096 - q2_loss: 0.0431 - q3_loss: 0.0538 - q4_loss: 0.0680 - q5_loss: 0.0548 - q6_loss: 0.0432 - q7_loss: 0.0109 - q8_loss: 0.0044 - val_loss: 0.2869 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0514 - val_q4_loss: 0.0656 - val_q5_loss: 0.0547 - val_q6_loss: 0.0436 - val_q7_loss: 0.0119 - val_q8_loss: 0.0042\n",
      "Epoch 74/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2915 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0428 - q3_loss: 0.0535 - q4_loss: 0.0676 - q5_loss: 0.0553 - q6_loss: 0.0434 - q7_loss: 0.0109 - q8_loss: 0.0042 - val_loss: 0.2973 - val_q0_loss: 0.0023 - val_q1_loss: 0.0097 - val_q2_loss: 0.0452 - val_q3_loss: 0.0522 - val_q4_loss: 0.0656 - val_q5_loss: 0.0585 - val_q6_loss: 0.0434 - val_q7_loss: 0.0124 - val_q8_loss: 0.0043\n",
      "Epoch 75/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2879 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0533 - q4_loss: 0.0667 - q5_loss: 0.0546 - q6_loss: 0.0424 - q7_loss: 0.0106 - q8_loss: 0.0043 - val_loss: 0.2871 - val_q0_loss: 0.0021 - val_q1_loss: 0.0088 - val_q2_loss: 0.0398 - val_q3_loss: 0.0510 - val_q4_loss: 0.0664 - val_q5_loss: 0.0550 - val_q6_loss: 0.0453 - val_q7_loss: 0.0115 - val_q8_loss: 0.0043\n",
      "Epoch 76/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2902 - q0_loss: 0.0024 - q1_loss: 0.0093 - q2_loss: 0.0418 - q3_loss: 0.0537 - q4_loss: 0.0691 - q5_loss: 0.0551 - q6_loss: 0.0443 - q7_loss: 0.0111 - q8_loss: 0.0043 - val_loss: 0.3246 - val_q0_loss: 0.0025 - val_q1_loss: 0.0093 - val_q2_loss: 0.0417 - val_q3_loss: 0.0556 - val_q4_loss: 0.0722 - val_q5_loss: 0.0604 - val_q6_loss: 0.0536 - val_q7_loss: 0.0116 - val_q8_loss: 0.0116\n",
      "Epoch 77/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2896 - q0_loss: 0.0024 - q1_loss: 0.0093 - q2_loss: 0.0425 - q3_loss: 0.0540 - q4_loss: 0.0685 - q5_loss: 0.0553 - q6_loss: 0.0434 - q7_loss: 0.0107 - q8_loss: 0.0046 - val_loss: 0.2846 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0402 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0548 - val_q6_loss: 0.0434 - val_q7_loss: 0.0112 - val_q8_loss: 0.0040\n",
      "Epoch 78/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2936 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0424 - q3_loss: 0.0544 - q4_loss: 0.0697 - q5_loss: 0.0554 - q6_loss: 0.0446 - q7_loss: 0.0111 - q8_loss: 0.0046 - val_loss: 0.2962 - val_q0_loss: 0.0020 - val_q1_loss: 0.0087 - val_q2_loss: 0.0406 - val_q3_loss: 0.0525 - val_q4_loss: 0.0694 - val_q5_loss: 0.0571 - val_q6_loss: 0.0468 - val_q7_loss: 0.0118 - val_q8_loss: 0.0048\n",
      "Epoch 79/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2898 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0428 - q3_loss: 0.0539 - q4_loss: 0.0681 - q5_loss: 0.0546 - q6_loss: 0.0434 - q7_loss: 0.0106 - q8_loss: 0.0042 - val_loss: 0.3077 - val_q0_loss: 0.0023 - val_q1_loss: 0.0097 - val_q2_loss: 0.0456 - val_q3_loss: 0.0555 - val_q4_loss: 0.0681 - val_q5_loss: 0.0611 - val_q6_loss: 0.0455 - val_q7_loss: 0.0121 - val_q8_loss: 0.0050\n",
      "Epoch 80/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2908 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0423 - q3_loss: 0.0537 - q4_loss: 0.0687 - q5_loss: 0.0542 - q6_loss: 0.0432 - q7_loss: 0.0105 - q8_loss: 0.0042 - val_loss: 0.2874 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0407 - val_q3_loss: 0.0515 - val_q4_loss: 0.0655 - val_q5_loss: 0.0543 - val_q6_loss: 0.0436 - val_q7_loss: 0.0115 - val_q8_loss: 0.0041\n",
      "Epoch 81/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2880 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0425 - q3_loss: 0.0535 - q4_loss: 0.0676 - q5_loss: 0.0547 - q6_loss: 0.0426 - q7_loss: 0.0104 - q8_loss: 0.0041 - val_loss: 0.3046 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0435 - val_q3_loss: 0.0533 - val_q4_loss: 0.0679 - val_q5_loss: 0.0585 - val_q6_loss: 0.0473 - val_q7_loss: 0.0115 - val_q8_loss: 0.0057\n",
      "Epoch 82/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2937 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0424 - q3_loss: 0.0545 - q4_loss: 0.0697 - q5_loss: 0.0553 - q6_loss: 0.0444 - q7_loss: 0.0107 - q8_loss: 0.0043 - val_loss: 0.2946 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0402 - val_q3_loss: 0.0526 - val_q4_loss: 0.0679 - val_q5_loss: 0.0558 - val_q6_loss: 0.0464 - val_q7_loss: 0.0113 - val_q8_loss: 0.0042\n",
      "Epoch 83/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2901 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0425 - q3_loss: 0.0541 - q4_loss: 0.0687 - q5_loss: 0.0531 - q6_loss: 0.0440 - q7_loss: 0.0103 - q8_loss: 0.0043 - val_loss: 0.3043 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0419 - val_q3_loss: 0.0526 - val_q4_loss: 0.0732 - val_q5_loss: 0.0548 - val_q6_loss: 0.0516 - val_q7_loss: 0.0114 - val_q8_loss: 0.0049\n",
      "Epoch 84/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2861 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0533 - q4_loss: 0.0679 - q5_loss: 0.0544 - q6_loss: 0.0431 - q7_loss: 0.0104 - q8_loss: 0.0040 - val_loss: 0.2885 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0400 - val_q3_loss: 0.0512 - val_q4_loss: 0.0656 - val_q5_loss: 0.0569 - val_q6_loss: 0.0451 - val_q7_loss: 0.0109 - val_q8_loss: 0.0040\n",
      "Epoch 85/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2882 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0436 - q3_loss: 0.0541 - q4_loss: 0.0681 - q5_loss: 0.0549 - q6_loss: 0.0424 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.3082 - val_q0_loss: 0.0023 - val_q1_loss: 0.0095 - val_q2_loss: 0.0447 - val_q3_loss: 0.0551 - val_q4_loss: 0.0695 - val_q5_loss: 0.0600 - val_q6_loss: 0.0463 - val_q7_loss: 0.0129 - val_q8_loss: 0.0063\n",
      "Epoch 86/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2839 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0428 - q3_loss: 0.0535 - q4_loss: 0.0674 - q5_loss: 0.0538 - q6_loss: 0.0422 - q7_loss: 0.0102 - q8_loss: 0.0043 - val_loss: 0.2942 - val_q0_loss: 0.0021 - val_q1_loss: 0.0089 - val_q2_loss: 0.0418 - val_q3_loss: 0.0526 - val_q4_loss: 0.0673 - val_q5_loss: 0.0571 - val_q6_loss: 0.0468 - val_q7_loss: 0.0112 - val_q8_loss: 0.0041\n",
      "Epoch 87/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2894 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0433 - q3_loss: 0.0541 - q4_loss: 0.0685 - q5_loss: 0.0546 - q6_loss: 0.0431 - q7_loss: 0.0103 - q8_loss: 0.0039 - val_loss: 0.3052 - val_q0_loss: 0.0023 - val_q1_loss: 0.0097 - val_q2_loss: 0.0457 - val_q3_loss: 0.0545 - val_q4_loss: 0.0669 - val_q5_loss: 0.0596 - val_q6_loss: 0.0459 - val_q7_loss: 0.0125 - val_q8_loss: 0.0057\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2868 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0423 - q3_loss: 0.0528 - q4_loss: 0.0671 - q5_loss: 0.0535 - q6_loss: 0.0432 - q7_loss: 0.0101 - q8_loss: 0.0042 - val_loss: 0.2904 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0411 - val_q3_loss: 0.0521 - val_q4_loss: 0.0664 - val_q5_loss: 0.0555 - val_q6_loss: 0.0452 - val_q7_loss: 0.0111 - val_q8_loss: 0.0040\n",
      "Epoch 89/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2906 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0539 - q4_loss: 0.0685 - q5_loss: 0.0545 - q6_loss: 0.0447 - q7_loss: 0.0104 - q8_loss: 0.0041 - val_loss: 0.2879 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0413 - val_q3_loss: 0.0519 - val_q4_loss: 0.0657 - val_q5_loss: 0.0556 - val_q6_loss: 0.0437 - val_q7_loss: 0.0113 - val_q8_loss: 0.0042\n",
      "Epoch 90/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2868 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0422 - q3_loss: 0.0531 - q4_loss: 0.0671 - q5_loss: 0.0547 - q6_loss: 0.0421 - q7_loss: 0.0102 - q8_loss: 0.0041 - val_loss: 0.2973 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0430 - val_q3_loss: 0.0536 - val_q4_loss: 0.0677 - val_q5_loss: 0.0567 - val_q6_loss: 0.0438 - val_q7_loss: 0.0120 - val_q8_loss: 0.0043\n",
      "Epoch 91/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2883 - q0_loss: 0.0024 - q1_loss: 0.0097 - q2_loss: 0.0428 - q3_loss: 0.0542 - q4_loss: 0.0679 - q5_loss: 0.0534 - q6_loss: 0.0434 - q7_loss: 0.0101 - q8_loss: 0.0041 - val_loss: 0.2852 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0399 - val_q3_loss: 0.0514 - val_q4_loss: 0.0663 - val_q5_loss: 0.0544 - val_q6_loss: 0.0433 - val_q7_loss: 0.0111 - val_q8_loss: 0.0041\n",
      "Epoch 92/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2874 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0423 - q3_loss: 0.0538 - q4_loss: 0.0684 - q5_loss: 0.0549 - q6_loss: 0.0430 - q7_loss: 0.0104 - q8_loss: 0.0041 - val_loss: 0.3006 - val_q0_loss: 0.0022 - val_q1_loss: 0.0099 - val_q2_loss: 0.0464 - val_q3_loss: 0.0536 - val_q4_loss: 0.0661 - val_q5_loss: 0.0601 - val_q6_loss: 0.0432 - val_q7_loss: 0.0120 - val_q8_loss: 0.0036\n",
      "Epoch 93/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2953 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0441 - q3_loss: 0.0543 - q4_loss: 0.0690 - q5_loss: 0.0576 - q6_loss: 0.0439 - q7_loss: 0.0108 - q8_loss: 0.0042 - val_loss: 0.2863 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0412 - val_q3_loss: 0.0516 - val_q4_loss: 0.0658 - val_q5_loss: 0.0545 - val_q6_loss: 0.0436 - val_q7_loss: 0.0108 - val_q8_loss: 0.0037\n",
      "Epoch 94/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2843 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0423 - q3_loss: 0.0527 - q4_loss: 0.0663 - q5_loss: 0.0542 - q6_loss: 0.0425 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.2954 - val_q0_loss: 0.0022 - val_q1_loss: 0.0096 - val_q2_loss: 0.0440 - val_q3_loss: 0.0530 - val_q4_loss: 0.0658 - val_q5_loss: 0.0572 - val_q6_loss: 0.0451 - val_q7_loss: 0.0113 - val_q8_loss: 0.0042\n",
      "Epoch 95/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2854 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0420 - q3_loss: 0.0531 - q4_loss: 0.0678 - q5_loss: 0.0539 - q6_loss: 0.0430 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.2876 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0400 - val_q3_loss: 0.0512 - val_q4_loss: 0.0655 - val_q5_loss: 0.0552 - val_q6_loss: 0.0449 - val_q7_loss: 0.0109 - val_q8_loss: 0.0042\n",
      "Epoch 96/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2860 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0423 - q3_loss: 0.0531 - q4_loss: 0.0677 - q5_loss: 0.0539 - q6_loss: 0.0425 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.2938 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0442 - val_q3_loss: 0.0526 - val_q4_loss: 0.0659 - val_q5_loss: 0.0579 - val_q6_loss: 0.0434 - val_q7_loss: 0.0113 - val_q8_loss: 0.0036\n",
      "Epoch 97/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2898 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0426 - q3_loss: 0.0538 - q4_loss: 0.0688 - q5_loss: 0.0560 - q6_loss: 0.0434 - q7_loss: 0.0104 - q8_loss: 0.0042 - val_loss: 0.2942 - val_q0_loss: 0.0021 - val_q1_loss: 0.0089 - val_q2_loss: 0.0415 - val_q3_loss: 0.0518 - val_q4_loss: 0.0693 - val_q5_loss: 0.0562 - val_q6_loss: 0.0463 - val_q7_loss: 0.0108 - val_q8_loss: 0.0045\n",
      "Epoch 98/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2879 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0424 - q3_loss: 0.0536 - q4_loss: 0.0688 - q5_loss: 0.0540 - q6_loss: 0.0442 - q7_loss: 0.0105 - q8_loss: 0.0042 - val_loss: 0.2905 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0425 - val_q3_loss: 0.0529 - val_q4_loss: 0.0658 - val_q5_loss: 0.0556 - val_q6_loss: 0.0442 - val_q7_loss: 0.0112 - val_q8_loss: 0.0036\n",
      "Epoch 99/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2856 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0419 - q3_loss: 0.0523 - q4_loss: 0.0666 - q5_loss: 0.0539 - q6_loss: 0.0427 - q7_loss: 0.0101 - q8_loss: 0.0041 - val_loss: 0.2858 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0412 - val_q3_loss: 0.0515 - val_q4_loss: 0.0654 - val_q5_loss: 0.0551 - val_q6_loss: 0.0428 - val_q7_loss: 0.0110 - val_q8_loss: 0.0039\n",
      "Epoch 100/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2859 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0432 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0536 - q6_loss: 0.0430 - q7_loss: 0.0099 - q8_loss: 0.0038 - val_loss: 0.2938 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0410 - val_q3_loss: 0.0523 - val_q4_loss: 0.0686 - val_q5_loss: 0.0577 - val_q6_loss: 0.0451 - val_q7_loss: 0.0108 - val_q8_loss: 0.0042\n",
      "Epoch 101/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2846 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0426 - q3_loss: 0.0535 - q4_loss: 0.0670 - q5_loss: 0.0541 - q6_loss: 0.0419 - q7_loss: 0.0100 - q8_loss: 0.0039 - val_loss: 0.2874 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0518 - val_q4_loss: 0.0664 - val_q5_loss: 0.0541 - val_q6_loss: 0.0437 - val_q7_loss: 0.0114 - val_q8_loss: 0.0039\n",
      "Epoch 102/300\n",
      "1575/1575 [==============================] - 0s 147us/sample - loss: 0.2835 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0417 - q3_loss: 0.0531 - q4_loss: 0.0671 - q5_loss: 0.0535 - q6_loss: 0.0416 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.2860 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0397 - val_q3_loss: 0.0515 - val_q4_loss: 0.0651 - val_q5_loss: 0.0550 - val_q6_loss: 0.0454 - val_q7_loss: 0.0108 - val_q8_loss: 0.0040\n",
      "Epoch 103/300\n",
      "1575/1575 [==============================] - 0s 179us/sample - loss: 0.2837 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0669 - q5_loss: 0.0534 - q6_loss: 0.0422 - q7_loss: 0.0101 - q8_loss: 0.0038 - val_loss: 0.2879 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0416 - val_q3_loss: 0.0519 - val_q4_loss: 0.0657 - val_q5_loss: 0.0554 - val_q6_loss: 0.0438 - val_q7_loss: 0.0109 - val_q8_loss: 0.0034\n",
      "Epoch 104/300\n",
      "1575/1575 [==============================] - 0s 191us/sample - loss: 0.2949 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0434 - q3_loss: 0.0555 - q4_loss: 0.0707 - q5_loss: 0.0571 - q6_loss: 0.0449 - q7_loss: 0.0107 - q8_loss: 0.0041 - val_loss: 0.2933 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0405 - val_q3_loss: 0.0529 - val_q4_loss: 0.0689 - val_q5_loss: 0.0543 - val_q6_loss: 0.0456 - val_q7_loss: 0.0114 - val_q8_loss: 0.0042\n",
      "Epoch 105/300\n",
      "1575/1575 [==============================] - 0s 140us/sample - loss: 0.2871 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0422 - q3_loss: 0.0535 - q4_loss: 0.0673 - q5_loss: 0.0543 - q6_loss: 0.0419 - q7_loss: 0.0104 - q8_loss: 0.0039 - val_loss: 0.2887 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0405 - val_q3_loss: 0.0519 - val_q4_loss: 0.0665 - val_q5_loss: 0.0553 - val_q6_loss: 0.0439 - val_q7_loss: 0.0113 - val_q8_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/300\n",
      "1575/1575 [==============================] - 0s 153us/sample - loss: 0.2859 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0419 - q3_loss: 0.0528 - q4_loss: 0.0669 - q5_loss: 0.0536 - q6_loss: 0.0430 - q7_loss: 0.0101 - q8_loss: 0.0039 - val_loss: 0.2842 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0405 - val_q3_loss: 0.0510 - val_q4_loss: 0.0651 - val_q5_loss: 0.0552 - val_q6_loss: 0.0430 - val_q7_loss: 0.0107 - val_q8_loss: 0.0038\n",
      "Epoch 107/300\n",
      "1575/1575 [==============================] - 0s 189us/sample - loss: 0.2844 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0414 - q3_loss: 0.0528 - q4_loss: 0.0669 - q5_loss: 0.0530 - q6_loss: 0.0426 - q7_loss: 0.0101 - q8_loss: 0.0038 - val_loss: 0.2973 - val_q0_loss: 0.0024 - val_q1_loss: 0.0090 - val_q2_loss: 0.0403 - val_q3_loss: 0.0530 - val_q4_loss: 0.0676 - val_q5_loss: 0.0569 - val_q6_loss: 0.0471 - val_q7_loss: 0.0116 - val_q8_loss: 0.0044\n",
      "Epoch 108/300\n",
      "1575/1575 [==============================] - 0s 126us/sample - loss: 0.2872 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0536 - q4_loss: 0.0680 - q5_loss: 0.0537 - q6_loss: 0.0434 - q7_loss: 0.0100 - q8_loss: 0.0039 - val_loss: 0.2891 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0518 - val_q4_loss: 0.0674 - val_q5_loss: 0.0547 - val_q6_loss: 0.0458 - val_q7_loss: 0.0110 - val_q8_loss: 0.0041\n",
      "Epoch 109/300\n",
      "1575/1575 [==============================] - 0s 164us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0533 - q4_loss: 0.0670 - q5_loss: 0.0531 - q6_loss: 0.0423 - q7_loss: 0.0099 - q8_loss: 0.0038 - val_loss: 0.2860 - val_q0_loss: 0.0021 - val_q1_loss: 0.0089 - val_q2_loss: 0.0396 - val_q3_loss: 0.0512 - val_q4_loss: 0.0657 - val_q5_loss: 0.0548 - val_q6_loss: 0.0465 - val_q7_loss: 0.0106 - val_q8_loss: 0.0037\n",
      "Epoch 110/300\n",
      "1575/1575 [==============================] - 0s 160us/sample - loss: 0.2891 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0418 - q3_loss: 0.0541 - q4_loss: 0.0686 - q5_loss: 0.0545 - q6_loss: 0.0437 - q7_loss: 0.0102 - q8_loss: 0.0039 - val_loss: 0.2940 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0416 - val_q3_loss: 0.0525 - val_q4_loss: 0.0695 - val_q5_loss: 0.0548 - val_q6_loss: 0.0466 - val_q7_loss: 0.0110 - val_q8_loss: 0.0041\n",
      "Epoch 111/300\n",
      "1575/1575 [==============================] - 0s 135us/sample - loss: 0.2876 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0422 - q3_loss: 0.0535 - q4_loss: 0.0680 - q5_loss: 0.0537 - q6_loss: 0.0434 - q7_loss: 0.0100 - q8_loss: 0.0039 - val_loss: 0.2902 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0420 - val_q3_loss: 0.0520 - val_q4_loss: 0.0655 - val_q5_loss: 0.0565 - val_q6_loss: 0.0442 - val_q7_loss: 0.0111 - val_q8_loss: 0.0036\n",
      "Epoch 112/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2890 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0428 - q3_loss: 0.0540 - q4_loss: 0.0684 - q5_loss: 0.0544 - q6_loss: 0.0429 - q7_loss: 0.0103 - q8_loss: 0.0039 - val_loss: 0.2893 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0397 - val_q3_loss: 0.0518 - val_q4_loss: 0.0661 - val_q5_loss: 0.0548 - val_q6_loss: 0.0469 - val_q7_loss: 0.0107 - val_q8_loss: 0.0038\n",
      "Epoch 113/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0535 - q4_loss: 0.0673 - q5_loss: 0.0533 - q6_loss: 0.0420 - q7_loss: 0.0100 - q8_loss: 0.0036 - val_loss: 0.2888 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0404 - val_q3_loss: 0.0514 - val_q4_loss: 0.0661 - val_q5_loss: 0.0565 - val_q6_loss: 0.0442 - val_q7_loss: 0.0111 - val_q8_loss: 0.0036\n",
      "Epoch 114/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2841 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0420 - q3_loss: 0.0532 - q4_loss: 0.0674 - q5_loss: 0.0530 - q6_loss: 0.0430 - q7_loss: 0.0099 - q8_loss: 0.0037 - val_loss: 0.2884 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0418 - val_q3_loss: 0.0513 - val_q4_loss: 0.0652 - val_q5_loss: 0.0557 - val_q6_loss: 0.0443 - val_q7_loss: 0.0111 - val_q8_loss: 0.0037\n",
      "Epoch 115/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2857 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0421 - q3_loss: 0.0534 - q4_loss: 0.0675 - q5_loss: 0.0542 - q6_loss: 0.0421 - q7_loss: 0.0100 - q8_loss: 0.0038 - val_loss: 0.2907 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0422 - val_q3_loss: 0.0513 - val_q4_loss: 0.0652 - val_q5_loss: 0.0578 - val_q6_loss: 0.0439 - val_q7_loss: 0.0110 - val_q8_loss: 0.0038\n",
      "Epoch 116/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2894 - q0_loss: 0.0023 - q1_loss: 0.0098 - q2_loss: 0.0433 - q3_loss: 0.0542 - q4_loss: 0.0679 - q5_loss: 0.0550 - q6_loss: 0.0438 - q7_loss: 0.0104 - q8_loss: 0.0039 - val_loss: 0.2915 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0422 - val_q3_loss: 0.0518 - val_q4_loss: 0.0674 - val_q5_loss: 0.0567 - val_q6_loss: 0.0446 - val_q7_loss: 0.0109 - val_q8_loss: 0.0039\n",
      "Epoch 117/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2865 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0536 - q4_loss: 0.0683 - q5_loss: 0.0545 - q6_loss: 0.0434 - q7_loss: 0.0100 - q8_loss: 0.0036 - val_loss: 0.2894 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0420 - val_q3_loss: 0.0518 - val_q4_loss: 0.0668 - val_q5_loss: 0.0558 - val_q6_loss: 0.0437 - val_q7_loss: 0.0108 - val_q8_loss: 0.0037\n",
      "Epoch 118/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2879 - q0_loss: 0.0025 - q1_loss: 0.0097 - q2_loss: 0.0419 - q3_loss: 0.0541 - q4_loss: 0.0689 - q5_loss: 0.0544 - q6_loss: 0.0444 - q7_loss: 0.0102 - q8_loss: 0.0037 - val_loss: 0.2914 - val_q0_loss: 0.0021 - val_q1_loss: 0.0091 - val_q2_loss: 0.0413 - val_q3_loss: 0.0516 - val_q4_loss: 0.0675 - val_q5_loss: 0.0550 - val_q6_loss: 0.0468 - val_q7_loss: 0.0107 - val_q8_loss: 0.0040\n",
      "Epoch 119/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2945 - q0_loss: 0.0024 - q1_loss: 0.0099 - q2_loss: 0.0445 - q3_loss: 0.0546 - q4_loss: 0.0687 - q5_loss: 0.0563 - q6_loss: 0.0440 - q7_loss: 0.0107 - q8_loss: 0.0042 - val_loss: 0.2854 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0413 - val_q3_loss: 0.0514 - val_q4_loss: 0.0652 - val_q5_loss: 0.0551 - val_q6_loss: 0.0436 - val_q7_loss: 0.0107 - val_q8_loss: 0.0035\n",
      "Epoch 120/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2880 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0536 - q4_loss: 0.0674 - q5_loss: 0.0548 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0036 - val_loss: 0.2915 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0412 - val_q3_loss: 0.0527 - val_q4_loss: 0.0663 - val_q5_loss: 0.0553 - val_q6_loss: 0.0459 - val_q7_loss: 0.0114 - val_q8_loss: 0.0036\n",
      "Epoch 121/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2839 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0534 - q4_loss: 0.0676 - q5_loss: 0.0541 - q6_loss: 0.0424 - q7_loss: 0.0100 - q8_loss: 0.0035 - val_loss: 0.2865 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0404 - val_q3_loss: 0.0519 - val_q4_loss: 0.0666 - val_q5_loss: 0.0540 - val_q6_loss: 0.0431 - val_q7_loss: 0.0112 - val_q8_loss: 0.0036\n",
      "Epoch 122/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2833 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0417 - q3_loss: 0.0529 - q4_loss: 0.0668 - q5_loss: 0.0536 - q6_loss: 0.0423 - q7_loss: 0.0100 - q8_loss: 0.0035 - val_loss: 0.2845 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0395 - val_q3_loss: 0.0516 - val_q4_loss: 0.0666 - val_q5_loss: 0.0543 - val_q6_loss: 0.0430 - val_q7_loss: 0.0111 - val_q8_loss: 0.0033\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2889 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0433 - q3_loss: 0.0538 - q4_loss: 0.0679 - q5_loss: 0.0549 - q6_loss: 0.0419 - q7_loss: 0.0102 - q8_loss: 0.0034 - val_loss: 0.2855 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0406 - val_q3_loss: 0.0517 - val_q4_loss: 0.0659 - val_q5_loss: 0.0552 - val_q6_loss: 0.0433 - val_q7_loss: 0.0109 - val_q8_loss: 0.0031\n",
      "Epoch 124/300\n",
      "1575/1575 [==============================] - 0s 110us/sample - loss: 0.2847 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0422 - q3_loss: 0.0534 - q4_loss: 0.0675 - q5_loss: 0.0535 - q6_loss: 0.0430 - q7_loss: 0.0100 - q8_loss: 0.0034 - val_loss: 0.2864 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0408 - val_q3_loss: 0.0514 - val_q4_loss: 0.0657 - val_q5_loss: 0.0550 - val_q6_loss: 0.0428 - val_q7_loss: 0.0111 - val_q8_loss: 0.0035\n",
      "Epoch 125/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2880 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0425 - q3_loss: 0.0532 - q4_loss: 0.0668 - q5_loss: 0.0558 - q6_loss: 0.0422 - q7_loss: 0.0105 - q8_loss: 0.0036 - val_loss: 0.2838 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0406 - val_q3_loss: 0.0512 - val_q4_loss: 0.0650 - val_q5_loss: 0.0546 - val_q6_loss: 0.0436 - val_q7_loss: 0.0107 - val_q8_loss: 0.0032\n",
      "Epoch 126/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2831 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0417 - q3_loss: 0.0529 - q4_loss: 0.0668 - q5_loss: 0.0531 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0034 - val_loss: 0.2847 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0407 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0558 - val_q6_loss: 0.0436 - val_q7_loss: 0.0107 - val_q8_loss: 0.0032\n",
      "Epoch 127/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2870 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0422 - q3_loss: 0.0537 - q4_loss: 0.0684 - q5_loss: 0.0547 - q6_loss: 0.0433 - q7_loss: 0.0103 - q8_loss: 0.0036 - val_loss: 0.2878 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0519 - val_q4_loss: 0.0660 - val_q5_loss: 0.0555 - val_q6_loss: 0.0450 - val_q7_loss: 0.0110 - val_q8_loss: 0.0034\n",
      "Epoch 128/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0422 - q3_loss: 0.0538 - q4_loss: 0.0679 - q5_loss: 0.0532 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0035 - val_loss: 0.2893 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0417 - val_q3_loss: 0.0524 - val_q4_loss: 0.0663 - val_q5_loss: 0.0554 - val_q6_loss: 0.0440 - val_q7_loss: 0.0114 - val_q8_loss: 0.0032\n",
      "Epoch 129/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2872 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0427 - q3_loss: 0.0539 - q4_loss: 0.0672 - q5_loss: 0.0545 - q6_loss: 0.0423 - q7_loss: 0.0104 - q8_loss: 0.0035 - val_loss: 0.2881 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0398 - val_q3_loss: 0.0513 - val_q4_loss: 0.0656 - val_q5_loss: 0.0563 - val_q6_loss: 0.0454 - val_q7_loss: 0.0110 - val_q8_loss: 0.0034\n",
      "Epoch 130/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2822 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0672 - q5_loss: 0.0530 - q6_loss: 0.0424 - q7_loss: 0.0099 - q8_loss: 0.0033 - val_loss: 0.2845 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0515 - val_q4_loss: 0.0659 - val_q5_loss: 0.0550 - val_q6_loss: 0.0438 - val_q7_loss: 0.0110 - val_q8_loss: 0.0030\n",
      "Epoch 131/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2824 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0416 - q3_loss: 0.0531 - q4_loss: 0.0674 - q5_loss: 0.0529 - q6_loss: 0.0418 - q7_loss: 0.0099 - q8_loss: 0.0031 - val_loss: 0.2848 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0394 - val_q3_loss: 0.0512 - val_q4_loss: 0.0655 - val_q5_loss: 0.0552 - val_q6_loss: 0.0439 - val_q7_loss: 0.0110 - val_q8_loss: 0.0032\n",
      "Epoch 132/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2831 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0532 - q4_loss: 0.0671 - q5_loss: 0.0534 - q6_loss: 0.0420 - q7_loss: 0.0101 - q8_loss: 0.0032 - val_loss: 0.2866 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0416 - val_q3_loss: 0.0516 - val_q4_loss: 0.0651 - val_q5_loss: 0.0559 - val_q6_loss: 0.0443 - val_q7_loss: 0.0109 - val_q8_loss: 0.0032\n",
      "Epoch 133/300\n",
      "1575/1575 [==============================] - 0s 132us/sample - loss: 0.2859 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0436 - q3_loss: 0.0541 - q4_loss: 0.0680 - q5_loss: 0.0551 - q6_loss: 0.0425 - q7_loss: 0.0104 - q8_loss: 0.0034 - val_loss: 0.2893 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0420 - val_q3_loss: 0.0526 - val_q4_loss: 0.0661 - val_q5_loss: 0.0556 - val_q6_loss: 0.0440 - val_q7_loss: 0.0111 - val_q8_loss: 0.0028\n",
      "Epoch 134/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2863 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0539 - q4_loss: 0.0671 - q5_loss: 0.0544 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0032 - val_loss: 0.3021 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0416 - val_q3_loss: 0.0554 - val_q4_loss: 0.0703 - val_q5_loss: 0.0556 - val_q6_loss: 0.0481 - val_q7_loss: 0.0120 - val_q8_loss: 0.0034\n",
      "Epoch 135/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2841 - q0_loss: 0.0024 - q1_loss: 0.0092 - q2_loss: 0.0418 - q3_loss: 0.0535 - q4_loss: 0.0677 - q5_loss: 0.0540 - q6_loss: 0.0427 - q7_loss: 0.0100 - q8_loss: 0.0031 - val_loss: 0.2878 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0426 - val_q3_loss: 0.0516 - val_q4_loss: 0.0653 - val_q5_loss: 0.0556 - val_q6_loss: 0.0430 - val_q7_loss: 0.0114 - val_q8_loss: 0.0029\n",
      "Epoch 136/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2839 - q0_loss: 0.0022 - q1_loss: 0.0095 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0671 - q5_loss: 0.0542 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0031 - val_loss: 0.2886 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0402 - val_q3_loss: 0.0513 - val_q4_loss: 0.0663 - val_q5_loss: 0.0556 - val_q6_loss: 0.0446 - val_q7_loss: 0.0111 - val_q8_loss: 0.0034\n",
      "Epoch 137/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2876 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0430 - q3_loss: 0.0537 - q4_loss: 0.0678 - q5_loss: 0.0546 - q6_loss: 0.0429 - q7_loss: 0.0102 - q8_loss: 0.0032 - val_loss: 0.2832 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0396 - val_q3_loss: 0.0511 - val_q4_loss: 0.0655 - val_q5_loss: 0.0547 - val_q6_loss: 0.0439 - val_q7_loss: 0.0108 - val_q8_loss: 0.0030\n",
      "Epoch 138/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2878 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0428 - q3_loss: 0.0537 - q4_loss: 0.0678 - q5_loss: 0.0558 - q6_loss: 0.0426 - q7_loss: 0.0104 - q8_loss: 0.0032 - val_loss: 0.3117 - val_q0_loss: 0.0021 - val_q1_loss: 0.0093 - val_q2_loss: 0.0451 - val_q3_loss: 0.0551 - val_q4_loss: 0.0710 - val_q5_loss: 0.0646 - val_q6_loss: 0.0463 - val_q7_loss: 0.0119 - val_q8_loss: 0.0036\n",
      "Epoch 139/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2931 - q0_loss: 0.0023 - q1_loss: 0.0099 - q2_loss: 0.0443 - q3_loss: 0.0545 - q4_loss: 0.0685 - q5_loss: 0.0563 - q6_loss: 0.0434 - q7_loss: 0.0110 - q8_loss: 0.0035 - val_loss: 0.2924 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0409 - val_q3_loss: 0.0531 - val_q4_loss: 0.0682 - val_q5_loss: 0.0571 - val_q6_loss: 0.0439 - val_q7_loss: 0.0114 - val_q8_loss: 0.0033\n",
      "Epoch 140/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2850 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0415 - q3_loss: 0.0533 - q4_loss: 0.0673 - q5_loss: 0.0543 - q6_loss: 0.0425 - q7_loss: 0.0102 - q8_loss: 0.0032 - val_loss: 0.2896 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0422 - val_q3_loss: 0.0526 - val_q4_loss: 0.0660 - val_q5_loss: 0.0555 - val_q6_loss: 0.0445 - val_q7_loss: 0.0110 - val_q8_loss: 0.0028\n",
      "Epoch 141/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2845 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0423 - q3_loss: 0.0536 - q4_loss: 0.0683 - q5_loss: 0.0543 - q6_loss: 0.0435 - q7_loss: 0.0102 - q8_loss: 0.0032 - val_loss: 0.2947 - val_q0_loss: 0.0023 - val_q1_loss: 0.0098 - val_q2_loss: 0.0445 - val_q3_loss: 0.0523 - val_q4_loss: 0.0661 - val_q5_loss: 0.0575 - val_q6_loss: 0.0430 - val_q7_loss: 0.0117 - val_q8_loss: 0.0029\n",
      "Epoch 142/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2841 - q0_loss: 0.0024 - q1_loss: 0.0099 - q2_loss: 0.0432 - q3_loss: 0.0537 - q4_loss: 0.0673 - q5_loss: 0.0541 - q6_loss: 0.0420 - q7_loss: 0.0097 - q8_loss: 0.0028 - val_loss: 0.2971 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0427 - val_q3_loss: 0.0531 - val_q4_loss: 0.0673 - val_q5_loss: 0.0570 - val_q6_loss: 0.0470 - val_q7_loss: 0.0120 - val_q8_loss: 0.0042\n",
      "Epoch 143/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2861 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0538 - q4_loss: 0.0677 - q5_loss: 0.0540 - q6_loss: 0.0424 - q7_loss: 0.0100 - q8_loss: 0.0029 - val_loss: 0.2841 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0411 - val_q3_loss: 0.0516 - val_q4_loss: 0.0652 - val_q5_loss: 0.0543 - val_q6_loss: 0.0432 - val_q7_loss: 0.0109 - val_q8_loss: 0.0027\n",
      "Epoch 144/300\n",
      "1575/1575 [==============================] - 0s 124us/sample - loss: 0.2825 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0530 - q4_loss: 0.0669 - q5_loss: 0.0529 - q6_loss: 0.0421 - q7_loss: 0.0101 - q8_loss: 0.0029 - val_loss: 0.2851 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0402 - val_q3_loss: 0.0513 - val_q4_loss: 0.0665 - val_q5_loss: 0.0550 - val_q6_loss: 0.0448 - val_q7_loss: 0.0106 - val_q8_loss: 0.0028\n",
      "Epoch 145/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2822 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0413 - q3_loss: 0.0525 - q4_loss: 0.0666 - q5_loss: 0.0536 - q6_loss: 0.0424 - q7_loss: 0.0100 - q8_loss: 0.0028 - val_loss: 0.2861 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0405 - val_q3_loss: 0.0516 - val_q4_loss: 0.0663 - val_q5_loss: 0.0541 - val_q6_loss: 0.0441 - val_q7_loss: 0.0112 - val_q8_loss: 0.0029\n",
      "Epoch 146/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2847 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0429 - q3_loss: 0.0542 - q4_loss: 0.0679 - q5_loss: 0.0550 - q6_loss: 0.0430 - q7_loss: 0.0101 - q8_loss: 0.0029 - val_loss: 0.2856 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0414 - val_q3_loss: 0.0518 - val_q4_loss: 0.0651 - val_q5_loss: 0.0543 - val_q6_loss: 0.0437 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 147/300\n",
      "1575/1575 [==============================] - 0s 130us/sample - loss: 0.2829 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0422 - q3_loss: 0.0536 - q4_loss: 0.0675 - q5_loss: 0.0534 - q6_loss: 0.0417 - q7_loss: 0.0099 - q8_loss: 0.0029 - val_loss: 0.2859 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0407 - val_q3_loss: 0.0520 - val_q4_loss: 0.0655 - val_q5_loss: 0.0557 - val_q6_loss: 0.0443 - val_q7_loss: 0.0111 - val_q8_loss: 0.0027\n",
      "Epoch 148/300\n",
      "1575/1575 [==============================] - 0s 130us/sample - loss: 0.2851 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0533 - q4_loss: 0.0676 - q5_loss: 0.0535 - q6_loss: 0.0430 - q7_loss: 0.0102 - q8_loss: 0.0029 - val_loss: 0.2901 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0511 - val_q4_loss: 0.0676 - val_q5_loss: 0.0561 - val_q6_loss: 0.0451 - val_q7_loss: 0.0113 - val_q8_loss: 0.0031\n",
      "Epoch 149/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2866 - q0_loss: 0.0022 - q1_loss: 0.0094 - q2_loss: 0.0425 - q3_loss: 0.0538 - q4_loss: 0.0676 - q5_loss: 0.0547 - q6_loss: 0.0426 - q7_loss: 0.0103 - q8_loss: 0.0027 - val_loss: 0.2910 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0411 - val_q3_loss: 0.0524 - val_q4_loss: 0.0661 - val_q5_loss: 0.0574 - val_q6_loss: 0.0455 - val_q7_loss: 0.0112 - val_q8_loss: 0.0030\n",
      "Epoch 150/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2841 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0418 - q3_loss: 0.0533 - q4_loss: 0.0674 - q5_loss: 0.0532 - q6_loss: 0.0428 - q7_loss: 0.0102 - q8_loss: 0.0027 - val_loss: 0.2933 - val_q0_loss: 0.0022 - val_q1_loss: 0.0097 - val_q2_loss: 0.0446 - val_q3_loss: 0.0516 - val_q4_loss: 0.0656 - val_q5_loss: 0.0576 - val_q6_loss: 0.0440 - val_q7_loss: 0.0113 - val_q8_loss: 0.0028\n",
      "Epoch 151/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2884 - q0_loss: 0.0023 - q1_loss: 0.0098 - q2_loss: 0.0444 - q3_loss: 0.0542 - q4_loss: 0.0677 - q5_loss: 0.0556 - q6_loss: 0.0422 - q7_loss: 0.0102 - q8_loss: 0.0027 - val_loss: 0.2862 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0418 - val_q3_loss: 0.0519 - val_q4_loss: 0.0650 - val_q5_loss: 0.0542 - val_q6_loss: 0.0446 - val_q7_loss: 0.0109 - val_q8_loss: 0.0024\n",
      "Epoch 152/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2824 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0416 - q3_loss: 0.0533 - q4_loss: 0.0671 - q5_loss: 0.0537 - q6_loss: 0.0416 - q7_loss: 0.0103 - q8_loss: 0.0029 - val_loss: 0.2859 - val_q0_loss: 0.0024 - val_q1_loss: 0.0089 - val_q2_loss: 0.0394 - val_q3_loss: 0.0517 - val_q4_loss: 0.0666 - val_q5_loss: 0.0544 - val_q6_loss: 0.0437 - val_q7_loss: 0.0112 - val_q8_loss: 0.0026\n",
      "Epoch 153/300\n",
      "1575/1575 [==============================] - 0s 160us/sample - loss: 0.2821 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0415 - q3_loss: 0.0533 - q4_loss: 0.0672 - q5_loss: 0.0532 - q6_loss: 0.0423 - q7_loss: 0.0098 - q8_loss: 0.0025 - val_loss: 0.3014 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0435 - val_q3_loss: 0.0537 - val_q4_loss: 0.0674 - val_q5_loss: 0.0601 - val_q6_loss: 0.0459 - val_q7_loss: 0.0132 - val_q8_loss: 0.0035\n",
      "Epoch 154/300\n",
      "1575/1575 [==============================] - 0s 137us/sample - loss: 0.2917 - q0_loss: 0.0023 - q1_loss: 0.0099 - q2_loss: 0.0441 - q3_loss: 0.0547 - q4_loss: 0.0690 - q5_loss: 0.0568 - q6_loss: 0.0434 - q7_loss: 0.0103 - q8_loss: 0.0026 - val_loss: 0.2845 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0401 - val_q3_loss: 0.0515 - val_q4_loss: 0.0658 - val_q5_loss: 0.0546 - val_q6_loss: 0.0437 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 155/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2833 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0421 - q3_loss: 0.0534 - q4_loss: 0.0669 - q5_loss: 0.0534 - q6_loss: 0.0425 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0399 - val_q3_loss: 0.0515 - val_q4_loss: 0.0657 - val_q5_loss: 0.0548 - val_q6_loss: 0.0444 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 156/300\n",
      "1575/1575 [==============================] - 0s 131us/sample - loss: 0.2811 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0416 - q3_loss: 0.0535 - q4_loss: 0.0674 - q5_loss: 0.0537 - q6_loss: 0.0421 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2875 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0410 - val_q3_loss: 0.0512 - val_q4_loss: 0.0675 - val_q5_loss: 0.0541 - val_q6_loss: 0.0456 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 138us/sample - loss: 0.2840 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0526 - q4_loss: 0.0670 - q5_loss: 0.0541 - q6_loss: 0.0424 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2945 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0404 - val_q3_loss: 0.0525 - val_q4_loss: 0.0680 - val_q5_loss: 0.0574 - val_q6_loss: 0.0474 - val_q7_loss: 0.0113 - val_q8_loss: 0.0031\n",
      "Epoch 158/300\n",
      "1575/1575 [==============================] - 0s 129us/sample - loss: 0.2844 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0421 - q3_loss: 0.0531 - q4_loss: 0.0673 - q5_loss: 0.0536 - q6_loss: 0.0419 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2879 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0419 - val_q3_loss: 0.0520 - val_q4_loss: 0.0653 - val_q5_loss: 0.0552 - val_q6_loss: 0.0444 - val_q7_loss: 0.0113 - val_q8_loss: 0.0025\n",
      "Epoch 159/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2839 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0422 - q3_loss: 0.0536 - q4_loss: 0.0663 - q5_loss: 0.0535 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2867 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0403 - val_q3_loss: 0.0519 - val_q4_loss: 0.0658 - val_q5_loss: 0.0549 - val_q6_loss: 0.0452 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 160/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2829 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0534 - q4_loss: 0.0674 - q5_loss: 0.0545 - q6_loss: 0.0427 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2825 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0396 - val_q3_loss: 0.0515 - val_q4_loss: 0.0656 - val_q5_loss: 0.0544 - val_q6_loss: 0.0427 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 161/300\n",
      "1575/1575 [==============================] - 0s 141us/sample - loss: 0.2844 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0426 - q3_loss: 0.0539 - q4_loss: 0.0672 - q5_loss: 0.0538 - q6_loss: 0.0419 - q7_loss: 0.0101 - q8_loss: 0.0026 - val_loss: 0.2851 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0412 - val_q3_loss: 0.0517 - val_q4_loss: 0.0654 - val_q5_loss: 0.0549 - val_q6_loss: 0.0436 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 162/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2820 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0533 - q4_loss: 0.0667 - q5_loss: 0.0535 - q6_loss: 0.0420 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2868 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0414 - val_q3_loss: 0.0517 - val_q4_loss: 0.0651 - val_q5_loss: 0.0552 - val_q6_loss: 0.0442 - val_q7_loss: 0.0113 - val_q8_loss: 0.0026\n",
      "Epoch 163/300\n",
      "1575/1575 [==============================] - 0s 126us/sample - loss: 0.2857 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0422 - q3_loss: 0.0536 - q4_loss: 0.0673 - q5_loss: 0.0545 - q6_loss: 0.0428 - q7_loss: 0.0102 - q8_loss: 0.0024 - val_loss: 0.2988 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0414 - val_q3_loss: 0.0536 - val_q4_loss: 0.0689 - val_q5_loss: 0.0571 - val_q6_loss: 0.0479 - val_q7_loss: 0.0123 - val_q8_loss: 0.0032\n",
      "Epoch 164/300\n",
      "1575/1575 [==============================] - 0s 126us/sample - loss: 0.2849 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0433 - q3_loss: 0.0543 - q4_loss: 0.0678 - q5_loss: 0.0541 - q6_loss: 0.0421 - q7_loss: 0.0103 - q8_loss: 0.0025 - val_loss: 0.2856 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0407 - val_q3_loss: 0.0514 - val_q4_loss: 0.0656 - val_q5_loss: 0.0543 - val_q6_loss: 0.0443 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 165/300\n",
      "1575/1575 [==============================] - 0s 143us/sample - loss: 0.2866 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0437 - q3_loss: 0.0548 - q4_loss: 0.0684 - q5_loss: 0.0539 - q6_loss: 0.0431 - q7_loss: 0.0104 - q8_loss: 0.0026 - val_loss: 0.2848 - val_q0_loss: 0.0021 - val_q1_loss: 0.0094 - val_q2_loss: 0.0414 - val_q3_loss: 0.0511 - val_q4_loss: 0.0655 - val_q5_loss: 0.0541 - val_q6_loss: 0.0439 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 166/300\n",
      "1575/1575 [==============================] - 0s 146us/sample - loss: 0.2853 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0425 - q3_loss: 0.0541 - q4_loss: 0.0685 - q5_loss: 0.0548 - q6_loss: 0.0434 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2843 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0404 - val_q3_loss: 0.0516 - val_q4_loss: 0.0655 - val_q5_loss: 0.0540 - val_q6_loss: 0.0443 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 167/300\n",
      "1575/1575 [==============================] - 0s 135us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0098 - q2_loss: 0.0426 - q3_loss: 0.0535 - q4_loss: 0.0673 - q5_loss: 0.0542 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2868 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0402 - val_q3_loss: 0.0520 - val_q4_loss: 0.0666 - val_q5_loss: 0.0551 - val_q6_loss: 0.0446 - val_q7_loss: 0.0108 - val_q8_loss: 0.0027\n",
      "Epoch 168/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2832 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0536 - q4_loss: 0.0675 - q5_loss: 0.0546 - q6_loss: 0.0428 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2881 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0422 - val_q3_loss: 0.0514 - val_q4_loss: 0.0653 - val_q5_loss: 0.0554 - val_q6_loss: 0.0444 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 169/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 0.2816 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0412 - q3_loss: 0.0529 - q4_loss: 0.0669 - q5_loss: 0.0534 - q6_loss: 0.0424 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0407 - val_q3_loss: 0.0513 - val_q4_loss: 0.0656 - val_q5_loss: 0.0548 - val_q6_loss: 0.0436 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 170/300\n",
      "1575/1575 [==============================] - 0s 132us/sample - loss: 0.2820 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0416 - q3_loss: 0.0536 - q4_loss: 0.0675 - q5_loss: 0.0533 - q6_loss: 0.0422 - q7_loss: 0.0098 - q8_loss: 0.0025 - val_loss: 0.2865 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0407 - val_q3_loss: 0.0520 - val_q4_loss: 0.0654 - val_q5_loss: 0.0551 - val_q6_loss: 0.0446 - val_q7_loss: 0.0112 - val_q8_loss: 0.0026\n",
      "Epoch 171/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2817 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0415 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0539 - q6_loss: 0.0419 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2960 - val_q0_loss: 0.0023 - val_q1_loss: 0.0095 - val_q2_loss: 0.0432 - val_q3_loss: 0.0534 - val_q4_loss: 0.0663 - val_q5_loss: 0.0562 - val_q6_loss: 0.0462 - val_q7_loss: 0.0119 - val_q8_loss: 0.0029\n",
      "Epoch 172/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2826 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0531 - q4_loss: 0.0667 - q5_loss: 0.0539 - q6_loss: 0.0425 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2901 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0412 - val_q3_loss: 0.0520 - val_q4_loss: 0.0664 - val_q5_loss: 0.0562 - val_q6_loss: 0.0458 - val_q7_loss: 0.0110 - val_q8_loss: 0.0027\n",
      "Epoch 173/300\n",
      "1575/1575 [==============================] - 0s 135us/sample - loss: 0.2856 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0432 - q3_loss: 0.0546 - q4_loss: 0.0685 - q5_loss: 0.0551 - q6_loss: 0.0436 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2889 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0397 - val_q3_loss: 0.0521 - val_q4_loss: 0.0677 - val_q5_loss: 0.0563 - val_q6_loss: 0.0447 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2829 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0531 - q4_loss: 0.0669 - q5_loss: 0.0540 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2882 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0430 - val_q3_loss: 0.0521 - val_q4_loss: 0.0650 - val_q5_loss: 0.0553 - val_q6_loss: 0.0443 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 175/300\n",
      "1575/1575 [==============================] - 0s 150us/sample - loss: 0.2839 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0427 - q3_loss: 0.0529 - q4_loss: 0.0665 - q5_loss: 0.0541 - q6_loss: 0.0418 - q7_loss: 0.0104 - q8_loss: 0.0025 - val_loss: 0.3049 - val_q0_loss: 0.0022 - val_q1_loss: 0.0096 - val_q2_loss: 0.0451 - val_q3_loss: 0.0552 - val_q4_loss: 0.0693 - val_q5_loss: 0.0613 - val_q6_loss: 0.0444 - val_q7_loss: 0.0118 - val_q8_loss: 0.0028\n",
      "Epoch 176/300\n",
      "1575/1575 [==============================] - 0s 156us/sample - loss: 0.2868 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0427 - q3_loss: 0.0541 - q4_loss: 0.0680 - q5_loss: 0.0546 - q6_loss: 0.0425 - q7_loss: 0.0104 - q8_loss: 0.0025 - val_loss: 0.2870 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0404 - val_q3_loss: 0.0519 - val_q4_loss: 0.0668 - val_q5_loss: 0.0543 - val_q6_loss: 0.0435 - val_q7_loss: 0.0111 - val_q8_loss: 0.0028\n",
      "Epoch 177/300\n",
      "1575/1575 [==============================] - 0s 152us/sample - loss: 0.2808 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0414 - q3_loss: 0.0531 - q4_loss: 0.0671 - q5_loss: 0.0536 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2986 - val_q0_loss: 0.0023 - val_q1_loss: 0.0096 - val_q2_loss: 0.0431 - val_q3_loss: 0.0528 - val_q4_loss: 0.0669 - val_q5_loss: 0.0571 - val_q6_loss: 0.0469 - val_q7_loss: 0.0125 - val_q8_loss: 0.0032\n",
      "Epoch 178/300\n",
      "1575/1575 [==============================] - 0s 138us/sample - loss: 0.2852 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0428 - q3_loss: 0.0541 - q4_loss: 0.0676 - q5_loss: 0.0538 - q6_loss: 0.0423 - q7_loss: 0.0103 - q8_loss: 0.0026 - val_loss: 0.2860 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0408 - val_q3_loss: 0.0520 - val_q4_loss: 0.0657 - val_q5_loss: 0.0552 - val_q6_loss: 0.0445 - val_q7_loss: 0.0111 - val_q8_loss: 0.0025\n",
      "Epoch 179/300\n",
      "1575/1575 [==============================] - 0s 146us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0531 - q4_loss: 0.0669 - q5_loss: 0.0532 - q6_loss: 0.0421 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2846 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0394 - val_q3_loss: 0.0513 - val_q4_loss: 0.0655 - val_q5_loss: 0.0558 - val_q6_loss: 0.0455 - val_q7_loss: 0.0108 - val_q8_loss: 0.0024\n",
      "Epoch 180/300\n",
      "1575/1575 [==============================] - 0s 162us/sample - loss: 0.2804 - q0_loss: 0.0024 - q1_loss: 0.0098 - q2_loss: 0.0422 - q3_loss: 0.0534 - q4_loss: 0.0667 - q5_loss: 0.0531 - q6_loss: 0.0416 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2821 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0512 - val_q4_loss: 0.0650 - val_q5_loss: 0.0548 - val_q6_loss: 0.0440 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 181/300\n",
      "1575/1575 [==============================] - 0s 141us/sample - loss: 0.2826 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0417 - q3_loss: 0.0534 - q4_loss: 0.0668 - q5_loss: 0.0533 - q6_loss: 0.0419 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0393 - val_q3_loss: 0.0513 - val_q4_loss: 0.0656 - val_q5_loss: 0.0549 - val_q6_loss: 0.0436 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 182/300\n",
      "1575/1575 [==============================] - 0s 201us/sample - loss: 0.2818 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0419 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0531 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2834 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0393 - val_q3_loss: 0.0508 - val_q4_loss: 0.0651 - val_q5_loss: 0.0557 - val_q6_loss: 0.0439 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 183/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0665 - q5_loss: 0.0528 - q6_loss: 0.0419 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2862 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0415 - val_q3_loss: 0.0515 - val_q4_loss: 0.0650 - val_q5_loss: 0.0550 - val_q6_loss: 0.0441 - val_q7_loss: 0.0111 - val_q8_loss: 0.0027\n",
      "Epoch 184/300\n",
      "1575/1575 [==============================] - 0s 137us/sample - loss: 0.2799 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0417 - q3_loss: 0.0531 - q4_loss: 0.0667 - q5_loss: 0.0534 - q6_loss: 0.0417 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2842 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0514 - val_q4_loss: 0.0658 - val_q5_loss: 0.0548 - val_q6_loss: 0.0433 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 185/300\n",
      "1575/1575 [==============================] - 0s 165us/sample - loss: 0.2818 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0530 - q4_loss: 0.0672 - q5_loss: 0.0533 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2954 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0430 - val_q3_loss: 0.0535 - val_q4_loss: 0.0660 - val_q5_loss: 0.0570 - val_q6_loss: 0.0448 - val_q7_loss: 0.0122 - val_q8_loss: 0.0030\n",
      "Epoch 186/300\n",
      "1575/1575 [==============================] - 0s 148us/sample - loss: 0.2854 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0427 - q3_loss: 0.0538 - q4_loss: 0.0673 - q5_loss: 0.0545 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2840 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0399 - val_q3_loss: 0.0513 - val_q4_loss: 0.0653 - val_q5_loss: 0.0553 - val_q6_loss: 0.0434 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 187/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.2802 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0528 - q4_loss: 0.0667 - q5_loss: 0.0535 - q6_loss: 0.0419 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2832 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0396 - val_q3_loss: 0.0510 - val_q4_loss: 0.0651 - val_q5_loss: 0.0551 - val_q6_loss: 0.0446 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 188/300\n",
      "1575/1575 [==============================] - 0s 143us/sample - loss: 0.2827 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0532 - q4_loss: 0.0671 - q5_loss: 0.0538 - q6_loss: 0.0426 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2865 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0415 - val_q3_loss: 0.0514 - val_q4_loss: 0.0663 - val_q5_loss: 0.0540 - val_q6_loss: 0.0442 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 189/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0412 - q3_loss: 0.0525 - q4_loss: 0.0662 - q5_loss: 0.0531 - q6_loss: 0.0419 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2921 - val_q0_loss: 0.0024 - val_q1_loss: 0.0091 - val_q2_loss: 0.0404 - val_q3_loss: 0.0527 - val_q4_loss: 0.0679 - val_q5_loss: 0.0549 - val_q6_loss: 0.0443 - val_q7_loss: 0.0118 - val_q8_loss: 0.0031\n",
      "Epoch 190/300\n",
      "1575/1575 [==============================] - 0s 140us/sample - loss: 0.2840 - q0_loss: 0.0024 - q1_loss: 0.0093 - q2_loss: 0.0420 - q3_loss: 0.0537 - q4_loss: 0.0676 - q5_loss: 0.0538 - q6_loss: 0.0425 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2852 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0403 - val_q3_loss: 0.0516 - val_q4_loss: 0.0659 - val_q5_loss: 0.0544 - val_q6_loss: 0.0431 - val_q7_loss: 0.0111 - val_q8_loss: 0.0027\n",
      "Epoch 191/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 138us/sample - loss: 0.2826 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0533 - q4_loss: 0.0670 - q5_loss: 0.0543 - q6_loss: 0.0424 - q7_loss: 0.0103 - q8_loss: 0.0025 - val_loss: 0.3007 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0421 - val_q3_loss: 0.0535 - val_q4_loss: 0.0681 - val_q5_loss: 0.0582 - val_q6_loss: 0.0477 - val_q7_loss: 0.0127 - val_q8_loss: 0.0032\n",
      "Epoch 192/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.2773 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0409 - q3_loss: 0.0525 - q4_loss: 0.0660 - q5_loss: 0.0525 - q6_loss: 0.0414 - q7_loss: 0.0098 - q8_loss: 0.002 - 0s 123us/sample - loss: 0.2817 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0532 - q4_loss: 0.0677 - q5_loss: 0.0545 - q6_loss: 0.0430 - q7_loss: 0.0104 - q8_loss: 0.0026 - val_loss: 0.2861 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0399 - val_q3_loss: 0.0519 - val_q4_loss: 0.0661 - val_q5_loss: 0.0548 - val_q6_loss: 0.0443 - val_q7_loss: 0.0112 - val_q8_loss: 0.0026\n",
      "Epoch 193/300\n",
      "1575/1575 [==============================] - 0s 123us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0422 - q3_loss: 0.0540 - q4_loss: 0.0680 - q5_loss: 0.0548 - q6_loss: 0.0420 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2831 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0396 - val_q3_loss: 0.0513 - val_q4_loss: 0.0658 - val_q5_loss: 0.0551 - val_q6_loss: 0.0430 - val_q7_loss: 0.0107 - val_q8_loss: 0.0027\n",
      "Epoch 194/300\n",
      "1575/1575 [==============================] - 0s 131us/sample - loss: 0.2818 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0422 - q3_loss: 0.0531 - q4_loss: 0.0667 - q5_loss: 0.0534 - q6_loss: 0.0416 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2820 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0397 - val_q3_loss: 0.0512 - val_q4_loss: 0.0649 - val_q5_loss: 0.0544 - val_q6_loss: 0.0436 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 195/300\n",
      "1575/1575 [==============================] - 0s 131us/sample - loss: 0.2815 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0423 - q3_loss: 0.0536 - q4_loss: 0.0668 - q5_loss: 0.0533 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2878 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0513 - val_q4_loss: 0.0682 - val_q5_loss: 0.0551 - val_q6_loss: 0.0455 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 196/300\n",
      "1575/1575 [==============================] - 0s 146us/sample - loss: 0.2834 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0538 - q4_loss: 0.0674 - q5_loss: 0.0534 - q6_loss: 0.0421 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2894 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0414 - val_q3_loss: 0.0518 - val_q4_loss: 0.0665 - val_q5_loss: 0.0578 - val_q6_loss: 0.0428 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 197/300\n",
      "1575/1575 [==============================] - 0s 154us/sample - loss: 0.2814 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0413 - q3_loss: 0.0528 - q4_loss: 0.0665 - q5_loss: 0.0533 - q6_loss: 0.0417 - q7_loss: 0.0101 - q8_loss: 0.0026 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0409 - val_q3_loss: 0.0514 - val_q4_loss: 0.0649 - val_q5_loss: 0.0542 - val_q6_loss: 0.0439 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 198/300\n",
      "1575/1575 [==============================] - 0s 140us/sample - loss: 0.2843 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0419 - q3_loss: 0.0537 - q4_loss: 0.0677 - q5_loss: 0.0536 - q6_loss: 0.0424 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2848 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0518 - val_q4_loss: 0.0660 - val_q5_loss: 0.0548 - val_q6_loss: 0.0431 - val_q7_loss: 0.0109 - val_q8_loss: 0.0027\n",
      "Epoch 199/300\n",
      "1575/1575 [==============================] - 0s 168us/sample - loss: 0.2805 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0412 - q3_loss: 0.0529 - q4_loss: 0.0665 - q5_loss: 0.0535 - q6_loss: 0.0415 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2842 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0409 - val_q3_loss: 0.0514 - val_q4_loss: 0.0652 - val_q5_loss: 0.0550 - val_q6_loss: 0.0442 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 200/300\n",
      "1575/1575 [==============================] - 0s 163us/sample - loss: 0.2815 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0417 - q3_loss: 0.0531 - q4_loss: 0.0673 - q5_loss: 0.0532 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2840 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0555 - val_q6_loss: 0.0449 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 201/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.2808 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0414 - q3_loss: 0.0530 - q4_loss: 0.0667 - q5_loss: 0.0529 - q6_loss: 0.0417 - q7_loss: 0.0098 - q8_loss: 0.0024 - val_loss: 0.2910 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0398 - val_q3_loss: 0.0526 - val_q4_loss: 0.0696 - val_q5_loss: 0.0552 - val_q6_loss: 0.0452 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 202/300\n",
      "1575/1575 [==============================] - 0s 144us/sample - loss: 0.2842 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0419 - q3_loss: 0.0535 - q4_loss: 0.0675 - q5_loss: 0.0537 - q6_loss: 0.0425 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2906 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0415 - val_q3_loss: 0.0526 - val_q4_loss: 0.0667 - val_q5_loss: 0.0561 - val_q6_loss: 0.0449 - val_q7_loss: 0.0118 - val_q8_loss: 0.0028\n",
      "Epoch 203/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 0.2819 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0417 - q3_loss: 0.0531 - q4_loss: 0.0676 - q5_loss: 0.0539 - q6_loss: 0.0429 - q7_loss: 0.0103 - q8_loss: 0.0025 - val_loss: 0.2907 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0419 - val_q3_loss: 0.0524 - val_q4_loss: 0.0663 - val_q5_loss: 0.0557 - val_q6_loss: 0.0448 - val_q7_loss: 0.0115 - val_q8_loss: 0.0028\n",
      "Epoch 204/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 0.2817 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0419 - q3_loss: 0.0532 - q4_loss: 0.0675 - q5_loss: 0.0537 - q6_loss: 0.0421 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2853 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0410 - val_q3_loss: 0.0518 - val_q4_loss: 0.0652 - val_q5_loss: 0.0552 - val_q6_loss: 0.0438 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 205/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 0.2838 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0422 - q3_loss: 0.0535 - q4_loss: 0.0678 - q5_loss: 0.0553 - q6_loss: 0.0431 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2854 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0398 - val_q3_loss: 0.0512 - val_q4_loss: 0.0663 - val_q5_loss: 0.0566 - val_q6_loss: 0.0437 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 206/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2881 - q0_loss: 0.0024 - q1_loss: 0.0097 - q2_loss: 0.0429 - q3_loss: 0.0544 - q4_loss: 0.0682 - q5_loss: 0.0542 - q6_loss: 0.0433 - q7_loss: 0.0104 - q8_loss: 0.0025 - val_loss: 0.2911 - val_q0_loss: 0.0023 - val_q1_loss: 0.0095 - val_q2_loss: 0.0422 - val_q3_loss: 0.0522 - val_q4_loss: 0.0664 - val_q5_loss: 0.0556 - val_q6_loss: 0.0447 - val_q7_loss: 0.0113 - val_q8_loss: 0.0027\n",
      "Epoch 207/300\n",
      "1575/1575 [==============================] - 0s 125us/sample - loss: 0.2814 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0527 - q4_loss: 0.0665 - q5_loss: 0.0530 - q6_loss: 0.0416 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2903 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0415 - val_q3_loss: 0.0526 - val_q4_loss: 0.0662 - val_q5_loss: 0.0557 - val_q6_loss: 0.0446 - val_q7_loss: 0.0113 - val_q8_loss: 0.0028\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2812 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0414 - q3_loss: 0.0529 - q4_loss: 0.0667 - q5_loss: 0.0536 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.3015 - val_q0_loss: 0.0023 - val_q1_loss: 0.0097 - val_q2_loss: 0.0439 - val_q3_loss: 0.0535 - val_q4_loss: 0.0677 - val_q5_loss: 0.0586 - val_q6_loss: 0.0453 - val_q7_loss: 0.0129 - val_q8_loss: 0.0032\n",
      "Epoch 209/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2818 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0418 - q3_loss: 0.0533 - q4_loss: 0.0668 - q5_loss: 0.0533 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2850 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0409 - val_q3_loss: 0.0515 - val_q4_loss: 0.0650 - val_q5_loss: 0.0554 - val_q6_loss: 0.0442 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 210/300\n",
      "1575/1575 [==============================] - 0s 130us/sample - loss: 0.2813 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0531 - q6_loss: 0.0422 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0395 - val_q3_loss: 0.0513 - val_q4_loss: 0.0656 - val_q5_loss: 0.0545 - val_q6_loss: 0.0431 - val_q7_loss: 0.0108 - val_q8_loss: 0.0027\n",
      "Epoch 211/300\n",
      "1575/1575 [==============================] - 0s 135us/sample - loss: 0.2802 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0423 - q3_loss: 0.0537 - q4_loss: 0.0674 - q5_loss: 0.0529 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2855 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0512 - val_q4_loss: 0.0653 - val_q5_loss: 0.0560 - val_q6_loss: 0.0447 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 212/300\n",
      "1575/1575 [==============================] - 0s 139us/sample - loss: 0.2836 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0418 - q3_loss: 0.0532 - q4_loss: 0.0669 - q5_loss: 0.0537 - q6_loss: 0.0415 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2856 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0414 - val_q3_loss: 0.0511 - val_q4_loss: 0.0654 - val_q5_loss: 0.0545 - val_q6_loss: 0.0447 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 213/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2801 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0415 - q3_loss: 0.0531 - q4_loss: 0.0675 - q5_loss: 0.0539 - q6_loss: 0.0428 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2830 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0396 - val_q3_loss: 0.0512 - val_q4_loss: 0.0654 - val_q5_loss: 0.0556 - val_q6_loss: 0.0432 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 214/300\n",
      "1575/1575 [==============================] - 0s 146us/sample - loss: 0.2855 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0429 - q3_loss: 0.0536 - q4_loss: 0.0671 - q5_loss: 0.0539 - q6_loss: 0.0422 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2829 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0394 - val_q3_loss: 0.0510 - val_q4_loss: 0.0649 - val_q5_loss: 0.0555 - val_q6_loss: 0.0443 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 215/300\n",
      "1575/1575 [==============================] - 0s 124us/sample - loss: 0.2808 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0529 - q4_loss: 0.0667 - q5_loss: 0.0536 - q6_loss: 0.0415 - q7_loss: 0.0099 - q8_loss: 0.0026 - val_loss: 0.2850 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0409 - val_q3_loss: 0.0512 - val_q4_loss: 0.0652 - val_q5_loss: 0.0553 - val_q6_loss: 0.0445 - val_q7_loss: 0.0109 - val_q8_loss: 0.0024\n",
      "Epoch 216/300\n",
      "1575/1575 [==============================] - 0s 132us/sample - loss: 0.2836 - q0_loss: 0.0025 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0539 - q4_loss: 0.0678 - q5_loss: 0.0541 - q6_loss: 0.0421 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0403 - val_q3_loss: 0.0512 - val_q4_loss: 0.0663 - val_q5_loss: 0.0539 - val_q6_loss: 0.0439 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 217/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2797 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0529 - q4_loss: 0.0663 - q5_loss: 0.0527 - q6_loss: 0.0417 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2835 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0397 - val_q3_loss: 0.0511 - val_q4_loss: 0.0660 - val_q5_loss: 0.0550 - val_q6_loss: 0.0440 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 218/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2818 - q0_loss: 0.0022 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0532 - q4_loss: 0.0671 - q5_loss: 0.0533 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2880 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0425 - val_q3_loss: 0.0516 - val_q4_loss: 0.0653 - val_q5_loss: 0.0555 - val_q6_loss: 0.0437 - val_q7_loss: 0.0114 - val_q8_loss: 0.0027\n",
      "Epoch 219/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2850 - q0_loss: 0.0023 - q1_loss: 0.0099 - q2_loss: 0.0430 - q3_loss: 0.0544 - q4_loss: 0.0675 - q5_loss: 0.0549 - q6_loss: 0.0426 - q7_loss: 0.0105 - q8_loss: 0.0028 - val_loss: 0.2873 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0412 - val_q3_loss: 0.0517 - val_q4_loss: 0.0657 - val_q5_loss: 0.0571 - val_q6_loss: 0.0430 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 220/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2854 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0421 - q3_loss: 0.0537 - q4_loss: 0.0673 - q5_loss: 0.0543 - q6_loss: 0.0421 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2833 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0394 - val_q3_loss: 0.0514 - val_q4_loss: 0.0655 - val_q5_loss: 0.0551 - val_q6_loss: 0.0429 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 221/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2826 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0415 - q3_loss: 0.0530 - q4_loss: 0.0669 - q5_loss: 0.0536 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2822 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0512 - val_q4_loss: 0.0650 - val_q5_loss: 0.0543 - val_q6_loss: 0.0434 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 222/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2797 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0527 - q4_loss: 0.0664 - q5_loss: 0.0525 - q6_loss: 0.0414 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2987 - val_q0_loss: 0.0024 - val_q1_loss: 0.0090 - val_q2_loss: 0.0408 - val_q3_loss: 0.0532 - val_q4_loss: 0.0689 - val_q5_loss: 0.0568 - val_q6_loss: 0.0483 - val_q7_loss: 0.0120 - val_q8_loss: 0.0032\n",
      "Epoch 223/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2821 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0419 - q3_loss: 0.0535 - q4_loss: 0.0675 - q5_loss: 0.0534 - q6_loss: 0.0422 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2833 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0399 - val_q3_loss: 0.0515 - val_q4_loss: 0.0656 - val_q5_loss: 0.0551 - val_q6_loss: 0.0432 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 224/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2824 - q0_loss: 0.0026 - q1_loss: 0.0097 - q2_loss: 0.0424 - q3_loss: 0.0540 - q4_loss: 0.0671 - q5_loss: 0.0545 - q6_loss: 0.0421 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2867 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0413 - val_q3_loss: 0.0521 - val_q4_loss: 0.0655 - val_q5_loss: 0.0549 - val_q6_loss: 0.0444 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2819 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0423 - q3_loss: 0.0535 - q4_loss: 0.0673 - q5_loss: 0.0537 - q6_loss: 0.0416 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2834 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0396 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0550 - val_q6_loss: 0.0437 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 226/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2832 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0420 - q3_loss: 0.0535 - q4_loss: 0.0669 - q5_loss: 0.0542 - q6_loss: 0.0420 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2880 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0422 - val_q3_loss: 0.0519 - val_q4_loss: 0.0653 - val_q5_loss: 0.0557 - val_q6_loss: 0.0450 - val_q7_loss: 0.0111 - val_q8_loss: 0.0024\n",
      "Epoch 227/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2826 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0538 - q4_loss: 0.0675 - q5_loss: 0.0537 - q6_loss: 0.0420 - q7_loss: 0.0100 - q8_loss: 0.0026 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0399 - val_q3_loss: 0.0512 - val_q4_loss: 0.0654 - val_q5_loss: 0.0549 - val_q6_loss: 0.0432 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 228/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2823 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0422 - q3_loss: 0.0532 - q4_loss: 0.0674 - q5_loss: 0.0545 - q6_loss: 0.0420 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2840 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0395 - val_q3_loss: 0.0511 - val_q4_loss: 0.0654 - val_q5_loss: 0.0549 - val_q6_loss: 0.0440 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 229/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2811 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0417 - q3_loss: 0.0533 - q4_loss: 0.0671 - q5_loss: 0.0534 - q6_loss: 0.0419 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2844 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0410 - val_q3_loss: 0.0513 - val_q4_loss: 0.0649 - val_q5_loss: 0.0543 - val_q6_loss: 0.0445 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 230/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2834 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0536 - q4_loss: 0.0676 - q5_loss: 0.0544 - q6_loss: 0.0424 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0087 - val_q2_loss: 0.0399 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0556 - val_q6_loss: 0.0436 - val_q7_loss: 0.0106 - val_q8_loss: 0.0025\n",
      "Epoch 231/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2825 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0536 - q4_loss: 0.0676 - q5_loss: 0.0536 - q6_loss: 0.0422 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2836 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0403 - val_q3_loss: 0.0513 - val_q4_loss: 0.0650 - val_q5_loss: 0.0549 - val_q6_loss: 0.0445 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 232/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0420 - q3_loss: 0.0539 - q4_loss: 0.0678 - q5_loss: 0.0543 - q6_loss: 0.0428 - q7_loss: 0.0106 - q8_loss: 0.0025 - val_loss: 0.2861 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0412 - val_q3_loss: 0.0516 - val_q4_loss: 0.0651 - val_q5_loss: 0.0551 - val_q6_loss: 0.0454 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 233/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2823 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0423 - q3_loss: 0.0536 - q4_loss: 0.0675 - q5_loss: 0.0542 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2858 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0415 - val_q3_loss: 0.0515 - val_q4_loss: 0.0650 - val_q5_loss: 0.0548 - val_q6_loss: 0.0449 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 234/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2816 - q0_loss: 0.0024 - q1_loss: 0.0095 - q2_loss: 0.0419 - q3_loss: 0.0532 - q4_loss: 0.0670 - q5_loss: 0.0533 - q6_loss: 0.0421 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2824 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0401 - val_q3_loss: 0.0515 - val_q4_loss: 0.0651 - val_q5_loss: 0.0539 - val_q6_loss: 0.0432 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 235/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2812 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0530 - q4_loss: 0.0667 - q5_loss: 0.0532 - q6_loss: 0.0422 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2882 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0399 - val_q3_loss: 0.0514 - val_q4_loss: 0.0678 - val_q5_loss: 0.0564 - val_q6_loss: 0.0456 - val_q7_loss: 0.0108 - val_q8_loss: 0.0024\n",
      "Epoch 236/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0413 - q3_loss: 0.0534 - q4_loss: 0.0672 - q5_loss: 0.0534 - q6_loss: 0.0419 - q7_loss: 0.0100 - q8_loss: 0.0026 - val_loss: 0.2830 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0515 - val_q4_loss: 0.0650 - val_q5_loss: 0.0542 - val_q6_loss: 0.0440 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 237/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2822 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0418 - q3_loss: 0.0536 - q4_loss: 0.0672 - q5_loss: 0.0535 - q6_loss: 0.0420 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2864 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0404 - val_q3_loss: 0.0512 - val_q4_loss: 0.0658 - val_q5_loss: 0.0578 - val_q6_loss: 0.0442 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 238/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2817 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0417 - q3_loss: 0.0529 - q4_loss: 0.0662 - q5_loss: 0.0537 - q6_loss: 0.0416 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2856 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0396 - val_q3_loss: 0.0511 - val_q4_loss: 0.0653 - val_q5_loss: 0.0559 - val_q6_loss: 0.0441 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 239/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0528 - q4_loss: 0.0666 - q5_loss: 0.0532 - q6_loss: 0.0416 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2859 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0412 - val_q3_loss: 0.0515 - val_q4_loss: 0.0650 - val_q5_loss: 0.0550 - val_q6_loss: 0.0442 - val_q7_loss: 0.0111 - val_q8_loss: 0.0027\n",
      "Epoch 240/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0414 - q3_loss: 0.0530 - q4_loss: 0.0670 - q5_loss: 0.0536 - q6_loss: 0.0418 - q7_loss: 0.0098 - q8_loss: 0.0024 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0392 - val_q3_loss: 0.0510 - val_q4_loss: 0.0653 - val_q5_loss: 0.0550 - val_q6_loss: 0.0449 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 241/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2791 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0415 - q3_loss: 0.0532 - q4_loss: 0.0667 - q5_loss: 0.0526 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2997 - val_q0_loss: 0.0023 - val_q1_loss: 0.0096 - val_q2_loss: 0.0431 - val_q3_loss: 0.0539 - val_q4_loss: 0.0669 - val_q5_loss: 0.0585 - val_q6_loss: 0.0459 - val_q7_loss: 0.0120 - val_q8_loss: 0.0031\n",
      "Epoch 242/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2815 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0424 - q3_loss: 0.0533 - q4_loss: 0.0665 - q5_loss: 0.0537 - q6_loss: 0.0413 - q7_loss: 0.0098 - q8_loss: 0.0024 - val_loss: 0.2844 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0399 - val_q3_loss: 0.0515 - val_q4_loss: 0.0652 - val_q5_loss: 0.0554 - val_q6_loss: 0.0447 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 243/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2813 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0534 - q4_loss: 0.0678 - q5_loss: 0.0542 - q6_loss: 0.0423 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2886 - val_q0_loss: 0.0022 - val_q1_loss: 0.0096 - val_q2_loss: 0.0429 - val_q3_loss: 0.0521 - val_q4_loss: 0.0649 - val_q5_loss: 0.0549 - val_q6_loss: 0.0445 - val_q7_loss: 0.0112 - val_q8_loss: 0.0026\n",
      "Epoch 244/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2862 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0428 - q3_loss: 0.0538 - q4_loss: 0.0676 - q5_loss: 0.0557 - q6_loss: 0.0419 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2836 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0405 - val_q3_loss: 0.0515 - val_q4_loss: 0.0655 - val_q5_loss: 0.0544 - val_q6_loss: 0.0429 - val_q7_loss: 0.0109 - val_q8_loss: 0.0027\n",
      "Epoch 245/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2807 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0532 - q4_loss: 0.0669 - q5_loss: 0.0532 - q6_loss: 0.0415 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2835 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0405 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0549 - val_q6_loss: 0.0443 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 246/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2811 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0414 - q3_loss: 0.0533 - q4_loss: 0.0668 - q5_loss: 0.0532 - q6_loss: 0.0422 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2965 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0410 - val_q3_loss: 0.0536 - val_q4_loss: 0.0682 - val_q5_loss: 0.0566 - val_q6_loss: 0.0473 - val_q7_loss: 0.0120 - val_q8_loss: 0.0030\n",
      "Epoch 247/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2835 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0421 - q3_loss: 0.0533 - q4_loss: 0.0669 - q5_loss: 0.0534 - q6_loss: 0.0415 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2911 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0415 - val_q3_loss: 0.0526 - val_q4_loss: 0.0662 - val_q5_loss: 0.0564 - val_q6_loss: 0.0459 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 248/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0530 - q4_loss: 0.0669 - q5_loss: 0.0534 - q6_loss: 0.0418 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2820 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0511 - val_q4_loss: 0.0649 - val_q5_loss: 0.0551 - val_q6_loss: 0.0431 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 249/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2807 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0412 - q3_loss: 0.0526 - q4_loss: 0.0668 - q5_loss: 0.0533 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2874 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0409 - val_q3_loss: 0.0515 - val_q4_loss: 0.0657 - val_q5_loss: 0.0552 - val_q6_loss: 0.0442 - val_q7_loss: 0.0113 - val_q8_loss: 0.0027\n",
      "Epoch 250/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0416 - q3_loss: 0.0537 - q4_loss: 0.0676 - q5_loss: 0.0531 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2836 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0405 - val_q3_loss: 0.0513 - val_q4_loss: 0.0651 - val_q5_loss: 0.0539 - val_q6_loss: 0.0436 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 251/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2799 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0664 - q5_loss: 0.0530 - q6_loss: 0.0417 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2853 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0517 - val_q4_loss: 0.0656 - val_q5_loss: 0.0547 - val_q6_loss: 0.0447 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 252/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2815 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0417 - q3_loss: 0.0533 - q4_loss: 0.0672 - q5_loss: 0.0538 - q6_loss: 0.0419 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2914 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0408 - val_q3_loss: 0.0525 - val_q4_loss: 0.0672 - val_q5_loss: 0.0556 - val_q6_loss: 0.0462 - val_q7_loss: 0.0114 - val_q8_loss: 0.0029\n",
      "Epoch 253/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2815 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0534 - q4_loss: 0.0672 - q5_loss: 0.0531 - q6_loss: 0.0419 - q7_loss: 0.0097 - q8_loss: 0.0024 - val_loss: 0.2877 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0419 - val_q3_loss: 0.0522 - val_q4_loss: 0.0656 - val_q5_loss: 0.0552 - val_q6_loss: 0.0437 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 254/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2837 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0424 - q3_loss: 0.0533 - q4_loss: 0.0675 - q5_loss: 0.0551 - q6_loss: 0.0424 - q7_loss: 0.0102 - q8_loss: 0.0026 - val_loss: 0.2900 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0417 - val_q3_loss: 0.0528 - val_q4_loss: 0.0672 - val_q5_loss: 0.0556 - val_q6_loss: 0.0439 - val_q7_loss: 0.0113 - val_q8_loss: 0.0028\n",
      "Epoch 255/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2818 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0534 - q4_loss: 0.0674 - q5_loss: 0.0535 - q6_loss: 0.0418 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2841 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0512 - val_q4_loss: 0.0652 - val_q5_loss: 0.0551 - val_q6_loss: 0.0446 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 256/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2813 - q0_loss: 0.0024 - q1_loss: 0.0096 - q2_loss: 0.0423 - q3_loss: 0.0537 - q4_loss: 0.0671 - q5_loss: 0.0538 - q6_loss: 0.0413 - q7_loss: 0.0098 - q8_loss: 0.0025 - val_loss: 0.2888 - val_q0_loss: 0.0023 - val_q1_loss: 0.0093 - val_q2_loss: 0.0422 - val_q3_loss: 0.0517 - val_q4_loss: 0.0653 - val_q5_loss: 0.0553 - val_q6_loss: 0.0441 - val_q7_loss: 0.0116 - val_q8_loss: 0.0027\n",
      "Epoch 257/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2806 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0415 - q3_loss: 0.0530 - q4_loss: 0.0670 - q5_loss: 0.0541 - q6_loss: 0.0425 - q7_loss: 0.0107 - q8_loss: 0.0026 - val_loss: 0.2830 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0401 - val_q3_loss: 0.0511 - val_q4_loss: 0.0654 - val_q5_loss: 0.0545 - val_q6_loss: 0.0438 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 258/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2800 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0415 - q3_loss: 0.0535 - q4_loss: 0.0676 - q5_loss: 0.0536 - q6_loss: 0.0420 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2907 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0419 - val_q3_loss: 0.0524 - val_q4_loss: 0.0660 - val_q5_loss: 0.0562 - val_q6_loss: 0.0445 - val_q7_loss: 0.0114 - val_q8_loss: 0.0028\n",
      "Epoch 259/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0419 - q3_loss: 0.0538 - q4_loss: 0.0673 - q5_loss: 0.0532 - q6_loss: 0.0419 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2821 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0400 - val_q3_loss: 0.0514 - val_q4_loss: 0.0651 - val_q5_loss: 0.0542 - val_q6_loss: 0.0433 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 260/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2816 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0413 - q3_loss: 0.0530 - q4_loss: 0.0675 - q5_loss: 0.0536 - q6_loss: 0.0423 - q7_loss: 0.0101 - q8_loss: 0.0026 - val_loss: 0.2830 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0402 - val_q3_loss: 0.0513 - val_q4_loss: 0.0649 - val_q5_loss: 0.0549 - val_q6_loss: 0.0434 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 261/300\n",
      "1575/1575 [==============================] - 0s 116us/sample - loss: 0.2793 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0531 - q4_loss: 0.0670 - q5_loss: 0.0529 - q6_loss: 0.0415 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2841 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0391 - val_q3_loss: 0.0511 - val_q4_loss: 0.0662 - val_q5_loss: 0.0555 - val_q6_loss: 0.0443 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 262/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2814 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0417 - q3_loss: 0.0536 - q4_loss: 0.0675 - q5_loss: 0.0539 - q6_loss: 0.0421 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0402 - val_q3_loss: 0.0514 - val_q4_loss: 0.0662 - val_q5_loss: 0.0546 - val_q6_loss: 0.0438 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 263/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2812 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0415 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0535 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2874 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0415 - val_q3_loss: 0.0515 - val_q4_loss: 0.0651 - val_q5_loss: 0.0557 - val_q6_loss: 0.0448 - val_q7_loss: 0.0113 - val_q8_loss: 0.0026\n",
      "Epoch 264/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2803 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0534 - q4_loss: 0.0667 - q5_loss: 0.0533 - q6_loss: 0.0415 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2833 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0406 - val_q3_loss: 0.0511 - val_q4_loss: 0.0648 - val_q5_loss: 0.0552 - val_q6_loss: 0.0434 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 265/300\n",
      "1575/1575 [==============================] - 0s 124us/sample - loss: 0.2822 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0417 - q3_loss: 0.0530 - q4_loss: 0.0671 - q5_loss: 0.0542 - q6_loss: 0.0417 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2866 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0424 - val_q3_loss: 0.0514 - val_q4_loss: 0.0652 - val_q5_loss: 0.0550 - val_q6_loss: 0.0441 - val_q7_loss: 0.0111 - val_q8_loss: 0.0026\n",
      "Epoch 266/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2821 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0533 - q4_loss: 0.0669 - q5_loss: 0.0533 - q6_loss: 0.0424 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2890 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0422 - val_q3_loss: 0.0523 - val_q4_loss: 0.0658 - val_q5_loss: 0.0554 - val_q6_loss: 0.0433 - val_q7_loss: 0.0116 - val_q8_loss: 0.0028\n",
      "Epoch 267/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2836 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0531 - q4_loss: 0.0668 - q5_loss: 0.0535 - q6_loss: 0.0422 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2868 - val_q0_loss: 0.0022 - val_q1_loss: 0.0095 - val_q2_loss: 0.0421 - val_q3_loss: 0.0516 - val_q4_loss: 0.0655 - val_q5_loss: 0.0552 - val_q6_loss: 0.0432 - val_q7_loss: 0.0111 - val_q8_loss: 0.0027\n",
      "Epoch 268/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2802 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0533 - q4_loss: 0.0676 - q5_loss: 0.0535 - q6_loss: 0.0427 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2843 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0393 - val_q3_loss: 0.0512 - val_q4_loss: 0.0664 - val_q5_loss: 0.0553 - val_q6_loss: 0.0438 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 269/300\n",
      "1575/1575 [==============================] - 0s 143us/sample - loss: 0.2812 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0531 - q4_loss: 0.0666 - q5_loss: 0.0534 - q6_loss: 0.0415 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2847 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0408 - val_q3_loss: 0.0514 - val_q4_loss: 0.0655 - val_q5_loss: 0.0548 - val_q6_loss: 0.0449 - val_q7_loss: 0.0106 - val_q8_loss: 0.0025\n",
      "Epoch 270/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2814 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0528 - q4_loss: 0.0670 - q5_loss: 0.0539 - q6_loss: 0.0419 - q7_loss: 0.0101 - q8_loss: 0.0026 - val_loss: 0.2847 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0403 - val_q3_loss: 0.0513 - val_q4_loss: 0.0654 - val_q5_loss: 0.0559 - val_q6_loss: 0.0434 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 271/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2845 - q0_loss: 0.0022 - q1_loss: 0.0094 - q2_loss: 0.0416 - q3_loss: 0.0532 - q4_loss: 0.0673 - q5_loss: 0.0540 - q6_loss: 0.0426 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2872 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0393 - val_q3_loss: 0.0517 - val_q4_loss: 0.0678 - val_q5_loss: 0.0561 - val_q6_loss: 0.0443 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 272/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2822 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0417 - q3_loss: 0.0538 - q4_loss: 0.0681 - q5_loss: 0.0546 - q6_loss: 0.0428 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2830 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0513 - val_q4_loss: 0.0652 - val_q5_loss: 0.0547 - val_q6_loss: 0.0440 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 273/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2832 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0420 - q3_loss: 0.0537 - q4_loss: 0.0672 - q5_loss: 0.0535 - q6_loss: 0.0419 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2854 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0397 - val_q3_loss: 0.0511 - val_q4_loss: 0.0662 - val_q5_loss: 0.0564 - val_q6_loss: 0.0442 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 274/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2821 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0414 - q3_loss: 0.0535 - q4_loss: 0.0677 - q5_loss: 0.0542 - q6_loss: 0.0430 - q7_loss: 0.0104 - q8_loss: 0.0025 - val_loss: 0.2820 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0394 - val_q3_loss: 0.0510 - val_q4_loss: 0.0650 - val_q5_loss: 0.0547 - val_q6_loss: 0.0438 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 275/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2803 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0416 - q3_loss: 0.0531 - q4_loss: 0.0670 - q5_loss: 0.0537 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2825 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0397 - val_q3_loss: 0.0511 - val_q4_loss: 0.0654 - val_q5_loss: 0.0549 - val_q6_loss: 0.0438 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.2829 - q0_loss: 0.0024 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0534 - q4_loss: 0.0677 - q5_loss: 0.0537 - q6_loss: 0.0419 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2863 - val_q0_loss: 0.0022 - val_q1_loss: 0.0093 - val_q2_loss: 0.0416 - val_q3_loss: 0.0518 - val_q4_loss: 0.0657 - val_q5_loss: 0.0546 - val_q6_loss: 0.0432 - val_q7_loss: 0.0112 - val_q8_loss: 0.0027\n",
      "Epoch 277/300\n",
      "1575/1575 [==============================] - 0s 130us/sample - loss: 0.2821 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0416 - q3_loss: 0.0530 - q4_loss: 0.0668 - q5_loss: 0.0536 - q6_loss: 0.0417 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2854 - val_q0_loss: 0.0021 - val_q1_loss: 0.0089 - val_q2_loss: 0.0396 - val_q3_loss: 0.0519 - val_q4_loss: 0.0666 - val_q5_loss: 0.0557 - val_q6_loss: 0.0437 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 278/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2824 - q0_loss: 0.0023 - q1_loss: 0.0097 - q2_loss: 0.0418 - q3_loss: 0.0536 - q4_loss: 0.0668 - q5_loss: 0.0540 - q6_loss: 0.0422 - q7_loss: 0.0103 - q8_loss: 0.0027 - val_loss: 0.2890 - val_q0_loss: 0.0022 - val_q1_loss: 0.0094 - val_q2_loss: 0.0419 - val_q3_loss: 0.0521 - val_q4_loss: 0.0656 - val_q5_loss: 0.0557 - val_q6_loss: 0.0445 - val_q7_loss: 0.0113 - val_q8_loss: 0.0026\n",
      "Epoch 279/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2820 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0417 - q3_loss: 0.0533 - q4_loss: 0.0671 - q5_loss: 0.0540 - q6_loss: 0.0418 - q7_loss: 0.0099 - q8_loss: 0.0024 - val_loss: 0.2852 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0405 - val_q3_loss: 0.0513 - val_q4_loss: 0.0653 - val_q5_loss: 0.0557 - val_q6_loss: 0.0448 - val_q7_loss: 0.0110 - val_q8_loss: 0.0025\n",
      "Epoch 280/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2803 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0530 - q4_loss: 0.0668 - q5_loss: 0.0533 - q6_loss: 0.0418 - q7_loss: 0.0098 - q8_loss: 0.0023 - val_loss: 0.2852 - val_q0_loss: 0.0023 - val_q1_loss: 0.0089 - val_q2_loss: 0.0395 - val_q3_loss: 0.0512 - val_q4_loss: 0.0657 - val_q5_loss: 0.0554 - val_q6_loss: 0.0443 - val_q7_loss: 0.0110 - val_q8_loss: 0.0026\n",
      "Epoch 281/300\n",
      "1575/1575 [==============================] - 0s 113us/sample - loss: 0.2801 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0415 - q3_loss: 0.0531 - q4_loss: 0.0663 - q5_loss: 0.0531 - q6_loss: 0.0412 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2855 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0404 - val_q3_loss: 0.0516 - val_q4_loss: 0.0654 - val_q5_loss: 0.0556 - val_q6_loss: 0.0444 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 282/300\n",
      "1575/1575 [==============================] - 0s 121us/sample - loss: 0.2810 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0412 - q3_loss: 0.0529 - q4_loss: 0.0671 - q5_loss: 0.0533 - q6_loss: 0.0421 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2854 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0398 - val_q3_loss: 0.0513 - val_q4_loss: 0.0657 - val_q5_loss: 0.0570 - val_q6_loss: 0.0435 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 283/300\n",
      "1575/1575 [==============================] - 0s 118us/sample - loss: 0.2813 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0414 - q3_loss: 0.0527 - q4_loss: 0.0665 - q5_loss: 0.0536 - q6_loss: 0.0417 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2827 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0402 - val_q3_loss: 0.0512 - val_q4_loss: 0.0651 - val_q5_loss: 0.0547 - val_q6_loss: 0.0439 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 284/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2808 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0416 - q3_loss: 0.0533 - q4_loss: 0.0671 - q5_loss: 0.0534 - q6_loss: 0.0420 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2850 - val_q0_loss: 0.0022 - val_q1_loss: 0.0089 - val_q2_loss: 0.0401 - val_q3_loss: 0.0514 - val_q4_loss: 0.0667 - val_q5_loss: 0.0545 - val_q6_loss: 0.0446 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 285/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2794 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0409 - q3_loss: 0.0525 - q4_loss: 0.0662 - q5_loss: 0.0525 - q6_loss: 0.0415 - q7_loss: 0.0100 - q8_loss: 0.0024 - val_loss: 0.2888 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0416 - val_q3_loss: 0.0519 - val_q4_loss: 0.0654 - val_q5_loss: 0.0564 - val_q6_loss: 0.0449 - val_q7_loss: 0.0112 - val_q8_loss: 0.0026\n",
      "Epoch 286/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2802 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0410 - q3_loss: 0.0525 - q4_loss: 0.0665 - q5_loss: 0.0531 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2891 - val_q0_loss: 0.0023 - val_q1_loss: 0.0092 - val_q2_loss: 0.0418 - val_q3_loss: 0.0524 - val_q4_loss: 0.0663 - val_q5_loss: 0.0555 - val_q6_loss: 0.0439 - val_q7_loss: 0.0111 - val_q8_loss: 0.0029\n",
      "Epoch 287/300\n",
      "1575/1575 [==============================] - 0s 117us/sample - loss: 0.2802 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0414 - q3_loss: 0.0532 - q4_loss: 0.0672 - q5_loss: 0.0530 - q6_loss: 0.0415 - q7_loss: 0.0098 - q8_loss: 0.0025 - val_loss: 0.2900 - val_q0_loss: 0.0023 - val_q1_loss: 0.0090 - val_q2_loss: 0.0412 - val_q3_loss: 0.0520 - val_q4_loss: 0.0656 - val_q5_loss: 0.0560 - val_q6_loss: 0.0460 - val_q7_loss: 0.0115 - val_q8_loss: 0.0027\n",
      "Epoch 288/300\n",
      "1575/1575 [==============================] - 0s 114us/sample - loss: 0.2813 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0531 - q4_loss: 0.0670 - q5_loss: 0.0532 - q6_loss: 0.0418 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.3020 - val_q0_loss: 0.0023 - val_q1_loss: 0.0094 - val_q2_loss: 0.0430 - val_q3_loss: 0.0531 - val_q4_loss: 0.0669 - val_q5_loss: 0.0601 - val_q6_loss: 0.0473 - val_q7_loss: 0.0124 - val_q8_loss: 0.0034\n",
      "Epoch 289/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2843 - q0_loss: 0.0023 - q1_loss: 0.0095 - q2_loss: 0.0421 - q3_loss: 0.0537 - q4_loss: 0.0669 - q5_loss: 0.0531 - q6_loss: 0.0423 - q7_loss: 0.0101 - q8_loss: 0.0025 - val_loss: 0.2830 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0397 - val_q3_loss: 0.0513 - val_q4_loss: 0.0650 - val_q5_loss: 0.0548 - val_q6_loss: 0.0443 - val_q7_loss: 0.0107 - val_q8_loss: 0.0026\n",
      "Epoch 290/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0092 - q2_loss: 0.0413 - q3_loss: 0.0531 - q4_loss: 0.0670 - q5_loss: 0.0535 - q6_loss: 0.0417 - q7_loss: 0.0099 - q8_loss: 0.0026 - val_loss: 0.2838 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0405 - val_q3_loss: 0.0513 - val_q4_loss: 0.0655 - val_q5_loss: 0.0547 - val_q6_loss: 0.0444 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 291/300\n",
      "1575/1575 [==============================] - 0s 115us/sample - loss: 0.2803 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0417 - q3_loss: 0.0534 - q4_loss: 0.0673 - q5_loss: 0.0541 - q6_loss: 0.0425 - q7_loss: 0.0101 - q8_loss: 0.0024 - val_loss: 0.2836 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0398 - val_q3_loss: 0.0514 - val_q4_loss: 0.0652 - val_q5_loss: 0.0545 - val_q6_loss: 0.0441 - val_q7_loss: 0.0109 - val_q8_loss: 0.0027\n",
      "Epoch 292/300\n",
      "1575/1575 [==============================] - 0s 128us/sample - loss: 0.2803 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0414 - q3_loss: 0.0530 - q4_loss: 0.0666 - q5_loss: 0.0531 - q6_loss: 0.0418 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2831 - val_q0_loss: 0.0023 - val_q1_loss: 0.0088 - val_q2_loss: 0.0396 - val_q3_loss: 0.0514 - val_q4_loss: 0.0652 - val_q5_loss: 0.0549 - val_q6_loss: 0.0439 - val_q7_loss: 0.0108 - val_q8_loss: 0.0026\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2807 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0416 - q3_loss: 0.0532 - q4_loss: 0.0669 - q5_loss: 0.0536 - q6_loss: 0.0416 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2867 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0410 - val_q3_loss: 0.0517 - val_q4_loss: 0.0655 - val_q5_loss: 0.0559 - val_q6_loss: 0.0444 - val_q7_loss: 0.0109 - val_q8_loss: 0.0025\n",
      "Epoch 294/300\n",
      "1575/1575 [==============================] - 0s 120us/sample - loss: 0.2806 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0413 - q3_loss: 0.0527 - q4_loss: 0.0667 - q5_loss: 0.0537 - q6_loss: 0.0415 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2838 - val_q0_loss: 0.0022 - val_q1_loss: 0.0092 - val_q2_loss: 0.0406 - val_q3_loss: 0.0515 - val_q4_loss: 0.0651 - val_q5_loss: 0.0542 - val_q6_loss: 0.0440 - val_q7_loss: 0.0110 - val_q8_loss: 0.0027\n",
      "Epoch 295/300\n",
      "1575/1575 [==============================] - 0s 127us/sample - loss: 0.2795 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0531 - q4_loss: 0.0670 - q5_loss: 0.0533 - q6_loss: 0.0419 - q7_loss: 0.0099 - q8_loss: 0.0025 - val_loss: 0.2860 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0412 - val_q3_loss: 0.0516 - val_q4_loss: 0.0653 - val_q5_loss: 0.0551 - val_q6_loss: 0.0436 - val_q7_loss: 0.0113 - val_q8_loss: 0.0027\n",
      "Epoch 296/300\n",
      "1575/1575 [==============================] - 0s 122us/sample - loss: 0.2804 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0412 - q3_loss: 0.0534 - q4_loss: 0.0672 - q5_loss: 0.0525 - q6_loss: 0.0415 - q7_loss: 0.0100 - q8_loss: 0.0025 - val_loss: 0.2859 - val_q0_loss: 0.0023 - val_q1_loss: 0.0091 - val_q2_loss: 0.0398 - val_q3_loss: 0.0518 - val_q4_loss: 0.0666 - val_q5_loss: 0.0557 - val_q6_loss: 0.0431 - val_q7_loss: 0.0109 - val_q8_loss: 0.0027\n",
      "Epoch 297/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2836 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0418 - q3_loss: 0.0530 - q4_loss: 0.0668 - q5_loss: 0.0538 - q6_loss: 0.0419 - q7_loss: 0.0102 - q8_loss: 0.0025 - val_loss: 0.2826 - val_q0_loss: 0.0022 - val_q1_loss: 0.0088 - val_q2_loss: 0.0398 - val_q3_loss: 0.0514 - val_q4_loss: 0.0654 - val_q5_loss: 0.0545 - val_q6_loss: 0.0433 - val_q7_loss: 0.0108 - val_q8_loss: 0.0025\n",
      "Epoch 298/300\n",
      "1575/1575 [==============================] - 0s 138us/sample - loss: 0.2830 - q0_loss: 0.0023 - q1_loss: 0.0096 - q2_loss: 0.0414 - q3_loss: 0.0532 - q4_loss: 0.0672 - q5_loss: 0.0541 - q6_loss: 0.0421 - q7_loss: 0.0101 - q8_loss: 0.0026 - val_loss: 0.2823 - val_q0_loss: 0.0022 - val_q1_loss: 0.0090 - val_q2_loss: 0.0399 - val_q3_loss: 0.0512 - val_q4_loss: 0.0650 - val_q5_loss: 0.0544 - val_q6_loss: 0.0437 - val_q7_loss: 0.0109 - val_q8_loss: 0.0026\n",
      "Epoch 299/300\n",
      "1575/1575 [==============================] - 0s 119us/sample - loss: 0.2795 - q0_loss: 0.0023 - q1_loss: 0.0094 - q2_loss: 0.0413 - q3_loss: 0.0529 - q4_loss: 0.0667 - q5_loss: 0.0531 - q6_loss: 0.0423 - q7_loss: 0.0098 - q8_loss: 0.0024 - val_loss: 0.2840 - val_q0_loss: 0.0021 - val_q1_loss: 0.0090 - val_q2_loss: 0.0403 - val_q3_loss: 0.0511 - val_q4_loss: 0.0658 - val_q5_loss: 0.0544 - val_q6_loss: 0.0448 - val_q7_loss: 0.0107 - val_q8_loss: 0.0025\n",
      "Epoch 300/300\n",
      "1575/1575 [==============================] - 0s 132us/sample - loss: 0.2830 - q0_loss: 0.0023 - q1_loss: 0.0093 - q2_loss: 0.0418 - q3_loss: 0.0530 - q4_loss: 0.0668 - q5_loss: 0.0542 - q6_loss: 0.0422 - q7_loss: 0.0103 - q8_loss: 0.0027 - val_loss: 0.2847 - val_q0_loss: 0.0022 - val_q1_loss: 0.0091 - val_q2_loss: 0.0398 - val_q3_loss: 0.0519 - val_q4_loss: 0.0664 - val_q5_loss: 0.0542 - val_q6_loss: 0.0433 - val_q7_loss: 0.0109 - val_q8_loss: 0.0028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_mo, epochs=300,\n",
    "                    validation_data=(X_val, y_val_mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41041088, 0.49317554, 0.6114328 , 0.6527271 , 0.7440677 ,\n",
       "        0.8256191 , 0.85717916, 1.0110995 , 1.0857059 ],\n",
       "       [0.8364941 , 0.93872774, 1.1946579 , 1.2441773 , 1.4037459 ,\n",
       "        1.5955403 , 1.6302515 , 1.9330577 , 2.0788462 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation set\n",
    "y_pred = model.predict(X_val)\n",
    "# revert multi output format to (n_samples, quantiles)\n",
    "y_pred = np.array(list(zip(*y_pred))).squeeze()\n",
    "y_pred[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005    0.415018\n",
       "0.025    0.497439\n",
       "0.165    0.623131\n",
       "0.250    0.662261\n",
       "0.500    0.750136\n",
       "0.750    0.837875\n",
       "0.835    0.876631\n",
       "0.975    1.004837\n",
       "0.995    1.083839\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"true\" quantiles\n",
    "pd.Series(np.random.normal(0.75, 0.13, size=100000)).quantile(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005    0.855376\n",
       "0.025    1.009875\n",
       "0.165    1.257012\n",
       "0.250    1.330647\n",
       "0.500    1.500027\n",
       "0.750    1.669428\n",
       "0.835    1.742808\n",
       "0.975    1.988162\n",
       "0.995    2.141759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"true\" quantiles\n",
    "pd.Series(np.random.normal(1.5, 0.25, size=100000)).quantile(quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: The toy dataset contains two simple distributions, with either $\\mu=0.75, \\sigma=0.13$ or $\\mu=1.5, \\sigma=0.25$, depending on whether it is a weekday or weekend. The observed 'demand' are samples distributed as such. For these simple distributions, the Pinball Loss is able to (approximately) retrieve the correct quantiles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01324b84642f4e1fafc49cf89f9ff391": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2573316ddee1409d897edfcfbd87e8ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5712bde02e284e70bc5e9c1d7367502a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01324b84642f4e1fafc49cf89f9ff391",
       "placeholder": "",
       "style": "IPY_MODEL_860311c3b0564afa891a4c6e24da2d3a",
       "value": " 42840/42840 [00:49&lt;00:00, 860.84it/s]"
      }
     },
     "5f64a626e4d342ccaa955ea1c68afacd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6314c6fca7a845618625e72ac301f6a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2573316ddee1409d897edfcfbd87e8ba",
       "max": 42840,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7370a0011b714f6dbba43bf3f3725de8",
       "value": 42840
      }
     },
     "7370a0011b714f6dbba43bf3f3725de8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "860311c3b0564afa891a4c6e24da2d3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8c18e2818bf648e08be0bc8e855fcb3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6314c6fca7a845618625e72ac301f6a7",
        "IPY_MODEL_5712bde02e284e70bc5e9c1d7367502a"
       ],
       "layout": "IPY_MODEL_5f64a626e4d342ccaa955ea1c68afacd"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
