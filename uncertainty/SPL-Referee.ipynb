{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joeranbosma/stack/Projects/M5Forecast\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/.DS_Store\n",
      "data/empty_pred.csv\n",
      "data/pred_skeleton.csv\n",
      "data/calendar.csv\n",
      "data/sales_train_money.csv\n",
      "data/sell_prices.csv\n",
      "data/sales_train_validation.csv\n",
      "data/sample_submission.csv\n",
      "data/prep/converted_sales_level_12.csv\n",
      "data/prep/converted_sales_level_11.csv\n",
      "data/prep/converted_sales_level_10.csv\n",
      "data/prep/converted_sales_all.csv\n",
      "data/prep/norm_level_11.csv\n",
      "data/prep/.DS_Store\n",
      "data/prep/norm_level_10.csv\n",
      "data/prep/norm_level_12.csv\n",
      "data/prep/norm_level_1.csv\n",
      "data/prep/norm_level_2.csv\n",
      "data/prep/norm_level_3.csv\n",
      "data/prep/norm_level_7.csv\n",
      "data/prep/norm_level_6.csv\n",
      "data/prep/converted_sales_level_9.csv\n",
      "data/prep/norm_level_4.csv\n",
      "data/prep/norm_level_5.csv\n",
      "data/prep/converted_sales_level_8.csv\n",
      "data/prep/converted_sales_level_5.csv\n",
      "data/prep/norm_level_8.csv\n",
      "data/prep/norm_level_9.csv\n",
      "data/prep/converted_sales_level_4.csv\n",
      "data/prep/converted_sales_level_6.csv\n",
      "data/prep/converted_sales_level_7.csv\n",
      "data/prep/converted_sales_level_3.csv\n",
      "data/prep/norm_all.csv\n",
      "data/prep/converted_sales_level_2.csv\n",
      "data/prep/converted_sales_level_1.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Reshape, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from flow import load_data, select_dates, sales_to_money, select_final_day, select_day_nums\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "os.environ['DATA_DIR'] = 'data/'\n",
    "os.environ['SUB_DIR'] = 'submissions_uncertainty/'\n",
    "for dirname, _, filenames in os.walk(os.environ['DATA_DIR']):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data set\n",
    "calendar, sales_train_validation, sell_prices = load_data()\n",
    "\n",
    "sales_true = select_dates(sales_train_validation, day_end=1913, num_days=28, include_metadata=True)\n",
    "sales_train = select_dates(sales_train_validation, day_start=1, num_days=1913-28, include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prediction set and a true-sales set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_levels = {\n",
    "    1: lambda x: 1,  # global: 1\n",
    "    2: ['state_id'],  # per state: 3\n",
    "    3: ['store_id'],  # per store: 10\n",
    "    4: ['cat_id'],  # per category: 3\n",
    "    5: ['dept_id'],  # per department: 7\n",
    "    6: ['state_id', 'cat_id'],  # per state & cat: 9\n",
    "    7: ['state_id', 'dept_id'],  # per state & dep: 21\n",
    "    8: ['store_id', 'cat_id'],  # per store & cat: 30\n",
    "    9: ['store_id', 'dept_id'],  # per store & dep: 70\n",
    "    10: ['item_id'],  # per item, across stores/states: 3049\n",
    "    11: ['item_id', 'state_id'],  # per item, across stores: 9,225\n",
    "    12: ['store_id','item_id']  # lowest level, per product, per store\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>quantile</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.251950</td>\n",
       "      <td>206.582632</td>\n",
       "      <td>80.916005</td>\n",
       "      <td>139.128480</td>\n",
       "      <td>147.253381</td>\n",
       "      <td>155.998292</td>\n",
       "      <td>193.611162</td>\n",
       "      <td>170.879367</td>\n",
       "      <td>177.932118</td>\n",
       "      <td>203.265270</td>\n",
       "      <td>...</td>\n",
       "      <td>279.402837</td>\n",
       "      <td>152.801732</td>\n",
       "      <td>210.701291</td>\n",
       "      <td>241.095206</td>\n",
       "      <td>282.526391</td>\n",
       "      <td>143.224673</td>\n",
       "      <td>134.211165</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.005_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603.533954</td>\n",
       "      <td>1166.494268</td>\n",
       "      <td>484.047630</td>\n",
       "      <td>798.623339</td>\n",
       "      <td>1659.661441</td>\n",
       "      <td>1360.472047</td>\n",
       "      <td>1681.291654</td>\n",
       "      <td>824.037769</td>\n",
       "      <td>1177.097908</td>\n",
       "      <td>1305.731026</td>\n",
       "      <td>...</td>\n",
       "      <td>599.456436</td>\n",
       "      <td>487.815415</td>\n",
       "      <td>1041.589606</td>\n",
       "      <td>623.261695</td>\n",
       "      <td>775.441350</td>\n",
       "      <td>1213.735126</td>\n",
       "      <td>688.867198</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.025_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6387.524982</td>\n",
       "      <td>3612.887744</td>\n",
       "      <td>5816.058248</td>\n",
       "      <td>6865.455248</td>\n",
       "      <td>4525.603591</td>\n",
       "      <td>7943.950903</td>\n",
       "      <td>11120.014768</td>\n",
       "      <td>6096.634123</td>\n",
       "      <td>3600.927513</td>\n",
       "      <td>6688.897042</td>\n",
       "      <td>...</td>\n",
       "      <td>5323.744941</td>\n",
       "      <td>7753.846768</td>\n",
       "      <td>7149.523721</td>\n",
       "      <td>7996.124778</td>\n",
       "      <td>7512.091424</td>\n",
       "      <td>10106.026170</td>\n",
       "      <td>6974.697335</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.165_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6937.242787</td>\n",
       "      <td>11815.129922</td>\n",
       "      <td>7508.025703</td>\n",
       "      <td>12700.529419</td>\n",
       "      <td>13244.618011</td>\n",
       "      <td>14770.489244</td>\n",
       "      <td>8671.760381</td>\n",
       "      <td>14646.364215</td>\n",
       "      <td>9423.840798</td>\n",
       "      <td>10550.424792</td>\n",
       "      <td>...</td>\n",
       "      <td>10688.490662</td>\n",
       "      <td>4844.851023</td>\n",
       "      <td>12630.150038</td>\n",
       "      <td>10430.172928</td>\n",
       "      <td>15166.757483</td>\n",
       "      <td>8229.783992</td>\n",
       "      <td>7931.543663</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.25_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25816.086542</td>\n",
       "      <td>20260.336247</td>\n",
       "      <td>9157.599795</td>\n",
       "      <td>21770.357064</td>\n",
       "      <td>28548.253059</td>\n",
       "      <td>37476.774168</td>\n",
       "      <td>34180.142253</td>\n",
       "      <td>12615.891870</td>\n",
       "      <td>10315.201676</td>\n",
       "      <td>10296.370380</td>\n",
       "      <td>...</td>\n",
       "      <td>9869.598593</td>\n",
       "      <td>24432.384756</td>\n",
       "      <td>12952.754880</td>\n",
       "      <td>22895.908159</td>\n",
       "      <td>17986.724858</td>\n",
       "      <td>33380.868141</td>\n",
       "      <td>31050.211100</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.5_validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1            F2           F3            F4            F5  \\\n",
       "1    165.251950    206.582632    80.916005    139.128480    147.253381   \n",
       "1    603.533954   1166.494268   484.047630    798.623339   1659.661441   \n",
       "1   6387.524982   3612.887744  5816.058248   6865.455248   4525.603591   \n",
       "1   6937.242787  11815.129922  7508.025703  12700.529419  13244.618011   \n",
       "1  25816.086542  20260.336247  9157.599795  21770.357064  28548.253059   \n",
       "\n",
       "             F6            F7            F8            F9           F10  ...  \\\n",
       "1    155.998292    193.611162    170.879367    177.932118    203.265270  ...   \n",
       "1   1360.472047   1681.291654    824.037769   1177.097908   1305.731026  ...   \n",
       "1   7943.950903  11120.014768   6096.634123   3600.927513   6688.897042  ...   \n",
       "1  14770.489244   8671.760381  14646.364215   9423.840798  10550.424792  ...   \n",
       "1  37476.774168  34180.142253  12615.891870  10315.201676  10296.370380  ...   \n",
       "\n",
       "            F22           F23           F24           F25           F26  \\\n",
       "1    279.402837    152.801732    210.701291    241.095206    282.526391   \n",
       "1    599.456436    487.815415   1041.589606    623.261695    775.441350   \n",
       "1   5323.744941   7753.846768   7149.523721   7996.124778   7512.091424   \n",
       "1  10688.490662   4844.851023  12630.150038  10430.172928  15166.757483   \n",
       "1   9869.598593  24432.384756  12952.754880  22895.908159  17986.724858   \n",
       "\n",
       "            F27           F28  quantile  level                        id  \n",
       "1    143.224673    134.211165     0.005      1  Total_X_0.005_validation  \n",
       "1   1213.735126    688.867198     0.025      1  Total_X_0.025_validation  \n",
       "1  10106.026170   6974.697335     0.165      1  Total_X_0.165_validation  \n",
       "1   8229.783992   7931.543663     0.250      1   Total_X_0.25_validation  \n",
       "1  33380.868141  31050.211100     0.500      1    Total_X_0.5_validation  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select true sales period\n",
    "sales_true = select_dates(sales_train_validation, day_end=1913, num_days=28, include_metadata=True)\n",
    "# Quantiles\n",
    "quantiles = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750,0.835, 0.975, 0.995]\n",
    "columns = ['d_%d' % d for d in range(1886, 1913 + 1)]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "np.random.seed(1)\n",
    "for level, groupby in tqdm(aggregation_levels.items()):\n",
    "    group = sales_true.groupby(groupby).sum()\n",
    "            \n",
    "    group_ = pd.DataFrame()\n",
    "    for quantile in quantiles:\n",
    "        g_ = group.copy()\n",
    "        vals = g_.index.values   \n",
    "        if level == 1:\n",
    "            ids = ['Total_X_' + str(quantile)  + '_validation' for val in vals]\n",
    "        if level in [2,3,4,5,10]:\n",
    "            ids = [val + '_X_' + str(quantile) + '_validation' for val in vals]\n",
    "        if level in[6,7,8,9]:\n",
    "            ids = [val[0] + '_' + val[1] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "        if level in [11,12]:\n",
    "            ids = [val[1] + '_' + val[0] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "            \n",
    "        for column in g_.columns: \n",
    "            if column[:2] == 'd_':\n",
    "                g_[column] = g_[column]*quantile*np.random.uniform(0.5,1.5)\n",
    "        \n",
    "        g_['quantile'] = quantile\n",
    "        g_['level'] = level\n",
    "        g_['id'] = ids\n",
    "        \n",
    "        group_ = group_.append(g_)\n",
    "        \n",
    "    data = data.append(group_)\n",
    "\n",
    "conv_dict = {'d_1886':'float64','d_1887':'float64','d_1888':'float64','d_1889':'float64','d_1890':'float64','d_1891':'float64',\n",
    "             'd_1892':'float64','d_1893':'float64','d_1894':'float64','d_1895':'float64','d_1896':'float64','d_1897':'float64',\n",
    "             'd_1898':'float64','d_1899':'float64','d_1900':'float64','d_1901':'float64','d_1902':'float64','d_1903':'float64',\n",
    "             'd_1904':'float64','d_1905':'float64','d_1906':'float64','d_1907':'float64','d_1908':'float64','d_1909':'float64',\n",
    "             'd_1910':'float64','d_1911':'float64','d_1912':'float64','d_1913':'float64'}\n",
    "\n",
    "data = data.astype(conv_dict)\n",
    "data.columns = ['F%d' % int(i+1) if x =='d_1' + str(i+886) else x for i, x in enumerate(data.columns)]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  6.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>quantile</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36041.0</td>\n",
       "      <td>33857.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34681.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>52672.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>40418.0</td>\n",
       "      <td>39683.0</td>\n",
       "      <td>39134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38059.0</td>\n",
       "      <td>37570.0</td>\n",
       "      <td>35343.0</td>\n",
       "      <td>35033.0</td>\n",
       "      <td>40517.0</td>\n",
       "      <td>48962.0</td>\n",
       "      <td>49795.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.005_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36041.0</td>\n",
       "      <td>33857.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34681.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>52672.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>40418.0</td>\n",
       "      <td>39683.0</td>\n",
       "      <td>39134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38059.0</td>\n",
       "      <td>37570.0</td>\n",
       "      <td>35343.0</td>\n",
       "      <td>35033.0</td>\n",
       "      <td>40517.0</td>\n",
       "      <td>48962.0</td>\n",
       "      <td>49795.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.025_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36041.0</td>\n",
       "      <td>33857.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34681.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>52672.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>40418.0</td>\n",
       "      <td>39683.0</td>\n",
       "      <td>39134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38059.0</td>\n",
       "      <td>37570.0</td>\n",
       "      <td>35343.0</td>\n",
       "      <td>35033.0</td>\n",
       "      <td>40517.0</td>\n",
       "      <td>48962.0</td>\n",
       "      <td>49795.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.165_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36041.0</td>\n",
       "      <td>33857.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34681.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>52672.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>40418.0</td>\n",
       "      <td>39683.0</td>\n",
       "      <td>39134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38059.0</td>\n",
       "      <td>37570.0</td>\n",
       "      <td>35343.0</td>\n",
       "      <td>35033.0</td>\n",
       "      <td>40517.0</td>\n",
       "      <td>48962.0</td>\n",
       "      <td>49795.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.25_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36041.0</td>\n",
       "      <td>33857.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34681.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>52672.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>40418.0</td>\n",
       "      <td>39683.0</td>\n",
       "      <td>39134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38059.0</td>\n",
       "      <td>37570.0</td>\n",
       "      <td>35343.0</td>\n",
       "      <td>35033.0</td>\n",
       "      <td>40517.0</td>\n",
       "      <td>48962.0</td>\n",
       "      <td>49795.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_X_0.5_validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        F1       F2       F3       F4       F5       F6       F7       F8  \\\n",
       "1  36041.0  33857.0  32359.0  34681.0  45536.0  52672.0  56425.0  40418.0   \n",
       "1  36041.0  33857.0  32359.0  34681.0  45536.0  52672.0  56425.0  40418.0   \n",
       "1  36041.0  33857.0  32359.0  34681.0  45536.0  52672.0  56425.0  40418.0   \n",
       "1  36041.0  33857.0  32359.0  34681.0  45536.0  52672.0  56425.0  40418.0   \n",
       "1  36041.0  33857.0  32359.0  34681.0  45536.0  52672.0  56425.0  40418.0   \n",
       "\n",
       "        F9      F10  ...      F22      F23      F24      F25      F26  \\\n",
       "1  39683.0  39134.0  ...  38059.0  37570.0  35343.0  35033.0  40517.0   \n",
       "1  39683.0  39134.0  ...  38059.0  37570.0  35343.0  35033.0  40517.0   \n",
       "1  39683.0  39134.0  ...  38059.0  37570.0  35343.0  35033.0  40517.0   \n",
       "1  39683.0  39134.0  ...  38059.0  37570.0  35343.0  35033.0  40517.0   \n",
       "1  39683.0  39134.0  ...  38059.0  37570.0  35343.0  35033.0  40517.0   \n",
       "\n",
       "       F27      F28  quantile  level                        id  \n",
       "1  48962.0  49795.0     0.005      1  Total_X_0.005_validation  \n",
       "1  48962.0  49795.0     0.025      1  Total_X_0.025_validation  \n",
       "1  48962.0  49795.0     0.165      1  Total_X_0.165_validation  \n",
       "1  48962.0  49795.0     0.250      1   Total_X_0.25_validation  \n",
       "1  48962.0  49795.0     0.500      1    Total_X_0.5_validation  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select true sales period\n",
    "sales_true = select_dates(sales_train_validation, day_end=1913, num_days=28, include_metadata=True)\n",
    "# Quantiles\n",
    "quantiles = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750,0.835, 0.975, 0.995]\n",
    "columns = ['d_%d' % d for d in range(1886, 1913 + 1)]\n",
    "\n",
    "true_sales = pd.DataFrame()\n",
    "for level, groupby in tqdm(aggregation_levels.items()):\n",
    "    group = sales_true.groupby(groupby).sum()\n",
    "            \n",
    "    group_ = pd.DataFrame()\n",
    "    for quantile in quantiles:\n",
    "        g_ = group.copy()\n",
    "        vals = g_.index.values   \n",
    "        if level == 1:\n",
    "            ids = ['Total_X_' + str(quantile)  + '_validation' for val in vals]\n",
    "        if level in [2,3,4,5,10]:\n",
    "            ids = [val + '_X_' + str(quantile) + '_validation' for val in vals]\n",
    "        if level in[6,7,8,9]:\n",
    "            ids = [val[0] + '_' + val[1] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "        if level in [11,12]:\n",
    "            ids = [val[1] + '_' + val[0] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "        \n",
    "        g_['quantile'] = quantile\n",
    "        g_['level'] = str(level)\n",
    "        g_['id'] = ids\n",
    "        \n",
    "        group_ = group_.append(g_)\n",
    "        \n",
    "    true_sales = true_sales.append(group_)\n",
    "\n",
    "conv_dict = {'d_1886':'float64','d_1887':'float64','d_1888':'float64','d_1889':'float64','d_1890':'float64','d_1891':'float64',\n",
    "             'd_1892':'float64','d_1893':'float64','d_1894':'float64','d_1895':'float64','d_1896':'float64','d_1897':'float64',\n",
    "             'd_1898':'float64','d_1899':'float64','d_1900':'float64','d_1901':'float64','d_1902':'float64','d_1903':'float64',\n",
    "             'd_1904':'float64','d_1905':'float64','d_1906':'float64','d_1907':'float64','d_1908':'float64','d_1909':'float64',\n",
    "             'd_1910':'float64','d_1911':'float64','d_1912':'float64','d_1913':'float64'}\n",
    "\n",
    "true_sales = true_sales.astype(conv_dict)\n",
    "true_sales.columns = ['F%d' % int(i+1) if x =='d_1' + str(i+886) else x for i, x in enumerate(true_sales.columns)]\n",
    "\n",
    "true_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_true_sales_to_quantiles(sales_true, aggregation_levels):\n",
    "    # Quantiles\n",
    "    quantiles = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750,0.835, 0.975, 0.995]\n",
    "    d_cols = select_day_nums(sales_true, as_int=False)\n",
    "\n",
    "    sales_true_quantiles = pd.DataFrame()\n",
    "    for level, groupby in tqdm(aggregation_levels.items()):\n",
    "        if level == 12:\n",
    "            groupby = ['store_id', 'item_id']\n",
    "        group = sales_true.groupby(groupby).sum()\n",
    "\n",
    "        group_ = pd.DataFrame()\n",
    "        for quantile in quantiles:\n",
    "            g_ = group.copy()\n",
    "            vals = g_.index.values\n",
    "            if level == 1:\n",
    "                ids = ['Total_X_' + str(quantile)  + '_validation' for val in vals]\n",
    "            if level in [2, 3, 4, 5, 10]:\n",
    "                ids = [val + '_X_' + str(quantile) + '_validation' for val in vals]\n",
    "            if level in[6, 7, 8, 9]:\n",
    "                ids = [val[0] + '_' + val[1] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "            if level in [11, 12]:\n",
    "                ids = [val[1] + '_' + val[0] + '_' + str(quantile) + '_validation' for val in vals]\n",
    "\n",
    "            g_['quantile'] = quantile\n",
    "            g_['level'] = level\n",
    "            g_['id'] = ids\n",
    "\n",
    "            group_ = group_.append(g_)\n",
    "\n",
    "        sales_true_quantiles = sales_true_quantiles.append(group_)\n",
    "\n",
    "    # convert quantiles to float\n",
    "    conv_dict = {d_col: 'float64' for d_col in d_cols}\n",
    "    sales_true_quantiles = sales_true_quantiles.astype(conv_dict)\n",
    "    sales_true_quantiles.columns = ['F%d' % int(i+1) if x =='d_1' + str(i+886) else x\n",
    "                                    for i, x in enumerate(sales_true_quantiles.columns)]\n",
    "\n",
    "    return sales_true_quantiles\n",
    "\n",
    "sales_true_quantiles = convert_true_sales_to_quantiles(sales_true, aggregation_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sales.iloc[:, 0:28].equals( sales_true_quantiles.iloc[:, 0:28] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New referee for SPL given predictions and true quantile sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_to_int(day, default=None):\n",
    "    try:\n",
    "        return int(day[2:])\n",
    "    except (ValueError, TypeError) as e:\n",
    "        return default\n",
    "\n",
    "class RefereeTest(object):\n",
    "    def __init__(self, sales_true, sales_train, prices, calendar, verbose=True):\n",
    "        if verbose: print(\"Initializing Referee\")\n",
    "        self.sales_true = sales_true\n",
    "        self.sales_train = sales_train\n",
    "        self.h = sales_true.shape[1]\n",
    "        self.n = sales_train.shape[1]\n",
    "        \n",
    "        self.quantiles = np.array([0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995])\n",
    "\n",
    "        # Define aggregation levels as their Pandas groupby\n",
    "        # Follow same order as https://github.com/Mcompetitions/M5-methods/blob/master/validation/Point%20Forecasts%20-%20Benchmarks.R\n",
    "        self.aggregation_levels = {\n",
    "            1: lambda x: 1,  # global: 1\n",
    "            2: ['state_id'],  # per state: 3\n",
    "            3: ['store_id'],  # per store: 10\n",
    "            4: ['cat_id'],  # per category: 3\n",
    "            5: ['dept_id'],  # per department: 7\n",
    "            6: ['state_id', 'cat_id'],  # per state & cat: 9\n",
    "            7: ['state_id', 'dept_id'],  # per state & dep: 21\n",
    "            8: ['store_id', 'cat_id'],  # per store & cat: 30\n",
    "            9: ['store_id', 'dept_id'],  # per store & dep: 70\n",
    "            10: ['item_id'],  # per item, across stores/states: 3049\n",
    "            11: ['item_id', 'state_id'],  # per item, across stores: 9,225\n",
    "            12: ['store_id', 'item_id']  # lowest level, per product, per store\n",
    "        }\n",
    "        \n",
    "        self.sales_true_quantiles = convert_true_sales_to_quantiles(sales_true, self.aggregation_levels)\n",
    "\n",
    "        # Set number of aggregation levels\n",
    "        self.K = len(self.aggregation_levels)  # 12 for full evaluation\n",
    "\n",
    "        # Calculate weights (based on cumulative dollars per product, in last 28 days of train data)\n",
    "        # Select final 28 days of training data\n",
    "        last_train_day = select_final_day(sales_train)\n",
    "        sales_train_final = select_dates(sales_train, day_end=last_train_day, num_days=28, include_metadata=True)\n",
    "\n",
    "        # Try to find money spent pre-converted\n",
    "        fn = os.environ['DATA_DIR'] + \"/sales_train_money.csv\"\n",
    "        if os.path.exists(fn):\n",
    "            sales_train_money = pd.read_csv(fn, index_col='id')\n",
    "            sales_train_final = select_dates(sales_train_money, day_end=last_train_day, num_days=28, include_metadata=True)\n",
    "        else:\n",
    "            # Convert quantities sold to money spent\n",
    "            sales_train_final = sales_to_money(sales_train_final, prices, calendar, verbose=verbose)\n",
    "\n",
    "        # Calculate weights of each level\n",
    "        if verbose: print(\"Calculating weights for each level...\")\n",
    "        self.weights = {}\n",
    "        for level, groupby in self.aggregation_levels.items():\n",
    "            self.weights[level] = self.calc_weights(sales_train_final, groupby=groupby)\n",
    "\n",
    "        # Calculate scale of each level\n",
    "        if verbose: print(\"Calculating scale for each level...\")\n",
    "        self.scales = {}\n",
    "        for level, groupby in self.aggregation_levels.items():\n",
    "            self.scales[level] = self.calc_scale(groupby=groupby)\n",
    "\n",
    "        if verbose: print(\"Finished setup.\")\n",
    "            \n",
    "    def get_scales(self):\n",
    "        return self.scales\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def calc_weights(self, sales, groupby=None):\n",
    "        \"\"\"From the docs: Since the M5 competition involves twelve aggregation levels, K is set equal to 12,\n",
    "        with the weights of the series being computed so that they sum to one at each aggregation level.\"\"\"\n",
    "        # Calculate aggregate dollars spent\n",
    "        if groupby:\n",
    "            sales = sales.groupby(groupby).sum()\n",
    "\n",
    "        weights = sales.sum(axis=1)\n",
    "\n",
    "        # Normalize weights to sum to one\n",
    "        weights /= weights.sum()\n",
    "        return weights\n",
    "\n",
    "    def calc_scale(self, groupby=None):\n",
    "        # Calculate scale: 1/(n-1) * sum |Yt - Y_t-1|\n",
    "        \"\"\"As done with RMSSE, the denominator of SPL is computed only for the time-periods for which the examined\n",
    "        items/products are actively sold, i.e., the periods following the first non-zero demand observed for the\n",
    "        series under evaluation. \n",
    "        \"\"\"\n",
    "        if groupby:\n",
    "            Yt = self.sales_train.groupby(groupby).sum()\n",
    "            Yt1 =Yt.shift(1, axis=1)\n",
    "        else:\n",
    "            day_cols = self.sales_train.filter(regex='d_').columns\n",
    "            Yt = self.sales_train[day_cols]\n",
    "            Yt1 = Yt.shift(1, axis=1)\n",
    "        \n",
    "        # Calculate number of sales since fist sale for each product (default is required when unit is not sold in\n",
    "        # training period, which also makes its weight zero.)\n",
    "        first_sold_day = Yt.replace(0, np.nan).apply(lambda x: day_to_int(x.first_valid_index(), default=-1), axis=1)\n",
    "        n = select_final_day(Yt) - first_sold_day  # list of numbers since first sale\n",
    "\n",
    "        scale = (np.abs(Yt - Yt1).sum(axis=1) / (n - 1))\n",
    "        return scale\n",
    "    \n",
    " \n",
    "    def evaluate_SPL(self, quantiles_pred):\n",
    "        \"\"\"Evaluate the Scaled Pinball Loss for a given set of predictions\"\"\"\n",
    "        metrics = {}\n",
    "\n",
    "        # Determine predicted levels\n",
    "        predicted_levels = quantiles_pred.level.unique()\n",
    "\n",
    "        # Calculate SPL for each level\n",
    "        for level, groupby in self.aggregation_levels.items():\n",
    "            if level in predicted_levels:\n",
    "                # The groupby, weights and scale will be selected using the level\n",
    "                metrics[level] = self.calc_SPL(quantiles_pred, level=level, groupby=groupby)\n",
    "\n",
    "        SPL = np.mean(list(metrics.values()))  # or sum and divide by self.K, take average over all aggregation levels\n",
    "        metrics['WSPL'] = SPL\n",
    "        return metrics\n",
    "\n",
    "    def calc_SPL(self, quantiles_pred, level=None, groupby=None, weights=None, scale=None):\n",
    "        \"\"\"Calculate the Scaled Pinball Loss for a given aggregation level\"\"\"\n",
    "        if level:\n",
    "            if groupby is None: groupby = self.aggregation_levels[level]\n",
    "            if weights is None: weights = self.weights[level]\n",
    "            if scale is None: scale = self.scales[level]\n",
    "        assert weights is not None, \"Provide level or weights\"\n",
    "        assert scale is not None, \"Provide level or scale\"\n",
    "\n",
    "        # Select the correct predictions and true sales based on the input level\n",
    "        predictions = quantiles_pred[quantiles_pred['level'] == level]\n",
    "        true_sales = self.sales_true_quantiles[self.sales_true_quantiles['level'] == level]\n",
    "\n",
    "        # Make sure that both the predictions and the true sales have the same\n",
    "        # id list, otherwise our calculation will go wrong\n",
    "        predictions = predictions.sort_values('id')\n",
    "        true_sales = true_sales.sort_values('id')\n",
    "\n",
    "        # Convert to numpy array\n",
    "        predictions = predictions.to_numpy()[:,1:29]\n",
    "        true_sales = true_sales.to_numpy()[:,1:29]\n",
    "\n",
    "        # Error\n",
    "        err = true_sales - predictions\n",
    "\n",
    "        # Number of rows\n",
    "        Nlevel = predictions.shape[0]\n",
    "\n",
    "        # Dummy array to save losses in\n",
    "        losses = np.zeros(Nlevel // 9)\n",
    "        for i in range(Nlevel // 9):\n",
    "            indices = np.arange(i*9,(i+1)*9) # per set of 9, take indices\n",
    "            subset = err[indices] # Take subset out of real set\n",
    "            res = np.mean(np.sum(np.amax(np.array([self.quantiles * subset.T, (self.quantiles - 1) * subset.T]),axis=0),axis=0)) #compute PL of set\n",
    "            losses[i] = res # Save resulting PL\n",
    "\n",
    "        loss = np.sum(np.array(losses * weights)/np.array(self.h*scale)) # Calculate SPL of aggregate level\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our created (random) prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:00<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Referee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weights for each level...\n",
      "Calculating scale for each level...\n",
      "Finished setup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 1.1210214349050245,\n",
       " 2: 1.0153875855884373,\n",
       " 3: 0.9212650321985366,\n",
       " 4: 1.1225041859572058,\n",
       " 5: 0.9974407717372311,\n",
       " 6: 0.9666953992823991,\n",
       " 7: 0.8645371305215135,\n",
       " 8: 0.8413401753512274,\n",
       " 9: 0.822862237419191,\n",
       " 10: 0.4316011238689629,\n",
       " 11: 0.23945040291756978,\n",
       " 12: 0.1481145269528085,\n",
       " 'WSPL': 0.7910183338916755}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_test = RefereeTest(sales_true, sales_train, sell_prices, calendar, verbose=True)\n",
    "\n",
    "ref_test.evaluate_SPL(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.9212650321985366, 12: 0.1481145269528085, 'WSPL': 0.5346897795756725}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only evaluate certain levels\n",
    "ref_test.evaluate_SPL(data[(data.level == 12) | (data.level == 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move to evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import Referee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Referee\n",
      "Converting true sales to quantile form\n",
      "Calculating weights for each level...\n",
      "Calculating scale for each level...\n",
      "Finished setup.\n"
     ]
    }
   ],
   "source": [
    "ref = Referee(sales_true, sales_train, sell_prices, calendar, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.1210214349050245,\n",
       " 2: 1.0153875855884373,\n",
       " 3: 0.9212650321985366,\n",
       " 4: 1.1225041859572058,\n",
       " 5: 0.9974407717372311,\n",
       " 6: 0.9666953992823991,\n",
       " 7: 0.8645371305215135,\n",
       " 8: 0.8413401753512274,\n",
       " 9: 0.822862237419191,\n",
       " 10: 0.4316011238689629,\n",
       " 11: 0.23945040291756978,\n",
       " 12: 0.1481145269528085,\n",
       " 'WSPL': 0.7910183338916755}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.evaluate_SPL(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.9212650321985366, 12: 0.1481145269528085, 'WSPL': 0.5346897795756725}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only evaluate certain levels\n",
    "ref.evaluate_SPL(data[(data.level == 12) | (data.level == 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
